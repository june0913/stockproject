{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "0e54188c",
   "metadata": {},
   "source": [
    "# 데이터 종류 및 개수 확인"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6ae05dd8",
   "metadata": {},
   "source": [
    "## 1. 기존 데이터셋 확인"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "8423776b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from PIL import Image\n",
    "import matplotlib.pylab as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "03a8ad63",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "i = Image.open('C:/Users/mit017/Desktop/myproject/XRAY_PROJECT/XrayInspection/dataset/test1/yolov3/X선이물검출기(06.23_09.22)/1호기(2020.09.22)/SN77128_20200622_NgImage/002_20200622_203053(2).bmp')\n",
    "\n",
    "plt.imshow(i)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8ff9cc8a",
   "metadata": {},
   "source": [
    "## 2. 데이터셋 재정리"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "9f88830f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "파일 복사 완료.\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import shutil\n",
    "\n",
    "# 원본 이미지가 저장된 디렉토리의 경로\n",
    "source_dir = 'C:/Users/mit017/Desktop/myproject/XRAY_PROJECT/XrayInspection/dataset/test1/yolov3/X선이물검출기(06.23_09.22)'\n",
    "\n",
    "# 새로운 디렉토리 경로\n",
    "target_dir_base = 'C:/Users/mit017/Desktop/myproject/XRAY_PROJECT/XrayInspection/dataset/test1/yolov3/X선이물검출기'\n",
    "\n",
    "# 원본 디렉토리에서 각 '호기(2020.09.22)' 폴더를 순회\n",
    "for i, ho_folder in enumerate(sorted(os.listdir(source_dir))):\n",
    "    ho_folder_path = os.path.join(source_dir, ho_folder)\n",
    "    \n",
    "    # '호기' 폴더 내부를 확인하여 'NgImage' 폴더가 있는지 검사\n",
    "    if os.path.isdir(ho_folder_path):\n",
    "        for ng_folder in os.listdir(ho_folder_path):\n",
    "            if 'NgImage' in ng_folder:\n",
    "                ng_folder_path = os.path.join(ho_folder_path, ng_folder)\n",
    "                \n",
    "                # 해당 'NgImage' 폴더 내의 파일들을 복사할 새로운 '호기' 폴더 생성\n",
    "                target_ho_folder = os.path.join(target_dir_base, f\"{i+1}호기\")\n",
    "                os.makedirs(target_ho_folder, exist_ok=True)\n",
    "                \n",
    "                # 'NgImage' 폴더 내의 파일들을 새로운 위치로 복사\n",
    "                for file in os.listdir(ng_folder_path):\n",
    "                    source_file_path = os.path.join(ng_folder_path, file)\n",
    "                    target_file_path = os.path.join(target_ho_folder, file)\n",
    "                    shutil.copy(source_file_path, target_file_path)\n",
    "\n",
    "print(\"파일 복사 완료.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "ef9d952e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "im = Image.open('C:/Users/mit017/Desktop/myproject/XRAY_PROJECT/XrayInspection/dataset/test1/yolov3/X선이물검출기/1호기/002_20200706_123038(9).bmp')\n",
    "\n",
    "plt.imshow(im)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "29630fbb",
   "metadata": {},
   "source": [
    "## 3.데이터 정제(전처리)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8f18b85a",
   "metadata": {},
   "source": [
    "### 1. 결함데이터 좌표 입력을 위한 Labeling 실행"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e4d49367",
   "metadata": {},
   "source": [
    "Labeling tools를 이용해 라벨링 작업후 폴더에 이동시킴"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "56b1fabb",
   "metadata": {},
   "source": [
    "bmp 파일을 jpg 파일로 바꿔줌"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "950515c0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "C:\\Users\\mit017\\Desktop\\myproject\\XRAY_PROJECT\\XrayInspection\\dataset\\test1\\yolov3\\images\n"
     ]
    }
   ],
   "source": [
    "%cd C:/Users/mit017/Desktop/myproject/XRAY_PROJECT/XrayInspection/dataset/test1/yolov3/images\n",
    "!ren *.* *.jpg*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "3c0a775a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "import os\n",
    "import subprocess\n",
    "import sys"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "9159335f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import random\n",
    "\n",
    "def split_data_set(image_dir):\n",
    "    # 테스트 세트와 훈련 세트 파일을 열기\n",
    "    f_val = open('test.txt', 'w')\n",
    "    f_train = open('train.txt', 'w')\n",
    "    \n",
    "    # 주어진 디렉토리에서 파일 목록을 얻기\n",
    "    path, dirs, files = next(os.walk(image_dir))\n",
    "    data_size = len(files)\n",
    "    \n",
    "    # 데이터 세트의 크기를 기반으로 테스트 세트의 크기를 결정\n",
    "    ind = 0\n",
    "    data_test_size = int(0.2 * data_size)\n",
    "    test_array = random.sample(range(data_size), k=data_test_size)\n",
    "    \n",
    "    for f in os.listdir(image_dir):\n",
    "        # 파일이 JPEG 이미지인지 확인\n",
    "        if f.endswith(\".jpg\"):\n",
    "            ind += 1\n",
    "            \n",
    "            # 파일 인덱스가 테스트 배열에 있는 경우, 테스트 세트에 추가\n",
    "            if ind in test_array:\n",
    "                f_val.write(image_dir + \"/\" + f + '\\n')\n",
    "            else:\n",
    "                # 그렇지 않으면 훈련 세트에 추가\n",
    "                f_train.write(image_dir + '/' + f + '\\n')\n",
    "\n",
    "    # 파일 닫기\n",
    "    f_val.close()\n",
    "    f_train.close()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "a828f92b",
   "metadata": {},
   "outputs": [],
   "source": [
    "image_dir='C:/Users/mit017/Desktop/myproject/XRAY_PROJECT/XrayInspection/dataset/test1/yolov3/images'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "830d42f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "split_data_set(image_dir)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "914e6b7a",
   "metadata": {},
   "source": [
    "## 15개"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "c53c6131",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Apex recommended for faster mixed precision training: https://github.com/NVIDIA/apex\n",
      "Namespace(epochs=15, batch_size=3, cfg='yolov3-spp.cfg', data='custom.data', multi_scale=False, img_size=[320, 640], rect=False, resume=False, nosave=True, notest=False, evolve=False, bucket='', cache_images=False, weights='weights/last.pt', name='', device='cpu', adam=False, single_cls=False, freeze_layers=False)\n",
      "Using CPU\n",
      "\n",
      "Start Tensorboard with \"tensorboard --logdir=runs\", view at http://localhost:6006/\n",
      "WARNING: smart bias initialization failure.\n",
      "WARNING: smart bias initialization failure.\n",
      "WARNING: smart bias initialization failure.\n",
      "Model Summary: 225 layers, 6.25733e+07 parameters, 6.25733e+07 gradients\n",
      "Optimizer groups: 76 .bias, 76 Conv2d.weight, 73 other\n",
      "weights/last.pt has been trained for 806 epochs. Fine-tuning for 15 additional epochs.\n",
      "Image sizes 320 - 640 train, 640 test\n",
      "Using 3 dataloader workers\n",
      "Starting training for 821 epochs...\n",
      "\n",
      "     Epoch   gpu_mem      GIoU       obj       cls     total   targets  img_size\n",
      "Apex recommended for faster mixed precision training: https://github.com/NVIDIA/apex\n",
      "Apex recommended for faster mixed precision training: https://github.com/NVIDIA/apex\n",
      "Apex recommended for faster mixed precision training: https://github.com/NVIDIA/apex\n",
      "Apex recommended for faster mixed precision training: https://github.com/NVIDIA/apex\n",
      "Apex recommended for faster mixed precision training: https://github.com/NVIDIA/apex\n",
      "Apex recommended for faster mixed precision training: https://github.com/NVIDIA/apex\n",
      "                 all         3         7     0.534     0.571     0.478     0.552\n",
      "\n",
      "     Epoch   gpu_mem      GIoU       obj       cls     total   targets  img_size\n",
      "Apex recommended for faster mixed precision training: https://github.com/NVIDIA/apex\n",
      "Apex recommended for faster mixed precision training: https://github.com/NVIDIA/apex\n",
      "Apex recommended for faster mixed precision training: https://github.com/NVIDIA/apex\n",
      "Apex recommended for faster mixed precision training: https://github.com/NVIDIA/apex\n",
      "Apex recommended for faster mixed precision training: https://github.com/NVIDIA/apex\n",
      "Apex recommended for faster mixed precision training: https://github.com/NVIDIA/apex\n",
      "                 all         3         7     0.532     0.571     0.478     0.551\n",
      "\n",
      "     Epoch   gpu_mem      GIoU       obj       cls     total   targets  img_size\n",
      "Apex recommended for faster mixed precision training: https://github.com/NVIDIA/apex\n",
      "Apex recommended for faster mixed precision training: https://github.com/NVIDIA/apex\n",
      "Apex recommended for faster mixed precision training: https://github.com/NVIDIA/apex\n",
      "Apex recommended for faster mixed precision training: https://github.com/NVIDIA/apex\n",
      "Apex recommended for faster mixed precision training: https://github.com/NVIDIA/apex\n",
      "Apex recommended for faster mixed precision training: https://github.com/NVIDIA/apex\n",
      "                 all         3         7     0.532     0.571     0.478     0.551\n",
      "\n",
      "     Epoch   gpu_mem      GIoU       obj       cls     total   targets  img_size\n",
      "Apex recommended for faster mixed precision training: https://github.com/NVIDIA/apex\n",
      "Apex recommended for faster mixed precision training: https://github.com/NVIDIA/apex\n",
      "Apex recommended for faster mixed precision training: https://github.com/NVIDIA/apex\n",
      "Apex recommended for faster mixed precision training: https://github.com/NVIDIA/apex\n",
      "Apex recommended for faster mixed precision training: https://github.com/NVIDIA/apex\n",
      "Apex recommended for faster mixed precision training: https://github.com/NVIDIA/apex\n",
      "                 all         3         7     0.532     0.571     0.478     0.551\n",
      "\n",
      "     Epoch   gpu_mem      GIoU       obj       cls     total   targets  img_size\n",
      "Apex recommended for faster mixed precision training: https://github.com/NVIDIA/apex\n",
      "Apex recommended for faster mixed precision training: https://github.com/NVIDIA/apex\n",
      "Apex recommended for faster mixed precision training: https://github.com/NVIDIA/apex\n",
      "Apex recommended for faster mixed precision training: https://github.com/NVIDIA/apex\n",
      "Apex recommended for faster mixed precision training: https://github.com/NVIDIA/apex\n",
      "Apex recommended for faster mixed precision training: https://github.com/NVIDIA/apex\n",
      "                 all         3         7     0.532     0.571     0.478     0.551\n",
      "\n",
      "     Epoch   gpu_mem      GIoU       obj       cls     total   targets  img_size\n",
      "Apex recommended for faster mixed precision training: https://github.com/NVIDIA/apex\n",
      "Apex recommended for faster mixed precision training: https://github.com/NVIDIA/apex\n",
      "Apex recommended for faster mixed precision training: https://github.com/NVIDIA/apex\n",
      "Apex recommended for faster mixed precision training: https://github.com/NVIDIA/apex\n",
      "Apex recommended for faster mixed precision training: https://github.com/NVIDIA/apex\n",
      "Apex recommended for faster mixed precision training: https://github.com/NVIDIA/apex\n",
      "                 all         3         7     0.532     0.571     0.478     0.551\n",
      "\n",
      "     Epoch   gpu_mem      GIoU       obj       cls     total   targets  img_size\n",
      "Apex recommended for faster mixed precision training: https://github.com/NVIDIA/apex\n",
      "Apex recommended for faster mixed precision training: https://github.com/NVIDIA/apex\n",
      "Apex recommended for faster mixed precision training: https://github.com/NVIDIA/apex\n",
      "Apex recommended for faster mixed precision training: https://github.com/NVIDIA/apex\n",
      "Apex recommended for faster mixed precision training: https://github.com/NVIDIA/apex\n",
      "Apex recommended for faster mixed precision training: https://github.com/NVIDIA/apex\n",
      "                 all         3         7     0.536     0.571     0.455     0.553\n",
      "\n",
      "     Epoch   gpu_mem      GIoU       obj       cls     total   targets  img_size\n",
      "Apex recommended for faster mixed precision training: https://github.com/NVIDIA/apex\n",
      "Apex recommended for faster mixed precision training: https://github.com/NVIDIA/apex\n",
      "Apex recommended for faster mixed precision training: https://github.com/NVIDIA/apex\n",
      "Apex recommended for faster mixed precision training: https://github.com/NVIDIA/apex\n",
      "Apex recommended for faster mixed precision training: https://github.com/NVIDIA/apex\n",
      "Apex recommended for faster mixed precision training: https://github.com/NVIDIA/apex\n",
      "                 all         3         7     0.536     0.571     0.455     0.553\n",
      "\n",
      "     Epoch   gpu_mem      GIoU       obj       cls     total   targets  img_size\n",
      "Apex recommended for faster mixed precision training: https://github.com/NVIDIA/apex\n",
      "Apex recommended for faster mixed precision training: https://github.com/NVIDIA/apex\n",
      "Apex recommended for faster mixed precision training: https://github.com/NVIDIA/apex\n",
      "Apex recommended for faster mixed precision training: https://github.com/NVIDIA/apex\n",
      "Apex recommended for faster mixed precision training: https://github.com/NVIDIA/apex\n",
      "Apex recommended for faster mixed precision training: https://github.com/NVIDIA/apex\n",
      "                 all         3         7     0.536     0.571     0.455     0.553\n",
      "\n",
      "     Epoch   gpu_mem      GIoU       obj       cls     total   targets  img_size\n",
      "Apex recommended for faster mixed precision training: https://github.com/NVIDIA/apex\n",
      "Apex recommended for faster mixed precision training: https://github.com/NVIDIA/apex\n",
      "Apex recommended for faster mixed precision training: https://github.com/NVIDIA/apex\n",
      "Apex recommended for faster mixed precision training: https://github.com/NVIDIA/apex\n",
      "Apex recommended for faster mixed precision training: https://github.com/NVIDIA/apex\n",
      "Apex recommended for faster mixed precision training: https://github.com/NVIDIA/apex\n",
      "                 all         3         7     0.536     0.571     0.455     0.553\n",
      "\n",
      "     Epoch   gpu_mem      GIoU       obj       cls     total   targets  img_size\n",
      "Apex recommended for faster mixed precision training: https://github.com/NVIDIA/apex\n",
      "Apex recommended for faster mixed precision training: https://github.com/NVIDIA/apex\n",
      "Apex recommended for faster mixed precision training: https://github.com/NVIDIA/apex\n",
      "Apex recommended for faster mixed precision training: https://github.com/NVIDIA/apex\n",
      "Apex recommended for faster mixed precision training: https://github.com/NVIDIA/apex\n",
      "Apex recommended for faster mixed precision training: https://github.com/NVIDIA/apex\n",
      "                 all         3         7     0.536     0.571     0.455     0.553\n",
      "\n",
      "     Epoch   gpu_mem      GIoU       obj       cls     total   targets  img_size\n",
      "Apex recommended for faster mixed precision training: https://github.com/NVIDIA/apex\n",
      "Apex recommended for faster mixed precision training: https://github.com/NVIDIA/apex\n",
      "Apex recommended for faster mixed precision training: https://github.com/NVIDIA/apex\n",
      "Apex recommended for faster mixed precision training: https://github.com/NVIDIA/apex\n",
      "Apex recommended for faster mixed precision training: https://github.com/NVIDIA/apex\n",
      "Apex recommended for faster mixed precision training: https://github.com/NVIDIA/apex\n",
      "                 all         3         7     0.536     0.571     0.455     0.553\n",
      "\n",
      "     Epoch   gpu_mem      GIoU       obj       cls     total   targets  img_size\n",
      "Apex recommended for faster mixed precision training: https://github.com/NVIDIA/apex\n",
      "Apex recommended for faster mixed precision training: https://github.com/NVIDIA/apex\n",
      "Apex recommended for faster mixed precision training: https://github.com/NVIDIA/apex\n",
      "Apex recommended for faster mixed precision training: https://github.com/NVIDIA/apex\n",
      "Apex recommended for faster mixed precision training: https://github.com/NVIDIA/apex\n",
      "Apex recommended for faster mixed precision training: https://github.com/NVIDIA/apex\n",
      "                 all         3         7     0.532     0.571     0.455     0.551\n",
      "\n",
      "     Epoch   gpu_mem      GIoU       obj       cls     total   targets  img_size\n",
      "Apex recommended for faster mixed precision training: https://github.com/NVIDIA/apex\n",
      "Apex recommended for faster mixed precision training: https://github.com/NVIDIA/apex\n",
      "Apex recommended for faster mixed precision training: https://github.com/NVIDIA/apex\n",
      "Apex recommended for faster mixed precision training: https://github.com/NVIDIA/apex\n",
      "Apex recommended for faster mixed precision training: https://github.com/NVIDIA/apex\n",
      "Apex recommended for faster mixed precision training: https://github.com/NVIDIA/apex\n",
      "                 all         3         7     0.532     0.571     0.455     0.551\n",
      "14 epochs completed in 0.176 hours.\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-03-04 14:55:00.246667: I tensorflow/core/util/port.cc:113] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
      "WARNING:tensorflow:From C:\\Users\\mit017\\anaconda3\\Lib\\site-packages\\keras\\src\\losses.py:2976: The name tf.losses.sparse_softmax_cross_entropy is deprecated. Please use tf.compat.v1.losses.sparse_softmax_cross_entropy instead.\n",
      "\n",
      "\n",
      "  0%|          | 0/12 [00:00<?, ?it/s]\n",
      "Caching labels C:\\Users\\mit017\\Desktop\\myproject\\XRAY_PROJECT\\XrayInspection\\dataset\\test1\\yolov3\\train.txt (12 found, 0 missing, 0 empty, 0 duplicate, for 12 images): 100%|##########| 12/12 [00:00<00:00, 2399.37it/s]\n",
      "\n",
      "  0%|          | 0/3 [00:00<?, ?it/s]\n",
      "Caching labels C:\\Users\\mit017\\Desktop\\myproject\\XRAY_PROJECT\\XrayInspection\\dataset\\test1\\yolov3\\test.txt (3 found, 0 missing, 0 empty, 0 duplicate, for 3 images): 100%|##########| 3/3 [00:00<00:00, 2985.27it/s]\n",
      "\n",
      "  0%|          | 0/4 [00:00<?, ?it/s]2024-03-04 14:55:13.234800: I tensorflow/core/util/port.cc:113] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
      "2024-03-04 14:55:13.341900: I tensorflow/core/util/port.cc:113] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
      "2024-03-04 14:55:13.494270: I tensorflow/core/util/port.cc:113] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
      "WARNING:tensorflow:From C:\\Users\\mit017\\anaconda3\\Lib\\site-packages\\keras\\src\\losses.py:2976: The name tf.losses.sparse_softmax_cross_entropy is deprecated. Please use tf.compat.v1.losses.sparse_softmax_cross_entropy instead.\n",
      "\n",
      "WARNING:tensorflow:From C:\\Users\\mit017\\anaconda3\\Lib\\site-packages\\keras\\src\\losses.py:2976: The name tf.losses.sparse_softmax_cross_entropy is deprecated. Please use tf.compat.v1.losses.sparse_softmax_cross_entropy instead.\n",
      "\n",
      "WARNING:tensorflow:From C:\\Users\\mit017\\anaconda3\\Lib\\site-packages\\keras\\src\\losses.py:2976: The name tf.losses.sparse_softmax_cross_entropy is deprecated. Please use tf.compat.v1.losses.sparse_softmax_cross_entropy instead.\n",
      "\n",
      "\n",
      "   807/820        0G      1.33    0.0142         0      1.34         3       640:   0%|          | 0/4 [00:20<?, ?it/s]\n",
      "   807/820        0G      1.33    0.0142         0      1.34         3       640:  25%|##5       | 1/4 [00:20<01:01, 20.36s/it]\n",
      "   807/820        0G      1.02    0.0208         0      1.04         7       640:  25%|##5       | 1/4 [00:27<01:01, 20.36s/it]\n",
      "   807/820        0G      1.02    0.0208         0      1.04         7       640:  50%|#####     | 2/4 [00:27<00:24, 12.38s/it]\n",
      "   807/820        0G      1.02     0.021         0      1.04         4       640:  50%|#####     | 2/4 [00:33<00:24, 12.38s/it]\n",
      "   807/820        0G      1.02     0.021         0      1.04         4       640:  75%|#######5  | 3/4 [00:33<00:09,  9.77s/it]\n",
      "   807/820        0G     0.982    0.0184         0         1         2       640:  75%|#######5  | 3/4 [00:40<00:09,  9.77s/it]\n",
      "   807/820        0G     0.982    0.0184         0         1         2       640: 100%|##########| 4/4 [00:40<00:00,  8.58s/it]\n",
      "   807/820        0G     0.982    0.0184         0         1         2       640: 100%|##########| 4/4 [00:41<00:00, 10.41s/it]\n",
      "C:\\Users\\mit017\\anaconda3\\Lib\\site-packages\\torch\\optim\\lr_scheduler.py:143: UserWarning: Detected call of `lr_scheduler.step()` before `optimizer.step()`. In PyTorch 1.1.0 and later, you should call them in the opposite order: `optimizer.step()` before `lr_scheduler.step()`.  Failure to do this will result in PyTorch skipping the first value of the learning rate schedule. See more details at https://pytorch.org/docs/stable/optim.html#how-to-adjust-learning-rate\n",
      "  warnings.warn(\"Detected call of `lr_scheduler.step()` before `optimizer.step()`. \"\n",
      "\n",
      "               Class    Images   Targets         P         R   mAP@0.5        F1:   0%|          | 0/1 [00:00<?, ?it/s]2024-03-04 14:55:54.896037: I tensorflow/core/util/port.cc:113] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
      "2024-03-04 14:55:54.908635: I tensorflow/core/util/port.cc:113] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
      "2024-03-04 14:55:54.908634: I tensorflow/core/util/port.cc:113] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
      "WARNING:tensorflow:From C:\\Users\\mit017\\anaconda3\\Lib\\site-packages\\keras\\src\\losses.py:2976: The name tf.losses.sparse_softmax_cross_entropy is deprecated. Please use tf.compat.v1.losses.sparse_softmax_cross_entropy instead.\n",
      "\n",
      "WARNING:tensorflow:From C:\\Users\\mit017\\anaconda3\\Lib\\site-packages\\keras\\src\\losses.py:2976: The name tf.losses.sparse_softmax_cross_entropy is deprecated. Please use tf.compat.v1.losses.sparse_softmax_cross_entropy instead.\n",
      "\n",
      "WARNING:tensorflow:From C:\\Users\\mit017\\anaconda3\\Lib\\site-packages\\keras\\src\\losses.py:2976: The name tf.losses.sparse_softmax_cross_entropy is deprecated. Please use tf.compat.v1.losses.sparse_softmax_cross_entropy instead.\n",
      "\n",
      "C:\\Users\\mit017\\anaconda3\\Lib\\site-packages\\torch\\functional.py:507: UserWarning: torch.meshgrid: in an upcoming release, it will be required to pass the indexing argument. (Triggered internally at ..\\aten\\src\\ATen\\native\\TensorShape.cpp:3550.)\n",
      "  return _VF.meshgrid(tensors, **kwargs)  # type: ignore[attr-defined]\n",
      "\n",
      "               Class    Images   Targets         P         R   mAP@0.5        F1: 100%|##########| 1/1 [00:14<00:00, 14.22s/it]\n",
      "               Class    Images   Targets         P         R   mAP@0.5        F1: 100%|##########| 1/1 [00:15<00:00, 15.56s/it]\n",
      "\n",
      "  0%|          | 0/4 [00:00<?, ?it/s]2024-03-04 14:56:10.969917: I tensorflow/core/util/port.cc:113] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
      "2024-03-04 14:56:11.032878: I tensorflow/core/util/port.cc:113] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
      "2024-03-04 14:56:11.130835: I tensorflow/core/util/port.cc:113] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
      "WARNING:tensorflow:From C:\\Users\\mit017\\anaconda3\\Lib\\site-packages\\keras\\src\\losses.py:2976: The name tf.losses.sparse_softmax_cross_entropy is deprecated. Please use tf.compat.v1.losses.sparse_softmax_cross_entropy instead.\n",
      "\n",
      "WARNING:tensorflow:From C:\\Users\\mit017\\anaconda3\\Lib\\site-packages\\keras\\src\\losses.py:2976: The name tf.losses.sparse_softmax_cross_entropy is deprecated. Please use tf.compat.v1.losses.sparse_softmax_cross_entropy instead.\n",
      "\n",
      "WARNING:tensorflow:From C:\\Users\\mit017\\anaconda3\\Lib\\site-packages\\keras\\src\\losses.py:2976: The name tf.losses.sparse_softmax_cross_entropy is deprecated. Please use tf.compat.v1.losses.sparse_softmax_cross_entropy instead.\n",
      "\n",
      "\n",
      "   808/820        0G         1    0.0192         0      1.02         3       640:   0%|          | 0/4 [00:19<?, ?it/s]\n",
      "   808/820        0G         1    0.0192         0      1.02         3       640:  25%|##5       | 1/4 [00:19<00:57, 19.00s/it]\n",
      "   808/820        0G      1.03    0.0205         0      1.05         7       640:  25%|##5       | 1/4 [00:26<00:57, 19.00s/it]\n",
      "   808/820        0G      1.03    0.0205         0      1.05         7       640:  50%|#####     | 2/4 [00:26<00:23, 11.96s/it]\n",
      "   808/820        0G     0.982    0.0186         0         1         3       512:  50%|#####     | 2/4 [00:30<00:23, 11.96s/it]\n",
      "   808/820        0G     0.982    0.0186         0         1         3       512:  75%|#######5  | 3/4 [00:30<00:08,  8.66s/it]\n",
      "   808/820        0G      1.02     0.019         0      1.04         4       512:  75%|#######5  | 3/4 [00:34<00:08,  8.66s/it]\n",
      "   808/820        0G      1.02     0.019         0      1.04         4       512: 100%|##########| 4/4 [00:34<00:00,  6.89s/it]\n",
      "   808/820        0G      1.02     0.019         0      1.04         4       512: 100%|##########| 4/4 [00:36<00:00,  9.02s/it]\n",
      "\n",
      "               Class    Images   Targets         P         R   mAP@0.5        F1:   0%|          | 0/1 [00:00<?, ?it/s]2024-03-04 14:56:47.365244: I tensorflow/core/util/port.cc:113] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
      "2024-03-04 14:56:47.366201: I tensorflow/core/util/port.cc:113] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
      "2024-03-04 14:56:47.369548: I tensorflow/core/util/port.cc:113] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
      "WARNING:tensorflow:From C:\\Users\\mit017\\anaconda3\\Lib\\site-packages\\keras\\src\\losses.py:2976: The name tf.losses.sparse_softmax_cross_entropy is deprecated. Please use tf.compat.v1.losses.sparse_softmax_cross_entropy instead.\n",
      "\n",
      "WARNING:tensorflow:From C:\\Users\\mit017\\anaconda3\\Lib\\site-packages\\keras\\src\\losses.py:2976: The name tf.losses.sparse_softmax_cross_entropy is deprecated. Please use tf.compat.v1.losses.sparse_softmax_cross_entropy instead.\n",
      "\n",
      "WARNING:tensorflow:From C:\\Users\\mit017\\anaconda3\\Lib\\site-packages\\keras\\src\\losses.py:2976: The name tf.losses.sparse_softmax_cross_entropy is deprecated. Please use tf.compat.v1.losses.sparse_softmax_cross_entropy instead.\n",
      "\n",
      "\n",
      "               Class    Images   Targets         P         R   mAP@0.5        F1: 100%|##########| 1/1 [00:14<00:00, 14.07s/it]\n",
      "               Class    Images   Targets         P         R   mAP@0.5        F1: 100%|##########| 1/1 [00:15<00:00, 15.12s/it]\n",
      "\n",
      "  0%|          | 0/4 [00:00<?, ?it/s]2024-03-04 14:57:02.199574: I tensorflow/core/util/port.cc:113] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
      "2024-03-04 14:57:02.302133: I tensorflow/core/util/port.cc:113] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
      "2024-03-04 14:57:02.379196: I tensorflow/core/util/port.cc:113] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
      "WARNING:tensorflow:From C:\\Users\\mit017\\anaconda3\\Lib\\site-packages\\keras\\src\\losses.py:2976: The name tf.losses.sparse_softmax_cross_entropy is deprecated. Please use tf.compat.v1.losses.sparse_softmax_cross_entropy instead.\n",
      "\n",
      "WARNING:tensorflow:From C:\\Users\\mit017\\anaconda3\\Lib\\site-packages\\keras\\src\\losses.py:2976: The name tf.losses.sparse_softmax_cross_entropy is deprecated. Please use tf.compat.v1.losses.sparse_softmax_cross_entropy instead.\n",
      "\n",
      "WARNING:tensorflow:From C:\\Users\\mit017\\anaconda3\\Lib\\site-packages\\keras\\src\\losses.py:2976: The name tf.losses.sparse_softmax_cross_entropy is deprecated. Please use tf.compat.v1.losses.sparse_softmax_cross_entropy instead.\n",
      "\n",
      "\n",
      "   809/820        0G     0.875    0.0183         0     0.893         3       512:   0%|          | 0/4 [00:16<?, ?it/s]\n",
      "   809/820        0G     0.875    0.0183         0     0.893         3       512:  25%|##5       | 1/4 [00:16<00:48, 16.18s/it]\n",
      "   809/820        0G      1.05    0.0156         0      1.06         3       512:  25%|##5       | 1/4 [00:20<00:48, 16.18s/it]\n",
      "   809/820        0G      1.05    0.0156         0      1.06         3       512:  50%|#####     | 2/4 [00:20<00:18,  9.13s/it]\n",
      "   809/820        0G     0.968    0.0161         0     0.984         5       512:  50%|#####     | 2/4 [00:24<00:18,  9.13s/it]\n",
      "   809/820        0G     0.968    0.0161         0     0.984         5       512:  75%|#######5  | 3/4 [00:24<00:06,  6.98s/it]\n",
      "   809/820        0G     0.975    0.0177         0     0.992         6       512:  75%|#######5  | 3/4 [00:28<00:06,  6.98s/it]\n",
      "   809/820        0G     0.975    0.0177         0     0.992         6       512: 100%|##########| 4/4 [00:28<00:00,  5.84s/it]\n",
      "   809/820        0G     0.975    0.0177         0     0.992         6       512: 100%|##########| 4/4 [00:29<00:00,  7.47s/it]\n",
      "\n",
      "               Class    Images   Targets         P         R   mAP@0.5        F1:   0%|          | 0/1 [00:00<?, ?it/s]2024-03-04 14:57:32.451755: I tensorflow/core/util/port.cc:113] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
      "2024-03-04 14:57:32.487574: I tensorflow/core/util/port.cc:113] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
      "2024-03-04 14:57:32.487578: I tensorflow/core/util/port.cc:113] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
      "WARNING:tensorflow:From C:\\Users\\mit017\\anaconda3\\Lib\\site-packages\\keras\\src\\losses.py:2976: The name tf.losses.sparse_softmax_cross_entropy is deprecated. Please use tf.compat.v1.losses.sparse_softmax_cross_entropy instead.\n",
      "\n",
      "WARNING:tensorflow:From C:\\Users\\mit017\\anaconda3\\Lib\\site-packages\\keras\\src\\losses.py:2976: The name tf.losses.sparse_softmax_cross_entropy is deprecated. Please use tf.compat.v1.losses.sparse_softmax_cross_entropy instead.\n",
      "\n",
      "WARNING:tensorflow:From C:\\Users\\mit017\\anaconda3\\Lib\\site-packages\\keras\\src\\losses.py:2976: The name tf.losses.sparse_softmax_cross_entropy is deprecated. Please use tf.compat.v1.losses.sparse_softmax_cross_entropy instead.\n",
      "\n",
      "\n",
      "               Class    Images   Targets         P         R   mAP@0.5        F1: 100%|##########| 1/1 [00:13<00:00, 13.69s/it]\n",
      "               Class    Images   Targets         P         R   mAP@0.5        F1: 100%|##########| 1/1 [00:14<00:00, 14.70s/it]\n",
      "\n",
      "  0%|          | 0/4 [00:00<?, ?it/s]2024-03-04 14:57:47.215622: I tensorflow/core/util/port.cc:113] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
      "2024-03-04 14:57:47.305092: I tensorflow/core/util/port.cc:113] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
      "2024-03-04 14:57:47.376950: I tensorflow/core/util/port.cc:113] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
      "WARNING:tensorflow:From C:\\Users\\mit017\\anaconda3\\Lib\\site-packages\\keras\\src\\losses.py:2976: The name tf.losses.sparse_softmax_cross_entropy is deprecated. Please use tf.compat.v1.losses.sparse_softmax_cross_entropy instead.\n",
      "\n",
      "WARNING:tensorflow:From C:\\Users\\mit017\\anaconda3\\Lib\\site-packages\\keras\\src\\losses.py:2976: The name tf.losses.sparse_softmax_cross_entropy is deprecated. Please use tf.compat.v1.losses.sparse_softmax_cross_entropy instead.\n",
      "\n",
      "WARNING:tensorflow:From C:\\Users\\mit017\\anaconda3\\Lib\\site-packages\\keras\\src\\losses.py:2976: The name tf.losses.sparse_softmax_cross_entropy is deprecated. Please use tf.compat.v1.losses.sparse_softmax_cross_entropy instead.\n",
      "\n",
      "\n",
      "   810/820        0G     0.642    0.0144         0     0.656         3       512:   0%|          | 0/4 [00:16<?, ?it/s]\n",
      "   810/820        0G     0.642    0.0144         0     0.656         3       512:  25%|##5       | 1/4 [00:16<00:49, 16.50s/it]\n",
      "   810/820        0G       1.1     0.013         0      1.11         3       512:  25%|##5       | 1/4 [00:20<00:49, 16.50s/it]\n",
      "   810/820        0G       1.1     0.013         0      1.11         3       512:  50%|#####     | 2/4 [00:20<00:18,  9.37s/it]\n",
      "   810/820        0G      1.12    0.0153         0      1.14         5       512:  50%|#####     | 2/4 [00:25<00:18,  9.37s/it]\n",
      "   810/820        0G      1.12    0.0153         0      1.14         5       512:  75%|#######5  | 3/4 [00:25<00:07,  7.09s/it]\n",
      "   810/820        0G      1.08    0.0146         0       1.1         3       512:  75%|#######5  | 3/4 [00:29<00:07,  7.09s/it]\n",
      "   810/820        0G      1.08    0.0146         0       1.1         3       512: 100%|##########| 4/4 [00:29<00:00,  5.97s/it]\n",
      "   810/820        0G      1.08    0.0146         0       1.1         3       512: 100%|##########| 4/4 [00:30<00:00,  7.63s/it]\n",
      "\n",
      "               Class    Images   Targets         P         R   mAP@0.5        F1:   0%|          | 0/1 [00:00<?, ?it/s]2024-03-04 14:58:17.891223: I tensorflow/core/util/port.cc:113] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
      "2024-03-04 14:58:17.897988: I tensorflow/core/util/port.cc:113] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
      "2024-03-04 14:58:17.898182: I tensorflow/core/util/port.cc:113] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
      "WARNING:tensorflow:From C:\\Users\\mit017\\anaconda3\\Lib\\site-packages\\keras\\src\\losses.py:2976: The name tf.losses.sparse_softmax_cross_entropy is deprecated. Please use tf.compat.v1.losses.sparse_softmax_cross_entropy instead.\n",
      "\n",
      "WARNING:tensorflow:From C:\\Users\\mit017\\anaconda3\\Lib\\site-packages\\keras\\src\\losses.py:2976: The name tf.losses.sparse_softmax_cross_entropy is deprecated. Please use tf.compat.v1.losses.sparse_softmax_cross_entropy instead.\n",
      "\n",
      "WARNING:tensorflow:From C:\\Users\\mit017\\anaconda3\\Lib\\site-packages\\keras\\src\\losses.py:2976: The name tf.losses.sparse_softmax_cross_entropy is deprecated. Please use tf.compat.v1.losses.sparse_softmax_cross_entropy instead.\n",
      "\n",
      "\n",
      "               Class    Images   Targets         P         R   mAP@0.5        F1: 100%|##########| 1/1 [00:13<00:00, 13.79s/it]\n",
      "               Class    Images   Targets         P         R   mAP@0.5        F1: 100%|##########| 1/1 [00:14<00:00, 14.73s/it]\n",
      "\n",
      "  0%|          | 0/4 [00:00<?, ?it/s]2024-03-04 14:58:32.623356: I tensorflow/core/util/port.cc:113] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
      "2024-03-04 14:58:32.695083: I tensorflow/core/util/port.cc:113] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
      "2024-03-04 14:58:32.797434: I tensorflow/core/util/port.cc:113] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
      "WARNING:tensorflow:From C:\\Users\\mit017\\anaconda3\\Lib\\site-packages\\keras\\src\\losses.py:2976: The name tf.losses.sparse_softmax_cross_entropy is deprecated. Please use tf.compat.v1.losses.sparse_softmax_cross_entropy instead.\n",
      "\n",
      "WARNING:tensorflow:From C:\\Users\\mit017\\anaconda3\\Lib\\site-packages\\keras\\src\\losses.py:2976: The name tf.losses.sparse_softmax_cross_entropy is deprecated. Please use tf.compat.v1.losses.sparse_softmax_cross_entropy instead.\n",
      "\n",
      "WARNING:tensorflow:From C:\\Users\\mit017\\anaconda3\\Lib\\site-packages\\keras\\src\\losses.py:2976: The name tf.losses.sparse_softmax_cross_entropy is deprecated. Please use tf.compat.v1.losses.sparse_softmax_cross_entropy instead.\n",
      "\n",
      "\n",
      "   811/820        0G      1.06    0.0149         0      1.07         3       512:   0%|          | 0/4 [00:15<?, ?it/s]\n",
      "   811/820        0G      1.06    0.0149         0      1.07         3       512:  25%|##5       | 1/4 [00:15<00:47, 15.73s/it]\n",
      "   811/820        0G       1.1    0.0158         0      1.11         4       512:  25%|##5       | 1/4 [00:19<00:47, 15.73s/it]\n",
      "   811/820        0G       1.1    0.0158         0      1.11         4       512:  50%|#####     | 2/4 [00:19<00:17,  8.97s/it]\n",
      "   811/820        0G      1.15    0.0147         0      1.17         3       512:  50%|#####     | 2/4 [00:24<00:17,  8.97s/it]\n",
      "   811/820        0G      1.15    0.0147         0      1.17         3       512:  75%|#######5  | 3/4 [00:24<00:06,  6.80s/it]\n",
      "   811/820        0G      1.14    0.0155         0      1.15         6       512:  75%|#######5  | 3/4 [00:28<00:06,  6.80s/it]\n",
      "   811/820        0G      1.14    0.0155         0      1.15         6       512: 100%|##########| 4/4 [00:28<00:00,  5.80s/it]\n",
      "   811/820        0G      1.14    0.0155         0      1.15         6       512: 100%|##########| 4/4 [00:29<00:00,  7.38s/it]\n",
      "\n",
      "               Class    Images   Targets         P         R   mAP@0.5        F1:   0%|          | 0/1 [00:00<?, ?it/s]2024-03-04 14:59:02.580020: I tensorflow/core/util/port.cc:113] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
      "2024-03-04 14:59:02.586938: I tensorflow/core/util/port.cc:113] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
      "2024-03-04 14:59:02.587445: I tensorflow/core/util/port.cc:113] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
      "WARNING:tensorflow:From C:\\Users\\mit017\\anaconda3\\Lib\\site-packages\\keras\\src\\losses.py:2976: The name tf.losses.sparse_softmax_cross_entropy is deprecated. Please use tf.compat.v1.losses.sparse_softmax_cross_entropy instead.\n",
      "\n",
      "WARNING:tensorflow:From C:\\Users\\mit017\\anaconda3\\Lib\\site-packages\\keras\\src\\losses.py:2976: The name tf.losses.sparse_softmax_cross_entropy is deprecated. Please use tf.compat.v1.losses.sparse_softmax_cross_entropy instead.\n",
      "\n",
      "WARNING:tensorflow:From C:\\Users\\mit017\\anaconda3\\Lib\\site-packages\\keras\\src\\losses.py:2976: The name tf.losses.sparse_softmax_cross_entropy is deprecated. Please use tf.compat.v1.losses.sparse_softmax_cross_entropy instead.\n",
      "\n",
      "\n",
      "               Class    Images   Targets         P         R   mAP@0.5        F1: 100%|##########| 1/1 [00:14<00:00, 14.52s/it]\n",
      "               Class    Images   Targets         P         R   mAP@0.5        F1: 100%|##########| 1/1 [00:15<00:00, 15.49s/it]\n",
      "\n",
      "  0%|          | 0/4 [00:00<?, ?it/s]2024-03-04 14:59:17.980236: I tensorflow/core/util/port.cc:113] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
      "2024-03-04 14:59:18.046007: I tensorflow/core/util/port.cc:113] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
      "2024-03-04 14:59:18.150097: I tensorflow/core/util/port.cc:113] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
      "WARNING:tensorflow:From C:\\Users\\mit017\\anaconda3\\Lib\\site-packages\\keras\\src\\losses.py:2976: The name tf.losses.sparse_softmax_cross_entropy is deprecated. Please use tf.compat.v1.losses.sparse_softmax_cross_entropy instead.\n",
      "\n",
      "WARNING:tensorflow:From C:\\Users\\mit017\\anaconda3\\Lib\\site-packages\\keras\\src\\losses.py:2976: The name tf.losses.sparse_softmax_cross_entropy is deprecated. Please use tf.compat.v1.losses.sparse_softmax_cross_entropy instead.\n",
      "\n",
      "WARNING:tensorflow:From C:\\Users\\mit017\\anaconda3\\Lib\\site-packages\\keras\\src\\losses.py:2976: The name tf.losses.sparse_softmax_cross_entropy is deprecated. Please use tf.compat.v1.losses.sparse_softmax_cross_entropy instead.\n",
      "\n",
      "\n",
      "   812/820        0G      1.23     0.013         0      1.25         3       512:   0%|          | 0/4 [00:15<?, ?it/s]\n",
      "   812/820        0G      1.23     0.013         0      1.25         3       512:  25%|##5       | 1/4 [00:15<00:45, 15.28s/it]\n",
      "   812/820        0G      1.09    0.0216         0      1.11         5       512:  25%|##5       | 1/4 [00:19<00:45, 15.28s/it]\n",
      "   812/820        0G      1.09    0.0216         0      1.11         5       512:  50%|#####     | 2/4 [00:19<00:17,  8.81s/it]\n",
      "   812/820        0G     0.965      0.02         0     0.985         3       512:  50%|#####     | 2/4 [00:23<00:17,  8.81s/it]\n",
      "   812/820        0G     0.965      0.02         0     0.985         3       512:  75%|#######5  | 3/4 [00:23<00:06,  6.75s/it]\n",
      "   812/820        0G      1.06    0.0184         0      1.08         3       512:  75%|#######5  | 3/4 [00:28<00:06,  6.75s/it]\n",
      "   812/820        0G      1.06    0.0184         0      1.08         3       512: 100%|##########| 4/4 [00:28<00:00,  5.73s/it]\n",
      "   812/820        0G      1.06    0.0184         0      1.08         3       512: 100%|##########| 4/4 [00:29<00:00,  7.26s/it]\n",
      "\n",
      "               Class    Images   Targets         P         R   mAP@0.5        F1:   0%|          | 0/1 [00:00<?, ?it/s]2024-03-04 14:59:47.344171: I tensorflow/core/util/port.cc:113] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
      "2024-03-04 14:59:47.347346: I tensorflow/core/util/port.cc:113] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
      "2024-03-04 14:59:47.348339: I tensorflow/core/util/port.cc:113] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
      "WARNING:tensorflow:From C:\\Users\\mit017\\anaconda3\\Lib\\site-packages\\keras\\src\\losses.py:2976: The name tf.losses.sparse_softmax_cross_entropy is deprecated. Please use tf.compat.v1.losses.sparse_softmax_cross_entropy instead.\n",
      "\n",
      "WARNING:tensorflow:From C:\\Users\\mit017\\anaconda3\\Lib\\site-packages\\keras\\src\\losses.py:2976: The name tf.losses.sparse_softmax_cross_entropy is deprecated. Please use tf.compat.v1.losses.sparse_softmax_cross_entropy instead.\n",
      "\n",
      "WARNING:tensorflow:From C:\\Users\\mit017\\anaconda3\\Lib\\site-packages\\keras\\src\\losses.py:2976: The name tf.losses.sparse_softmax_cross_entropy is deprecated. Please use tf.compat.v1.losses.sparse_softmax_cross_entropy instead.\n",
      "\n",
      "\n",
      "               Class    Images   Targets         P         R   mAP@0.5        F1: 100%|##########| 1/1 [00:13<00:00, 13.85s/it]\n",
      "               Class    Images   Targets         P         R   mAP@0.5        F1: 100%|##########| 1/1 [00:14<00:00, 14.85s/it]\n",
      "\n",
      "  0%|          | 0/4 [00:00<?, ?it/s]2024-03-04 15:00:02.347860: I tensorflow/core/util/port.cc:113] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
      "2024-03-04 15:00:02.460358: I tensorflow/core/util/port.cc:113] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
      "2024-03-04 15:00:02.520224: I tensorflow/core/util/port.cc:113] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
      "WARNING:tensorflow:From C:\\Users\\mit017\\anaconda3\\Lib\\site-packages\\keras\\src\\losses.py:2976: The name tf.losses.sparse_softmax_cross_entropy is deprecated. Please use tf.compat.v1.losses.sparse_softmax_cross_entropy instead.\n",
      "\n",
      "WARNING:tensorflow:From C:\\Users\\mit017\\anaconda3\\Lib\\site-packages\\keras\\src\\losses.py:2976: The name tf.losses.sparse_softmax_cross_entropy is deprecated. Please use tf.compat.v1.losses.sparse_softmax_cross_entropy instead.\n",
      "\n",
      "WARNING:tensorflow:From C:\\Users\\mit017\\anaconda3\\Lib\\site-packages\\keras\\src\\losses.py:2976: The name tf.losses.sparse_softmax_cross_entropy is deprecated. Please use tf.compat.v1.losses.sparse_softmax_cross_entropy instead.\n",
      "\n",
      "\n",
      "   813/820        0G     0.951    0.0121         0     0.963         3       512:   0%|          | 0/4 [00:16<?, ?it/s]\n",
      "   813/820        0G     0.951    0.0121         0     0.963         3       512:  25%|##5       | 1/4 [00:16<00:49, 16.40s/it]\n",
      "   813/820        0G      1.12    0.0156         0      1.14         4       512:  25%|##5       | 1/4 [00:20<00:49, 16.40s/it]\n",
      "   813/820        0G      1.12    0.0156         0      1.14         4       512:  50%|#####     | 2/4 [00:20<00:18,  9.41s/it]\n",
      "   813/820        0G      1.12    0.0155         0      1.14         3       512:  50%|#####     | 2/4 [00:25<00:18,  9.41s/it]\n",
      "   813/820        0G      1.12    0.0155         0      1.14         3       512:  75%|#######5  | 3/4 [00:25<00:07,  7.11s/it]\n",
      "   813/820        0G       1.1    0.0197         0      1.12         9       512:  75%|#######5  | 3/4 [00:29<00:07,  7.11s/it]\n",
      "   813/820        0G       1.1    0.0197         0      1.12         9       512: 100%|##########| 4/4 [00:29<00:00,  6.07s/it]\n",
      "   813/820        0G       1.1    0.0197         0      1.12         9       512: 100%|##########| 4/4 [00:30<00:00,  7.68s/it]\n",
      "\n",
      "               Class    Images   Targets         P         R   mAP@0.5        F1:   0%|          | 0/1 [00:00<?, ?it/s]2024-03-04 15:00:33.308225: I tensorflow/core/util/port.cc:113] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
      "2024-03-04 15:00:33.320110: I tensorflow/core/util/port.cc:113] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
      "2024-03-04 15:00:33.322089: I tensorflow/core/util/port.cc:113] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
      "WARNING:tensorflow:From C:\\Users\\mit017\\anaconda3\\Lib\\site-packages\\keras\\src\\losses.py:2976: The name tf.losses.sparse_softmax_cross_entropy is deprecated. Please use tf.compat.v1.losses.sparse_softmax_cross_entropy instead.\n",
      "\n",
      "WARNING:tensorflow:From C:\\Users\\mit017\\anaconda3\\Lib\\site-packages\\keras\\src\\losses.py:2976: The name tf.losses.sparse_softmax_cross_entropy is deprecated. Please use tf.compat.v1.losses.sparse_softmax_cross_entropy instead.\n",
      "\n",
      "WARNING:tensorflow:From C:\\Users\\mit017\\anaconda3\\Lib\\site-packages\\keras\\src\\losses.py:2976: The name tf.losses.sparse_softmax_cross_entropy is deprecated. Please use tf.compat.v1.losses.sparse_softmax_cross_entropy instead.\n",
      "\n",
      "\n",
      "               Class    Images   Targets         P         R   mAP@0.5        F1: 100%|##########| 1/1 [00:14<00:00, 14.46s/it]\n",
      "               Class    Images   Targets         P         R   mAP@0.5        F1: 100%|##########| 1/1 [00:15<00:00, 15.55s/it]\n",
      "\n",
      "  0%|          | 0/4 [00:00<?, ?it/s]2024-03-04 15:00:48.912928: I tensorflow/core/util/port.cc:113] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
      "2024-03-04 15:00:49.003700: I tensorflow/core/util/port.cc:113] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
      "2024-03-04 15:00:49.086992: I tensorflow/core/util/port.cc:113] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
      "WARNING:tensorflow:From C:\\Users\\mit017\\anaconda3\\Lib\\site-packages\\keras\\src\\losses.py:2976: The name tf.losses.sparse_softmax_cross_entropy is deprecated. Please use tf.compat.v1.losses.sparse_softmax_cross_entropy instead.\n",
      "\n",
      "WARNING:tensorflow:From C:\\Users\\mit017\\anaconda3\\Lib\\site-packages\\keras\\src\\losses.py:2976: The name tf.losses.sparse_softmax_cross_entropy is deprecated. Please use tf.compat.v1.losses.sparse_softmax_cross_entropy instead.\n",
      "\n",
      "WARNING:tensorflow:From C:\\Users\\mit017\\anaconda3\\Lib\\site-packages\\keras\\src\\losses.py:2976: The name tf.losses.sparse_softmax_cross_entropy is deprecated. Please use tf.compat.v1.losses.sparse_softmax_cross_entropy instead.\n",
      "\n",
      "\n",
      "   814/820        0G      1.06    0.0116         0      1.07         3       512:   0%|          | 0/4 [00:15<?, ?it/s]\n",
      "   814/820        0G      1.06    0.0116         0      1.07         3       512:  25%|##5       | 1/4 [00:15<00:47, 15.80s/it]\n",
      "   814/820        0G      1.07    0.0136         0      1.08         5       512:  25%|##5       | 1/4 [00:19<00:47, 15.80s/it]\n",
      "   814/820        0G      1.07    0.0136         0      1.08         5       512:  50%|#####     | 2/4 [00:19<00:17,  8.96s/it]\n",
      "   814/820        0G      1.11    0.0195         0      1.13         8       512:  50%|#####     | 2/4 [00:24<00:17,  8.96s/it]\n",
      "   814/820        0G      1.11    0.0195         0      1.13         8       512:  75%|#######5  | 3/4 [00:24<00:06,  6.87s/it]\n",
      "   814/820        0G      1.12    0.0203         0      1.14         6       512:  75%|#######5  | 3/4 [00:28<00:06,  6.87s/it]\n",
      "   814/820        0G      1.12    0.0203         0      1.14         6       512: 100%|##########| 4/4 [00:28<00:00,  5.89s/it]\n",
      "   814/820        0G      1.12    0.0203         0      1.14         6       512: 100%|##########| 4/4 [00:29<00:00,  7.45s/it]\n",
      "\n",
      "               Class    Images   Targets         P         R   mAP@0.5        F1:   0%|          | 0/1 [00:00<?, ?it/s]2024-03-04 15:01:19.071345: I tensorflow/core/util/port.cc:113] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
      "2024-03-04 15:01:19.071455: I tensorflow/core/util/port.cc:113] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
      "2024-03-04 15:01:19.072608: I tensorflow/core/util/port.cc:113] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
      "WARNING:tensorflow:From C:\\Users\\mit017\\anaconda3\\Lib\\site-packages\\keras\\src\\losses.py:2976: The name tf.losses.sparse_softmax_cross_entropy is deprecated. Please use tf.compat.v1.losses.sparse_softmax_cross_entropy instead.\n",
      "\n",
      "WARNING:tensorflow:From C:\\Users\\mit017\\anaconda3\\Lib\\site-packages\\keras\\src\\losses.py:2976: The name tf.losses.sparse_softmax_cross_entropy is deprecated. Please use tf.compat.v1.losses.sparse_softmax_cross_entropy instead.\n",
      "\n",
      "WARNING:tensorflow:From C:\\Users\\mit017\\anaconda3\\Lib\\site-packages\\keras\\src\\losses.py:2976: The name tf.losses.sparse_softmax_cross_entropy is deprecated. Please use tf.compat.v1.losses.sparse_softmax_cross_entropy instead.\n",
      "\n",
      "\n",
      "               Class    Images   Targets         P         R   mAP@0.5        F1: 100%|##########| 1/1 [00:13<00:00, 13.93s/it]\n",
      "               Class    Images   Targets         P         R   mAP@0.5        F1: 100%|##########| 1/1 [00:14<00:00, 14.87s/it]\n",
      "\n",
      "  0%|          | 0/4 [00:00<?, ?it/s]2024-03-04 15:01:34.067750: I tensorflow/core/util/port.cc:113] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
      "2024-03-04 15:01:34.164257: I tensorflow/core/util/port.cc:113] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
      "2024-03-04 15:01:34.231373: I tensorflow/core/util/port.cc:113] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
      "WARNING:tensorflow:From C:\\Users\\mit017\\anaconda3\\Lib\\site-packages\\keras\\src\\losses.py:2976: The name tf.losses.sparse_softmax_cross_entropy is deprecated. Please use tf.compat.v1.losses.sparse_softmax_cross_entropy instead.\n",
      "\n",
      "WARNING:tensorflow:From C:\\Users\\mit017\\anaconda3\\Lib\\site-packages\\keras\\src\\losses.py:2976: The name tf.losses.sparse_softmax_cross_entropy is deprecated. Please use tf.compat.v1.losses.sparse_softmax_cross_entropy instead.\n",
      "\n",
      "WARNING:tensorflow:From C:\\Users\\mit017\\anaconda3\\Lib\\site-packages\\keras\\src\\losses.py:2976: The name tf.losses.sparse_softmax_cross_entropy is deprecated. Please use tf.compat.v1.losses.sparse_softmax_cross_entropy instead.\n",
      "\n",
      "\n",
      "   815/820        0G     0.571    0.0158         0     0.587         3       512:   0%|          | 0/4 [00:15<?, ?it/s]\n",
      "   815/820        0G     0.571    0.0158         0     0.587         3       512:  25%|##5       | 1/4 [00:15<00:46, 15.61s/it]\n",
      "   815/820        0G     0.658    0.0144         0     0.672         3       512:  25%|##5       | 1/4 [00:19<00:46, 15.61s/it]\n",
      "   815/820        0G     0.658    0.0144         0     0.672         3       512:  50%|#####     | 2/4 [00:19<00:17,  8.86s/it]\n",
      "   815/820        0G     0.759    0.0135         0     0.772         3       512:  50%|#####     | 2/4 [00:24<00:17,  8.86s/it]\n",
      "   815/820        0G     0.759    0.0135         0     0.772         3       512:  75%|#######5  | 3/4 [00:24<00:06,  6.78s/it]\n",
      "   815/820        0G     0.794    0.0143         0     0.808         5       512:  75%|#######5  | 3/4 [00:28<00:06,  6.78s/it]\n",
      "   815/820        0G     0.794    0.0143         0     0.808         5       512: 100%|##########| 4/4 [00:28<00:00,  5.73s/it]\n",
      "   815/820        0G     0.794    0.0143         0     0.808         5       512: 100%|##########| 4/4 [00:29<00:00,  7.31s/it]\n",
      "\n",
      "               Class    Images   Targets         P         R   mAP@0.5        F1:   0%|          | 0/1 [00:00<?, ?it/s]2024-03-04 15:02:03.634568: I tensorflow/core/util/port.cc:113] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
      "2024-03-04 15:02:03.634568: I tensorflow/core/util/port.cc:113] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
      "2024-03-04 15:02:03.653223: I tensorflow/core/util/port.cc:113] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
      "WARNING:tensorflow:From C:\\Users\\mit017\\anaconda3\\Lib\\site-packages\\keras\\src\\losses.py:2976: The name tf.losses.sparse_softmax_cross_entropy is deprecated. Please use tf.compat.v1.losses.sparse_softmax_cross_entropy instead.\n",
      "\n",
      "WARNING:tensorflow:From C:\\Users\\mit017\\anaconda3\\Lib\\site-packages\\keras\\src\\losses.py:2976: The name tf.losses.sparse_softmax_cross_entropy is deprecated. Please use tf.compat.v1.losses.sparse_softmax_cross_entropy instead.\n",
      "\n",
      "WARNING:tensorflow:From C:\\Users\\mit017\\anaconda3\\Lib\\site-packages\\keras\\src\\losses.py:2976: The name tf.losses.sparse_softmax_cross_entropy is deprecated. Please use tf.compat.v1.losses.sparse_softmax_cross_entropy instead.\n",
      "\n",
      "\n",
      "               Class    Images   Targets         P         R   mAP@0.5        F1: 100%|##########| 1/1 [00:14<00:00, 14.61s/it]\n",
      "               Class    Images   Targets         P         R   mAP@0.5        F1: 100%|##########| 1/1 [00:15<00:00, 15.58s/it]\n",
      "\n",
      "  0%|          | 0/4 [00:00<?, ?it/s]2024-03-04 15:02:19.036070: I tensorflow/core/util/port.cc:113] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
      "2024-03-04 15:02:19.104025: I tensorflow/core/util/port.cc:113] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
      "2024-03-04 15:02:19.192955: I tensorflow/core/util/port.cc:113] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
      "WARNING:tensorflow:From C:\\Users\\mit017\\anaconda3\\Lib\\site-packages\\keras\\src\\losses.py:2976: The name tf.losses.sparse_softmax_cross_entropy is deprecated. Please use tf.compat.v1.losses.sparse_softmax_cross_entropy instead.\n",
      "\n",
      "WARNING:tensorflow:From C:\\Users\\mit017\\anaconda3\\Lib\\site-packages\\keras\\src\\losses.py:2976: The name tf.losses.sparse_softmax_cross_entropy is deprecated. Please use tf.compat.v1.losses.sparse_softmax_cross_entropy instead.\n",
      "\n",
      "WARNING:tensorflow:From C:\\Users\\mit017\\anaconda3\\Lib\\site-packages\\keras\\src\\losses.py:2976: The name tf.losses.sparse_softmax_cross_entropy is deprecated. Please use tf.compat.v1.losses.sparse_softmax_cross_entropy instead.\n",
      "\n",
      "\n",
      "   816/820        0G     0.735    0.0132         0     0.748         3       512:   0%|          | 0/4 [00:15<?, ?it/s]\n",
      "   816/820        0G     0.735    0.0132         0     0.748         3       512:  25%|##5       | 1/4 [00:15<00:47, 15.79s/it]\n",
      "   816/820        0G     0.998    0.0113         0      1.01         2       512:  25%|##5       | 1/4 [00:20<00:47, 15.79s/it]\n",
      "   816/820        0G     0.998    0.0113         0      1.01         2       512:  50%|#####     | 2/4 [00:20<00:18,  9.44s/it]\n",
      "   816/820        0G       1.1    0.0158         0      1.11         7       512:  50%|#####     | 2/4 [00:25<00:18,  9.44s/it]\n",
      "   816/820        0G       1.1    0.0158         0      1.11         7       512:  75%|#######5  | 3/4 [00:25<00:07,  7.29s/it]\n",
      "   816/820        0G      1.06    0.0159         0      1.08         3       512:  75%|#######5  | 3/4 [00:29<00:07,  7.29s/it]\n",
      "   816/820        0G      1.06    0.0159         0      1.08         3       512: 100%|##########| 4/4 [00:29<00:00,  6.09s/it]\n",
      "   816/820        0G      1.06    0.0159         0      1.08         3       512: 100%|##########| 4/4 [00:30<00:00,  7.69s/it]\n",
      "\n",
      "               Class    Images   Targets         P         R   mAP@0.5        F1:   0%|          | 0/1 [00:00<?, ?it/s]2024-03-04 15:02:50.213587: I tensorflow/core/util/port.cc:113] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
      "2024-03-04 15:02:50.213562: I tensorflow/core/util/port.cc:113] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
      "2024-03-04 15:02:50.214100: I tensorflow/core/util/port.cc:113] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
      "WARNING:tensorflow:From C:\\Users\\mit017\\anaconda3\\Lib\\site-packages\\keras\\src\\losses.py:2976: The name tf.losses.sparse_softmax_cross_entropy is deprecated. Please use tf.compat.v1.losses.sparse_softmax_cross_entropy instead.\n",
      "\n",
      "WARNING:tensorflow:From C:\\Users\\mit017\\anaconda3\\Lib\\site-packages\\keras\\src\\losses.py:2976: The name tf.losses.sparse_softmax_cross_entropy is deprecated. Please use tf.compat.v1.losses.sparse_softmax_cross_entropy instead.\n",
      "\n",
      "WARNING:tensorflow:From C:\\Users\\mit017\\anaconda3\\Lib\\site-packages\\keras\\src\\losses.py:2976: The name tf.losses.sparse_softmax_cross_entropy is deprecated. Please use tf.compat.v1.losses.sparse_softmax_cross_entropy instead.\n",
      "\n",
      "\n",
      "               Class    Images   Targets         P         R   mAP@0.5        F1: 100%|##########| 1/1 [00:14<00:00, 14.15s/it]\n",
      "               Class    Images   Targets         P         R   mAP@0.5        F1: 100%|##########| 1/1 [00:15<00:00, 15.22s/it]\n",
      "\n",
      "  0%|          | 0/4 [00:00<?, ?it/s]2024-03-04 15:03:05.485920: I tensorflow/core/util/port.cc:113] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
      "2024-03-04 15:03:05.553941: I tensorflow/core/util/port.cc:113] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
      "2024-03-04 15:03:05.670365: I tensorflow/core/util/port.cc:113] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
      "WARNING:tensorflow:From C:\\Users\\mit017\\anaconda3\\Lib\\site-packages\\keras\\src\\losses.py:2976: The name tf.losses.sparse_softmax_cross_entropy is deprecated. Please use tf.compat.v1.losses.sparse_softmax_cross_entropy instead.\n",
      "\n",
      "WARNING:tensorflow:From C:\\Users\\mit017\\anaconda3\\Lib\\site-packages\\keras\\src\\losses.py:2976: The name tf.losses.sparse_softmax_cross_entropy is deprecated. Please use tf.compat.v1.losses.sparse_softmax_cross_entropy instead.\n",
      "\n",
      "WARNING:tensorflow:From C:\\Users\\mit017\\anaconda3\\Lib\\site-packages\\keras\\src\\losses.py:2976: The name tf.losses.sparse_softmax_cross_entropy is deprecated. Please use tf.compat.v1.losses.sparse_softmax_cross_entropy instead.\n",
      "\n",
      "\n",
      "   817/820        0G         1     0.018         0      1.02         5       512:   0%|          | 0/4 [00:15<?, ?it/s]\n",
      "   817/820        0G         1     0.018         0      1.02         5       512:  25%|##5       | 1/4 [00:15<00:46, 15.49s/it]\n",
      "   817/820        0G     0.899    0.0213         0     0.921         5       512:  25%|##5       | 1/4 [00:19<00:46, 15.49s/it]\n",
      "   817/820        0G     0.899    0.0213         0     0.921         5       512:  50%|#####     | 2/4 [00:19<00:17,  8.85s/it]\n",
      "   817/820        0G     0.975    0.0216         0     0.996         6       512:  50%|#####     | 2/4 [00:23<00:17,  8.85s/it]\n",
      "   817/820        0G     0.975    0.0216         0     0.996         6       512:  75%|#######5  | 3/4 [00:23<00:06,  6.74s/it]\n",
      "   817/820        0G         1    0.0215         0      1.02         6       512:  75%|#######5  | 3/4 [00:28<00:06,  6.74s/it]\n",
      "   817/820        0G         1    0.0215         0      1.02         6       512: 100%|##########| 4/4 [00:28<00:00,  5.83s/it]\n",
      "   817/820        0G         1    0.0215         0      1.02         6       512: 100%|##########| 4/4 [00:29<00:00,  7.35s/it]\n",
      "\n",
      "               Class    Images   Targets         P         R   mAP@0.5        F1:   0%|          | 0/1 [00:00<?, ?it/s]2024-03-04 15:03:35.317538: I tensorflow/core/util/port.cc:113] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
      "2024-03-04 15:03:35.323020: I tensorflow/core/util/port.cc:113] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
      "2024-03-04 15:03:35.323066: I tensorflow/core/util/port.cc:113] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
      "WARNING:tensorflow:From C:\\Users\\mit017\\anaconda3\\Lib\\site-packages\\keras\\src\\losses.py:2976: The name tf.losses.sparse_softmax_cross_entropy is deprecated. Please use tf.compat.v1.losses.sparse_softmax_cross_entropy instead.\n",
      "\n",
      "WARNING:tensorflow:From C:\\Users\\mit017\\anaconda3\\Lib\\site-packages\\keras\\src\\losses.py:2976: The name tf.losses.sparse_softmax_cross_entropy is deprecated. Please use tf.compat.v1.losses.sparse_softmax_cross_entropy instead.\n",
      "\n",
      "WARNING:tensorflow:From C:\\Users\\mit017\\anaconda3\\Lib\\site-packages\\keras\\src\\losses.py:2976: The name tf.losses.sparse_softmax_cross_entropy is deprecated. Please use tf.compat.v1.losses.sparse_softmax_cross_entropy instead.\n",
      "\n",
      "\n",
      "               Class    Images   Targets         P         R   mAP@0.5        F1: 100%|##########| 1/1 [00:14<00:00, 14.23s/it]\n",
      "               Class    Images   Targets         P         R   mAP@0.5        F1: 100%|##########| 1/1 [00:15<00:00, 15.20s/it]\n",
      "\n",
      "  0%|          | 0/4 [00:00<?, ?it/s]2024-03-04 15:03:50.391237: I tensorflow/core/util/port.cc:113] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
      "2024-03-04 15:03:50.445528: I tensorflow/core/util/port.cc:113] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
      "2024-03-04 15:03:50.531689: I tensorflow/core/util/port.cc:113] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
      "WARNING:tensorflow:From C:\\Users\\mit017\\anaconda3\\Lib\\site-packages\\keras\\src\\losses.py:2976: The name tf.losses.sparse_softmax_cross_entropy is deprecated. Please use tf.compat.v1.losses.sparse_softmax_cross_entropy instead.\n",
      "\n",
      "WARNING:tensorflow:From C:\\Users\\mit017\\anaconda3\\Lib\\site-packages\\keras\\src\\losses.py:2976: The name tf.losses.sparse_softmax_cross_entropy is deprecated. Please use tf.compat.v1.losses.sparse_softmax_cross_entropy instead.\n",
      "\n",
      "WARNING:tensorflow:From C:\\Users\\mit017\\anaconda3\\Lib\\site-packages\\keras\\src\\losses.py:2976: The name tf.losses.sparse_softmax_cross_entropy is deprecated. Please use tf.compat.v1.losses.sparse_softmax_cross_entropy instead.\n",
      "\n",
      "\n",
      "   818/820        0G      1.18     0.013         0       1.2         3       512:   0%|          | 0/4 [00:16<?, ?it/s]\n",
      "   818/820        0G      1.18     0.013         0       1.2         3       512:  25%|##5       | 1/4 [00:16<00:48, 16.01s/it]\n",
      "   818/820        0G      1.02    0.0156         0      1.03         3       512:  25%|##5       | 1/4 [00:20<00:48, 16.01s/it]\n",
      "   818/820        0G      1.02    0.0156         0      1.03         3       512:  50%|#####     | 2/4 [00:20<00:18,  9.15s/it]\n",
      "   818/820        0G     0.964    0.0173         0     0.982         5       512:  50%|#####     | 2/4 [00:24<00:18,  9.15s/it]\n",
      "   818/820        0G     0.964    0.0173         0     0.982         5       512:  75%|#######5  | 3/4 [00:24<00:06,  6.97s/it]\n",
      "   818/820        0G     0.995    0.0184         0      1.01         5       512:  75%|#######5  | 3/4 [00:28<00:06,  6.97s/it]\n",
      "   818/820        0G     0.995    0.0184         0      1.01         5       512: 100%|##########| 4/4 [00:28<00:00,  5.90s/it]\n",
      "   818/820        0G     0.995    0.0184         0      1.01         5       512: 100%|##########| 4/4 [00:29<00:00,  7.49s/it]\n",
      "\n",
      "               Class    Images   Targets         P         R   mAP@0.5        F1:   0%|          | 0/1 [00:00<?, ?it/s]2024-03-04 15:04:20.749015: I tensorflow/core/util/port.cc:113] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
      "2024-03-04 15:04:20.749241: I tensorflow/core/util/port.cc:113] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
      "2024-03-04 15:04:20.756049: I tensorflow/core/util/port.cc:113] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
      "WARNING:tensorflow:From C:\\Users\\mit017\\anaconda3\\Lib\\site-packages\\keras\\src\\losses.py:2976: The name tf.losses.sparse_softmax_cross_entropy is deprecated. Please use tf.compat.v1.losses.sparse_softmax_cross_entropy instead.\n",
      "\n",
      "WARNING:tensorflow:From C:\\Users\\mit017\\anaconda3\\Lib\\site-packages\\keras\\src\\losses.py:2976: The name tf.losses.sparse_softmax_cross_entropy is deprecated. Please use tf.compat.v1.losses.sparse_softmax_cross_entropy instead.\n",
      "\n",
      "WARNING:tensorflow:From C:\\Users\\mit017\\anaconda3\\Lib\\site-packages\\keras\\src\\losses.py:2976: The name tf.losses.sparse_softmax_cross_entropy is deprecated. Please use tf.compat.v1.losses.sparse_softmax_cross_entropy instead.\n",
      "\n",
      "\n",
      "               Class    Images   Targets         P         R   mAP@0.5        F1: 100%|##########| 1/1 [00:13<00:00, 13.64s/it]\n",
      "               Class    Images   Targets         P         R   mAP@0.5        F1: 100%|##########| 1/1 [00:14<00:00, 14.60s/it]\n",
      "\n",
      "  0%|          | 0/4 [00:00<?, ?it/s]2024-03-04 15:04:35.225309: I tensorflow/core/util/port.cc:113] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
      "2024-03-04 15:04:35.323428: I tensorflow/core/util/port.cc:113] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
      "2024-03-04 15:04:35.406620: I tensorflow/core/util/port.cc:113] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
      "WARNING:tensorflow:From C:\\Users\\mit017\\anaconda3\\Lib\\site-packages\\keras\\src\\losses.py:2976: The name tf.losses.sparse_softmax_cross_entropy is deprecated. Please use tf.compat.v1.losses.sparse_softmax_cross_entropy instead.\n",
      "\n",
      "WARNING:tensorflow:From C:\\Users\\mit017\\anaconda3\\Lib\\site-packages\\keras\\src\\losses.py:2976: The name tf.losses.sparse_softmax_cross_entropy is deprecated. Please use tf.compat.v1.losses.sparse_softmax_cross_entropy instead.\n",
      "\n",
      "WARNING:tensorflow:From C:\\Users\\mit017\\anaconda3\\Lib\\site-packages\\keras\\src\\losses.py:2976: The name tf.losses.sparse_softmax_cross_entropy is deprecated. Please use tf.compat.v1.losses.sparse_softmax_cross_entropy instead.\n",
      "\n",
      "\n",
      "   819/820        0G      1.33    0.0329         0      1.36         7       320:   0%|          | 0/4 [00:13<?, ?it/s]\n",
      "   819/820        0G      1.33    0.0329         0      1.36         7       320:  25%|##5       | 1/4 [00:13<00:39, 13.10s/it]\n",
      "   819/820        0G      1.51    0.0301         0      1.54         3       320:  25%|##5       | 1/4 [00:14<00:39, 13.10s/it]\n",
      "   819/820        0G      1.51    0.0301         0      1.54         3       320:  50%|#####     | 2/4 [00:14<00:12,  6.39s/it]\n",
      "   819/820        0G      1.52    0.0265         0      1.55         5       320:  50%|#####     | 2/4 [00:16<00:12,  6.39s/it]\n",
      "   819/820        0G      1.52    0.0265         0      1.55         5       320:  75%|#######5  | 3/4 [00:16<00:04,  4.27s/it]\n",
      "   819/820        0G      1.53    0.0284         0      1.56         7       320:  75%|#######5  | 3/4 [00:18<00:04,  4.27s/it]\n",
      "   819/820        0G      1.53    0.0284         0      1.56         7       320: 100%|##########| 4/4 [00:18<00:00,  3.27s/it]\n",
      "   819/820        0G      1.53    0.0284         0      1.56         7       320: 100%|##########| 4/4 [00:19<00:00,  4.82s/it]\n",
      "\n",
      "               Class    Images   Targets         P         R   mAP@0.5        F1:   0%|          | 0/1 [00:00<?, ?it/s]2024-03-04 15:04:54.822071: I tensorflow/core/util/port.cc:113] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
      "2024-03-04 15:04:54.853299: I tensorflow/core/util/port.cc:113] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
      "2024-03-04 15:04:54.853358: I tensorflow/core/util/port.cc:113] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
      "WARNING:tensorflow:From C:\\Users\\mit017\\anaconda3\\Lib\\site-packages\\keras\\src\\losses.py:2976: The name tf.losses.sparse_softmax_cross_entropy is deprecated. Please use tf.compat.v1.losses.sparse_softmax_cross_entropy instead.\n",
      "\n",
      "WARNING:tensorflow:From C:\\Users\\mit017\\anaconda3\\Lib\\site-packages\\keras\\src\\losses.py:2976: The name tf.losses.sparse_softmax_cross_entropy is deprecated. Please use tf.compat.v1.losses.sparse_softmax_cross_entropy instead.\n",
      "\n",
      "WARNING:tensorflow:From C:\\Users\\mit017\\anaconda3\\Lib\\site-packages\\keras\\src\\losses.py:2976: The name tf.losses.sparse_softmax_cross_entropy is deprecated. Please use tf.compat.v1.losses.sparse_softmax_cross_entropy instead.\n",
      "\n",
      "\n",
      "               Class    Images   Targets         P         R   mAP@0.5        F1: 100%|##########| 1/1 [00:13<00:00, 13.47s/it]\n",
      "               Class    Images   Targets         P         R   mAP@0.5        F1: 100%|##########| 1/1 [00:14<00:00, 14.42s/it]\n",
      "\n",
      "  0%|          | 0/4 [00:00<?, ?it/s]2024-03-04 15:05:09.218537: I tensorflow/core/util/port.cc:113] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
      "2024-03-04 15:05:09.324515: I tensorflow/core/util/port.cc:113] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
      "2024-03-04 15:05:09.408883: I tensorflow/core/util/port.cc:113] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
      "WARNING:tensorflow:From C:\\Users\\mit017\\anaconda3\\Lib\\site-packages\\keras\\src\\losses.py:2976: The name tf.losses.sparse_softmax_cross_entropy is deprecated. Please use tf.compat.v1.losses.sparse_softmax_cross_entropy instead.\n",
      "\n",
      "WARNING:tensorflow:From C:\\Users\\mit017\\anaconda3\\Lib\\site-packages\\keras\\src\\losses.py:2976: The name tf.losses.sparse_softmax_cross_entropy is deprecated. Please use tf.compat.v1.losses.sparse_softmax_cross_entropy instead.\n",
      "\n",
      "WARNING:tensorflow:From C:\\Users\\mit017\\anaconda3\\Lib\\site-packages\\keras\\src\\losses.py:2976: The name tf.losses.sparse_softmax_cross_entropy is deprecated. Please use tf.compat.v1.losses.sparse_softmax_cross_entropy instead.\n",
      "\n",
      "\n",
      "   820/820        0G      1.16    0.0225         0      1.18         2       320:   0%|          | 0/4 [00:12<?, ?it/s]\n",
      "   820/820        0G      1.16    0.0225         0      1.18         2       320:  25%|##5       | 1/4 [00:12<00:38, 12.88s/it]\n",
      "   820/820        0G      1.06    0.0256         0      1.09         4       320:  25%|##5       | 1/4 [00:14<00:38, 12.88s/it]\n",
      "   820/820        0G      1.06    0.0256         0      1.09         4       320:  50%|#####     | 2/4 [00:14<00:12,  6.31s/it]\n",
      "   820/820        0G      1.03    0.0241         0      1.05         2       320:  50%|#####     | 2/4 [00:16<00:12,  6.31s/it]\n",
      "   820/820        0G      1.03    0.0241         0      1.05         2       320:  75%|#######5  | 3/4 [00:16<00:04,  4.22s/it]\n",
      "   820/820        0G     0.991    0.0236         0      1.01         3       320:  75%|#######5  | 3/4 [00:18<00:04,  4.22s/it]\n",
      "   820/820        0G     0.991    0.0236         0      1.01         3       320: 100%|##########| 4/4 [00:18<00:00,  3.24s/it]\n",
      "   820/820        0G     0.991    0.0236         0      1.01         3       320: 100%|##########| 4/4 [00:19<00:00,  4.76s/it]\n",
      "\n",
      "               Class    Images   Targets         P         R   mAP@0.5        F1:   0%|          | 0/1 [00:00<?, ?it/s]2024-03-04 15:05:28.580133: I tensorflow/core/util/port.cc:113] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
      "2024-03-04 15:05:28.582234: I tensorflow/core/util/port.cc:113] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
      "2024-03-04 15:05:28.582970: I tensorflow/core/util/port.cc:113] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
      "WARNING:tensorflow:From C:\\Users\\mit017\\anaconda3\\Lib\\site-packages\\keras\\src\\losses.py:2976: The name tf.losses.sparse_softmax_cross_entropy is deprecated. Please use tf.compat.v1.losses.sparse_softmax_cross_entropy instead.\n",
      "\n",
      "WARNING:tensorflow:From C:\\Users\\mit017\\anaconda3\\Lib\\site-packages\\keras\\src\\losses.py:2976: The name tf.losses.sparse_softmax_cross_entropy is deprecated. Please use tf.compat.v1.losses.sparse_softmax_cross_entropy instead.\n",
      "\n",
      "WARNING:tensorflow:From C:\\Users\\mit017\\anaconda3\\Lib\\site-packages\\keras\\src\\losses.py:2976: The name tf.losses.sparse_softmax_cross_entropy is deprecated. Please use tf.compat.v1.losses.sparse_softmax_cross_entropy instead.\n",
      "\n",
      "\n",
      "               Class    Images   Targets         P         R   mAP@0.5        F1: 100%|##########| 1/1 [00:13<00:00, 13.44s/it]\n",
      "               Class    Images   Targets         P         R   mAP@0.5        F1: 100%|##########| 1/1 [00:14<00:00, 14.39s/it]\n"
     ]
    }
   ],
   "source": [
    "!python train.py --epochs 15 --weights weights/last.pt --batch-size 3 --cfg yolov3-spp.cfg --data custom.data --nosave --device cpu"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "4f508e3c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "현재 작업 디렉토리: C:\\Users\\mit017\\Desktop\\myproject\\XRAY_PROJECT\\XrayInspection\\dataset\\test1\\yolov3\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "\n",
    "# 변경하고 싶은 디렉토리 경로\n",
    "new_directory = 'C:\\\\Users\\\\mit017\\\\Desktop\\\\myproject\\\\XRAY_PROJECT\\\\XrayInspection\\\\dataset\\\\test1\\\\yolov3'\n",
    "\n",
    "# 현재 작업 디렉토리 변경\n",
    "os.chdir(new_directory)\n",
    "\n",
    "# 현재 작업 디렉토리 확인\n",
    "print(\"현재 작업 디렉토리:\", os.getcwd())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "06776158",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: TensorFlow in c:\\users\\mit017\\anaconda3\\lib\\site-packages (2.15.0)\n",
      "Requirement already satisfied: tensorflow-intel==2.15.0 in c:\\users\\mit017\\anaconda3\\lib\\site-packages (from TensorFlow) (2.15.0)\n",
      "Requirement already satisfied: absl-py>=1.0.0 in c:\\users\\mit017\\anaconda3\\lib\\site-packages (from tensorflow-intel==2.15.0->TensorFlow) (2.1.0)\n",
      "Requirement already satisfied: astunparse>=1.6.0 in c:\\users\\mit017\\anaconda3\\lib\\site-packages (from tensorflow-intel==2.15.0->TensorFlow) (1.6.3)\n",
      "Requirement already satisfied: flatbuffers>=23.5.26 in c:\\users\\mit017\\anaconda3\\lib\\site-packages (from tensorflow-intel==2.15.0->TensorFlow) (23.5.26)\n",
      "Requirement already satisfied: gast!=0.5.0,!=0.5.1,!=0.5.2,>=0.2.1 in c:\\users\\mit017\\anaconda3\\lib\\site-packages (from tensorflow-intel==2.15.0->TensorFlow) (0.5.4)\n",
      "Requirement already satisfied: google-pasta>=0.1.1 in c:\\users\\mit017\\anaconda3\\lib\\site-packages (from tensorflow-intel==2.15.0->TensorFlow) (0.2.0)\n",
      "Requirement already satisfied: h5py>=2.9.0 in c:\\users\\mit017\\anaconda3\\lib\\site-packages (from tensorflow-intel==2.15.0->TensorFlow) (3.9.0)\n",
      "Requirement already satisfied: libclang>=13.0.0 in c:\\users\\mit017\\anaconda3\\lib\\site-packages (from tensorflow-intel==2.15.0->TensorFlow) (16.0.6)\n",
      "Requirement already satisfied: ml-dtypes~=0.2.0 in c:\\users\\mit017\\anaconda3\\lib\\site-packages (from tensorflow-intel==2.15.0->TensorFlow) (0.2.0)\n",
      "Requirement already satisfied: numpy<2.0.0,>=1.23.5 in c:\\users\\mit017\\anaconda3\\lib\\site-packages (from tensorflow-intel==2.15.0->TensorFlow) (1.24.3)\n",
      "Requirement already satisfied: opt-einsum>=2.3.2 in c:\\users\\mit017\\anaconda3\\lib\\site-packages (from tensorflow-intel==2.15.0->TensorFlow) (3.3.0)\n",
      "Requirement already satisfied: packaging in c:\\users\\mit017\\anaconda3\\lib\\site-packages (from tensorflow-intel==2.15.0->TensorFlow) (23.1)\n",
      "Requirement already satisfied: protobuf!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<5.0.0dev,>=3.20.3 in c:\\users\\mit017\\anaconda3\\lib\\site-packages (from tensorflow-intel==2.15.0->TensorFlow) (4.25.3)\n",
      "Requirement already satisfied: setuptools in c:\\users\\mit017\\anaconda3\\lib\\site-packages (from tensorflow-intel==2.15.0->TensorFlow) (69.1.1)\n",
      "Requirement already satisfied: six>=1.12.0 in c:\\users\\mit017\\anaconda3\\lib\\site-packages (from tensorflow-intel==2.15.0->TensorFlow) (1.16.0)\n",
      "Requirement already satisfied: termcolor>=1.1.0 in c:\\users\\mit017\\anaconda3\\lib\\site-packages (from tensorflow-intel==2.15.0->TensorFlow) (2.4.0)\n",
      "Requirement already satisfied: typing-extensions>=3.6.6 in c:\\users\\mit017\\anaconda3\\lib\\site-packages (from tensorflow-intel==2.15.0->TensorFlow) (4.10.0)\n",
      "Requirement already satisfied: wrapt<1.15,>=1.11.0 in c:\\users\\mit017\\anaconda3\\lib\\site-packages (from tensorflow-intel==2.15.0->TensorFlow) (1.14.1)\n",
      "Requirement already satisfied: tensorflow-io-gcs-filesystem>=0.23.1 in c:\\users\\mit017\\anaconda3\\lib\\site-packages (from tensorflow-intel==2.15.0->TensorFlow) (0.31.0)\n",
      "Requirement already satisfied: grpcio<2.0,>=1.24.3 in c:\\users\\mit017\\anaconda3\\lib\\site-packages (from tensorflow-intel==2.15.0->TensorFlow) (1.60.1)\n",
      "Requirement already satisfied: tensorboard<2.16,>=2.15 in c:\\users\\mit017\\anaconda3\\lib\\site-packages (from tensorflow-intel==2.15.0->TensorFlow) (2.15.2)\n",
      "Requirement already satisfied: tensorflow-estimator<2.16,>=2.15.0 in c:\\users\\mit017\\anaconda3\\lib\\site-packages (from tensorflow-intel==2.15.0->TensorFlow) (2.15.0)\n",
      "Requirement already satisfied: keras<2.16,>=2.15.0 in c:\\users\\mit017\\anaconda3\\lib\\site-packages (from tensorflow-intel==2.15.0->TensorFlow) (2.15.0)\n",
      "Requirement already satisfied: wheel<1.0,>=0.23.0 in c:\\users\\mit017\\anaconda3\\lib\\site-packages (from astunparse>=1.6.0->tensorflow-intel==2.15.0->TensorFlow) (0.38.4)\n",
      "Requirement already satisfied: google-auth<3,>=1.6.3 in c:\\users\\mit017\\anaconda3\\lib\\site-packages (from tensorboard<2.16,>=2.15->tensorflow-intel==2.15.0->TensorFlow) (2.28.0)\n",
      "Requirement already satisfied: google-auth-oauthlib<2,>=0.5 in c:\\users\\mit017\\anaconda3\\lib\\site-packages (from tensorboard<2.16,>=2.15->tensorflow-intel==2.15.0->TensorFlow) (1.2.0)\n",
      "Requirement already satisfied: markdown>=2.6.8 in c:\\users\\mit017\\anaconda3\\lib\\site-packages (from tensorboard<2.16,>=2.15->tensorflow-intel==2.15.0->TensorFlow) (3.4.1)\n",
      "Requirement already satisfied: requests<3,>=2.21.0 in c:\\users\\mit017\\anaconda3\\lib\\site-packages (from tensorboard<2.16,>=2.15->tensorflow-intel==2.15.0->TensorFlow) (2.31.0)\n",
      "Requirement already satisfied: tensorboard-data-server<0.8.0,>=0.7.0 in c:\\users\\mit017\\anaconda3\\lib\\site-packages (from tensorboard<2.16,>=2.15->tensorflow-intel==2.15.0->TensorFlow) (0.7.2)\n",
      "Requirement already satisfied: werkzeug>=1.0.1 in c:\\users\\mit017\\anaconda3\\lib\\site-packages (from tensorboard<2.16,>=2.15->tensorflow-intel==2.15.0->TensorFlow) (2.2.3)\n",
      "Requirement already satisfied: cachetools<6.0,>=2.0.0 in c:\\users\\mit017\\anaconda3\\lib\\site-packages (from google-auth<3,>=1.6.3->tensorboard<2.16,>=2.15->tensorflow-intel==2.15.0->TensorFlow) (5.3.2)\n",
      "Requirement already satisfied: pyasn1-modules>=0.2.1 in c:\\users\\mit017\\anaconda3\\lib\\site-packages (from google-auth<3,>=1.6.3->tensorboard<2.16,>=2.15->tensorflow-intel==2.15.0->TensorFlow) (0.2.8)\n",
      "Requirement already satisfied: rsa<5,>=3.1.4 in c:\\users\\mit017\\anaconda3\\lib\\site-packages (from google-auth<3,>=1.6.3->tensorboard<2.16,>=2.15->tensorflow-intel==2.15.0->TensorFlow) (4.9)\n",
      "Requirement already satisfied: requests-oauthlib>=0.7.0 in c:\\users\\mit017\\anaconda3\\lib\\site-packages (from google-auth-oauthlib<2,>=0.5->tensorboard<2.16,>=2.15->tensorflow-intel==2.15.0->TensorFlow) (1.3.1)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in c:\\users\\mit017\\anaconda3\\lib\\site-packages (from requests<3,>=2.21.0->tensorboard<2.16,>=2.15->tensorflow-intel==2.15.0->TensorFlow) (2.0.4)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\mit017\\anaconda3\\lib\\site-packages (from requests<3,>=2.21.0->tensorboard<2.16,>=2.15->tensorflow-intel==2.15.0->TensorFlow) (3.4)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\users\\mit017\\anaconda3\\lib\\site-packages (from requests<3,>=2.21.0->tensorboard<2.16,>=2.15->tensorflow-intel==2.15.0->TensorFlow) (1.26.16)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\mit017\\anaconda3\\lib\\site-packages (from requests<3,>=2.21.0->tensorboard<2.16,>=2.15->tensorflow-intel==2.15.0->TensorFlow) (2024.2.2)\n",
      "Requirement already satisfied: MarkupSafe>=2.1.1 in c:\\users\\mit017\\anaconda3\\lib\\site-packages (from werkzeug>=1.0.1->tensorboard<2.16,>=2.15->tensorflow-intel==2.15.0->TensorFlow) (2.1.1)\n",
      "Requirement already satisfied: pyasn1<0.5.0,>=0.4.6 in c:\\users\\mit017\\anaconda3\\lib\\site-packages (from pyasn1-modules>=0.2.1->google-auth<3,>=1.6.3->tensorboard<2.16,>=2.15->tensorflow-intel==2.15.0->TensorFlow) (0.4.8)\n",
      "Requirement already satisfied: oauthlib>=3.0.0 in c:\\users\\mit017\\anaconda3\\lib\\site-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<2,>=0.5->tensorboard<2.16,>=2.15->tensorflow-intel==2.15.0->TensorFlow) (3.2.2)\n"
     ]
    }
   ],
   "source": [
    "!pip install TensorFlow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "215acc46",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ['KMP_DUPLICATE_LIB_OK']='True'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "4ca07b4f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: tensorboard in c:\\users\\mit017\\anaconda3\\lib\\site-packages (2.15.2)\n",
      "Requirement already satisfied: absl-py>=0.4 in c:\\users\\mit017\\anaconda3\\lib\\site-packages (from tensorboard) (2.1.0)\n",
      "Requirement already satisfied: grpcio>=1.48.2 in c:\\users\\mit017\\anaconda3\\lib\\site-packages (from tensorboard) (1.60.1)\n",
      "Requirement already satisfied: google-auth<3,>=1.6.3 in c:\\users\\mit017\\anaconda3\\lib\\site-packages (from tensorboard) (2.28.0)\n",
      "Requirement already satisfied: google-auth-oauthlib<2,>=0.5 in c:\\users\\mit017\\anaconda3\\lib\\site-packages (from tensorboard) (1.2.0)\n",
      "Requirement already satisfied: markdown>=2.6.8 in c:\\users\\mit017\\anaconda3\\lib\\site-packages (from tensorboard) (3.4.1)\n",
      "Requirement already satisfied: numpy>=1.12.0 in c:\\users\\mit017\\anaconda3\\lib\\site-packages (from tensorboard) (1.24.3)\n",
      "Requirement already satisfied: protobuf!=4.24.0,>=3.19.6 in c:\\users\\mit017\\anaconda3\\lib\\site-packages (from tensorboard) (4.25.3)\n",
      "Requirement already satisfied: requests<3,>=2.21.0 in c:\\users\\mit017\\anaconda3\\lib\\site-packages (from tensorboard) (2.31.0)\n",
      "Requirement already satisfied: setuptools>=41.0.0 in c:\\users\\mit017\\anaconda3\\lib\\site-packages (from tensorboard) (69.1.1)\n",
      "Requirement already satisfied: six>1.9 in c:\\users\\mit017\\anaconda3\\lib\\site-packages (from tensorboard) (1.16.0)\n",
      "Requirement already satisfied: tensorboard-data-server<0.8.0,>=0.7.0 in c:\\users\\mit017\\anaconda3\\lib\\site-packages (from tensorboard) (0.7.2)\n",
      "Requirement already satisfied: werkzeug>=1.0.1 in c:\\users\\mit017\\anaconda3\\lib\\site-packages (from tensorboard) (2.2.3)\n",
      "Requirement already satisfied: cachetools<6.0,>=2.0.0 in c:\\users\\mit017\\anaconda3\\lib\\site-packages (from google-auth<3,>=1.6.3->tensorboard) (5.3.2)\n",
      "Requirement already satisfied: pyasn1-modules>=0.2.1 in c:\\users\\mit017\\anaconda3\\lib\\site-packages (from google-auth<3,>=1.6.3->tensorboard) (0.2.8)\n",
      "Requirement already satisfied: rsa<5,>=3.1.4 in c:\\users\\mit017\\anaconda3\\lib\\site-packages (from google-auth<3,>=1.6.3->tensorboard) (4.9)\n",
      "Requirement already satisfied: requests-oauthlib>=0.7.0 in c:\\users\\mit017\\anaconda3\\lib\\site-packages (from google-auth-oauthlib<2,>=0.5->tensorboard) (1.3.1)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in c:\\users\\mit017\\anaconda3\\lib\\site-packages (from requests<3,>=2.21.0->tensorboard) (2.0.4)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\mit017\\anaconda3\\lib\\site-packages (from requests<3,>=2.21.0->tensorboard) (3.4)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\users\\mit017\\anaconda3\\lib\\site-packages (from requests<3,>=2.21.0->tensorboard) (1.26.16)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\mit017\\anaconda3\\lib\\site-packages (from requests<3,>=2.21.0->tensorboard) (2024.2.2)\n",
      "Requirement already satisfied: MarkupSafe>=2.1.1 in c:\\users\\mit017\\anaconda3\\lib\\site-packages (from werkzeug>=1.0.1->tensorboard) (2.1.1)\n",
      "Requirement already satisfied: pyasn1<0.5.0,>=0.4.6 in c:\\users\\mit017\\anaconda3\\lib\\site-packages (from pyasn1-modules>=0.2.1->google-auth<3,>=1.6.3->tensorboard) (0.4.8)\n",
      "Requirement already satisfied: oauthlib>=3.0.0 in c:\\users\\mit017\\anaconda3\\lib\\site-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<2,>=0.5->tensorboard) (3.2.2)\n"
     ]
    }
   ],
   "source": [
    "!pip install tensorboard"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "3a882924",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Namespace(cfg='yolov3-spp.cfg', names='classes.names', weights='weights/last.pt', source='images', output='result', img_size=512, conf_thres=0.3, iou_thres=0.6, fourcc='mp4v', half=False, device='', view_img=False, save_txt=False, classes=None, agnostic_nms=False, augment=False)\n",
      "Using CPU\n",
      "\n",
      "Model Summary: 225 layers, 6.25733e+07 parameters, 6.25733e+07 gradients\n",
      "image 1/15 images\\001_20200622_203312(6).jpg: 416x512 Done. (0.505s)\n",
      "image 2/15 images\\001_20200623_003516(8).jpg: 416x512 Done. (0.421s)\n",
      "image 3/15 images\\001_20200901_003429(1).jpg: 416x512 Done. (0.415s)\n",
      "image 4/15 images\\001_20200922_163329(0).jpg: 416x512 Done. (0.412s)\n",
      "image 5/15 images\\001_20200922_163332(2).jpg: 416x512 Done. (0.428s)\n",
      "image 6/15 images\\002_20200714_043029(1).jpg: 512x512 1 defects, Done. (0.645s)\n",
      "image 7/15 images\\002_20200715_042416(9).jpg: 512x512 Done. (0.545s)\n",
      "image 8/15 images\\002_20200831_083545(0).jpg: 512x512 Done. (0.529s)\n",
      "image 9/15 images\\002_20200831_123134(5).jpg: 512x512 Done. (0.527s)\n",
      "image 10/15 images\\002_20200908_043137(8).jpg: 512x512 Done. (0.519s)\n",
      "image 11/15 images\\002_20200915_003459(4).jpg: 512x512 Done. (0.503s)\n",
      "image 12/15 images\\002_20200917_043110(7).jpg: 512x512 Done. (0.514s)\n",
      "image 13/15 images\\002_20200917_202952(6).jpg: 512x512 Done. (0.522s)\n",
      "image 14/15 images\\002_20200917_203001(5).jpg: 512x512 1 defects, Done. (0.502s)\n",
      "image 15/15 images\\002_20200922_083747(7).jpg: 512x512 1 defects, Done. (0.509s)\n",
      "Results saved to C:\\Users\\mit017\\Desktop\\myproject\\XRAY_PROJECT\\XrayInspection\\dataset\\test1\\yolov3\\result\n",
      "Done. (7.680s)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\mit017\\anaconda3\\Lib\\site-packages\\torch\\functional.py:507: UserWarning: torch.meshgrid: in an upcoming release, it will be required to pass the indexing argument. (Triggered internally at ..\\aten\\src\\ATen\\native\\TensorShape.cpp:3550.)\n",
      "  return _VF.meshgrid(tensors, **kwargs)  # type: ignore[attr-defined]\n"
     ]
    }
   ],
   "source": [
    "!python detect.py --weights weights/last.pt --source images --cfg yolov3-spp.cfg --names classes.names --output result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "9b5f3498",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Namespace(cfg='yolov3-spp.cfg', data='custom.data', weights='weights/last.pt', batch_size=16, img_size=512, conf_thres=0.001, iou_thres=0.6, save_json=False, task='test', device='', single_cls=False, augment=False)\n",
      "Using CPU\n",
      "\n",
      "WARNING: smart bias initialization failure.\n",
      "WARNING: smart bias initialization failure.\n",
      "WARNING: smart bias initialization failure.\n",
      "Model Summary: 225 layers, 6.25733e+07 parameters, 6.25733e+07 gradients\n",
      "Fusing layers...\n",
      "Model Summary: 152 layers, 6.25465e+07 parameters, 6.25465e+07 gradients\n",
      "                 all         3         7      0.78     0.571     0.675     0.659\n",
      "Speed: 465.3/3.8/469.0 ms inference/NMS/total per 512x512 image at batch-size 3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "  0%|          | 0/3 [00:00<?, ?it/s]\n",
      "Caching labels C:\\Users\\mit017\\Desktop\\myproject\\XRAY_PROJECT\\XrayInspection\\dataset\\test1\\yolov3\\test.txt (3 found, 0 missing, 0 empty, 0 duplicate, for 3 images): 100%|##########| 3/3 [00:00<00:00, 998.01it/s]\n",
      "\n",
      "               Class    Images   Targets         P         R   mAP@0.5        F1:   0%|          | 0/1 [00:00<?, ?it/s]C:\\Users\\mit017\\anaconda3\\Lib\\site-packages\\torch\\functional.py:507: UserWarning: torch.meshgrid: in an upcoming release, it will be required to pass the indexing argument. (Triggered internally at ..\\aten\\src\\ATen\\native\\TensorShape.cpp:3550.)\n",
      "  return _VF.meshgrid(tensors, **kwargs)  # type: ignore[attr-defined]\n",
      "\n",
      "               Class    Images   Targets         P         R   mAP@0.5        F1: 100%|##########| 1/1 [00:06<00:00,  6.16s/it]\n",
      "               Class    Images   Targets         P         R   mAP@0.5        F1: 100%|##########| 1/1 [00:06<00:00,  6.68s/it]\n"
     ]
    }
   ],
   "source": [
    "!python test.py --cfg yolov3-spp.cfg --data custom.data --weights weights/last.pt"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2c6adc73",
   "metadata": {},
   "source": [
    "## 200개 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "33d84dd4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-> Please ignore this error message\n",
      "\n",
      "Showing image 0/199, path: input\\002_20200622_203136(3).bmp\n",
      "Welcome!\n",
      " Press [h] for help.\n",
      "Showing image 1/199, path: input\\002_20200622_203140(8).bmp\n",
      "Showing image 1/199, path: input\\002_20200622_203140(8).bmp\n",
      "Showing image 2/199, path: input\\002_20200622_203145(3).bmp\n",
      "Showing image 2/199, path: input\\002_20200622_203145(3).bmp\n",
      "Showing image 3/199, path: input\\002_20200622_203149(8).bmp\n",
      "Showing image 3/199, path: input\\002_20200622_203149(8).bmp\n",
      "Showing image 4/199, path: input\\002_20200622_203154(3).bmp\n",
      "Showing image 4/199, path: input\\002_20200622_203154(3).bmp\n",
      "Showing image 5/199, path: input\\002_20200622_203158(8).bmp\n",
      "Showing image 5/199, path: input\\002_20200622_203158(8).bmp\n",
      "Showing image 6/199, path: input\\002_20200623_003351(2).bmp\n",
      "Showing image 6/199, path: input\\002_20200623_003351(2).bmp\n",
      "Showing image 7/199, path: input\\002_20200623_003355(7).bmp\n",
      "Showing image 7/199, path: input\\002_20200623_003355(7).bmp\n",
      "Showing image 8/199, path: input\\002_20200623_003400(2).bmp\n",
      "Showing image 8/199, path: input\\002_20200623_003400(2).bmp\n",
      "Showing image 9/199, path: input\\002_20200623_003404(7).bmp\n",
      "Showing image 9/199, path: input\\002_20200623_003404(7).bmp\n",
      "Showing image 10/199, path: input\\002_20200623_003409(2).bmp\n",
      "Showing image 10/199, path: input\\002_20200623_003409(2).bmp\n",
      "Showing image 11/199, path: input\\002_20200623_003413(7).bmp\n",
      "Showing image 11/199, path: input\\002_20200623_003413(7).bmp\n",
      "Showing image 12/199, path: input\\002_20200623_043056(0).bmp\n",
      "Showing image 12/199, path: input\\002_20200623_043056(0).bmp\n",
      "Showing image 13/199, path: input\\002_20200623_043100(6).bmp\n",
      "Showing image 13/199, path: input\\002_20200623_043100(6).bmp\n",
      "Showing image 14/199, path: input\\002_20200623_043105(0).bmp\n",
      "Showing image 14/199, path: input\\002_20200623_043105(0).bmp\n",
      "Showing image 15/199, path: input\\002_20200623_043109(4).bmp\n",
      "Showing image 15/199, path: input\\002_20200623_043109(4).bmp\n",
      "Showing image 16/199, path: input\\002_20200623_043115(4).bmp\n",
      "Showing image 16/199, path: input\\002_20200623_043115(4).bmp\n",
      "Showing image 17/199, path: input\\002_20200623_043120(0).bmp\n",
      "Showing image 17/199, path: input\\002_20200623_043120(0).bmp\n",
      "Showing image 18/199, path: input\\002_20200623_082249(3).bmp\n",
      "Showing image 18/199, path: input\\002_20200623_082249(3).bmp\n",
      "Showing image 19/199, path: input\\002_20200623_082253(8).bmp\n",
      "Showing image 19/199, path: input\\002_20200623_082253(8).bmp\n",
      "Showing image 20/199, path: input\\002_20200623_082258(4).bmp\n",
      "Showing image 20/199, path: input\\002_20200623_082258(4).bmp\n",
      "Showing image 21/199, path: input\\002_20200623_082302(7).bmp\n",
      "Showing image 21/199, path: input\\002_20200623_082302(7).bmp\n",
      "Showing image 22/199, path: input\\002_20200623_082307(2).bmp\n",
      "Showing image 22/199, path: input\\002_20200623_082307(2).bmp\n",
      "Showing image 23/199, path: input\\002_20200623_082311(8).bmp\n",
      "Showing image 23/199, path: input\\002_20200623_082311(8).bmp\n",
      "Showing image 24/199, path: input\\002_20200623_123042(0).bmp\n",
      "Showing image 24/199, path: input\\002_20200623_123042(0).bmp\n",
      "Showing image 25/199, path: input\\002_20200623_123046(4).bmp\n",
      "Showing image 25/199, path: input\\002_20200623_123046(4).bmp\n",
      "Showing image 26/199, path: input\\002_20200623_123051(1).bmp\n",
      "Showing image 26/199, path: input\\002_20200623_123051(1).bmp\n",
      "Showing image 27/199, path: input\\002_20200623_123055(5).bmp\n",
      "Showing image 27/199, path: input\\002_20200623_123055(5).bmp\n",
      "Showing image 28/199, path: input\\002_20200623_123100(0).bmp\n",
      "Showing image 28/199, path: input\\002_20200623_123100(0).bmp\n",
      "Showing image 29/199, path: input\\002_20200623_123104(5).bmp\n",
      "Showing image 29/199, path: input\\002_20200623_123104(5).bmp\n",
      "Showing image 30/199, path: input\\002_20200623_163020(3).bmp\n",
      "Showing image 30/199, path: input\\002_20200623_163020(3).bmp\n",
      "Showing image 31/199, path: input\\002_20200623_163023(3).bmp\n",
      "Showing image 31/199, path: input\\002_20200623_163023(3).bmp\n",
      "Showing image 32/199, path: input\\002_20200623_163026(3).bmp\n",
      "Showing image 32/199, path: input\\002_20200623_163026(3).bmp\n",
      "Showing image 33/199, path: input\\002_20200623_163029(6).bmp\n",
      "Showing image 33/199, path: input\\002_20200623_163029(6).bmp\n",
      "Showing image 34/199, path: input\\002_20200623_163032(5).bmp\n",
      "Showing image 34/199, path: input\\002_20200623_163032(5).bmp\n",
      "Showing image 35/199, path: input\\002_20200623_163035(5).bmp\n",
      "Showing image 35/199, path: input\\002_20200623_163035(5).bmp\n",
      "Showing image 36/199, path: input\\002_20200623_203033(6).bmp\n",
      "Showing image 36/199, path: input\\002_20200623_203033(6).bmp\n",
      "Showing image 37/199, path: input\\002_20200623_203038(0).bmp\n",
      "Showing image 37/199, path: input\\002_20200623_203038(0).bmp\n",
      "Showing image 38/199, path: input\\002_20200623_203042(5).bmp\n",
      "Showing image 38/199, path: input\\002_20200623_203042(5).bmp\n",
      "Showing image 39/199, path: input\\002_20200623_203047(0).bmp\n",
      "Showing image 39/199, path: input\\002_20200623_203047(0).bmp\n",
      "Showing image 40/199, path: input\\002_20200623_203050(0).bmp\n",
      "Showing image 40/199, path: input\\002_20200623_203050(0).bmp\n",
      "Showing image 41/199, path: input\\002_20200623_203054(6).bmp\n",
      "Showing image 41/199, path: input\\002_20200623_203054(6).bmp\n",
      "Showing image 42/199, path: input\\002_20200624_003115(6).bmp\n",
      "Showing image 42/199, path: input\\002_20200624_003115(6).bmp\n",
      "Showing image 43/199, path: input\\002_20200624_003118(6).bmp\n",
      "Showing image 43/199, path: input\\002_20200624_003118(6).bmp\n",
      "Showing image 44/199, path: input\\002_20200624_003123(0).bmp\n",
      "Showing image 44/199, path: input\\002_20200624_003123(0).bmp\n",
      "Showing image 45/199, path: input\\002_20200624_003127(5).bmp\n",
      "Showing image 45/199, path: input\\002_20200624_003127(5).bmp\n",
      "Showing image 46/199, path: input\\002_20200624_003132(0).bmp\n",
      "Showing image 46/199, path: input\\002_20200624_003132(0).bmp\n",
      "Showing image 47/199, path: input\\002_20200624_003136(5).bmp\n",
      "Showing image 47/199, path: input\\002_20200624_003136(5).bmp\n",
      "Showing image 48/199, path: input\\002_20200624_043136(9).bmp\n",
      "Showing image 48/199, path: input\\002_20200624_043136(9).bmp\n",
      "Showing image 49/199, path: input\\002_20200624_043141(4).bmp\n",
      "Showing image 49/199, path: input\\002_20200624_043141(4).bmp\n",
      "Showing image 50/199, path: input\\002_20200624_043145(8).bmp\n",
      "Showing image 50/199, path: input\\002_20200624_043145(8).bmp\n",
      "Showing image 51/199, path: input\\002_20200624_043150(3).bmp\n",
      "Showing image 51/199, path: input\\002_20200624_043150(3).bmp\n",
      "Showing image 52/199, path: input\\002_20200624_043154(8).bmp\n",
      "Showing image 52/199, path: input\\002_20200624_043154(8).bmp\n",
      "Showing image 53/199, path: input\\002_20200624_043159(4).bmp\n",
      "Showing image 53/199, path: input\\002_20200624_043159(4).bmp\n",
      "Showing image 54/199, path: input\\002_20200624_083032(4).bmp\n",
      "Showing image 54/199, path: input\\002_20200624_083032(4).bmp\n",
      "Showing image 55/199, path: input\\002_20200624_083036(9).bmp\n",
      "Showing image 55/199, path: input\\002_20200624_083036(9).bmp\n",
      "Showing image 56/199, path: input\\002_20200624_083041(3).bmp\n",
      "Showing image 56/199, path: input\\002_20200624_083041(3).bmp\n",
      "Showing image 57/199, path: input\\002_20200624_083045(8).bmp\n",
      "Showing image 57/199, path: input\\002_20200624_083045(8).bmp\n",
      "Showing image 58/199, path: input\\002_20200624_083050(4).bmp\n",
      "Showing image 58/199, path: input\\002_20200624_083050(4).bmp\n",
      "Showing image 59/199, path: input\\002_20200624_083054(9).bmp\n",
      "Showing image 59/199, path: input\\002_20200624_083054(9).bmp\n",
      "Showing image 60/199, path: input\\002_20200624_123144(0).bmp\n",
      "Showing image 60/199, path: input\\002_20200624_123144(0).bmp\n",
      "Showing image 61/199, path: input\\002_20200624_123148(2).bmp\n",
      "Showing image 61/199, path: input\\002_20200624_123148(2).bmp\n",
      "Showing image 62/199, path: input\\002_20200624_123152(7).bmp\n",
      "Showing image 62/199, path: input\\002_20200624_123152(7).bmp\n",
      "Showing image 63/199, path: input\\002_20200624_123157(4).bmp\n",
      "Showing image 63/199, path: input\\002_20200624_123157(4).bmp\n",
      "Showing image 64/199, path: input\\002_20200624_123201(7).bmp\n",
      "Showing image 64/199, path: input\\002_20200624_123201(7).bmp\n",
      "Showing image 65/199, path: input\\002_20200624_123206(2).bmp\n",
      "Showing image 65/199, path: input\\002_20200624_123206(2).bmp\n",
      "Showing image 66/199, path: input\\002_20200624_162708(9).bmp\n",
      "Showing image 66/199, path: input\\002_20200624_162708(9).bmp\n",
      "Showing image 67/199, path: input\\002_20200624_162713(4).bmp\n",
      "Showing image 67/199, path: input\\002_20200624_162713(4).bmp\n",
      "Showing image 68/199, path: input\\002_20200624_162717(9).bmp\n",
      "Showing image 68/199, path: input\\002_20200624_162717(9).bmp\n",
      "Showing image 69/199, path: input\\002_20200624_162722(4).bmp\n",
      "Showing image 69/199, path: input\\002_20200624_162722(4).bmp\n",
      "Showing image 70/199, path: input\\002_20200624_162726(9).bmp\n",
      "Showing image 70/199, path: input\\002_20200624_162726(9).bmp\n",
      "Showing image 71/199, path: input\\002_20200624_162737(5).bmp\n",
      "Showing image 71/199, path: input\\002_20200624_162737(5).bmp\n",
      "Showing image 72/199, path: input\\002_20200624_203111(4).bmp\n",
      "Showing image 72/199, path: input\\002_20200624_203111(4).bmp\n",
      "Showing image 73/199, path: input\\002_20200624_203114(3).bmp\n",
      "Showing image 73/199, path: input\\002_20200624_203114(3).bmp\n",
      "Showing image 74/199, path: input\\002_20200624_203117(3).bmp\n",
      "Showing image 74/199, path: input\\002_20200624_203117(3).bmp\n",
      "Showing image 75/199, path: input\\002_20200624_203120(3).bmp\n",
      "Showing image 75/199, path: input\\002_20200624_203120(3).bmp\n",
      "Showing image 76/199, path: input\\002_20200624_203123(3).bmp\n",
      "Showing image 76/199, path: input\\002_20200624_203123(3).bmp\n",
      "Showing image 77/199, path: input\\002_20200624_203126(3).bmp\n",
      "Showing image 77/199, path: input\\002_20200624_203126(3).bmp\n",
      "Showing image 78/199, path: input\\002_20200625_003352(9).bmp\n",
      "Showing image 78/199, path: input\\002_20200625_003352(9).bmp\n",
      "Showing image 79/199, path: input\\002_20200625_003357(4).bmp\n",
      "Showing image 79/199, path: input\\002_20200625_003357(4).bmp\n",
      "Showing image 80/199, path: input\\002_20200625_003401(8).bmp\n",
      "Showing image 80/199, path: input\\002_20200625_003401(8).bmp\n",
      "Showing image 81/199, path: input\\002_20200625_003406(3).bmp\n",
      "Showing image 81/199, path: input\\002_20200625_003406(3).bmp\n",
      "Showing image 82/199, path: input\\002_20200625_003410(8).bmp\n",
      "Showing image 82/199, path: input\\002_20200625_003410(8).bmp\n",
      "Showing image 83/199, path: input\\002_20200625_003415(4).bmp\n",
      "Showing image 83/199, path: input\\002_20200625_003415(4).bmp\n",
      "Showing image 84/199, path: input\\002_20200629_082823(5).bmp\n",
      "Showing image 84/199, path: input\\002_20200629_082823(5).bmp\n",
      "Showing image 85/199, path: input\\002_20200629_082828(5).bmp\n",
      "Showing image 85/199, path: input\\002_20200629_082828(5).bmp\n",
      "Showing image 86/199, path: input\\002_20200629_082831(3).bmp\n",
      "Showing image 86/199, path: input\\002_20200629_082831(3).bmp\n",
      "Showing image 87/199, path: input\\002_20200629_082834(2).bmp\n",
      "Showing image 87/199, path: input\\002_20200629_082834(2).bmp\n",
      "Showing image 88/199, path: input\\002_20200629_082837(0).bmp\n",
      "Showing image 88/199, path: input\\002_20200629_082837(0).bmp\n",
      "Showing image 89/199, path: input\\002_20200629_082839(9).bmp\n",
      "Showing image 89/199, path: input\\002_20200629_082839(9).bmp\n",
      "Showing image 90/199, path: input\\002_20200629_123442(5).bmp\n",
      "Showing image 90/199, path: input\\002_20200629_123442(5).bmp\n",
      "Showing image 91/199, path: input\\002_20200629_123447(0).bmp\n",
      "Showing image 91/199, path: input\\002_20200629_123447(0).bmp\n",
      "Showing image 92/199, path: input\\002_20200629_123451(5).bmp\n",
      "Showing image 92/199, path: input\\002_20200629_123451(5).bmp\n",
      "Showing image 93/199, path: input\\002_20200629_123456(0).bmp\n",
      "Showing image 93/199, path: input\\002_20200629_123456(0).bmp\n",
      "Showing image 94/199, path: input\\002_20200629_123500(5).bmp\n",
      "Showing image 94/199, path: input\\002_20200629_123500(5).bmp\n",
      "Showing image 95/199, path: input\\002_20200629_123505(0).bmp\n",
      "Showing image 95/199, path: input\\002_20200629_123505(0).bmp\n",
      "Showing image 96/199, path: input\\002_20200629_163656(7).bmp\n",
      "Showing image 96/199, path: input\\002_20200629_163656(7).bmp\n",
      "Showing image 97/199, path: input\\002_20200629_163659(7).bmp\n",
      "Showing image 97/199, path: input\\002_20200629_163659(7).bmp\n",
      "Showing image 98/199, path: input\\002_20200629_163702(8).bmp\n",
      "Showing image 98/199, path: input\\002_20200629_163702(8).bmp\n",
      "Showing image 99/199, path: input\\002_20200629_163705(8).bmp\n",
      "Showing image 99/199, path: input\\002_20200629_163705(8).bmp\n",
      "Showing image 100/199, path: input\\002_20200629_163708(9).bmp\n",
      "Showing image 100/199, path: input\\002_20200629_163708(9).bmp\n",
      "Showing image 101/199, path: input\\002_20200629_163711(8).bmp\n",
      "Showing image 101/199, path: input\\002_20200629_163711(8).bmp\n",
      "Showing image 102/199, path: input\\002_20200629_202727(4).bmp\n",
      "Showing image 102/199, path: input\\002_20200629_202727(4).bmp\n",
      "Showing image 103/199, path: input\\002_20200629_202731(9).bmp\n",
      "Showing image 103/199, path: input\\002_20200629_202731(9).bmp\n",
      "Showing image 104/199, path: input\\002_20200629_202736(4).bmp\n",
      "Showing image 104/199, path: input\\002_20200629_202736(4).bmp\n",
      "Showing image 105/199, path: input\\002_20200629_202741(1).bmp\n",
      "Showing image 105/199, path: input\\002_20200629_202741(1).bmp\n",
      "Showing image 106/199, path: input\\002_20200629_202745(5).bmp\n",
      "Showing image 106/199, path: input\\002_20200629_202745(5).bmp\n",
      "Showing image 107/199, path: input\\002_20200629_202750(0).bmp\n",
      "Showing image 107/199, path: input\\002_20200629_202750(0).bmp\n",
      "Showing image 108/199, path: input\\002_20200630_002937(6).bmp\n",
      "Showing image 108/199, path: input\\002_20200630_002937(6).bmp\n",
      "Showing image 109/199, path: input\\002_20200630_002942(1).bmp\n",
      "Showing image 109/199, path: input\\002_20200630_002942(1).bmp\n",
      "Showing image 108/199, path: input\\002_20200630_002937(6).bmp\n",
      "Showing image 108/199, path: input\\002_20200630_002937(6).bmp\n",
      "Showing image 107/199, path: input\\002_20200629_202750(0).bmp\n",
      "Showing image 107/199, path: input\\002_20200629_202750(0).bmp\n",
      "Showing image 106/199, path: input\\002_20200629_202745(5).bmp\n",
      "Showing image 106/199, path: input\\002_20200629_202745(5).bmp\n",
      "Showing image 105/199, path: input\\002_20200629_202741(1).bmp\n",
      "Showing image 105/199, path: input\\002_20200629_202741(1).bmp\n",
      "Showing image 106/199, path: input\\002_20200629_202745(5).bmp\n",
      "Showing image 106/199, path: input\\002_20200629_202745(5).bmp\n",
      "Showing image 107/199, path: input\\002_20200629_202750(0).bmp\n",
      "Showing image 107/199, path: input\\002_20200629_202750(0).bmp\n",
      "Showing image 108/199, path: input\\002_20200630_002937(6).bmp\n",
      "Showing image 108/199, path: input\\002_20200630_002937(6).bmp\n",
      "Showing image 109/199, path: input\\002_20200630_002942(1).bmp\n",
      "Showing image 109/199, path: input\\002_20200630_002942(1).bmp\n",
      "Showing image 110/199, path: input\\002_20200630_002946(4).bmp\n",
      "Showing image 110/199, path: input\\002_20200630_002946(4).bmp\n",
      "Showing image 111/199, path: input\\002_20200630_002951(2).bmp\n",
      "Showing image 111/199, path: input\\002_20200630_002951(2).bmp\n",
      "Showing image 112/199, path: input\\002_20200630_002955(6).bmp\n",
      "Showing image 112/199, path: input\\002_20200630_002955(6).bmp\n",
      "Showing image 113/199, path: input\\002_20200630_003000(0).bmp\n",
      "Showing image 113/199, path: input\\002_20200630_003000(0).bmp\n",
      "Showing image 114/199, path: input\\002_20200630_043222(4).bmp\n",
      "Showing image 114/199, path: input\\002_20200630_043222(4).bmp\n",
      "Showing image 115/199, path: input\\002_20200630_043226(7).bmp\n",
      "Showing image 115/199, path: input\\002_20200630_043226(7).bmp\n",
      "Showing image 116/199, path: input\\002_20200630_043231(3).bmp\n",
      "Showing image 116/199, path: input\\002_20200630_043231(3).bmp\n",
      "Showing image 117/199, path: input\\002_20200630_043235(6).bmp\n",
      "Showing image 117/199, path: input\\002_20200630_043235(6).bmp\n",
      "Showing image 118/199, path: input\\002_20200630_043240(2).bmp\n",
      "Showing image 118/199, path: input\\002_20200630_043240(2).bmp\n",
      "Showing image 119/199, path: input\\002_20200630_043244(6).bmp\n",
      "Showing image 119/199, path: input\\002_20200630_043244(6).bmp\n",
      "Showing image 118/199, path: input\\002_20200630_043240(2).bmp\n",
      "Showing image 118/199, path: input\\002_20200630_043240(2).bmp\n",
      "Showing image 119/199, path: input\\002_20200630_043244(6).bmp\n",
      "Showing image 119/199, path: input\\002_20200630_043244(6).bmp\n",
      "Showing image 120/199, path: input\\002_20200630_083221(8).bmp\n",
      "Showing image 120/199, path: input\\002_20200630_083221(8).bmp\n",
      "Showing image 121/199, path: input\\002_20200630_083224(8).bmp\n",
      "Showing image 121/199, path: input\\002_20200630_083224(8).bmp\n",
      "Showing image 122/199, path: input\\002_20200630_083227(8).bmp\n",
      "Showing image 122/199, path: input\\002_20200630_083227(8).bmp\n",
      "Showing image 123/199, path: input\\002_20200630_083230(8).bmp\n",
      "Showing image 123/199, path: input\\002_20200630_083230(8).bmp\n",
      "Showing image 124/199, path: input\\002_20200630_083233(8).bmp\n",
      "Showing image 124/199, path: input\\002_20200630_083233(8).bmp\n",
      "Showing image 125/199, path: input\\002_20200630_083236(8).bmp\n",
      "Showing image 125/199, path: input\\002_20200630_083236(8).bmp\n",
      "Showing image 126/199, path: input\\002_20200630_123159(3).bmp\n",
      "Showing image 126/199, path: input\\002_20200630_123159(3).bmp\n",
      "Showing image 127/199, path: input\\002_20200630_123203(6).bmp\n",
      "Showing image 127/199, path: input\\002_20200630_123203(6).bmp\n",
      "Showing image 126/199, path: input\\002_20200630_123159(3).bmp\n",
      "Showing image 126/199, path: input\\002_20200630_123159(3).bmp\n",
      "Showing image 127/199, path: input\\002_20200630_123203(6).bmp\n",
      "Showing image 127/199, path: input\\002_20200630_123203(6).bmp\n",
      "Showing image 128/199, path: input\\002_20200630_123232(0).bmp\n",
      "Showing image 128/199, path: input\\002_20200630_123232(0).bmp\n",
      "Showing image 129/199, path: input\\002_20200630_123235(0).bmp\n",
      "Showing image 129/199, path: input\\002_20200630_123235(0).bmp\n",
      "Showing image 130/199, path: input\\002_20200630_123238(0).bmp\n",
      "Showing image 130/199, path: input\\002_20200630_123238(0).bmp\n",
      "Showing image 131/199, path: input\\002_20200630_123241(0).bmp\n",
      "Showing image 131/199, path: input\\002_20200630_123241(0).bmp\n",
      "Showing image 132/199, path: input\\002_20200630_163105(7).bmp\n",
      "Showing image 132/199, path: input\\002_20200630_163105(7).bmp\n",
      "Showing image 133/199, path: input\\002_20200630_163108(9).bmp\n",
      "Showing image 133/199, path: input\\002_20200630_163108(9).bmp\n",
      "Showing image 134/199, path: input\\002_20200630_163112(5).bmp\n",
      "Showing image 134/199, path: input\\002_20200630_163112(5).bmp\n",
      "Showing image 135/199, path: input\\002_20200630_163116(0).bmp\n",
      "Showing image 135/199, path: input\\002_20200630_163116(0).bmp\n",
      "Showing image 136/199, path: input\\002_20200630_163119(5).bmp\n",
      "Showing image 136/199, path: input\\002_20200630_163119(5).bmp\n",
      "Showing image 137/199, path: input\\002_20200630_163122(8).bmp\n",
      "Showing image 137/199, path: input\\002_20200630_163122(8).bmp\n",
      "Showing image 138/199, path: input\\002_20200630_203013(9).bmp\n",
      "Showing image 138/199, path: input\\002_20200630_203013(9).bmp\n",
      "Showing image 139/199, path: input\\002_20200630_203018(4).bmp\n",
      "Showing image 139/199, path: input\\002_20200630_203018(4).bmp\n",
      "Showing image 140/199, path: input\\002_20200630_203022(9).bmp\n",
      "Showing image 140/199, path: input\\002_20200630_203022(9).bmp\n",
      "Showing image 141/199, path: input\\002_20200630_203027(4).bmp\n",
      "Showing image 141/199, path: input\\002_20200630_203027(4).bmp\n",
      "Showing image 142/199, path: input\\002_20200630_203031(8).bmp\n",
      "Showing image 142/199, path: input\\002_20200630_203031(8).bmp\n",
      "Showing image 143/199, path: input\\002_20200630_203036(4).bmp\n",
      "Showing image 143/199, path: input\\002_20200630_203036(4).bmp\n",
      "Showing image 144/199, path: input\\002_20200701_004107(2).bmp\n",
      "Showing image 144/199, path: input\\002_20200701_004107(2).bmp\n",
      "Showing image 145/199, path: input\\002_20200701_004111(5).bmp\n",
      "Showing image 145/199, path: input\\002_20200701_004111(5).bmp\n",
      "Showing image 146/199, path: input\\002_20200701_004116(1).bmp\n",
      "Showing image 146/199, path: input\\002_20200701_004116(1).bmp\n",
      "Showing image 147/199, path: input\\002_20200701_004120(5).bmp\n",
      "Showing image 147/199, path: input\\002_20200701_004120(5).bmp\n",
      "Showing image 148/199, path: input\\002_20200701_004125(0).bmp\n",
      "Showing image 148/199, path: input\\002_20200701_004125(0).bmp\n",
      "Showing image 149/199, path: input\\002_20200701_004129(6).bmp\n",
      "Showing image 149/199, path: input\\002_20200701_004129(6).bmp\n",
      "Showing image 150/199, path: input\\002_20200701_043204(8).bmp\n",
      "Showing image 150/199, path: input\\002_20200701_043204(8).bmp\n",
      "Showing image 151/199, path: input\\002_20200701_043209(5).bmp\n",
      "Showing image 151/199, path: input\\002_20200701_043209(5).bmp\n",
      "Showing image 152/199, path: input\\002_20200701_043213(9).bmp\n",
      "Showing image 152/199, path: input\\002_20200701_043213(9).bmp\n",
      "Showing image 153/199, path: input\\002_20200701_043218(4).bmp\n",
      "Showing image 153/199, path: input\\002_20200701_043218(4).bmp\n",
      "Showing image 154/199, path: input\\002_20200701_043222(8).bmp\n",
      "Showing image 154/199, path: input\\002_20200701_043222(8).bmp\n",
      "Showing image 155/199, path: input\\002_20200701_043227(2).bmp\n",
      "Showing image 155/199, path: input\\002_20200701_043227(2).bmp\n",
      "Showing image 156/199, path: input\\002_20200701_083102(9).bmp\n",
      "Showing image 156/199, path: input\\002_20200701_083102(9).bmp\n",
      "Showing image 157/199, path: input\\002_20200701_083105(7).bmp\n",
      "Showing image 157/199, path: input\\002_20200701_083105(7).bmp\n",
      "Showing image 158/199, path: input\\002_20200701_083108(8).bmp\n",
      "Showing image 158/199, path: input\\002_20200701_083108(8).bmp\n",
      "Showing image 159/199, path: input\\002_20200701_083111(8).bmp\n",
      "Showing image 159/199, path: input\\002_20200701_083111(8).bmp\n",
      "Showing image 160/199, path: input\\002_20200701_083114(8).bmp\n",
      "Showing image 160/199, path: input\\002_20200701_083114(8).bmp\n",
      "Showing image 161/199, path: input\\002_20200701_083117(8).bmp\n",
      "Showing image 161/199, path: input\\002_20200701_083117(8).bmp\n",
      "Showing image 162/199, path: input\\002_20200701_123502(6).bmp\n",
      "Showing image 162/199, path: input\\002_20200701_123502(6).bmp\n",
      "Showing image 163/199, path: input\\002_20200701_123505(9).bmp\n",
      "Showing image 163/199, path: input\\002_20200701_123505(9).bmp\n",
      "Showing image 164/199, path: input\\002_20200701_123508(7).bmp\n",
      "Showing image 164/199, path: input\\002_20200701_123508(7).bmp\n",
      "Showing image 165/199, path: input\\002_20200701_123511(5).bmp\n",
      "Showing image 165/199, path: input\\002_20200701_123511(5).bmp\n",
      "Showing image 166/199, path: input\\002_20200701_123514(1).bmp\n",
      "Showing image 166/199, path: input\\002_20200701_123514(1).bmp\n",
      "Showing image 167/199, path: input\\002_20200701_123516(7).bmp\n",
      "Showing image 167/199, path: input\\002_20200701_123516(7).bmp\n",
      "Showing image 168/199, path: input\\002_20200701_163100(6).bmp\n",
      "Showing image 168/199, path: input\\002_20200701_163100(6).bmp\n",
      "Showing image 169/199, path: input\\002_20200701_163104(5).bmp\n",
      "Showing image 169/199, path: input\\002_20200701_163104(5).bmp\n",
      "Showing image 170/199, path: input\\002_20200701_163108(4).bmp\n",
      "Showing image 170/199, path: input\\002_20200701_163108(4).bmp\n",
      "Showing image 171/199, path: input\\002_20200701_163112(3).bmp\n",
      "Showing image 171/199, path: input\\002_20200701_163112(3).bmp\n",
      "Showing image 172/199, path: input\\002_20200701_163116(3).bmp\n",
      "Showing image 172/199, path: input\\002_20200701_163116(3).bmp\n",
      "Showing image 173/199, path: input\\002_20200701_163120(4).bmp\n",
      "Showing image 173/199, path: input\\002_20200701_163120(4).bmp\n",
      "Showing image 174/199, path: input\\002_20200701_203449(7).bmp\n",
      "Showing image 174/199, path: input\\002_20200701_203449(7).bmp\n",
      "Showing image 175/199, path: input\\002_20200701_203454(3).bmp\n",
      "Showing image 175/199, path: input\\002_20200701_203454(3).bmp\n",
      "Showing image 176/199, path: input\\002_20200701_203458(5).bmp\n",
      "Showing image 176/199, path: input\\002_20200701_203458(5).bmp\n",
      "Showing image 177/199, path: input\\002_20200701_203503(2).bmp\n",
      "Showing image 177/199, path: input\\002_20200701_203503(2).bmp\n",
      "Showing image 178/199, path: input\\002_20200701_203507(7).bmp\n",
      "Showing image 178/199, path: input\\002_20200701_203507(7).bmp\n",
      "Showing image 179/199, path: input\\002_20200701_203512(1).bmp\n",
      "Showing image 179/199, path: input\\002_20200701_203512(1).bmp\n",
      "Showing image 180/199, path: input\\002_20200702_002959(7).bmp\n",
      "Showing image 180/199, path: input\\002_20200702_002959(7).bmp\n",
      "Showing image 181/199, path: input\\002_20200702_003004(2).bmp\n",
      "Showing image 181/199, path: input\\002_20200702_003004(2).bmp\n",
      "Showing image 182/199, path: input\\002_20200702_003008(7).bmp\n",
      "Showing image 182/199, path: input\\002_20200702_003008(7).bmp\n",
      "Showing image 183/199, path: input\\002_20200702_003011(7).bmp\n",
      "Showing image 183/199, path: input\\002_20200702_003011(7).bmp\n",
      "Showing image 184/199, path: input\\002_20200702_003016(3).bmp\n",
      "Showing image 184/199, path: input\\002_20200702_003016(3).bmp\n",
      "Showing image 185/199, path: input\\002_20200702_003020(8).bmp\n",
      "Showing image 185/199, path: input\\002_20200702_003020(8).bmp\n",
      "Showing image 186/199, path: input\\002_20200702_043936(2).bmp\n",
      "Showing image 186/199, path: input\\002_20200702_043936(2).bmp\n",
      "Showing image 187/199, path: input\\002_20200702_043940(7).bmp\n",
      "Showing image 187/199, path: input\\002_20200702_043940(7).bmp\n",
      "Showing image 188/199, path: input\\002_20200702_043945(1).bmp\n",
      "Showing image 188/199, path: input\\002_20200702_043945(1).bmp\n",
      "Showing image 189/199, path: input\\002_20200702_043949(6).bmp\n",
      "Showing image 189/199, path: input\\002_20200702_043949(6).bmp\n",
      "Showing image 190/199, path: input\\002_20200702_043954(0).bmp\n",
      "Showing image 190/199, path: input\\002_20200702_043954(0).bmp\n",
      "Showing image 191/199, path: input\\002_20200702_043958(5).bmp\n",
      "Showing image 191/199, path: input\\002_20200702_043958(5).bmp\n",
      "Showing image 192/199, path: input\\002_20200706_083210(1).bmp\n",
      "Showing image 192/199, path: input\\002_20200706_083210(1).bmp\n",
      "Showing image 193/199, path: input\\002_20200706_083227(7).bmp\n",
      "Showing image 193/199, path: input\\002_20200706_083227(7).bmp\n",
      "Showing image 194/199, path: input\\002_20200706_083231(8).bmp\n",
      "Showing image 194/199, path: input\\002_20200706_083231(8).bmp\n",
      "Showing image 195/199, path: input\\002_20200706_083234(7).bmp\n",
      "Showing image 195/199, path: input\\002_20200706_083234(7).bmp\n",
      "Showing image 196/199, path: input\\002_20200706_083237(9).bmp\n",
      "Showing image 196/199, path: input\\002_20200706_083237(9).bmp\n",
      "Showing image 197/199, path: input\\002_20200706_083241(0).bmp\n",
      "Showing image 197/199, path: input\\002_20200706_083241(0).bmp\n",
      "Showing image 198/199, path: input\\002_20200706_123239(6).bmp\n",
      "Showing image 198/199, path: input\\002_20200706_123239(6).bmp\n",
      "Showing image 199/199, path: input\\002_20200706_123242(9).bmp\n",
      "Showing image 199/199, path: input\\002_20200706_123242(9).bmp\n",
      "Showing image 0/199, path: input\\002_20200622_203136(3).bmp\n",
      "Showing image 0/199, path: input\\002_20200622_203136(3).bmp\n",
      "Showing image 1/199, path: input\\002_20200622_203140(8).bmp\n",
      "Showing image 1/199, path: input\\002_20200622_203140(8).bmp\n",
      "Showing image 2/199, path: input\\002_20200622_203145(3).bmp\n",
      "Showing image 2/199, path: input\\002_20200622_203145(3).bmp\n",
      "Showing image 3/199, path: input\\002_20200622_203149(8).bmp\n",
      "Showing image 3/199, path: input\\002_20200622_203149(8).bmp\n",
      "Showing image 4/199, path: input\\002_20200622_203154(3).bmp\n",
      "Showing image 4/199, path: input\\002_20200622_203154(3).bmp\n",
      "Showing image 5/199, path: input\\002_20200622_203158(8).bmp\n",
      "Showing image 5/199, path: input\\002_20200622_203158(8).bmp\n",
      "Showing image 6/199, path: input\\002_20200623_003351(2).bmp\n",
      "Showing image 6/199, path: input\\002_20200623_003351(2).bmp\n",
      "Showing image 7/199, path: input\\002_20200623_003355(7).bmp\n",
      "Showing image 7/199, path: input\\002_20200623_003355(7).bmp\n",
      "Showing image 8/199, path: input\\002_20200623_003400(2).bmp\n",
      "Showing image 8/199, path: input\\002_20200623_003400(2).bmp\n",
      "Showing image 9/199, path: input\\002_20200623_003404(7).bmp\n",
      "Showing image 9/199, path: input\\002_20200623_003404(7).bmp\n",
      "Showing image 10/199, path: input\\002_20200623_003409(2).bmp\n",
      "Showing image 10/199, path: input\\002_20200623_003409(2).bmp\n",
      "Showing image 11/199, path: input\\002_20200623_003413(7).bmp\n",
      "Showing image 11/199, path: input\\002_20200623_003413(7).bmp\n",
      "Showing image 12/199, path: input\\002_20200623_043056(0).bmp\n",
      "Showing image 12/199, path: input\\002_20200623_043056(0).bmp\n",
      "Showing image 13/199, path: input\\002_20200623_043100(6).bmp\n",
      "Showing image 13/199, path: input\\002_20200623_043100(6).bmp\n",
      "Showing image 14/199, path: input\\002_20200623_043105(0).bmp\n",
      "Showing image 14/199, path: input\\002_20200623_043105(0).bmp\n",
      "Showing image 15/199, path: input\\002_20200623_043109(4).bmp\n",
      "Showing image 15/199, path: input\\002_20200623_043109(4).bmp\n",
      "Showing image 16/199, path: input\\002_20200623_043115(4).bmp\n",
      "Showing image 16/199, path: input\\002_20200623_043115(4).bmp\n",
      "Showing image 17/199, path: input\\002_20200623_043120(0).bmp\n",
      "Showing image 17/199, path: input\\002_20200623_043120(0).bmp\n",
      "Showing image 18/199, path: input\\002_20200623_082249(3).bmp\n",
      "Showing image 18/199, path: input\\002_20200623_082249(3).bmp\n",
      "Showing image 19/199, path: input\\002_20200623_082253(8).bmp\n",
      "Showing image 19/199, path: input\\002_20200623_082253(8).bmp\n",
      "Showing image 20/199, path: input\\002_20200623_082258(4).bmp\n",
      "Showing image 20/199, path: input\\002_20200623_082258(4).bmp\n",
      "Showing image 21/199, path: input\\002_20200623_082302(7).bmp\n",
      "Showing image 21/199, path: input\\002_20200623_082302(7).bmp\n",
      "Showing image 22/199, path: input\\002_20200623_082307(2).bmp\n",
      "Showing image 22/199, path: input\\002_20200623_082307(2).bmp\n",
      "Showing image 23/199, path: input\\002_20200623_082311(8).bmp\n",
      "Showing image 23/199, path: input\\002_20200623_082311(8).bmp\n",
      "Showing image 24/199, path: input\\002_20200623_123042(0).bmp\n",
      "Showing image 24/199, path: input\\002_20200623_123042(0).bmp\n",
      "Showing image 25/199, path: input\\002_20200623_123046(4).bmp\n",
      "Showing image 25/199, path: input\\002_20200623_123046(4).bmp\n",
      "Showing image 26/199, path: input\\002_20200623_123051(1).bmp\n",
      "Showing image 26/199, path: input\\002_20200623_123051(1).bmp\n",
      "Showing image 27/199, path: input\\002_20200623_123055(5).bmp\n",
      "Showing image 27/199, path: input\\002_20200623_123055(5).bmp\n",
      "Showing image 28/199, path: input\\002_20200623_123100(0).bmp\n",
      "Showing image 28/199, path: input\\002_20200623_123100(0).bmp\n",
      "Showing image 29/199, path: input\\002_20200623_123104(5).bmp\n",
      "Showing image 29/199, path: input\\002_20200623_123104(5).bmp\n",
      "Showing image 30/199, path: input\\002_20200623_163020(3).bmp\n",
      "Showing image 30/199, path: input\\002_20200623_163020(3).bmp\n",
      "Showing image 31/199, path: input\\002_20200623_163023(3).bmp\n",
      "Showing image 31/199, path: input\\002_20200623_163023(3).bmp\n",
      "Showing image 32/199, path: input\\002_20200623_163026(3).bmp\n",
      "Showing image 32/199, path: input\\002_20200623_163026(3).bmp\n",
      "Showing image 33/199, path: input\\002_20200623_163029(6).bmp\n",
      "Showing image 33/199, path: input\\002_20200623_163029(6).bmp\n",
      "Showing image 34/199, path: input\\002_20200623_163032(5).bmp\n",
      "Showing image 34/199, path: input\\002_20200623_163032(5).bmp\n",
      "Showing image 35/199, path: input\\002_20200623_163035(5).bmp\n",
      "Showing image 35/199, path: input\\002_20200623_163035(5).bmp\n",
      "Showing image 36/199, path: input\\002_20200623_203033(6).bmp\n",
      "Showing image 36/199, path: input\\002_20200623_203033(6).bmp\n",
      "Showing image 37/199, path: input\\002_20200623_203038(0).bmp\n",
      "Showing image 37/199, path: input\\002_20200623_203038(0).bmp\n",
      "Showing image 38/199, path: input\\002_20200623_203042(5).bmp\n",
      "Showing image 38/199, path: input\\002_20200623_203042(5).bmp\n",
      "Showing image 39/199, path: input\\002_20200623_203047(0).bmp\n",
      "Showing image 39/199, path: input\\002_20200623_203047(0).bmp\n",
      "Showing image 40/199, path: input\\002_20200623_203050(0).bmp\n",
      "Showing image 40/199, path: input\\002_20200623_203050(0).bmp\n",
      "Showing image 41/199, path: input\\002_20200623_203054(6).bmp\n",
      "Showing image 41/199, path: input\\002_20200623_203054(6).bmp\n",
      "Showing image 42/199, path: input\\002_20200624_003115(6).bmp\n",
      "Showing image 42/199, path: input\\002_20200624_003115(6).bmp\n",
      "Showing image 43/199, path: input\\002_20200624_003118(6).bmp\n",
      "Showing image 43/199, path: input\\002_20200624_003118(6).bmp\n",
      "Showing image 44/199, path: input\\002_20200624_003123(0).bmp\n",
      "Showing image 44/199, path: input\\002_20200624_003123(0).bmp\n",
      "Showing image 45/199, path: input\\002_20200624_003127(5).bmp\n",
      "Showing image 45/199, path: input\\002_20200624_003127(5).bmp\n",
      "Showing image 46/199, path: input\\002_20200624_003132(0).bmp\n",
      "Showing image 46/199, path: input\\002_20200624_003132(0).bmp\n",
      "Showing image 47/199, path: input\\002_20200624_003136(5).bmp\n",
      "Showing image 47/199, path: input\\002_20200624_003136(5).bmp\n",
      "Showing image 48/199, path: input\\002_20200624_043136(9).bmp\n",
      "Showing image 48/199, path: input\\002_20200624_043136(9).bmp\n",
      "Showing image 49/199, path: input\\002_20200624_043141(4).bmp\n",
      "Showing image 49/199, path: input\\002_20200624_043141(4).bmp\n",
      "Showing image 50/199, path: input\\002_20200624_043145(8).bmp\n",
      "Showing image 50/199, path: input\\002_20200624_043145(8).bmp\n",
      "Showing image 51/199, path: input\\002_20200624_043150(3).bmp\n",
      "Showing image 51/199, path: input\\002_20200624_043150(3).bmp\n",
      "Showing image 52/199, path: input\\002_20200624_043154(8).bmp\n",
      "Showing image 52/199, path: input\\002_20200624_043154(8).bmp\n",
      "Showing image 53/199, path: input\\002_20200624_043159(4).bmp\n",
      "Showing image 53/199, path: input\\002_20200624_043159(4).bmp\n",
      "Showing image 54/199, path: input\\002_20200624_083032(4).bmp\n",
      "Showing image 54/199, path: input\\002_20200624_083032(4).bmp\n",
      "Showing image 55/199, path: input\\002_20200624_083036(9).bmp\n",
      "Showing image 55/199, path: input\\002_20200624_083036(9).bmp\n",
      "Showing image 56/199, path: input\\002_20200624_083041(3).bmp\n",
      "Showing image 56/199, path: input\\002_20200624_083041(3).bmp\n",
      "Showing image 57/199, path: input\\002_20200624_083045(8).bmp\n",
      "Showing image 57/199, path: input\\002_20200624_083045(8).bmp\n",
      "Showing image 58/199, path: input\\002_20200624_083050(4).bmp\n",
      "Showing image 58/199, path: input\\002_20200624_083050(4).bmp\n",
      "Showing image 59/199, path: input\\002_20200624_083054(9).bmp\n",
      "Showing image 59/199, path: input\\002_20200624_083054(9).bmp\n",
      "Showing image 60/199, path: input\\002_20200624_123144(0).bmp\n",
      "Showing image 60/199, path: input\\002_20200624_123144(0).bmp\n",
      "Showing image 61/199, path: input\\002_20200624_123148(2).bmp\n",
      "Showing image 61/199, path: input\\002_20200624_123148(2).bmp\n",
      "Showing image 62/199, path: input\\002_20200624_123152(7).bmp\n",
      "Showing image 62/199, path: input\\002_20200624_123152(7).bmp\n",
      "Showing image 63/199, path: input\\002_20200624_123157(4).bmp\n",
      "Showing image 63/199, path: input\\002_20200624_123157(4).bmp\n",
      "Showing image 64/199, path: input\\002_20200624_123201(7).bmp\n",
      "Showing image 64/199, path: input\\002_20200624_123201(7).bmp\n",
      "Showing image 65/199, path: input\\002_20200624_123206(2).bmp\n",
      "Showing image 65/199, path: input\\002_20200624_123206(2).bmp\n",
      "Showing image 66/199, path: input\\002_20200624_162708(9).bmp\n",
      "Showing image 66/199, path: input\\002_20200624_162708(9).bmp\n",
      "Showing image 67/199, path: input\\002_20200624_162713(4).bmp\n",
      "Showing image 67/199, path: input\\002_20200624_162713(4).bmp\n",
      "Showing image 68/199, path: input\\002_20200624_162717(9).bmp\n",
      "Showing image 68/199, path: input\\002_20200624_162717(9).bmp\n",
      "Showing image 69/199, path: input\\002_20200624_162722(4).bmp\n",
      "Showing image 69/199, path: input\\002_20200624_162722(4).bmp\n",
      "Showing image 70/199, path: input\\002_20200624_162726(9).bmp\n",
      "Showing image 70/199, path: input\\002_20200624_162726(9).bmp\n",
      "Showing image 71/199, path: input\\002_20200624_162737(5).bmp\n",
      "Showing image 71/199, path: input\\002_20200624_162737(5).bmp\n",
      "Showing image 72/199, path: input\\002_20200624_203111(4).bmp\n",
      "Showing image 72/199, path: input\\002_20200624_203111(4).bmp\n",
      "Showing image 73/199, path: input\\002_20200624_203114(3).bmp\n",
      "Showing image 73/199, path: input\\002_20200624_203114(3).bmp\n",
      "Showing image 74/199, path: input\\002_20200624_203117(3).bmp\n",
      "Showing image 74/199, path: input\\002_20200624_203117(3).bmp\n",
      "Showing image 75/199, path: input\\002_20200624_203120(3).bmp\n",
      "Showing image 75/199, path: input\\002_20200624_203120(3).bmp\n",
      "Showing image 76/199, path: input\\002_20200624_203123(3).bmp\n",
      "Showing image 76/199, path: input\\002_20200624_203123(3).bmp\n",
      "Showing image 77/199, path: input\\002_20200624_203126(3).bmp\n",
      "Showing image 77/199, path: input\\002_20200624_203126(3).bmp\n",
      "Showing image 78/199, path: input\\002_20200625_003352(9).bmp\n",
      "Showing image 78/199, path: input\\002_20200625_003352(9).bmp\n",
      "Showing image 79/199, path: input\\002_20200625_003357(4).bmp\n",
      "Showing image 79/199, path: input\\002_20200625_003357(4).bmp\n",
      "Showing image 80/199, path: input\\002_20200625_003401(8).bmp\n",
      "Showing image 80/199, path: input\\002_20200625_003401(8).bmp\n",
      "Showing image 81/199, path: input\\002_20200625_003406(3).bmp\n",
      "Showing image 81/199, path: input\\002_20200625_003406(3).bmp\n",
      "Showing image 82/199, path: input\\002_20200625_003410(8).bmp\n",
      "Showing image 82/199, path: input\\002_20200625_003410(8).bmp\n",
      "Showing image 83/199, path: input\\002_20200625_003415(4).bmp\n",
      "Showing image 83/199, path: input\\002_20200625_003415(4).bmp\n",
      "Showing image 84/199, path: input\\002_20200629_082823(5).bmp\n",
      "Showing image 84/199, path: input\\002_20200629_082823(5).bmp\n",
      "Showing image 85/199, path: input\\002_20200629_082828(5).bmp\n",
      "Showing image 85/199, path: input\\002_20200629_082828(5).bmp\n",
      "Showing image 86/199, path: input\\002_20200629_082831(3).bmp\n",
      "Showing image 86/199, path: input\\002_20200629_082831(3).bmp\n",
      "Showing image 87/199, path: input\\002_20200629_082834(2).bmp\n",
      "Showing image 87/199, path: input\\002_20200629_082834(2).bmp\n",
      "Showing image 88/199, path: input\\002_20200629_082837(0).bmp\n",
      "Showing image 88/199, path: input\\002_20200629_082837(0).bmp\n",
      "Showing image 89/199, path: input\\002_20200629_082839(9).bmp\n",
      "Showing image 89/199, path: input\\002_20200629_082839(9).bmp\n",
      "Showing image 90/199, path: input\\002_20200629_123442(5).bmp\n",
      "Showing image 90/199, path: input\\002_20200629_123442(5).bmp\n",
      "Showing image 91/199, path: input\\002_20200629_123447(0).bmp\n",
      "Showing image 91/199, path: input\\002_20200629_123447(0).bmp\n",
      "Showing image 92/199, path: input\\002_20200629_123451(5).bmp\n",
      "Showing image 92/199, path: input\\002_20200629_123451(5).bmp\n",
      "Showing image 93/199, path: input\\002_20200629_123456(0).bmp\n",
      "Showing image 93/199, path: input\\002_20200629_123456(0).bmp\n",
      "Showing image 94/199, path: input\\002_20200629_123500(5).bmp\n",
      "Showing image 94/199, path: input\\002_20200629_123500(5).bmp\n",
      "Showing image 95/199, path: input\\002_20200629_123505(0).bmp\n",
      "Showing image 95/199, path: input\\002_20200629_123505(0).bmp\n",
      "Showing image 96/199, path: input\\002_20200629_163656(7).bmp\n",
      "Showing image 96/199, path: input\\002_20200629_163656(7).bmp\n",
      "Showing image 97/199, path: input\\002_20200629_163659(7).bmp\n",
      "Showing image 97/199, path: input\\002_20200629_163659(7).bmp\n",
      "Showing image 98/199, path: input\\002_20200629_163702(8).bmp\n",
      "Showing image 98/199, path: input\\002_20200629_163702(8).bmp\n",
      "Showing image 99/199, path: input\\002_20200629_163705(8).bmp\n",
      "Showing image 99/199, path: input\\002_20200629_163705(8).bmp\n",
      "Showing image 100/199, path: input\\002_20200629_163708(9).bmp\n",
      "Showing image 100/199, path: input\\002_20200629_163708(9).bmp\n",
      "Showing image 101/199, path: input\\002_20200629_163711(8).bmp\n",
      "Showing image 101/199, path: input\\002_20200629_163711(8).bmp\n",
      "Showing image 102/199, path: input\\002_20200629_202727(4).bmp\n",
      "Showing image 102/199, path: input\\002_20200629_202727(4).bmp\n",
      "Showing image 103/199, path: input\\002_20200629_202731(9).bmp\n",
      "Showing image 103/199, path: input\\002_20200629_202731(9).bmp\n",
      "Showing image 104/199, path: input\\002_20200629_202736(4).bmp\n",
      "Showing image 104/199, path: input\\002_20200629_202736(4).bmp\n",
      "Showing image 105/199, path: input\\002_20200629_202741(1).bmp\n",
      "Showing image 105/199, path: input\\002_20200629_202741(1).bmp\n",
      "Showing image 106/199, path: input\\002_20200629_202745(5).bmp\n",
      "Showing image 106/199, path: input\\002_20200629_202745(5).bmp\n",
      "Showing image 107/199, path: input\\002_20200629_202750(0).bmp\n",
      "Showing image 107/199, path: input\\002_20200629_202750(0).bmp\n",
      "Showing image 108/199, path: input\\002_20200630_002937(6).bmp\n",
      "Showing image 108/199, path: input\\002_20200630_002937(6).bmp\n",
      "Showing image 109/199, path: input\\002_20200630_002942(1).bmp\n",
      "Showing image 109/199, path: input\\002_20200630_002942(1).bmp\n",
      "Showing image 110/199, path: input\\002_20200630_002946(4).bmp\n",
      "Showing image 110/199, path: input\\002_20200630_002946(4).bmp\n",
      "Showing image 111/199, path: input\\002_20200630_002951(2).bmp\n",
      "Showing image 111/199, path: input\\002_20200630_002951(2).bmp\n",
      "Showing image 112/199, path: input\\002_20200630_002955(6).bmp\n",
      "Showing image 112/199, path: input\\002_20200630_002955(6).bmp\n",
      "Showing image 113/199, path: input\\002_20200630_003000(0).bmp\n",
      "Showing image 113/199, path: input\\002_20200630_003000(0).bmp\n",
      "Showing image 114/199, path: input\\002_20200630_043222(4).bmp\n",
      "Showing image 114/199, path: input\\002_20200630_043222(4).bmp\n",
      "Showing image 115/199, path: input\\002_20200630_043226(7).bmp\n",
      "Showing image 115/199, path: input\\002_20200630_043226(7).bmp\n",
      "Showing image 116/199, path: input\\002_20200630_043231(3).bmp\n",
      "Showing image 116/199, path: input\\002_20200630_043231(3).bmp\n",
      "Showing image 117/199, path: input\\002_20200630_043235(6).bmp\n",
      "Showing image 117/199, path: input\\002_20200630_043235(6).bmp\n",
      "Showing image 118/199, path: input\\002_20200630_043240(2).bmp\n",
      "Showing image 118/199, path: input\\002_20200630_043240(2).bmp\n",
      "Showing image 119/199, path: input\\002_20200630_043244(6).bmp\n",
      "Showing image 119/199, path: input\\002_20200630_043244(6).bmp\n",
      "Showing image 120/199, path: input\\002_20200630_083221(8).bmp\n",
      "Showing image 120/199, path: input\\002_20200630_083221(8).bmp\n",
      "Showing image 121/199, path: input\\002_20200630_083224(8).bmp\n",
      "Showing image 121/199, path: input\\002_20200630_083224(8).bmp\n",
      "Showing image 122/199, path: input\\002_20200630_083227(8).bmp\n",
      "Showing image 122/199, path: input\\002_20200630_083227(8).bmp\n",
      "Showing image 123/199, path: input\\002_20200630_083230(8).bmp\n",
      "Showing image 123/199, path: input\\002_20200630_083230(8).bmp\n",
      "Showing image 124/199, path: input\\002_20200630_083233(8).bmp\n",
      "Showing image 124/199, path: input\\002_20200630_083233(8).bmp\n",
      "Showing image 125/199, path: input\\002_20200630_083236(8).bmp\n",
      "Showing image 125/199, path: input\\002_20200630_083236(8).bmp\n",
      "Showing image 126/199, path: input\\002_20200630_123159(3).bmp\n",
      "Showing image 126/199, path: input\\002_20200630_123159(3).bmp\n",
      "Showing image 127/199, path: input\\002_20200630_123203(6).bmp\n",
      "Showing image 127/199, path: input\\002_20200630_123203(6).bmp\n",
      "Showing image 128/199, path: input\\002_20200630_123232(0).bmp\n",
      "Showing image 128/199, path: input\\002_20200630_123232(0).bmp\n",
      "Showing image 129/199, path: input\\002_20200630_123235(0).bmp\n",
      "Showing image 129/199, path: input\\002_20200630_123235(0).bmp\n",
      "Showing image 130/199, path: input\\002_20200630_123238(0).bmp\n",
      "Showing image 130/199, path: input\\002_20200630_123238(0).bmp\n",
      "Showing image 131/199, path: input\\002_20200630_123241(0).bmp\n",
      "Showing image 131/199, path: input\\002_20200630_123241(0).bmp\n",
      "Showing image 132/199, path: input\\002_20200630_163105(7).bmp\n",
      "Showing image 132/199, path: input\\002_20200630_163105(7).bmp\n",
      "Showing image 133/199, path: input\\002_20200630_163108(9).bmp\n",
      "Showing image 133/199, path: input\\002_20200630_163108(9).bmp\n",
      "Showing image 134/199, path: input\\002_20200630_163112(5).bmp\n",
      "Showing image 134/199, path: input\\002_20200630_163112(5).bmp\n",
      "Showing image 135/199, path: input\\002_20200630_163116(0).bmp\n",
      "Showing image 135/199, path: input\\002_20200630_163116(0).bmp\n",
      "Showing image 136/199, path: input\\002_20200630_163119(5).bmp\n",
      "Showing image 136/199, path: input\\002_20200630_163119(5).bmp\n",
      "Showing image 137/199, path: input\\002_20200630_163122(8).bmp\n",
      "Showing image 137/199, path: input\\002_20200630_163122(8).bmp\n",
      "Showing image 138/199, path: input\\002_20200630_203013(9).bmp\n",
      "Showing image 138/199, path: input\\002_20200630_203013(9).bmp\n",
      "Showing image 139/199, path: input\\002_20200630_203018(4).bmp\n",
      "Showing image 139/199, path: input\\002_20200630_203018(4).bmp\n",
      "Showing image 140/199, path: input\\002_20200630_203022(9).bmp\n",
      "Showing image 140/199, path: input\\002_20200630_203022(9).bmp\n",
      "Showing image 141/199, path: input\\002_20200630_203027(4).bmp\n",
      "Showing image 141/199, path: input\\002_20200630_203027(4).bmp\n",
      "Showing image 142/199, path: input\\002_20200630_203031(8).bmp\n",
      "Showing image 142/199, path: input\\002_20200630_203031(8).bmp\n",
      "Showing image 143/199, path: input\\002_20200630_203036(4).bmp\n",
      "Showing image 143/199, path: input\\002_20200630_203036(4).bmp\n",
      "Showing image 144/199, path: input\\002_20200701_004107(2).bmp\n",
      "Showing image 144/199, path: input\\002_20200701_004107(2).bmp\n",
      "Showing image 145/199, path: input\\002_20200701_004111(5).bmp\n",
      "Showing image 145/199, path: input\\002_20200701_004111(5).bmp\n",
      "Showing image 146/199, path: input\\002_20200701_004116(1).bmp\n",
      "Showing image 146/199, path: input\\002_20200701_004116(1).bmp\n",
      "Showing image 147/199, path: input\\002_20200701_004120(5).bmp\n",
      "Showing image 147/199, path: input\\002_20200701_004120(5).bmp\n",
      "Showing image 148/199, path: input\\002_20200701_004125(0).bmp\n",
      "Showing image 148/199, path: input\\002_20200701_004125(0).bmp\n",
      "Showing image 149/199, path: input\\002_20200701_004129(6).bmp\n",
      "Showing image 149/199, path: input\\002_20200701_004129(6).bmp\n",
      "Showing image 150/199, path: input\\002_20200701_043204(8).bmp\n",
      "Showing image 150/199, path: input\\002_20200701_043204(8).bmp\n",
      "Showing image 151/199, path: input\\002_20200701_043209(5).bmp\n",
      "Showing image 151/199, path: input\\002_20200701_043209(5).bmp\n",
      "Showing image 152/199, path: input\\002_20200701_043213(9).bmp\n",
      "Showing image 152/199, path: input\\002_20200701_043213(9).bmp\n",
      "Showing image 153/199, path: input\\002_20200701_043218(4).bmp\n",
      "Showing image 153/199, path: input\\002_20200701_043218(4).bmp\n",
      "Showing image 154/199, path: input\\002_20200701_043222(8).bmp\n",
      "Showing image 154/199, path: input\\002_20200701_043222(8).bmp\n",
      "Showing image 155/199, path: input\\002_20200701_043227(2).bmp\n",
      "Showing image 155/199, path: input\\002_20200701_043227(2).bmp\n",
      "Showing image 156/199, path: input\\002_20200701_083102(9).bmp\n",
      "Showing image 156/199, path: input\\002_20200701_083102(9).bmp\n",
      "Showing image 157/199, path: input\\002_20200701_083105(7).bmp\n",
      "Showing image 157/199, path: input\\002_20200701_083105(7).bmp\n",
      "Showing image 158/199, path: input\\002_20200701_083108(8).bmp\n",
      "Showing image 158/199, path: input\\002_20200701_083108(8).bmp\n",
      "Showing image 159/199, path: input\\002_20200701_083111(8).bmp\n",
      "Showing image 159/199, path: input\\002_20200701_083111(8).bmp\n",
      "Showing image 160/199, path: input\\002_20200701_083114(8).bmp\n",
      "Showing image 160/199, path: input\\002_20200701_083114(8).bmp\n",
      "Showing image 161/199, path: input\\002_20200701_083117(8).bmp\n",
      "Showing image 161/199, path: input\\002_20200701_083117(8).bmp\n",
      "Showing image 162/199, path: input\\002_20200701_123502(6).bmp\n",
      "Showing image 162/199, path: input\\002_20200701_123502(6).bmp\n",
      "Showing image 163/199, path: input\\002_20200701_123505(9).bmp\n",
      "Showing image 163/199, path: input\\002_20200701_123505(9).bmp\n",
      "Showing image 164/199, path: input\\002_20200701_123508(7).bmp\n",
      "Showing image 164/199, path: input\\002_20200701_123508(7).bmp\n",
      "Showing image 165/199, path: input\\002_20200701_123511(5).bmp\n",
      "Showing image 165/199, path: input\\002_20200701_123511(5).bmp\n",
      "Showing image 166/199, path: input\\002_20200701_123514(1).bmp\n",
      "Showing image 166/199, path: input\\002_20200701_123514(1).bmp\n",
      "Showing image 167/199, path: input\\002_20200701_123516(7).bmp\n",
      "Showing image 167/199, path: input\\002_20200701_123516(7).bmp\n",
      "Showing image 168/199, path: input\\002_20200701_163100(6).bmp\n",
      "Showing image 168/199, path: input\\002_20200701_163100(6).bmp\n",
      "Showing image 169/199, path: input\\002_20200701_163104(5).bmp\n",
      "Showing image 169/199, path: input\\002_20200701_163104(5).bmp\n",
      "Showing image 170/199, path: input\\002_20200701_163108(4).bmp\n",
      "Showing image 170/199, path: input\\002_20200701_163108(4).bmp\n",
      "Showing image 171/199, path: input\\002_20200701_163112(3).bmp\n",
      "Showing image 171/199, path: input\\002_20200701_163112(3).bmp\n",
      "Showing image 172/199, path: input\\002_20200701_163116(3).bmp\n",
      "Showing image 172/199, path: input\\002_20200701_163116(3).bmp\n",
      "Showing image 173/199, path: input\\002_20200701_163120(4).bmp\n",
      "Showing image 173/199, path: input\\002_20200701_163120(4).bmp\n",
      "Showing image 174/199, path: input\\002_20200701_203449(7).bmp\n",
      "Showing image 174/199, path: input\\002_20200701_203449(7).bmp\n",
      "Showing image 175/199, path: input\\002_20200701_203454(3).bmp\n",
      "Showing image 175/199, path: input\\002_20200701_203454(3).bmp\n",
      "Showing image 176/199, path: input\\002_20200701_203458(5).bmp\n",
      "Showing image 176/199, path: input\\002_20200701_203458(5).bmp\n",
      "Showing image 177/199, path: input\\002_20200701_203503(2).bmp\n",
      "Showing image 177/199, path: input\\002_20200701_203503(2).bmp\n",
      "Showing image 178/199, path: input\\002_20200701_203507(7).bmp\n",
      "Showing image 178/199, path: input\\002_20200701_203507(7).bmp\n",
      "Showing image 179/199, path: input\\002_20200701_203512(1).bmp\n",
      "Showing image 179/199, path: input\\002_20200701_203512(1).bmp\n",
      "Showing image 180/199, path: input\\002_20200702_002959(7).bmp\n",
      "Showing image 180/199, path: input\\002_20200702_002959(7).bmp\n"
     ]
    }
   ],
   "source": [
    "!python C:/Users/mit017/Desktop/myproject/XRAY_PROJECT/XrayInspection/dataset/OpenLabeling-master/main/main.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "1c683cac",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "C:\\Users\\mit017\\Desktop\\myproject\\XRAY_PROJECT\\XrayInspection\\dataset\\test1\\yolov3\\images\n"
     ]
    }
   ],
   "source": [
    "%cd C:/Users/mit017/Desktop/myproject/XRAY_PROJECT/XrayInspection/dataset/test1/yolov3/images\n",
    "!ren *.* *.jpg*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "d2bdb633",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "C:\\Users\\mit017\\Desktop\\myproject\\XRAY_PROJECT\\XrayInspection\\dataset\\test1\\yolov3\n"
     ]
    }
   ],
   "source": [
    "%cd C:/Users/mit017/Desktop/myproject/XRAY_PROJECT/XrayInspection/dataset/test1/yolov3/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "ffa25dfd",
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "import os\n",
    "import subprocess\n",
    "import sys\n",
    "\n",
    "def split_data_set(image_dir):\n",
    "    # 테스트 세트와 훈련 세트 파일을 열기\n",
    "    f_val = open('test.txt', 'w')\n",
    "    f_train = open('train.txt', 'w')\n",
    "    \n",
    "    # 주어진 디렉토리에서 파일 목록을 얻기\n",
    "    path, dirs, files = next(os.walk(image_dir))\n",
    "    data_size = len(files)\n",
    "    \n",
    "    # 데이터 세트의 크기를 기반으로 테스트 세트의 크기를 결정\n",
    "    ind = 0\n",
    "    data_test_size = int(0.2 * data_size)\n",
    "    test_array = random.sample(range(data_size), k=data_test_size)\n",
    "    \n",
    "    for f in os.listdir(image_dir):\n",
    "        # 파일이 JPEG 이미지인지 확인\n",
    "        if f.endswith(\".jpg\"):\n",
    "            ind += 1\n",
    "            \n",
    "            # 파일 인덱스가 테스트 배열에 있는 경우, 테스트 세트에 추가\n",
    "            if ind in test_array:\n",
    "                f_val.write(image_dir + \"/\" + f + '\\n')\n",
    "            else:\n",
    "                # 그렇지 않으면 훈련 세트에 추가\n",
    "                f_train.write(image_dir + '/' + f + '\\n')\n",
    "\n",
    "    # 파일 닫기\n",
    "    f_val.close()\n",
    "    f_train.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "d4cea7a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "image_dir='C:/Users/mit017/Desktop/myproject/XRAY_PROJECT/XrayInspection/dataset/test1/yolov3/images'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "1276c1e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "import os\n",
    "import subprocess\n",
    "import sys\n",
    "\n",
    "split_data_set(image_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "5f56d44d",
   "metadata": {},
   "outputs": [],
   "source": [
    "!python splitdata.py images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "5fe9d66c",
   "metadata": {},
   "outputs": [],
   "source": [
    "split_data_set(image_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "bd959d4c",
   "metadata": {},
   "outputs": [],
   "source": [
    "os.environ['KMP_DUPLICATE_LIB_OK']='True'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "c9c610e4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Apex recommended for faster mixed precision training: https://github.com/NVIDIA/apex"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-03-04 16:07:36.276218: I tensorflow/core/util/port.cc:113] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
      "WARNING:tensorflow:From C:\\Users\\mit017\\anaconda3\\Lib\\site-packages\\keras\\src\\losses.py:2976: The name tf.losses.sparse_softmax_cross_entropy is deprecated. Please use tf.compat.v1.losses.sparse_softmax_cross_entropy instead.\n",
      "\n",
      "\n",
      "  0%|          | 0/160 [00:00<?, ?it/s]\n",
      "Caching labels C:\\Users\\mit017\\Desktop\\myproject\\XRAY_PROJECT\\XrayInspection\\dataset\\test1\\yolov3\\train.txt (160 found, 0 missing, 0 empty, 0 duplicate, for 160 images): 100%|##########| 160/160 [00:00<00:00, 2755.23it/s]\n",
      "\n",
      "  0%|          | 0/40 [00:00<?, ?it/s]\n",
      "Caching labels C:\\Users\\mit017\\Desktop\\myproject\\XRAY_PROJECT\\XrayInspection\\dataset\\test1\\yolov3\\test.txt (40 found, 0 missing, 0 empty, 0 duplicate, for 40 images): 100%|##########| 40/40 [00:00<00:00, 2852.54it/s]\n",
      "2024-03-04 16:07:48.962792: I tensorflow/core/util/port.cc:113] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
      "WARNING:tensorflow:From C:\\Users\\mit017\\anaconda3\\Lib\\site-packages\\keras\\src\\losses.py:2976: The name tf.losses.sparse_softmax_cross_entropy is deprecated. Please use tf.compat.v1.losses.sparse_softmax_cross_entropy instead.\n",
      "\n",
      "2024-03-04 16:07:59.152124: I tensorflow/core/util/port.cc:113] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
      "WARNING:tensorflow:From C:\\Users\\mit017\\anaconda3\\Lib\\site-packages\\keras\\src\\losses.py:2976: The name tf.losses.sparse_softmax_cross_entropy is deprecated. Please use tf.compat.v1.losses.sparse_softmax_cross_entropy instead.\n",
      "\n",
      "2024-03-04 16:08:09.363323: I tensorflow/core/util/port.cc:113] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
      "WARNING:tensorflow:From C:\\Users\\mit017\\anaconda3\\Lib\\site-packages\\keras\\src\\losses.py:2976: The name tf.losses.sparse_softmax_cross_entropy is deprecated. Please use tf.compat.v1.losses.sparse_softmax_cross_entropy instead.\n",
      "\n",
      "\n",
      "  0%|          | 0/54 [00:00<?, ?it/s]\n",
      "   821/834        0G      5.63    0.0638         0       5.7         8       640:   0%|          | 0/54 [00:06<?, ?it/s]\n",
      "   821/834        0G      5.63    0.0638         0       5.7         8       640:   2%|1         | 1/54 [00:06<06:01,  6.82s/it]\n",
      "   821/834        0G      4.92    0.0804         0         5         9       640:   2%|1         | 1/54 [00:13<06:01,  6.82s/it]\n",
      "   821/834        0G      4.92    0.0804         0         5         9       640:   4%|3         | 2/54 [00:13<05:45,  6.64s/it]\n",
      "   821/834        0G      4.84      0.09         0      4.93         9       640:   4%|3         | 2/54 [00:20<05:45,  6.64s/it]\n",
      "   821/834        0G      4.84      0.09         0      4.93         9       640:   6%|5         | 3/54 [00:20<05:39,  6.66s/it]\n",
      "   821/834        0G      4.78    0.0876         0      4.87         9       640:   6%|5         | 3/54 [00:26<05:39,  6.66s/it]\n",
      "   821/834        0G      4.78    0.0876         0      4.87         9       640:   7%|7         | 4/54 [00:26<05:30,  6.60s/it]\n",
      "   821/834        0G      4.78    0.0953         0      4.88         9       640:   7%|7         | 4/54 [00:33<05:30,  6.60s/it]\n",
      "   821/834        0G      4.78    0.0953         0      4.88         9       640:   9%|9         | 5/54 [00:33<05:29,  6.73s/it]\n",
      "   821/834        0G      4.75    0.0955         0      4.84         9       640:   9%|9         | 5/54 [00:40<05:29,  6.73s/it]\n",
      "   821/834        0G      4.75    0.0955         0      4.84         9       640:  11%|#1        | 6/54 [00:40<05:20,  6.67s/it]\n",
      "   821/834        0G      4.73    0.0924         0      4.82         9       640:  11%|#1        | 6/54 [00:47<05:20,  6.67s/it]\n",
      "   821/834        0G      4.73    0.0924         0      4.82         9       640:  13%|#2        | 7/54 [00:47<05:22,  6.87s/it]\n",
      "   821/834        0G      4.64    0.0889         0      4.73         9       640:  13%|#2        | 7/54 [00:54<05:22,  6.87s/it]\n",
      "   821/834        0G      4.64    0.0889         0      4.73         9       640:  15%|#4        | 8/54 [00:54<05:24,  7.06s/it]\n",
      "   821/834        0G      4.72    0.0856         0       4.8         9       640:  15%|#4        | 8/54 [01:03<05:24,  7.06s/it]\n",
      "   821/834        0G      4.72    0.0856         0       4.8         9       640:  17%|#6        | 9/54 [01:03<05:47,  7.73s/it]\n",
      "   821/834        0G      4.74    0.0871         0      4.83        11       640:  17%|#6        | 9/54 [01:11<05:47,  7.73s/it]\n",
      "   821/834        0G      4.74    0.0871         0      4.83        11       640:  19%|#8        | 10/54 [01:11<05:42,  7.78s/it]\n",
      "   821/834        0G      4.74    0.0857         0      4.83         9       640:  19%|#8        | 10/54 [01:18<05:42,  7.78s/it]\n",
      "   821/834        0G      4.74    0.0857         0      4.83         9       640:  20%|##        | 11/54 [01:18<05:23,  7.53s/it]\n",
      "   821/834        0G      4.72    0.0865         0       4.8         9       640:  20%|##        | 11/54 [01:25<05:23,  7.53s/it]\n",
      "   821/834        0G      4.72    0.0865         0       4.8         9       640:  22%|##2       | 12/54 [01:25<05:10,  7.40s/it]\n",
      "   821/834        0G      4.71     0.089         0       4.8         9       640:  22%|##2       | 12/54 [01:33<05:10,  7.40s/it]\n",
      "   821/834        0G      4.71     0.089         0       4.8         9       640:  24%|##4       | 13/54 [01:33<05:03,  7.39s/it]\n",
      "   821/834        0G      4.69    0.0883         0      4.78         9       640:  24%|##4       | 13/54 [01:40<05:03,  7.39s/it]\n",
      "   821/834        0G      4.69    0.0883         0      4.78         9       640:  26%|##5       | 14/54 [01:40<04:47,  7.19s/it]\n",
      "   821/834        0G      4.71    0.0872         0      4.79         9       640:  26%|##5       | 14/54 [01:47<04:47,  7.19s/it]\n",
      "   821/834        0G      4.71    0.0872         0      4.79         9       640:  28%|##7       | 15/54 [01:47<04:41,  7.23s/it]\n",
      "   821/834        0G      4.74    0.0883         0      4.82         9       640:  28%|##7       | 15/54 [01:54<04:41,  7.23s/it]\n",
      "   821/834        0G      4.74    0.0883         0      4.82         9       640:  30%|##9       | 16/54 [01:54<04:28,  7.07s/it]\n",
      "   821/834        0G      4.72    0.0894         0      4.81         9       640:  30%|##9       | 16/54 [02:01<04:28,  7.07s/it]\n",
      "   821/834        0G      4.72    0.0894         0      4.81         9       640:  31%|###1      | 17/54 [02:01<04:23,  7.13s/it]\n",
      "   821/834        0G      4.74    0.0884         0      4.83        10       640:  31%|###1      | 17/54 [02:08<04:23,  7.13s/it]\n",
      "   821/834        0G      4.74    0.0884         0      4.83        10       640:  33%|###3      | 18/54 [02:08<04:13,  7.03s/it]\n",
      "   821/834        0G       4.6    0.0864         0      4.69         9       512:  33%|###3      | 18/54 [02:13<04:13,  7.03s/it]\n",
      "   821/834        0G       4.6    0.0864         0      4.69         9       512:  35%|###5      | 19/54 [02:13<03:44,  6.42s/it]\n",
      "   821/834        0G      4.43    0.0869         0      4.52         9       512:  35%|###5      | 19/54 [02:17<03:44,  6.42s/it]\n",
      "   821/834        0G      4.43    0.0869         0      4.52         9       512:  37%|###7      | 20/54 [02:17<03:17,  5.82s/it]\n",
      "   821/834        0G      4.27    0.0894         0      4.36        12       512:  37%|###7      | 20/54 [02:22<03:17,  5.82s/it]\n",
      "   821/834        0G      4.27    0.0894         0      4.36        12       512:  39%|###8      | 21/54 [02:22<02:59,  5.44s/it]\n",
      "   821/834        0G      4.14    0.0912         0      4.23        11       512:  39%|###8      | 21/54 [02:26<02:59,  5.44s/it]\n",
      "   821/834        0G      4.14    0.0912         0      4.23        11       512:  41%|####      | 22/54 [02:26<02:47,  5.23s/it]\n",
      "   821/834        0G      4.01    0.0918         0       4.1        10       512:  41%|####      | 22/54 [02:31<02:47,  5.23s/it]\n",
      "   821/834        0G      4.01    0.0918         0       4.1        10       512:  43%|####2     | 23/54 [02:31<02:35,  5.02s/it]\n",
      "   821/834        0G       3.9     0.092         0      3.99         9       512:  43%|####2     | 23/54 [02:35<02:35,  5.02s/it]\n",
      "   821/834        0G       3.9     0.092         0      3.99         9       512:  44%|####4     | 24/54 [02:35<02:24,  4.81s/it]\n",
      "   821/834        0G      4.04     0.092         0      4.13         9       512:  44%|####4     | 24/54 [02:39<02:24,  4.81s/it]\n",
      "   821/834        0G      4.04     0.092         0      4.13         9       512:  46%|####6     | 25/54 [02:39<02:14,  4.64s/it]\n",
      "   821/834        0G      3.94    0.0919         0      4.03         8       512:  46%|####6     | 25/54 [02:44<02:14,  4.64s/it]\n",
      "   821/834        0G      3.94    0.0919         0      4.03         8       512:  48%|####8     | 26/54 [02:44<02:06,  4.52s/it]\n",
      "   821/834        0G      4.06    0.0911         0      4.15         9       512:  48%|####8     | 26/54 [02:48<02:06,  4.52s/it]\n",
      "   821/834        0G      4.06    0.0911         0      4.15         9       512:  50%|#####     | 27/54 [02:48<02:00,  4.46s/it]\n",
      "   821/834        0G      3.95    0.0919         0      4.04        10       512:  50%|#####     | 27/54 [02:52<02:00,  4.46s/it]\n",
      "   821/834        0G      3.95    0.0919         0      4.04        10       512:  52%|#####1    | 28/54 [02:52<01:54,  4.40s/it]\n",
      "   821/834        0G      4.04     0.092         0      4.14         9       512:  52%|#####1    | 28/54 [02:57<01:54,  4.40s/it]\n",
      "   821/834        0G      4.04     0.092         0      4.14         9       512:  54%|#####3    | 29/54 [02:57<01:48,  4.36s/it]\n",
      "   821/834        0G      3.96    0.0913         0      4.05         7       512:  54%|#####3    | 29/54 [03:01<01:48,  4.36s/it]\n",
      "   821/834        0G      3.96    0.0913         0      4.05         7       512:  56%|#####5    | 30/54 [03:01<01:43,  4.33s/it]\n",
      "   821/834        0G      3.87    0.0916         0      3.97         9       512:  56%|#####5    | 30/54 [03:05<01:43,  4.33s/it]\n",
      "   821/834        0G      3.87    0.0916         0      3.97         9       512:  57%|#####7    | 31/54 [03:05<01:39,  4.31s/it]\n",
      "   821/834        0G      3.79     0.092         0      3.88        10       512:  57%|#####7    | 31/54 [03:09<01:39,  4.31s/it]\n",
      "   821/834        0G      3.79     0.092         0      3.88        10       512:  59%|#####9    | 32/54 [03:09<01:34,  4.32s/it]\n",
      "   821/834        0G      3.71    0.0926         0      3.81        10       512:  59%|#####9    | 32/54 [03:14<01:34,  4.32s/it]\n",
      "   821/834        0G      3.71    0.0926         0      3.81        10       512:  61%|######1   | 33/54 [03:14<01:30,  4.31s/it]\n",
      "   821/834        0G      3.64    0.0923         0      3.74         9       512:  61%|######1   | 33/54 [03:18<01:30,  4.31s/it]\n",
      "   821/834        0G      3.64    0.0923         0      3.74         9       512:  63%|######2   | 34/54 [03:18<01:26,  4.34s/it]\n",
      "   821/834        0G      3.58     0.092         0      3.68        11       512:  63%|######2   | 34/54 [03:23<01:26,  4.34s/it]\n",
      "   821/834        0G      3.58     0.092         0      3.68        11       512:  65%|######4   | 35/54 [03:23<01:24,  4.47s/it]\n",
      "   821/834        0G      3.52    0.0917         0      3.61         8       512:  65%|######4   | 35/54 [03:27<01:24,  4.47s/it]\n",
      "   821/834        0G      3.52    0.0917         0      3.61         8       512:  67%|######6   | 36/54 [03:27<01:21,  4.50s/it]\n",
      "   821/834        0G      3.46    0.0916         0      3.55         9       512:  67%|######6   | 36/54 [03:32<01:21,  4.50s/it]\n",
      "   821/834        0G      3.46    0.0916         0      3.55         9       512:  69%|######8   | 37/54 [03:32<01:17,  4.54s/it]\n",
      "   821/834        0G      3.41     0.091         0       3.5         8       512:  69%|######8   | 37/54 [03:37<01:17,  4.54s/it]\n",
      "   821/834        0G      3.41     0.091         0       3.5         8       512:  70%|#######   | 38/54 [03:37<01:13,  4.57s/it]\n",
      "   821/834        0G      3.35    0.0913         0      3.44        10       512:  70%|#######   | 38/54 [03:41<01:13,  4.57s/it]\n",
      "   821/834        0G      3.35    0.0913         0      3.44        10       512:  72%|#######2  | 39/54 [03:41<01:08,  4.58s/it]\n",
      "   821/834        0G      3.31    0.0919         0       3.4        11       512:  72%|#######2  | 39/54 [03:46<01:08,  4.58s/it]\n",
      "   821/834        0G      3.31    0.0919         0       3.4        11       512:  74%|#######4  | 40/54 [03:46<01:05,  4.65s/it]\n",
      "   821/834        0G      3.41    0.0921         0       3.5        10       512:  74%|#######4  | 40/54 [03:51<01:05,  4.65s/it]\n",
      "   821/834        0G      3.41    0.0921         0       3.5        10       512:  76%|#######5  | 41/54 [03:51<01:00,  4.62s/it]\n",
      "   821/834        0G      3.35     0.093         0      3.44        13       512:  76%|#######5  | 41/54 [03:55<01:00,  4.62s/it]\n",
      "   821/834        0G      3.35     0.093         0      3.44        13       512:  78%|#######7  | 42/54 [03:55<00:55,  4.59s/it]\n",
      "   821/834        0G      3.31    0.0929         0       3.4        10       512:  78%|#######7  | 42/54 [04:00<00:55,  4.59s/it]\n",
      "   821/834        0G      3.31    0.0929         0       3.4        10       512:  80%|#######9  | 43/54 [04:00<00:51,  4.64s/it]\n",
      "   821/834        0G      3.39     0.094         0      3.48        12       512:  80%|#######9  | 43/54 [04:05<00:51,  4.64s/it]\n",
      "   821/834        0G      3.39     0.094         0      3.48        12       512:  81%|########1 | 44/54 [04:05<00:46,  4.67s/it]\n",
      "   821/834        0G      3.47    0.0936         0      3.57         9       512:  81%|########1 | 44/54 [04:09<00:46,  4.67s/it]\n",
      "   821/834        0G      3.47    0.0936         0      3.57         9       512:  83%|########3 | 45/54 [04:09<00:41,  4.60s/it]\n",
      "   821/834        0G      3.42    0.0939         0      3.51        10       512:  83%|########3 | 45/54 [04:14<00:41,  4.60s/it]\n",
      "   821/834        0G      3.42    0.0939         0      3.51        10       512:  85%|########5 | 46/54 [04:14<00:36,  4.54s/it]\n",
      "   821/834        0G      3.38    0.0933         0      3.47         8       512:  85%|########5 | 46/54 [04:18<00:36,  4.54s/it]\n",
      "   821/834        0G      3.38    0.0933         0      3.47         8       512:  87%|########7 | 47/54 [04:18<00:32,  4.57s/it]\n",
      "   821/834        0G      3.34     0.093         0      3.43         9       512:  87%|########7 | 47/54 [04:23<00:32,  4.57s/it]\n",
      "   821/834        0G      3.34     0.093         0      3.43         9       512:  89%|########8 | 48/54 [04:23<00:27,  4.58s/it]\n",
      "   821/834        0G      3.39    0.0931         0      3.48         8       512:  89%|########8 | 48/54 [04:28<00:27,  4.58s/it]\n",
      "   821/834        0G      3.39    0.0931         0      3.48         8       512:  91%|######### | 49/54 [04:28<00:23,  4.63s/it]\n",
      "   821/834        0G      3.35    0.0927         0      3.44         8       512:  91%|######### | 49/54 [04:32<00:23,  4.63s/it]\n",
      "   821/834        0G      3.35    0.0927         0      3.44         8       512:  93%|#########2| 50/54 [04:32<00:18,  4.62s/it]\n",
      "   821/834        0G      3.31    0.0923         0       3.4         9       512:  93%|#########2| 50/54 [04:37<00:18,  4.62s/it]\n",
      "   821/834        0G      3.31    0.0923         0       3.4         9       512:  94%|#########4| 51/54 [04:37<00:13,  4.64s/it]\n",
      "   821/834        0G      3.27    0.0924         0      3.36        10       512:  94%|#########4| 51/54 [04:41<00:13,  4.64s/it]\n",
      "   821/834        0G      3.27    0.0924         0      3.36        10       512:  96%|#########6| 52/54 [04:41<00:09,  4.63s/it]\n",
      "   821/834        0G      3.23    0.0922         0      3.33         9       512:  96%|#########6| 52/54 [04:46<00:09,  4.63s/it]\n",
      "   821/834        0G      3.23    0.0922         0      3.33         9       512:  98%|#########8| 53/54 [04:46<00:04,  4.62s/it]\n",
      "   821/834        0G       3.2    0.0914         0      3.29         3       512:  98%|#########8| 53/54 [04:48<00:04,  4.62s/it]\n",
      "   821/834        0G       3.2    0.0914         0      3.29         3       512: 100%|##########| 54/54 [04:48<00:00,  3.70s/it]\n",
      "   821/834        0G       3.2    0.0914         0      3.29         3       512: 100%|##########| 54/54 [04:49<00:00,  5.36s/it]\n",
      "\n",
      "               Class    Images   Targets         P         R   mAP@0.5        F1:   0%|          | 0/14 [00:00<?, ?it/s]2024-03-04 16:13:08.966536: I tensorflow/core/util/port.cc:113] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
      "WARNING:tensorflow:From C:\\Users\\mit017\\anaconda3\\Lib\\site-packages\\keras\\src\\losses.py:2976: The name tf.losses.sparse_softmax_cross_entropy is deprecated. Please use tf.compat.v1.losses.sparse_softmax_cross_entropy instead.\n",
      "\n",
      "2024-03-04 16:13:20.296511: I tensorflow/core/util/port.cc:113] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
      "WARNING:tensorflow:From C:\\Users\\mit017\\anaconda3\\Lib\\site-packages\\keras\\src\\losses.py:2976: The name tf.losses.sparse_softmax_cross_entropy is deprecated. Please use tf.compat.v1.losses.sparse_softmax_cross_entropy instead.\n",
      "\n",
      "2024-03-04 16:13:31.504747: I tensorflow/core/util/port.cc:113] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
      "WARNING:tensorflow:From C:\\Users\\mit017\\anaconda3\\Lib\\site-packages\\keras\\src\\losses.py:2976: The name tf.losses.sparse_softmax_cross_entropy is deprecated. Please use tf.compat.v1.losses.sparse_softmax_cross_entropy instead.\n",
      "\n",
      "C:\\Users\\mit017\\anaconda3\\Lib\\site-packages\\torch\\functional.py:507: UserWarning: torch.meshgrid: in an upcoming release, it will be required to pass the indexing argument. (Triggered internally at ..\\aten\\src\\ATen\\native\\TensorShape.cpp:3550.)\n",
      "  return _VF.meshgrid(tensors, **kwargs)  # type: ignore[attr-defined]\n",
      "\n",
      "               Class    Images   Targets         P         R   mAP@0.5        F1:   7%|7         | 1/14 [00:36<07:55, 36.58s/it]\n",
      "               Class    Images   Targets         P         R   mAP@0.5        F1:  14%|#4        | 2/14 [00:38<03:16, 16.36s/it]\n",
      "               Class    Images   Targets         P         R   mAP@0.5        F1:  21%|##1       | 3/14 [00:40<01:48,  9.87s/it]\n",
      "               Class    Images   Targets         P         R   mAP@0.5        F1:  29%|##8       | 4/14 [00:43<01:08,  6.87s/it]\n",
      "               Class    Images   Targets         P         R   mAP@0.5        F1:  36%|###5      | 5/14 [00:45<00:46,  5.16s/it]\n",
      "               Class    Images   Targets         P         R   mAP@0.5        F1:  43%|####2     | 6/14 [00:47<00:32,  4.11s/it]\n",
      "               Class    Images   Targets         P         R   mAP@0.5        F1:  50%|#####     | 7/14 [00:49<00:24,  3.45s/it]\n",
      "               Class    Images   Targets         P         R   mAP@0.5        F1:  57%|#####7    | 8/14 [00:51<00:18,  3.02s/it]\n",
      "               Class    Images   Targets         P         R   mAP@0.5        F1:  64%|######4   | 9/14 [00:53<00:13,  2.72s/it]\n",
      "               Class    Images   Targets         P         R   mAP@0.5        F1:  71%|#######1  | 10/14 [00:55<00:10,  2.52s/it]\n",
      "               Class    Images   Targets         P         R   mAP@0.5        F1:  79%|#######8  | 11/14 [00:57<00:07,  2.39s/it]\n",
      "               Class    Images   Targets         P         R   mAP@0.5        F1:  86%|########5 | 12/14 [00:59<00:04,  2.30s/it]\n",
      "               Class    Images   Targets         P         R   mAP@0.5        F1:  93%|#########2| 13/14 [01:02<00:02,  2.25s/it]\n",
      "               Class    Images   Targets         P         R   mAP@0.5        F1: 100%|##########| 14/14 [01:02<00:00,  1.80s/it]\n",
      "               Class    Images   Targets         P         R   mAP@0.5        F1: 100%|##########| 14/14 [01:03<00:00,  4.56s/it]\n",
      "2024-03-04 16:14:12.613819: I tensorflow/core/util/port.cc:113] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
      "WARNING:tensorflow:From C:\\Users\\mit017\\anaconda3\\Lib\\site-packages\\keras\\src\\losses.py:2976: The name tf.losses.sparse_softmax_cross_entropy is deprecated. Please use tf.compat.v1.losses.sparse_softmax_cross_entropy instead.\n",
      "\n",
      "2024-03-04 16:14:23.162310: I tensorflow/core/util/port.cc:113] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
      "WARNING:tensorflow:From C:\\Users\\mit017\\anaconda3\\Lib\\site-packages\\keras\\src\\losses.py:2976: The name tf.losses.sparse_softmax_cross_entropy is deprecated. Please use tf.compat.v1.losses.sparse_softmax_cross_entropy instead.\n",
      "\n",
      "2024-03-04 16:14:34.775806: I tensorflow/core/util/port.cc:113] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
      "WARNING:tensorflow:From C:\\Users\\mit017\\anaconda3\\Lib\\site-packages\\keras\\src\\losses.py:2976: The name tf.losses.sparse_softmax_cross_entropy is deprecated. Please use tf.compat.v1.losses.sparse_softmax_cross_entropy instead.\n",
      "\n",
      "\n",
      "  0%|          | 0/54 [00:00<?, ?it/s]\n",
      "   822/834        0G      1.16     0.121         0      1.28        10       512:   0%|          | 0/54 [00:04<?, ?it/s]\n",
      "   822/834        0G      1.16     0.121         0      1.28        10       512:   2%|1         | 1/54 [00:04<03:59,  4.51s/it]\n",
      "   822/834        0G      1.22     0.117         0      1.33        12       512:   2%|1         | 1/54 [00:09<03:59,  4.51s/it]\n",
      "   822/834        0G      1.22     0.117         0      1.33        12       512:   4%|3         | 2/54 [00:09<04:01,  4.65s/it]\n",
      "   822/834        0G      3.27     0.124         0       3.4        12       512:   4%|3         | 2/54 [00:13<04:01,  4.65s/it]\n",
      "   822/834        0G      3.27     0.124         0       3.4        12       512:   6%|5         | 3/54 [00:13<03:53,  4.58s/it]\n",
      "   822/834        0G      2.85     0.109         0      2.96         9       512:   6%|5         | 3/54 [00:18<03:53,  4.58s/it]\n",
      "   822/834        0G      2.85     0.109         0      2.96         9       512:   7%|7         | 4/54 [00:18<03:46,  4.53s/it]\n",
      "   822/834        0G      3.43     0.111         0      3.54        10       512:   7%|7         | 4/54 [00:22<03:46,  4.53s/it]\n",
      "   822/834        0G      3.43     0.111         0      3.54        10       512:   9%|9         | 5/54 [00:22<03:44,  4.57s/it]\n",
      "   822/834        0G      3.09     0.106         0       3.2         9       512:   9%|9         | 5/54 [00:27<03:44,  4.57s/it]\n",
      "   822/834        0G      3.09     0.106         0       3.2         9       512:  11%|#1        | 6/54 [00:27<03:42,  4.63s/it]\n",
      "   822/834        0G      2.88     0.103         0      2.98         9       320:  11%|#1        | 6/54 [00:29<03:42,  4.63s/it]\n",
      "   822/834        0G      2.88     0.103         0      2.98         9       320:  13%|#2        | 7/54 [00:29<03:02,  3.88s/it]\n",
      "   822/834        0G       2.7     0.102         0       2.8         9       320:  13%|#2        | 7/54 [00:31<03:02,  3.88s/it]\n",
      "   822/834        0G       2.7     0.102         0       2.8         9       320:  15%|#4        | 8/54 [00:31<02:29,  3.25s/it]\n",
      "   822/834        0G      2.57     0.105         0      2.67        11       320:  15%|#4        | 8/54 [00:33<02:29,  3.25s/it]\n",
      "   822/834        0G      2.57     0.105         0      2.67        11       320:  17%|#6        | 9/54 [00:33<02:06,  2.82s/it]\n",
      "   822/834        0G      2.42     0.105         0      2.52         8       320:  17%|#6        | 9/54 [00:35<02:06,  2.82s/it]\n",
      "   822/834        0G      2.42     0.105         0      2.52         8       320:  19%|#8        | 10/54 [00:35<01:50,  2.52s/it]\n",
      "   822/834        0G      2.32     0.107         0      2.43         9       320:  19%|#8        | 10/54 [00:37<01:50,  2.52s/it]\n",
      "   822/834        0G      2.32     0.107         0      2.43         9       320:  20%|##        | 11/54 [00:37<01:39,  2.32s/it]\n",
      "   822/834        0G      2.23      0.11         0      2.34        11       320:  20%|##        | 11/54 [00:39<01:39,  2.32s/it]\n",
      "   822/834        0G      2.23      0.11         0      2.34        11       320:  22%|##2       | 12/54 [00:39<01:30,  2.16s/it]\n",
      "   822/834        0G      2.16     0.114         0      2.28         9       320:  22%|##2       | 12/54 [00:41<01:30,  2.16s/it]\n",
      "   822/834        0G      2.16     0.114         0      2.28         9       320:  24%|##4       | 13/54 [00:41<01:24,  2.06s/it]\n",
      "   822/834        0G       2.1     0.116         0      2.22         9       320:  24%|##4       | 13/54 [00:42<01:24,  2.06s/it]\n",
      "   822/834        0G       2.1     0.116         0      2.22         9       320:  26%|##5       | 14/54 [00:42<01:19,  2.00s/it]\n",
      "   822/834        0G      2.06     0.117         0      2.17         9       320:  26%|##5       | 14/54 [00:44<01:19,  2.00s/it]\n",
      "   822/834        0G      2.06     0.117         0      2.17         9       320:  28%|##7       | 15/54 [00:44<01:16,  1.95s/it]\n",
      "   822/834        0G      2.01     0.123         0      2.14        12       320:  28%|##7       | 15/54 [00:46<01:16,  1.95s/it]\n",
      "   822/834        0G      2.01     0.123         0      2.14        12       320:  30%|##9       | 16/54 [00:46<01:14,  1.95s/it]\n",
      "   822/834        0G      1.97     0.122         0      2.09         9       320:  30%|##9       | 16/54 [00:48<01:14,  1.95s/it]\n",
      "   822/834        0G      1.97     0.122         0      2.09         9       320:  31%|###1      | 17/54 [00:48<01:12,  1.96s/it]\n",
      "   822/834        0G      1.94     0.124         0      2.07        12       320:  31%|###1      | 17/54 [00:50<01:12,  1.96s/it]\n",
      "   822/834        0G      1.94     0.124         0      2.07        12       320:  33%|###3      | 18/54 [00:50<01:11,  2.00s/it]\n",
      "   822/834        0G      1.91     0.124         0      2.04        10       320:  33%|###3      | 18/54 [00:52<01:11,  2.00s/it]\n",
      "   822/834        0G      1.91     0.124         0      2.04        10       320:  35%|###5      | 19/54 [00:52<01:08,  1.96s/it]\n",
      "   822/834        0G      1.89     0.123         0      2.01         9       320:  35%|###5      | 19/54 [00:54<01:08,  1.96s/it]\n",
      "   822/834        0G      1.89     0.123         0      2.01         9       320:  37%|###7      | 20/54 [00:54<01:05,  1.92s/it]\n",
      "   822/834        0G      1.87     0.121         0      1.99         8       320:  37%|###7      | 20/54 [00:56<01:05,  1.92s/it]\n",
      "   822/834        0G      1.87     0.121         0      1.99         8       320:  39%|###8      | 21/54 [00:56<01:03,  1.93s/it]\n",
      "   822/834        0G      1.85      0.12         0      1.97         9       320:  39%|###8      | 21/54 [00:58<01:03,  1.93s/it]\n",
      "   822/834        0G      1.85      0.12         0      1.97         9       320:  41%|####      | 22/54 [00:58<01:01,  1.93s/it]\n",
      "   822/834        0G      1.83      0.12         0      1.95        12       320:  41%|####      | 22/54 [01:00<01:01,  1.93s/it]\n",
      "   822/834        0G      1.83      0.12         0      1.95        12       320:  43%|####2     | 23/54 [01:00<00:59,  1.93s/it]\n",
      "   822/834        0G      1.81      0.12         0      1.93         9       320:  43%|####2     | 23/54 [01:02<00:59,  1.93s/it]\n",
      "   822/834        0G      1.81      0.12         0      1.93         9       320:  44%|####4     | 24/54 [01:02<00:57,  1.93s/it]\n",
      "   822/834        0G      1.79     0.119         0      1.91         8       320:  44%|####4     | 24/54 [01:04<00:57,  1.93s/it]\n",
      "   822/834        0G      1.79     0.119         0      1.91         8       320:  46%|####6     | 25/54 [01:04<00:57,  1.97s/it]\n",
      "   822/834        0G      1.78     0.122         0       1.9        12       320:  46%|####6     | 25/54 [01:06<00:57,  1.97s/it]\n",
      "   822/834        0G      1.78     0.122         0       1.9        12       320:  48%|####8     | 26/54 [01:06<00:55,  1.98s/it]\n",
      "   822/834        0G      1.76     0.123         0      1.88        10       320:  48%|####8     | 26/54 [01:08<00:55,  1.98s/it]\n",
      "   822/834        0G      1.76     0.123         0      1.88        10       320:  50%|#####     | 27/54 [01:08<00:53,  1.98s/it]\n",
      "   822/834        0G      1.73     0.123         0      1.85         9       448:  50%|#####     | 27/54 [01:12<00:53,  1.98s/it]\n",
      "   822/834        0G      1.73     0.123         0      1.85         9       448:  52%|#####1    | 28/54 [01:12<01:06,  2.55s/it]\n",
      "   822/834        0G      1.71     0.122         0      1.83         9       448:  52%|#####1    | 28/54 [01:15<01:06,  2.55s/it]\n",
      "   822/834        0G      1.71     0.122         0      1.83         9       448:  54%|#####3    | 29/54 [01:15<01:11,  2.85s/it]\n",
      "   822/834        0G      1.69     0.122         0      1.81        11       448:  54%|#####3    | 29/54 [01:19<01:11,  2.85s/it]\n",
      "   822/834        0G      1.69     0.122         0      1.81        11       448:  56%|#####5    | 30/54 [01:19<01:12,  3.04s/it]\n",
      "   822/834        0G      1.68     0.121         0       1.8         9       448:  56%|#####5    | 30/54 [01:22<01:12,  3.04s/it]\n",
      "   822/834        0G      1.68     0.121         0       1.8         9       448:  57%|#####7    | 31/54 [01:22<01:11,  3.11s/it]\n",
      "   822/834        0G      1.66     0.121         0      1.78         9       448:  57%|#####7    | 31/54 [01:25<01:11,  3.11s/it]\n",
      "   822/834        0G      1.66     0.121         0      1.78         9       448:  59%|#####9    | 32/54 [01:25<01:09,  3.16s/it]\n",
      "   822/834        0G      1.64      0.12         0      1.76         9       448:  59%|#####9    | 32/54 [01:28<01:09,  3.16s/it]\n",
      "   822/834        0G      1.64      0.12         0      1.76         9       448:  61%|######1   | 33/54 [01:28<01:07,  3.19s/it]\n",
      "   822/834        0G      1.63     0.121         0      1.75        12       448:  61%|######1   | 33/54 [01:32<01:07,  3.19s/it]\n",
      "   822/834        0G      1.63     0.121         0      1.75        12       448:  63%|######2   | 34/54 [01:32<01:03,  3.19s/it]\n",
      "   822/834        0G      1.62      0.12         0      1.74        10       448:  63%|######2   | 34/54 [01:35<01:03,  3.19s/it]\n",
      "   822/834        0G      1.62      0.12         0      1.74        10       448:  65%|######4   | 35/54 [01:35<01:00,  3.20s/it]\n",
      "   822/834        0G      1.61     0.119         0      1.73         9       448:  65%|######4   | 35/54 [01:38<01:00,  3.20s/it]\n",
      "   822/834        0G      1.61     0.119         0      1.73         9       448:  67%|######6   | 36/54 [01:38<00:57,  3.21s/it]\n",
      "   822/834        0G       1.6     0.118         0      1.72         9       448:  67%|######6   | 36/54 [01:42<00:57,  3.21s/it]\n",
      "   822/834        0G       1.6     0.118         0      1.72         9       448:  69%|######8   | 37/54 [01:42<00:55,  3.26s/it]\n",
      "   822/834        0G      1.59     0.118         0      1.71         9       448:  69%|######8   | 37/54 [01:45<00:55,  3.26s/it]\n",
      "   822/834        0G      1.59     0.118         0      1.71         9       448:  70%|#######   | 38/54 [01:45<00:52,  3.28s/it]\n",
      "   822/834        0G      1.58     0.117         0       1.7        10       448:  70%|#######   | 38/54 [01:49<00:52,  3.28s/it]\n",
      "   822/834        0G      1.58     0.117         0       1.7        10       448:  72%|#######2  | 39/54 [01:49<00:50,  3.40s/it]\n",
      "   822/834        0G      1.57     0.117         0      1.69         8       448:  72%|#######2  | 39/54 [01:52<00:50,  3.40s/it]\n",
      "   822/834        0G      1.57     0.117         0      1.69         8       448:  74%|#######4  | 40/54 [01:52<00:48,  3.47s/it]\n",
      "   822/834        0G      1.56     0.116         0      1.68         9       448:  74%|#######4  | 40/54 [01:56<00:48,  3.47s/it]\n",
      "   822/834        0G      1.56     0.116         0      1.68         9       448:  76%|#######5  | 41/54 [01:56<00:45,  3.52s/it]\n",
      "   822/834        0G      1.56     0.115         0      1.67        12       448:  76%|#######5  | 41/54 [01:59<00:45,  3.52s/it]\n",
      "   822/834        0G      1.56     0.115         0      1.67        12       448:  78%|#######7  | 42/54 [01:59<00:41,  3.50s/it]\n",
      "   822/834        0G      1.54     0.115         0      1.66         9       448:  78%|#######7  | 42/54 [02:03<00:41,  3.50s/it]\n",
      "   822/834        0G      1.54     0.115         0      1.66         9       448:  80%|#######9  | 43/54 [02:03<00:38,  3.51s/it]\n",
      "   822/834        0G      1.54     0.115         0      1.65         9       448:  80%|#######9  | 43/54 [02:06<00:38,  3.51s/it]\n",
      "   822/834        0G      1.54     0.115         0      1.65         9       448:  81%|########1 | 44/54 [02:06<00:34,  3.48s/it]\n",
      "   822/834        0G      1.53     0.114         0      1.65         9       448:  81%|########1 | 44/54 [02:10<00:34,  3.48s/it]\n",
      "   822/834        0G      1.53     0.114         0      1.65         9       448:  83%|########3 | 45/54 [02:10<00:31,  3.53s/it]\n",
      "   822/834        0G      1.52     0.114         0      1.64         9       448:  83%|########3 | 45/54 [02:13<00:31,  3.53s/it]\n",
      "   822/834        0G      1.52     0.114         0      1.64         9       448:  85%|########5 | 46/54 [02:13<00:27,  3.50s/it]\n",
      "   822/834        0G      1.52     0.115         0      1.63         9       448:  85%|########5 | 46/54 [02:17<00:27,  3.50s/it]\n",
      "   822/834        0G      1.52     0.115         0      1.63         9       448:  87%|########7 | 47/54 [02:17<00:24,  3.45s/it]\n",
      "   822/834        0G      1.52     0.114         0      1.63        11       448:  87%|########7 | 47/54 [02:20<00:24,  3.45s/it]\n",
      "   822/834        0G      1.52     0.114         0      1.63        11       448:  89%|########8 | 48/54 [02:20<00:20,  3.40s/it]\n",
      "   822/834        0G      1.63     0.114         0      1.74        12       576:  89%|########8 | 48/54 [02:25<00:20,  3.40s/it]\n",
      "   822/834        0G      1.63     0.114         0      1.74        12       576:  91%|######### | 49/54 [02:25<00:20,  4.07s/it]\n",
      "   822/834        0G      1.73     0.113         0      1.85         9       576:  91%|######### | 49/54 [02:31<00:20,  4.07s/it]\n",
      "   822/834        0G      1.73     0.113         0      1.85         9       576:  93%|#########2| 50/54 [02:31<00:17,  4.45s/it]\n",
      "   822/834        0G      1.78     0.113         0       1.9         9       576:  93%|#########2| 50/54 [02:36<00:17,  4.45s/it]\n",
      "   822/834        0G      1.78     0.113         0       1.9         9       576:  94%|#########4| 51/54 [02:36<00:14,  4.74s/it]\n",
      "   822/834        0G      1.89     0.112         0         2        10       576:  94%|#########4| 51/54 [02:42<00:14,  4.74s/it]\n",
      "   822/834        0G      1.89     0.112         0         2        10       576:  96%|#########6| 52/54 [02:42<00:09,  4.99s/it]\n",
      "   822/834        0G      1.88     0.112         0      1.99         9       576:  96%|#########6| 52/54 [02:48<00:09,  4.99s/it]\n",
      "   822/834        0G      1.88     0.112         0      1.99         9       576:  98%|#########8| 53/54 [02:48<00:05,  5.30s/it]\n",
      "   822/834        0G      1.98     0.111         0      2.09         3       576:  98%|#########8| 53/54 [02:50<00:05,  5.30s/it]\n",
      "   822/834        0G      1.98     0.111         0      2.09         3       576: 100%|##########| 54/54 [02:50<00:00,  4.38s/it]\n",
      "   822/834        0G      1.98     0.111         0      2.09         3       576: 100%|##########| 54/54 [02:51<00:00,  3.18s/it]\n",
      "\n",
      "               Class    Images   Targets         P         R   mAP@0.5        F1:   0%|          | 0/14 [00:00<?, ?it/s]2024-03-04 16:17:37.436863: I tensorflow/core/util/port.cc:113] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
      "WARNING:tensorflow:From C:\\Users\\mit017\\anaconda3\\Lib\\site-packages\\keras\\src\\losses.py:2976: The name tf.losses.sparse_softmax_cross_entropy is deprecated. Please use tf.compat.v1.losses.sparse_softmax_cross_entropy instead.\n",
      "\n",
      "2024-03-04 16:17:48.365174: I tensorflow/core/util/port.cc:113] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
      "WARNING:tensorflow:From C:\\Users\\mit017\\anaconda3\\Lib\\site-packages\\keras\\src\\losses.py:2976: The name tf.losses.sparse_softmax_cross_entropy is deprecated. Please use tf.compat.v1.losses.sparse_softmax_cross_entropy instead.\n",
      "\n",
      "2024-03-04 16:17:59.191616: I tensorflow/core/util/port.cc:113] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
      "WARNING:tensorflow:From C:\\Users\\mit017\\anaconda3\\Lib\\site-packages\\keras\\src\\losses.py:2976: The name tf.losses.sparse_softmax_cross_entropy is deprecated. Please use tf.compat.v1.losses.sparse_softmax_cross_entropy instead.\n",
      "\n",
      "\n",
      "               Class    Images   Targets         P         R   mAP@0.5        F1:   7%|7         | 1/14 [00:34<07:34, 34.94s/it]\n",
      "               Class    Images   Targets         P         R   mAP@0.5        F1:  14%|#4        | 2/14 [00:37<03:08, 15.69s/it]\n",
      "               Class    Images   Targets         P         R   mAP@0.5        F1:  21%|##1       | 3/14 [00:39<01:43,  9.44s/it]\n",
      "               Class    Images   Targets         P         R   mAP@0.5        F1:  29%|##8       | 4/14 [00:41<01:05,  6.59s/it]\n",
      "               Class    Images   Targets         P         R   mAP@0.5        F1:  36%|###5      | 5/14 [00:43<00:44,  4.95s/it]\n",
      "               Class    Images   Targets         P         R   mAP@0.5        F1:  43%|####2     | 6/14 [00:45<00:31,  3.96s/it]\n",
      "               Class    Images   Targets         P         R   mAP@0.5        F1:  50%|#####     | 7/14 [00:47<00:23,  3.32s/it]\n",
      "               Class    Images   Targets         P         R   mAP@0.5        F1:  57%|#####7    | 8/14 [00:49<00:17,  2.93s/it]\n",
      "               Class    Images   Targets         P         R   mAP@0.5        F1:  64%|######4   | 9/14 [00:51<00:13,  2.65s/it]\n",
      "               Class    Images   Targets         P         R   mAP@0.5        F1:  71%|#######1  | 10/14 [00:53<00:09,  2.46s/it]\n",
      "               Class    Images   Targets         P         R   mAP@0.5        F1:  79%|#######8  | 11/14 [00:55<00:06,  2.33s/it]\n",
      "               Class    Images   Targets         P         R   mAP@0.5        F1:  86%|########5 | 12/14 [00:57<00:04,  2.23s/it]\n",
      "               Class    Images   Targets         P         R   mAP@0.5        F1:  93%|#########2| 13/14 [00:59<00:02,  2.15s/it]\n",
      "               Class    Images   Targets         P         R   mAP@0.5        F1: 100%|##########| 14/14 [01:00<00:00,  1.72s/it]\n",
      "               Class    Images   Targets         P         R   mAP@0.5        F1: 100%|##########| 14/14 [01:01<00:00,  4.38s/it]\n",
      "2024-03-04 16:18:38.483680: I tensorflow/core/util/port.cc:113] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
      "WARNING:tensorflow:From C:\\Users\\mit017\\anaconda3\\Lib\\site-packages\\keras\\src\\losses.py:2976: The name tf.losses.sparse_softmax_cross_entropy is deprecated. Please use tf.compat.v1.losses.sparse_softmax_cross_entropy instead.\n",
      "\n",
      "2024-03-04 16:18:48.919231: I tensorflow/core/util/port.cc:113] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
      "WARNING:tensorflow:From C:\\Users\\mit017\\anaconda3\\Lib\\site-packages\\keras\\src\\losses.py:2976: The name tf.losses.sparse_softmax_cross_entropy is deprecated. Please use tf.compat.v1.losses.sparse_softmax_cross_entropy instead.\n",
      "\n",
      "2024-03-04 16:18:59.155553: I tensorflow/core/util/port.cc:113] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
      "WARNING:tensorflow:From C:\\Users\\mit017\\anaconda3\\Lib\\site-packages\\keras\\src\\losses.py:2976: The name tf.losses.sparse_softmax_cross_entropy is deprecated. Please use tf.compat.v1.losses.sparse_softmax_cross_entropy instead.\n",
      "\n",
      "\n",
      "  0%|          | 0/54 [00:00<?, ?it/s]\n",
      "   823/834        0G      6.93      0.07         0         7         9       576:   0%|          | 0/54 [00:05<?, ?it/s]\n",
      "   823/834        0G      6.93      0.07         0         7         9       576:   2%|1         | 1/54 [00:05<04:51,  5.51s/it]\n",
      "   823/834        0G      3.94    0.0794         0      4.02         9       576:   2%|1         | 1/54 [00:12<04:51,  5.51s/it]\n",
      "   823/834        0G      3.94    0.0794         0      4.02         9       576:   4%|3         | 2/54 [00:12<05:22,  6.19s/it]\n",
      "   823/834        0G      4.86    0.0838         0      4.94         9       576:   4%|3         | 2/54 [00:18<05:22,  6.19s/it]\n",
      "   823/834        0G      4.86    0.0838         0      4.94         9       576:   6%|5         | 3/54 [00:18<05:21,  6.31s/it]\n",
      "   823/834        0G      3.88    0.0853         0      3.96         9       576:   6%|5         | 3/54 [00:24<05:21,  6.31s/it]\n",
      "   823/834        0G      3.88    0.0853         0      3.96         9       576:   7%|7         | 4/54 [00:24<05:00,  6.01s/it]\n",
      "   823/834        0G      3.34    0.0863         0      3.42        11       576:   7%|7         | 4/54 [00:29<05:00,  6.01s/it]\n",
      "   823/834        0G      3.34    0.0863         0      3.42        11       576:   9%|9         | 5/54 [00:29<04:46,  5.85s/it]\n",
      "   823/834        0G      3.97    0.0838         0      4.06         9       576:   9%|9         | 5/54 [00:35<04:46,  5.85s/it]\n",
      "   823/834        0G      3.97    0.0838         0      4.06         9       576:  11%|#1        | 6/54 [00:35<04:45,  5.94s/it]\n",
      "   823/834        0G      4.38    0.0824         0      4.47         9       576:  11%|#1        | 6/54 [00:41<04:45,  5.94s/it]\n",
      "   823/834        0G      4.38    0.0824         0      4.47         9       576:  13%|#2        | 7/54 [00:41<04:38,  5.92s/it]\n",
      "   823/834        0G      3.98    0.0821         0      4.06         9       576:  13%|#2        | 7/54 [00:48<04:38,  5.92s/it]\n",
      "   823/834        0G      3.98    0.0821         0      4.06         9       576:  15%|#4        | 8/54 [00:48<04:38,  6.05s/it]\n",
      "   823/834        0G      4.17     0.081         0      4.25         9       576:  15%|#4        | 8/54 [00:54<04:38,  6.05s/it]\n",
      "   823/834        0G      4.17     0.081         0      4.25         9       576:  17%|#6        | 9/54 [00:54<04:31,  6.03s/it]\n",
      "   823/834        0G      3.87    0.0818         0      3.95         9       576:  17%|#6        | 9/54 [00:59<04:31,  6.03s/it]\n",
      "   823/834        0G      3.87    0.0818         0      3.95         9       576:  19%|#8        | 10/54 [00:59<04:20,  5.92s/it]\n",
      "   823/834        0G      4.19    0.0807         0      4.27         9       576:  19%|#8        | 10/54 [01:05<04:20,  5.92s/it]\n",
      "   823/834        0G      4.19    0.0807         0      4.27         9       576:  20%|##        | 11/54 [01:05<04:13,  5.91s/it]\n",
      "   823/834        0G      4.37    0.0792         0      4.45         8       576:  20%|##        | 11/54 [01:11<04:13,  5.91s/it]\n",
      "   823/834        0G      4.37    0.0792         0      4.45         8       576:  22%|##2       | 12/54 [01:11<04:09,  5.93s/it]\n",
      "   823/834        0G      4.59    0.0803         0      4.67        11       576:  22%|##2       | 12/54 [01:17<04:09,  5.93s/it]\n",
      "   823/834        0G      4.59    0.0803         0      4.67        11       576:  24%|##4       | 13/54 [01:17<04:04,  5.95s/it]\n",
      "   823/834        0G      4.36    0.0795         0      4.44         9       576:  24%|##4       | 13/54 [01:23<04:04,  5.95s/it]\n",
      "   823/834        0G      4.36    0.0795         0      4.44         9       576:  26%|##5       | 14/54 [01:23<03:59,  5.98s/it]\n",
      "   823/834        0G      4.48    0.0792         0      4.55        10       576:  26%|##5       | 14/54 [01:29<03:59,  5.98s/it]\n",
      "   823/834        0G      4.48    0.0792         0      4.55        10       576:  28%|##7       | 15/54 [01:29<03:51,  5.94s/it]\n",
      "   823/834        0G      4.65    0.0797         0      4.73         9       544:  28%|##7       | 15/54 [01:34<03:51,  5.94s/it]\n",
      "   823/834        0G      4.65    0.0797         0      4.73         9       544:  30%|##9       | 16/54 [01:34<03:40,  5.81s/it]\n",
      "   823/834        0G      4.69    0.0803         0      4.77         9       544:  30%|##9       | 16/54 [01:39<03:40,  5.81s/it]\n",
      "   823/834        0G      4.69    0.0803         0      4.77         9       544:  31%|###1      | 17/54 [01:39<03:25,  5.55s/it]\n",
      "   823/834        0G       4.5    0.0831         0      4.59        13       544:  31%|###1      | 17/54 [01:44<03:25,  5.55s/it]\n",
      "   823/834        0G       4.5    0.0831         0      4.59        13       544:  33%|###3      | 18/54 [01:44<03:14,  5.39s/it]\n",
      "   823/834        0G      4.33    0.0841         0      4.41        12       544:  33%|###3      | 18/54 [01:50<03:14,  5.39s/it]\n",
      "   823/834        0G      4.33    0.0841         0      4.41        12       544:  35%|###5      | 19/54 [01:50<03:05,  5.31s/it]\n",
      "   823/834        0G      4.46    0.0862         0      4.54        12       544:  35%|###5      | 19/54 [01:55<03:05,  5.31s/it]\n",
      "   823/834        0G      4.46    0.0862         0      4.54        12       544:  37%|###7      | 20/54 [01:55<03:05,  5.46s/it]\n",
      "   823/834        0G      4.31    0.0857         0      4.39         9       544:  37%|###7      | 20/54 [02:01<03:05,  5.46s/it]\n",
      "   823/834        0G      4.31    0.0857         0      4.39         9       544:  39%|###8      | 21/54 [02:01<02:56,  5.36s/it]\n",
      "   823/834        0G      4.17    0.0856         0      4.25         9       544:  39%|###8      | 21/54 [02:05<02:56,  5.36s/it]\n",
      "   823/834        0G      4.17    0.0856         0      4.25         9       544:  41%|####      | 22/54 [02:05<02:47,  5.23s/it]\n",
      "   823/834        0G       4.3    0.0868         0      4.39        11       544:  41%|####      | 22/54 [02:11<02:47,  5.23s/it]\n",
      "   823/834        0G       4.3    0.0868         0      4.39        11       544:  43%|####2     | 23/54 [02:11<02:41,  5.20s/it]\n",
      "   823/834        0G      4.17    0.0873         0      4.26        10       544:  43%|####2     | 23/54 [02:16<02:41,  5.20s/it]\n",
      "   823/834        0G      4.17    0.0873         0      4.26        10       544:  44%|####4     | 24/54 [02:16<02:34,  5.16s/it]\n",
      "   823/834        0G      4.29    0.0869         0      4.37         9       544:  44%|####4     | 24/54 [02:21<02:34,  5.16s/it]\n",
      "   823/834        0G      4.29    0.0869         0      4.37         9       544:  46%|####6     | 25/54 [02:21<02:29,  5.17s/it]\n",
      "   823/834        0G       4.4     0.087         0      4.49         9       544:  46%|####6     | 25/54 [02:26<02:29,  5.17s/it]\n",
      "   823/834        0G       4.4     0.087         0      4.49         9       544:  48%|####8     | 26/54 [02:26<02:24,  5.16s/it]\n",
      "   823/834        0G      4.28    0.0876         0      4.37         9       544:  48%|####8     | 26/54 [02:31<02:24,  5.16s/it]\n",
      "   823/834        0G      4.28    0.0876         0      4.37         9       544:  50%|#####     | 27/54 [02:31<02:20,  5.20s/it]\n",
      "   823/834        0G      4.17    0.0886         0      4.26        12       544:  50%|#####     | 27/54 [02:36<02:20,  5.20s/it]\n",
      "   823/834        0G      4.17    0.0886         0      4.26        12       544:  52%|#####1    | 28/54 [02:36<02:11,  5.06s/it]\n",
      "   823/834        0G      4.07     0.088         0      4.16         8       544:  52%|#####1    | 28/54 [02:41<02:11,  5.06s/it]\n",
      "   823/834        0G      4.07     0.088         0      4.16         8       544:  54%|#####3    | 29/54 [02:41<02:04,  4.98s/it]\n",
      "   823/834        0G      4.11    0.0883         0      4.19        11       544:  54%|#####3    | 29/54 [02:46<02:04,  4.98s/it]\n",
      "   823/834        0G      4.11    0.0883         0      4.19        11       544:  56%|#####5    | 30/54 [02:46<01:58,  4.92s/it]\n",
      "   823/834        0G      4.21    0.0883         0       4.3         9       544:  56%|#####5    | 30/54 [02:50<01:58,  4.92s/it]\n",
      "   823/834        0G      4.21    0.0883         0       4.3         9       544:  57%|#####7    | 31/54 [02:50<01:51,  4.85s/it]\n",
      "   823/834        0G      4.29    0.0883         0      4.38         9       544:  57%|#####7    | 31/54 [02:55<01:51,  4.85s/it]\n",
      "   823/834        0G      4.29    0.0883         0      4.38         9       544:  59%|#####9    | 32/54 [02:55<01:46,  4.82s/it]\n",
      "   823/834        0G      4.19    0.0878         0      4.28         8       544:  59%|#####9    | 32/54 [03:00<01:46,  4.82s/it]\n",
      "   823/834        0G      4.19    0.0878         0      4.28         8       544:  61%|######1   | 33/54 [03:00<01:41,  4.82s/it]\n",
      "   823/834        0G      4.25    0.0893         0      4.34        12       544:  61%|######1   | 33/54 [03:05<01:41,  4.82s/it]\n",
      "   823/834        0G      4.25    0.0893         0      4.34        12       544:  63%|######2   | 34/54 [03:05<01:35,  4.79s/it]\n",
      "   823/834        0G      4.17    0.0889         0      4.25         9       544:  63%|######2   | 34/54 [03:10<01:35,  4.79s/it]\n",
      "   823/834        0G      4.17    0.0889         0      4.25         9       544:  65%|######4   | 35/54 [03:10<01:32,  4.89s/it]\n",
      "   823/834        0G      4.25    0.0886         0      4.34         9       544:  65%|######4   | 35/54 [03:15<01:32,  4.89s/it]\n",
      "   823/834        0G      4.25    0.0886         0      4.34         9       544:  67%|######6   | 36/54 [03:15<01:30,  5.04s/it]\n",
      "   823/834        0G      4.16    0.0895         0      4.25        12       512:  67%|######6   | 36/54 [03:20<01:30,  5.04s/it]\n",
      "   823/834        0G      4.16    0.0895         0      4.25        12       512:  69%|######8   | 37/54 [03:20<01:24,  4.96s/it]\n",
      "   823/834        0G      4.08    0.0898         0      4.17         9       512:  69%|######8   | 37/54 [03:24<01:24,  4.96s/it]\n",
      "   823/834        0G      4.08    0.0898         0      4.17         9       512:  70%|#######   | 38/54 [03:24<01:16,  4.76s/it]\n",
      "   823/834        0G      4.02    0.0913         0      4.11        15       512:  70%|#######   | 38/54 [03:28<01:16,  4.76s/it]\n",
      "   823/834        0G      4.02    0.0913         0      4.11        15       512:  72%|#######2  | 39/54 [03:28<01:09,  4.63s/it]\n",
      "   823/834        0G      3.95    0.0912         0      4.04        10       512:  72%|#######2  | 39/54 [03:33<01:09,  4.63s/it]\n",
      "   823/834        0G      3.95    0.0912         0      4.04        10       512:  74%|#######4  | 40/54 [03:33<01:04,  4.57s/it]\n",
      "   823/834        0G      4.01    0.0916         0       4.1        11       512:  74%|#######4  | 40/54 [03:37<01:04,  4.57s/it]\n",
      "   823/834        0G      4.01    0.0916         0       4.1        11       512:  76%|#######5  | 41/54 [03:37<00:59,  4.54s/it]\n",
      "   823/834        0G      3.94    0.0929         0      4.03        14       512:  76%|#######5  | 41/54 [03:42<00:59,  4.54s/it]\n",
      "   823/834        0G      3.94    0.0929         0      4.03        14       512:  78%|#######7  | 42/54 [03:42<00:53,  4.45s/it]\n",
      "   823/834        0G      4.01    0.0924         0       4.1         9       512:  78%|#######7  | 42/54 [03:46<00:53,  4.45s/it]\n",
      "   823/834        0G      4.01    0.0924         0       4.1         9       512:  80%|#######9  | 43/54 [03:46<00:48,  4.38s/it]\n",
      "   823/834        0G      3.95    0.0921         0      4.04         9       512:  80%|#######9  | 43/54 [03:50<00:48,  4.38s/it]\n",
      "   823/834        0G      3.95    0.0921         0      4.04         9       512:  81%|########1 | 44/54 [03:50<00:43,  4.33s/it]\n",
      "   823/834        0G      4.01     0.093         0      4.11        12       512:  81%|########1 | 44/54 [03:54<00:43,  4.33s/it]\n",
      "   823/834        0G      4.01     0.093         0      4.11        12       512:  83%|########3 | 45/54 [03:54<00:38,  4.30s/it]\n",
      "   823/834        0G      3.95     0.093         0      4.04        10       512:  83%|########3 | 45/54 [03:58<00:38,  4.30s/it]\n",
      "   823/834        0G      3.95     0.093         0      4.04        10       512:  85%|########5 | 46/54 [03:58<00:34,  4.28s/it]\n",
      "   823/834        0G      3.89    0.0927         0      3.98         8       512:  85%|########5 | 46/54 [04:03<00:34,  4.28s/it]\n",
      "   823/834        0G      3.89    0.0927         0      3.98         8       512:  87%|########7 | 47/54 [04:03<00:29,  4.27s/it]\n",
      "   823/834        0G      3.95    0.0926         0      4.04         9       512:  87%|########7 | 47/54 [04:07<00:29,  4.27s/it]\n",
      "   823/834        0G      3.95    0.0926         0      4.04         9       512:  89%|########8 | 48/54 [04:07<00:25,  4.29s/it]\n",
      "   823/834        0G      3.89    0.0929         0      3.98         9       512:  89%|########8 | 48/54 [04:12<00:25,  4.29s/it]\n",
      "   823/834        0G      3.89    0.0929         0      3.98         9       512:  91%|######### | 49/54 [04:12<00:21,  4.38s/it]\n",
      "   823/834        0G      3.84    0.0924         0      3.93         9       512:  91%|######### | 49/54 [04:16<00:21,  4.38s/it]\n",
      "   823/834        0G      3.84    0.0924         0      3.93         9       512:  93%|#########2| 50/54 [04:16<00:17,  4.42s/it]\n",
      "   823/834        0G      3.91    0.0926         0         4         9       512:  93%|#########2| 50/54 [04:20<00:17,  4.42s/it]\n",
      "   823/834        0G      3.91    0.0926         0         4         9       512:  94%|#########4| 51/54 [04:20<00:13,  4.38s/it]\n",
      "   823/834        0G      3.86    0.0923         0      3.95         8       512:  94%|#########4| 51/54 [04:25<00:13,  4.38s/it]\n",
      "   823/834        0G      3.86    0.0923         0      3.95         8       512:  96%|#########6| 52/54 [04:25<00:08,  4.41s/it]\n",
      "   823/834        0G      3.81     0.092         0       3.9         9       512:  96%|#########6| 52/54 [04:29<00:08,  4.41s/it]\n",
      "   823/834        0G      3.81     0.092         0       3.9         9       512:  98%|#########8| 53/54 [04:29<00:04,  4.41s/it]\n",
      "   823/834        0G      3.76     0.092         0      3.85         3       512:  98%|#########8| 53/54 [04:31<00:04,  4.41s/it]\n",
      "   823/834        0G      3.76     0.092         0      3.85         3       512: 100%|##########| 54/54 [04:31<00:00,  3.59s/it]\n",
      "   823/834        0G      3.76     0.092         0      3.85         3       512: 100%|##########| 54/54 [04:32<00:00,  5.05s/it]\n",
      "\n",
      "               Class    Images   Targets         P         R   mAP@0.5        F1:   0%|          | 0/14 [00:00<?, ?it/s]2024-03-04 16:23:42.829862: I tensorflow/core/util/port.cc:113] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
      "WARNING:tensorflow:From C:\\Users\\mit017\\anaconda3\\Lib\\site-packages\\keras\\src\\losses.py:2976: The name tf.losses.sparse_softmax_cross_entropy is deprecated. Please use tf.compat.v1.losses.sparse_softmax_cross_entropy instead.\n",
      "\n",
      "2024-03-04 16:23:55.396485: I tensorflow/core/util/port.cc:113] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
      "WARNING:tensorflow:From C:\\Users\\mit017\\anaconda3\\Lib\\site-packages\\keras\\src\\losses.py:2976: The name tf.losses.sparse_softmax_cross_entropy is deprecated. Please use tf.compat.v1.losses.sparse_softmax_cross_entropy instead.\n",
      "\n",
      "2024-03-04 16:24:05.790687: I tensorflow/core/util/port.cc:113] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
      "WARNING:tensorflow:From C:\\Users\\mit017\\anaconda3\\Lib\\site-packages\\keras\\src\\losses.py:2976: The name tf.losses.sparse_softmax_cross_entropy is deprecated. Please use tf.compat.v1.losses.sparse_softmax_cross_entropy instead.\n",
      "\n",
      "\n",
      "               Class    Images   Targets         P         R   mAP@0.5        F1:   7%|7         | 1/14 [00:36<07:52, 36.32s/it]\n",
      "               Class    Images   Targets         P         R   mAP@0.5        F1:  14%|#4        | 2/14 [00:38<03:13, 16.14s/it]\n",
      "               Class    Images   Targets         P         R   mAP@0.5        F1:  21%|##1       | 3/14 [00:40<01:47,  9.74s/it]\n",
      "               Class    Images   Targets         P         R   mAP@0.5        F1:  29%|##8       | 4/14 [00:42<01:08,  6.82s/it]\n",
      "               Class    Images   Targets         P         R   mAP@0.5        F1:  36%|###5      | 5/14 [00:45<00:46,  5.20s/it]\n",
      "               Class    Images   Targets         P         R   mAP@0.5        F1:  43%|####2     | 6/14 [00:47<00:33,  4.16s/it]\n",
      "               Class    Images   Targets         P         R   mAP@0.5        F1:  50%|#####     | 7/14 [00:49<00:24,  3.45s/it]\n",
      "               Class    Images   Targets         P         R   mAP@0.5        F1:  57%|#####7    | 8/14 [00:51<00:17,  2.99s/it]\n",
      "               Class    Images   Targets         P         R   mAP@0.5        F1:  64%|######4   | 9/14 [00:53<00:13,  2.69s/it]\n",
      "               Class    Images   Targets         P         R   mAP@0.5        F1:  71%|#######1  | 10/14 [00:55<00:09,  2.46s/it]\n",
      "               Class    Images   Targets         P         R   mAP@0.5        F1:  79%|#######8  | 11/14 [00:57<00:06,  2.30s/it]\n",
      "               Class    Images   Targets         P         R   mAP@0.5        F1:  86%|########5 | 12/14 [00:59<00:04,  2.23s/it]\n",
      "               Class    Images   Targets         P         R   mAP@0.5        F1:  93%|#########2| 13/14 [01:01<00:02,  2.27s/it]\n",
      "               Class    Images   Targets         P         R   mAP@0.5        F1: 100%|##########| 14/14 [01:02<00:00,  1.92s/it]\n",
      "               Class    Images   Targets         P         R   mAP@0.5        F1: 100%|##########| 14/14 [01:03<00:00,  4.56s/it]\n",
      "2024-03-04 16:24:46.112497: I tensorflow/core/util/port.cc:113] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
      "WARNING:tensorflow:From C:\\Users\\mit017\\anaconda3\\Lib\\site-packages\\keras\\src\\losses.py:2976: The name tf.losses.sparse_softmax_cross_entropy is deprecated. Please use tf.compat.v1.losses.sparse_softmax_cross_entropy instead.\n",
      "\n",
      "2024-03-04 16:24:56.568213: I tensorflow/core/util/port.cc:113] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
      "WARNING:tensorflow:From C:\\Users\\mit017\\anaconda3\\Lib\\site-packages\\keras\\src\\losses.py:2976: The name tf.losses.sparse_softmax_cross_entropy is deprecated. Please use tf.compat.v1.losses.sparse_softmax_cross_entropy instead.\n",
      "\n",
      "2024-03-04 16:25:07.347818: I tensorflow/core/util/port.cc:113] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
      "WARNING:tensorflow:From C:\\Users\\mit017\\anaconda3\\Lib\\site-packages\\keras\\src\\losses.py:2976: The name tf.losses.sparse_softmax_cross_entropy is deprecated. Please use tf.compat.v1.losses.sparse_softmax_cross_entropy instead.\n",
      "\n",
      "\n",
      "  0%|          | 0/54 [00:00<?, ?it/s]\n",
      "   824/834        0G      6.98    0.0937         0      7.07        10       512:   0%|          | 0/54 [00:04<?, ?it/s]\n",
      "   824/834        0G      6.98    0.0937         0      7.07        10       512:   2%|1         | 1/54 [00:04<04:24,  5.00s/it]\n",
      "   824/834        0G      7.19    0.0862         0      7.28         9       512:   2%|1         | 1/54 [00:09<04:24,  5.00s/it]\n",
      "   824/834        0G      7.19    0.0862         0      7.28         9       512:   4%|3         | 2/54 [00:09<04:02,  4.67s/it]\n",
      "   824/834        0G      5.19    0.0884         0      5.28         9       512:   4%|3         | 2/54 [00:14<04:02,  4.67s/it]\n",
      "   824/834        0G      5.19    0.0884         0      5.28         9       512:   6%|5         | 3/54 [00:14<03:58,  4.67s/it]\n",
      "   824/834        0G       4.2    0.0989         0       4.3         9       448:   6%|5         | 3/54 [00:18<03:58,  4.67s/it]\n",
      "   824/834        0G       4.2    0.0989         0       4.3         9       448:   7%|7         | 4/54 [00:18<03:38,  4.37s/it]\n",
      "   824/834        0G      3.62     0.101         0      3.72         9       448:   7%|7         | 4/54 [00:21<03:38,  4.37s/it]\n",
      "   824/834        0G      3.62     0.101         0      3.72         9       448:   9%|9         | 5/54 [00:21<03:21,  4.11s/it]\n",
      "   824/834        0G      3.22     0.101         0      3.32         8       448:   9%|9         | 5/54 [00:25<03:21,  4.11s/it]\n",
      "   824/834        0G      3.22     0.101         0      3.32         8       448:  11%|#1        | 6/54 [00:25<03:11,  3.98s/it]\n",
      "   824/834        0G      3.76     0.107         0      3.86        11       448:  11%|#1        | 6/54 [00:28<03:11,  3.98s/it]\n",
      "   824/834        0G      3.76     0.107         0      3.86        11       448:  13%|#2        | 7/54 [00:28<02:59,  3.82s/it]\n",
      "   824/834        0G      3.43     0.111         0      3.54         9       448:  13%|#2        | 7/54 [00:32<02:59,  3.82s/it]\n",
      "   824/834        0G      3.43     0.111         0      3.54         9       448:  15%|#4        | 8/54 [00:32<02:47,  3.64s/it]\n",
      "   824/834        0G      3.19     0.112         0      3.31        12       448:  15%|#4        | 8/54 [00:35<02:47,  3.64s/it]\n",
      "   824/834        0G      3.19     0.112         0      3.31        12       448:  17%|#6        | 9/54 [00:35<02:38,  3.53s/it]\n",
      "   824/834        0G      2.99     0.113         0      3.11        11       448:  17%|#6        | 9/54 [00:38<02:38,  3.53s/it]\n",
      "   824/834        0G      2.99     0.113         0      3.11        11       448:  19%|#8        | 10/54 [00:38<02:33,  3.49s/it]\n",
      "   824/834        0G      2.83     0.114         0      2.94        10       448:  19%|#8        | 10/54 [00:42<02:33,  3.49s/it]\n",
      "   824/834        0G      2.83     0.114         0      2.94        10       448:  20%|##        | 11/54 [00:42<02:30,  3.50s/it]\n",
      "   824/834        0G      2.69     0.113         0      2.81         9       448:  20%|##        | 11/54 [00:45<02:30,  3.50s/it]\n",
      "   824/834        0G      2.69     0.113         0      2.81         9       448:  22%|##2       | 12/54 [00:45<02:25,  3.48s/it]\n",
      "   824/834        0G      2.59     0.113         0      2.71         9       448:  22%|##2       | 12/54 [00:49<02:25,  3.48s/it]\n",
      "   824/834        0G      2.59     0.113         0      2.71         9       448:  24%|##4       | 13/54 [00:49<02:24,  3.52s/it]\n",
      "   824/834        0G      2.48     0.115         0      2.59         9       448:  24%|##4       | 13/54 [00:52<02:24,  3.52s/it]\n",
      "   824/834        0G      2.48     0.115         0      2.59         9       448:  26%|##5       | 14/54 [00:52<02:21,  3.54s/it]\n",
      "   824/834        0G       2.4     0.114         0      2.51         9       448:  26%|##5       | 14/54 [00:56<02:21,  3.54s/it]\n",
      "   824/834        0G       2.4     0.114         0      2.51         9       448:  28%|##7       | 15/54 [00:56<02:14,  3.45s/it]\n",
      "   824/834        0G      2.31     0.116         0      2.43        12       448:  28%|##7       | 15/54 [00:59<02:14,  3.45s/it]\n",
      "   824/834        0G      2.31     0.116         0      2.43        12       448:  30%|##9       | 16/54 [00:59<02:10,  3.44s/it]\n",
      "   824/834        0G      2.26     0.113         0      2.38         9       448:  30%|##9       | 16/54 [01:03<02:10,  3.44s/it]\n",
      "   824/834        0G      2.26     0.113         0      2.38         9       448:  31%|###1      | 17/54 [01:03<02:07,  3.45s/it]\n",
      "   824/834        0G      2.19     0.113         0       2.3         8       448:  31%|###1      | 17/54 [01:06<02:07,  3.45s/it]\n",
      "   824/834        0G      2.19     0.113         0       2.3         8       448:  33%|###3      | 18/54 [01:06<02:03,  3.42s/it]\n",
      "   824/834        0G      2.13     0.113         0      2.25         8       448:  33%|###3      | 18/54 [01:10<02:03,  3.42s/it]\n",
      "   824/834        0G      2.13     0.113         0      2.25         8       448:  35%|###5      | 19/54 [01:10<02:01,  3.46s/it]\n",
      "   824/834        0G      2.07     0.114         0      2.18         9       448:  35%|###5      | 19/54 [01:13<02:01,  3.46s/it]\n",
      "   824/834        0G      2.07     0.114         0      2.18         9       448:  37%|###7      | 20/54 [01:13<01:57,  3.44s/it]\n",
      "   824/834        0G      2.02     0.114         0      2.13         9       448:  37%|###7      | 20/54 [01:16<01:57,  3.44s/it]\n",
      "   824/834        0G      2.02     0.114         0      2.13         9       448:  39%|###8      | 21/54 [01:16<01:53,  3.44s/it]\n",
      "   824/834        0G      1.97     0.115         0      2.09        11       448:  39%|###8      | 21/54 [01:20<01:53,  3.44s/it]\n",
      "   824/834        0G      1.97     0.115         0      2.09        11       448:  41%|####      | 22/54 [01:20<01:49,  3.41s/it]\n",
      "   824/834        0G      1.92     0.114         0      2.04         9       448:  41%|####      | 22/54 [01:23<01:49,  3.41s/it]\n",
      "   824/834        0G      1.92     0.114         0      2.04         9       448:  43%|####2     | 23/54 [01:23<01:45,  3.41s/it]\n",
      "   824/834        0G       1.9     0.114         0      2.01        10       448:  43%|####2     | 23/54 [01:26<01:45,  3.41s/it]\n",
      "   824/834        0G       1.9     0.114         0      2.01        10       448:  44%|####4     | 24/54 [01:26<01:41,  3.38s/it]\n",
      "   824/834        0G      1.86     0.113         0      1.97         9       544:  44%|####4     | 24/54 [01:31<01:41,  3.38s/it]\n",
      "   824/834        0G      1.86     0.113         0      1.97         9       544:  46%|####6     | 25/54 [01:31<01:52,  3.88s/it]\n",
      "   824/834        0G      1.97     0.113         0      2.09         8       544:  46%|####6     | 25/54 [01:36<01:52,  3.88s/it]\n",
      "   824/834        0G      1.97     0.113         0      2.09         8       544:  48%|####8     | 26/54 [01:36<01:57,  4.18s/it]\n",
      "   824/834        0G      1.94     0.114         0      2.06        15       544:  48%|####8     | 26/54 [01:41<01:57,  4.18s/it]\n",
      "   824/834        0G      1.94     0.114         0      2.06        15       544:  50%|#####     | 27/54 [01:41<01:58,  4.40s/it]\n",
      "   824/834        0G      2.06     0.113         0      2.18         9       544:  50%|#####     | 27/54 [01:46<01:58,  4.40s/it]\n",
      "   824/834        0G      2.06     0.113         0      2.18         9       544:  52%|#####1    | 28/54 [01:46<02:00,  4.64s/it]\n",
      "   824/834        0G      2.17     0.112         0      2.28         9       544:  52%|#####1    | 28/54 [01:52<02:00,  4.64s/it]\n",
      "   824/834        0G      2.17     0.112         0      2.28         9       544:  54%|#####3    | 29/54 [01:52<02:01,  4.85s/it]\n",
      "   824/834        0G      2.13     0.112         0      2.24        12       544:  54%|#####3    | 29/54 [01:57<02:01,  4.85s/it]\n",
      "   824/834        0G      2.13     0.112         0      2.24        12       544:  56%|#####5    | 30/54 [01:57<01:56,  4.85s/it]\n",
      "   824/834        0G      2.27     0.111         0      2.38         9       544:  56%|#####5    | 30/54 [02:02<01:56,  4.85s/it]\n",
      "   824/834        0G      2.27     0.111         0      2.38         9       544:  57%|#####7    | 31/54 [02:02<01:53,  4.93s/it]\n",
      "   824/834        0G      2.37      0.11         0      2.48         9       544:  57%|#####7    | 31/54 [02:07<01:53,  4.93s/it]\n",
      "   824/834        0G      2.37      0.11         0      2.48         9       544:  59%|#####9    | 32/54 [02:07<01:53,  5.16s/it]\n",
      "   824/834        0G      2.34     0.109         0      2.45         9       544:  59%|#####9    | 32/54 [02:13<01:53,  5.16s/it]\n",
      "   824/834        0G      2.34     0.109         0      2.45         9       544:  61%|######1   | 33/54 [02:13<01:49,  5.21s/it]\n",
      "   824/834        0G      2.31     0.108         0      2.42         8       544:  61%|######1   | 33/54 [02:18<01:49,  5.21s/it]\n",
      "   824/834        0G      2.31     0.108         0      2.42         8       544:  63%|######2   | 34/54 [02:18<01:43,  5.16s/it]\n",
      "   824/834        0G      2.43     0.108         0      2.53         9       544:  63%|######2   | 34/54 [02:23<01:43,  5.16s/it]\n",
      "   824/834        0G      2.43     0.108         0      2.53         9       544:  65%|######4   | 35/54 [02:23<01:36,  5.06s/it]\n",
      "   824/834        0G      2.49     0.107         0       2.6         8       544:  65%|######4   | 35/54 [02:27<01:36,  5.06s/it]\n",
      "   824/834        0G      2.49     0.107         0       2.6         8       544:  67%|######6   | 36/54 [02:27<01:29,  4.96s/it]\n",
      "   824/834        0G      2.46     0.106         0      2.56         9       544:  67%|######6   | 36/54 [02:32<01:29,  4.96s/it]\n",
      "   824/834        0G      2.46     0.106         0      2.56         9       544:  69%|######8   | 37/54 [02:32<01:23,  4.90s/it]\n",
      "   824/834        0G      2.43     0.107         0      2.53        12       544:  69%|######8   | 37/54 [02:37<01:23,  4.90s/it]\n",
      "   824/834        0G      2.43     0.107         0      2.53        12       544:  70%|#######   | 38/54 [02:37<01:17,  4.87s/it]\n",
      "   824/834        0G      2.49     0.107         0       2.6        13       544:  70%|#######   | 38/54 [02:43<01:17,  4.87s/it]\n",
      "   824/834        0G      2.49     0.107         0       2.6        13       544:  72%|#######2  | 39/54 [02:43<01:16,  5.10s/it]\n",
      "   824/834        0G      2.57     0.107         0      2.68         9       544:  72%|#######2  | 39/54 [02:48<01:16,  5.10s/it]\n",
      "   824/834        0G      2.57     0.107         0      2.68         9       544:  74%|#######4  | 40/54 [02:48<01:11,  5.10s/it]\n",
      "   824/834        0G      2.64     0.107         0      2.75        10       544:  74%|#######4  | 40/54 [02:53<01:11,  5.10s/it]\n",
      "   824/834        0G      2.64     0.107         0      2.75        10       544:  76%|#######5  | 41/54 [02:53<01:08,  5.31s/it]\n",
      "   824/834        0G      2.74     0.106         0      2.84         9       544:  76%|#######5  | 41/54 [03:00<01:08,  5.31s/it]\n",
      "   824/834        0G      2.74     0.106         0      2.84         9       544:  78%|#######7  | 42/54 [03:00<01:06,  5.54s/it]\n",
      "   824/834        0G       2.7     0.105         0      2.81         9       544:  78%|#######7  | 42/54 [03:06<01:06,  5.54s/it]\n",
      "   824/834        0G       2.7     0.105         0      2.81         9       544:  80%|#######9  | 43/54 [03:06<01:02,  5.69s/it]\n",
      "   824/834        0G      2.78     0.105         0      2.88         9       544:  80%|#######9  | 43/54 [03:12<01:02,  5.69s/it]\n",
      "   824/834        0G      2.78     0.105         0      2.88         9       544:  81%|########1 | 44/54 [03:12<00:58,  5.82s/it]\n",
      "   824/834        0G      2.87     0.105         0      2.98        10       544:  81%|########1 | 44/54 [03:18<00:58,  5.82s/it]\n",
      "   824/834        0G      2.87     0.105         0      2.98        10       544:  83%|########3 | 45/54 [03:18<00:53,  5.90s/it]\n",
      "   824/834        0G      2.96     0.105         0      3.07        11       480:  83%|########3 | 45/54 [03:23<00:53,  5.90s/it]\n",
      "   824/834        0G      2.96     0.105         0      3.07        11       480:  85%|########5 | 46/54 [03:23<00:45,  5.69s/it]\n",
      "   824/834        0G      2.92     0.105         0      3.03         9       480:  85%|########5 | 46/54 [03:28<00:45,  5.69s/it]\n",
      "   824/834        0G      2.92     0.105         0      3.03         9       480:  87%|########7 | 47/54 [03:28<00:37,  5.36s/it]\n",
      "   824/834        0G      2.89     0.105         0      2.99         9       480:  87%|########7 | 47/54 [03:32<00:37,  5.36s/it]\n",
      "   824/834        0G      2.89     0.105         0      2.99         9       480:  89%|########8 | 48/54 [03:32<00:30,  5.14s/it]\n",
      "   824/834        0G      2.85     0.104         0      2.96         9       480:  89%|########8 | 48/54 [03:37<00:30,  5.14s/it]\n",
      "   824/834        0G      2.85     0.104         0      2.96         9       480:  91%|######### | 49/54 [03:37<00:24,  4.96s/it]\n",
      "   824/834        0G      2.82     0.105         0      2.92        10       480:  91%|######### | 49/54 [03:41<00:24,  4.96s/it]\n",
      "   824/834        0G      2.82     0.105         0      2.92        10       480:  93%|#########2| 50/54 [03:41<00:19,  4.85s/it]\n",
      "   824/834        0G      2.78     0.105         0      2.89         9       480:  93%|#########2| 50/54 [03:46<00:19,  4.85s/it]\n",
      "   824/834        0G      2.78     0.105         0      2.89         9       480:  94%|#########4| 51/54 [03:46<00:14,  4.78s/it]\n",
      "   824/834        0G      2.75     0.105         0      2.85         9       480:  94%|#########4| 51/54 [03:51<00:14,  4.78s/it]\n",
      "   824/834        0G      2.75     0.105         0      2.85         9       480:  96%|#########6| 52/54 [03:51<00:09,  4.73s/it]\n",
      "   824/834        0G      2.72     0.105         0      2.82         9       480:  96%|#########6| 52/54 [03:55<00:09,  4.73s/it]\n",
      "   824/834        0G      2.72     0.105         0      2.82         9       480:  98%|#########8| 53/54 [03:55<00:04,  4.68s/it]\n",
      "   824/834        0G       2.7     0.104         0       2.8         3       480:  98%|#########8| 53/54 [03:57<00:04,  4.68s/it]\n",
      "   824/834        0G       2.7     0.104         0       2.8         3       480: 100%|##########| 54/54 [03:57<00:00,  3.81s/it]\n",
      "   824/834        0G       2.7     0.104         0       2.8         3       480: 100%|##########| 54/54 [03:58<00:00,  4.42s/it]\n",
      "\n",
      "               Class    Images   Targets         P         R   mAP@0.5        F1:   0%|          | 0/14 [00:00<?, ?it/s]2024-03-04 16:29:17.180975: I tensorflow/core/util/port.cc:113] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
      "WARNING:tensorflow:From C:\\Users\\mit017\\anaconda3\\Lib\\site-packages\\keras\\src\\losses.py:2976: The name tf.losses.sparse_softmax_cross_entropy is deprecated. Please use tf.compat.v1.losses.sparse_softmax_cross_entropy instead.\n",
      "\n",
      "2024-03-04 16:29:28.086609: I tensorflow/core/util/port.cc:113] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
      "WARNING:tensorflow:From C:\\Users\\mit017\\anaconda3\\Lib\\site-packages\\keras\\src\\losses.py:2976: The name tf.losses.sparse_softmax_cross_entropy is deprecated. Please use tf.compat.v1.losses.sparse_softmax_cross_entropy instead.\n",
      "\n",
      "2024-03-04 16:29:39.736106: I tensorflow/core/util/port.cc:113] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
      "WARNING:tensorflow:From C:\\Users\\mit017\\anaconda3\\Lib\\site-packages\\keras\\src\\losses.py:2976: The name tf.losses.sparse_softmax_cross_entropy is deprecated. Please use tf.compat.v1.losses.sparse_softmax_cross_entropy instead.\n",
      "\n",
      "\n",
      "               Class    Images   Targets         P         R   mAP@0.5        F1:   7%|7         | 1/14 [00:36<07:52, 36.34s/it]\n",
      "               Class    Images   Targets         P         R   mAP@0.5        F1:  14%|#4        | 2/14 [00:38<03:14, 16.21s/it]\n",
      "               Class    Images   Targets         P         R   mAP@0.5        F1:  21%|##1       | 3/14 [00:40<01:47,  9.74s/it]\n",
      "               Class    Images   Targets         P         R   mAP@0.5        F1:  29%|##8       | 4/14 [00:42<01:08,  6.83s/it]\n",
      "               Class    Images   Targets         P         R   mAP@0.5        F1:  36%|###5      | 5/14 [00:45<00:46,  5.19s/it]\n",
      "               Class    Images   Targets         P         R   mAP@0.5        F1:  43%|####2     | 6/14 [00:47<00:33,  4.19s/it]\n",
      "               Class    Images   Targets         P         R   mAP@0.5        F1:  50%|#####     | 7/14 [00:49<00:25,  3.62s/it]\n",
      "               Class    Images   Targets         P         R   mAP@0.5        F1:  57%|#####7    | 8/14 [00:51<00:18,  3.14s/it]\n",
      "               Class    Images   Targets         P         R   mAP@0.5        F1:  64%|######4   | 9/14 [00:54<00:14,  2.86s/it]\n",
      "               Class    Images   Targets         P         R   mAP@0.5        F1:  71%|#######1  | 10/14 [00:56<00:10,  2.62s/it]\n",
      "               Class    Images   Targets         P         R   mAP@0.5        F1:  79%|#######8  | 11/14 [00:58<00:07,  2.48s/it]\n",
      "               Class    Images   Targets         P         R   mAP@0.5        F1:  86%|########5 | 12/14 [01:00<00:04,  2.43s/it]\n",
      "               Class    Images   Targets         P         R   mAP@0.5        F1:  93%|#########2| 13/14 [01:02<00:02,  2.35s/it]\n",
      "               Class    Images   Targets         P         R   mAP@0.5        F1: 100%|##########| 14/14 [01:03<00:00,  1.88s/it]\n",
      "               Class    Images   Targets         P         R   mAP@0.5        F1: 100%|##########| 14/14 [01:04<00:00,  4.63s/it]\n",
      "2024-03-04 16:30:21.971672: I tensorflow/core/util/port.cc:113] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
      "WARNING:tensorflow:From C:\\Users\\mit017\\anaconda3\\Lib\\site-packages\\keras\\src\\losses.py:2976: The name tf.losses.sparse_softmax_cross_entropy is deprecated. Please use tf.compat.v1.losses.sparse_softmax_cross_entropy instead.\n",
      "\n",
      "2024-03-04 16:30:32.934482: I tensorflow/core/util/port.cc:113] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
      "WARNING:tensorflow:From C:\\Users\\mit017\\anaconda3\\Lib\\site-packages\\keras\\src\\losses.py:2976: The name tf.losses.sparse_softmax_cross_entropy is deprecated. Please use tf.compat.v1.losses.sparse_softmax_cross_entropy instead.\n",
      "\n",
      "2024-03-04 16:30:43.193446: I tensorflow/core/util/port.cc:113] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
      "WARNING:tensorflow:From C:\\Users\\mit017\\anaconda3\\Lib\\site-packages\\keras\\src\\losses.py:2976: The name tf.losses.sparse_softmax_cross_entropy is deprecated. Please use tf.compat.v1.losses.sparse_softmax_cross_entropy instead.\n",
      "\n",
      "\n",
      "  0%|          | 0/54 [00:00<?, ?it/s]\n",
      "   825/834        0G      1.37     0.077         0      1.45         9       480:   0%|          | 0/54 [00:03<?, ?it/s]\n",
      "   825/834        0G      1.37     0.077         0      1.45         9       480:   2%|1         | 1/54 [00:03<03:25,  3.88s/it]\n",
      "   825/834        0G      1.26    0.0933         0      1.35        10       480:   2%|1         | 1/54 [00:07<03:25,  3.88s/it]\n",
      "   825/834        0G      1.26    0.0933         0      1.35        10       480:   4%|3         | 2/54 [00:07<03:15,  3.75s/it]\n",
      "   825/834        0G      1.31    0.0979         0      1.41        13       480:   4%|3         | 2/54 [00:11<03:15,  3.75s/it]\n",
      "   825/834        0G      1.31    0.0979         0      1.41        13       480:   6%|5         | 3/54 [00:11<03:10,  3.74s/it]\n",
      "   825/834        0G      1.28     0.115         0      1.39        15       480:   6%|5         | 3/54 [00:14<03:10,  3.74s/it]\n",
      "   825/834        0G      1.28     0.115         0      1.39        15       480:   7%|7         | 4/54 [00:14<03:06,  3.72s/it]\n",
      "   825/834        0G      1.31     0.111         0      1.42        11       480:   7%|7         | 4/54 [00:18<03:06,  3.72s/it]\n",
      "   825/834        0G      1.31     0.111         0      1.42        11       480:   9%|9         | 5/54 [00:18<03:01,  3.71s/it]\n",
      "   825/834        0G      2.15     0.112         0      2.26         9       480:   9%|9         | 5/54 [00:22<03:01,  3.71s/it]\n",
      "   825/834        0G      2.15     0.112         0      2.26         9       480:  11%|#1        | 6/54 [00:22<02:57,  3.70s/it]\n",
      "   825/834        0G      2.05     0.109         0      2.16         9       480:  11%|#1        | 6/54 [00:25<02:57,  3.70s/it]\n",
      "   825/834        0G      2.05     0.109         0      2.16         9       480:  13%|#2        | 7/54 [00:25<02:52,  3.67s/it]\n",
      "   825/834        0G      1.94     0.106         0      2.05         9       480:  13%|#2        | 7/54 [00:29<02:52,  3.67s/it]\n",
      "   825/834        0G      1.94     0.106         0      2.05         9       480:  15%|#4        | 8/54 [00:29<02:48,  3.67s/it]\n",
      "   825/834        0G      1.85     0.104         0      1.96        10       480:  15%|#4        | 8/54 [00:33<02:48,  3.67s/it]\n",
      "   825/834        0G      1.85     0.104         0      1.96        10       480:  17%|#6        | 9/54 [00:33<02:45,  3.67s/it]\n",
      "   825/834        0G       2.1     0.106         0      2.21        12       480:  17%|#6        | 9/54 [00:36<02:45,  3.67s/it]\n",
      "   825/834        0G       2.1     0.106         0      2.21        12       480:  19%|#8        | 10/54 [00:36<02:41,  3.67s/it]\n",
      "   825/834        0G      2.44     0.103         0      2.55         9       480:  19%|#8        | 10/54 [00:40<02:41,  3.67s/it]\n",
      "   825/834        0G      2.44     0.103         0      2.55         9       480:  20%|##        | 11/54 [00:40<02:37,  3.67s/it]\n",
      "   825/834        0G      2.34     0.102         0      2.44         9       480:  20%|##        | 11/54 [00:44<02:37,  3.67s/it]\n",
      "   825/834        0G      2.34     0.102         0      2.44         9       480:  22%|##2       | 12/54 [00:44<02:33,  3.66s/it]\n",
      "   825/834        0G      2.49       0.1         0      2.59         9       608:  22%|##2       | 12/54 [00:50<02:33,  3.66s/it]\n",
      "   825/834        0G      2.49       0.1         0      2.59         9       608:  24%|##4       | 13/54 [00:50<03:00,  4.40s/it]\n",
      "   825/834        0G      2.69    0.0989         0      2.79         9       608:  24%|##4       | 13/54 [00:56<03:00,  4.40s/it]\n",
      "   825/834        0G      2.69    0.0989         0      2.79         9       608:  26%|##5       | 14/54 [00:56<03:13,  4.84s/it]\n",
      "   825/834        0G      2.83    0.0979         0      2.92         9       608:  26%|##5       | 14/54 [01:02<03:13,  4.84s/it]\n",
      "   825/834        0G      2.83    0.0979         0      2.92         9       608:  28%|##7       | 15/54 [01:02<03:20,  5.13s/it]\n",
      "   825/834        0G      2.93    0.0965         0      3.02         9       608:  28%|##7       | 15/54 [01:07<03:20,  5.13s/it]\n",
      "   825/834        0G      2.93    0.0965         0      3.02         9       608:  30%|##9       | 16/54 [01:07<03:22,  5.34s/it]\n",
      "   825/834        0G      3.03    0.0959         0      3.12         9       608:  30%|##9       | 16/54 [01:13<03:22,  5.34s/it]\n",
      "   825/834        0G      3.03    0.0959         0      3.12         9       608:  31%|###1      | 17/54 [01:13<03:23,  5.50s/it]\n",
      "   825/834        0G      3.12    0.0965         0      3.22        12       608:  31%|###1      | 17/54 [01:19<03:23,  5.50s/it]\n",
      "   825/834        0G      3.12    0.0965         0      3.22        12       608:  33%|###3      | 18/54 [01:19<03:23,  5.64s/it]\n",
      "   825/834        0G      3.22    0.0962         0      3.32         9       608:  33%|###3      | 18/54 [01:25<03:23,  5.64s/it]\n",
      "   825/834        0G      3.22    0.0962         0      3.32         9       608:  35%|###5      | 19/54 [01:25<03:19,  5.71s/it]\n",
      "   825/834        0G      3.25    0.0957         0      3.35         9       608:  35%|###5      | 19/54 [01:31<03:19,  5.71s/it]\n",
      "   825/834        0G      3.25    0.0957         0      3.35         9       608:  37%|###7      | 20/54 [01:31<03:18,  5.84s/it]\n",
      "   825/834        0G      3.31    0.0957         0      3.41         9       608:  37%|###7      | 20/54 [01:37<03:18,  5.84s/it]\n",
      "   825/834        0G      3.31    0.0957         0      3.41         9       608:  39%|###8      | 21/54 [01:37<03:13,  5.86s/it]\n",
      "   825/834        0G      3.35    0.0955         0      3.44         8       608:  39%|###8      | 21/54 [01:43<03:13,  5.86s/it]\n",
      "   825/834        0G      3.35    0.0955         0      3.44         8       608:  41%|####      | 22/54 [01:43<03:08,  5.89s/it]\n",
      "   825/834        0G      3.39    0.0962         0      3.49        11       608:  41%|####      | 22/54 [01:49<03:08,  5.89s/it]\n",
      "   825/834        0G      3.39    0.0962         0      3.49        11       608:  43%|####2     | 23/54 [01:49<03:04,  5.94s/it]\n",
      "   825/834        0G       3.3    0.0953         0      3.39         9       608:  43%|####2     | 23/54 [01:55<03:04,  5.94s/it]\n",
      "   825/834        0G       3.3    0.0953         0      3.39         9       608:  44%|####4     | 24/54 [01:55<02:57,  5.92s/it]\n",
      "   825/834        0G      3.34    0.0954         0      3.44         9       608:  44%|####4     | 24/54 [02:01<02:57,  5.92s/it]\n",
      "   825/834        0G      3.34    0.0954         0      3.44         9       608:  46%|####6     | 25/54 [02:01<02:53,  5.97s/it]\n",
      "   825/834        0G       3.4     0.096         0      3.49        10       608:  46%|####6     | 25/54 [02:07<02:53,  5.97s/it]\n",
      "   825/834        0G       3.4     0.096         0      3.49        10       608:  48%|####8     | 26/54 [02:07<02:46,  5.96s/it]\n",
      "   825/834        0G      3.44    0.0963         0      3.53        10       608:  48%|####8     | 26/54 [02:13<02:46,  5.96s/it]\n",
      "   825/834        0G      3.44    0.0963         0      3.53        10       608:  50%|#####     | 27/54 [02:13<02:40,  5.96s/it]\n",
      "   825/834        0G      3.46    0.0973         0      3.56        12       608:  50%|#####     | 27/54 [02:19<02:40,  5.96s/it]\n",
      "   825/834        0G      3.46    0.0973         0      3.56        12       608:  52%|#####1    | 28/54 [02:19<02:35,  5.96s/it]\n",
      "   825/834        0G       3.5    0.0971         0       3.6         9       608:  52%|#####1    | 28/54 [02:25<02:35,  5.96s/it]\n",
      "   825/834        0G       3.5    0.0971         0       3.6         9       608:  54%|#####3    | 29/54 [02:25<02:29,  5.99s/it]\n",
      "   825/834        0G      3.54    0.0963         0      3.64         9       608:  54%|#####3    | 29/54 [02:31<02:29,  5.99s/it]\n",
      "   825/834        0G      3.54    0.0963         0      3.64         9       608:  56%|#####5    | 30/54 [02:31<02:23,  5.97s/it]\n",
      "   825/834        0G      3.56    0.0962         0      3.66         9       608:  56%|#####5    | 30/54 [02:37<02:23,  5.97s/it]\n",
      "   825/834        0G      3.56    0.0962         0      3.66         9       608:  57%|#####7    | 31/54 [02:37<02:16,  5.96s/it]\n",
      "   825/834        0G      3.59    0.0958         0      3.69         9       608:  57%|#####7    | 31/54 [02:43<02:16,  5.96s/it]\n",
      "   825/834        0G      3.59    0.0958         0      3.69         9       608:  59%|#####9    | 32/54 [02:43<02:11,  5.98s/it]\n",
      "   825/834        0G      3.61    0.0958         0       3.7         9       608:  59%|#####9    | 32/54 [02:49<02:11,  5.98s/it]\n",
      "   825/834        0G      3.61    0.0958         0       3.7         9       608:  61%|######1   | 33/54 [02:49<02:05,  5.99s/it]\n",
      "   825/834        0G      3.53    0.0962         0      3.63         9       416:  61%|######1   | 33/54 [02:52<02:05,  5.99s/it]\n",
      "   825/834        0G      3.53    0.0962         0      3.63         9       416:  63%|######2   | 34/54 [02:52<01:43,  5.16s/it]\n",
      "   825/834        0G      3.46    0.0971         0      3.56         9       416:  63%|######2   | 34/54 [02:55<01:43,  5.16s/it]\n",
      "   825/834        0G      3.46    0.0971         0      3.56         9       416:  65%|######4   | 35/54 [02:55<01:26,  4.53s/it]\n",
      "   825/834        0G      3.41    0.0972         0       3.5         8       416:  65%|######4   | 35/54 [02:58<01:26,  4.53s/it]\n",
      "   825/834        0G      3.41    0.0972         0       3.5         8       416:  67%|######6   | 36/54 [02:58<01:12,  4.02s/it]\n",
      "   825/834        0G      3.34    0.0976         0      3.44         8       416:  67%|######6   | 36/54 [03:01<01:12,  4.02s/it]\n",
      "   825/834        0G      3.34    0.0976         0      3.44         8       416:  69%|######8   | 37/54 [03:01<01:02,  3.67s/it]\n",
      "   825/834        0G      3.28    0.0985         0      3.38        11       416:  69%|######8   | 37/54 [03:04<01:02,  3.67s/it]\n",
      "   825/834        0G      3.28    0.0985         0      3.38        11       416:  70%|#######   | 38/54 [03:04<00:54,  3.41s/it]\n",
      "   825/834        0G      3.23    0.0994         0      3.33        10       416:  70%|#######   | 38/54 [03:06<00:54,  3.41s/it]\n",
      "   825/834        0G      3.23    0.0994         0      3.33        10       416:  72%|#######2  | 39/54 [03:06<00:48,  3.23s/it]\n",
      "   825/834        0G      3.18       0.1         0      3.28         9       416:  72%|#######2  | 39/54 [03:09<00:48,  3.23s/it]\n",
      "   825/834        0G      3.18       0.1         0      3.28         9       416:  74%|#######4  | 40/54 [03:09<00:43,  3.10s/it]\n",
      "   825/834        0G      3.14       0.1         0      3.24        11       416:  74%|#######4  | 40/54 [03:12<00:43,  3.10s/it]\n",
      "   825/834        0G      3.14       0.1         0      3.24        11       416:  76%|#######5  | 41/54 [03:12<00:39,  3.02s/it]\n",
      "   825/834        0G      3.09     0.101         0      3.19         9       416:  76%|#######5  | 41/54 [03:15<00:39,  3.02s/it]\n",
      "   825/834        0G      3.09     0.101         0      3.19         9       416:  78%|#######7  | 42/54 [03:15<00:35,  2.96s/it]\n",
      "   825/834        0G      3.05       0.1         0      3.15         9       416:  78%|#######7  | 42/54 [03:18<00:35,  2.96s/it]\n",
      "   825/834        0G      3.05       0.1         0      3.15         9       416:  80%|#######9  | 43/54 [03:18<00:32,  2.93s/it]\n",
      "   825/834        0G      3.01     0.101         0      3.11        10       416:  80%|#######9  | 43/54 [03:21<00:32,  2.93s/it]\n",
      "   825/834        0G      3.01     0.101         0      3.11        10       416:  81%|########1 | 44/54 [03:21<00:28,  2.87s/it]\n",
      "   825/834        0G      2.98       0.1         0      3.08         9       416:  81%|########1 | 44/54 [03:23<00:28,  2.87s/it]\n",
      "   825/834        0G      2.98       0.1         0      3.08         9       416:  83%|########3 | 45/54 [03:23<00:25,  2.85s/it]\n",
      "   825/834        0G      2.93     0.101         0      3.03         9       416:  83%|########3 | 45/54 [03:26<00:25,  2.85s/it]\n",
      "   825/834        0G      2.93     0.101         0      3.03         9       416:  85%|########5 | 46/54 [03:26<00:22,  2.84s/it]\n",
      "   825/834        0G       2.9     0.101         0         3         9       416:  85%|########5 | 46/54 [03:29<00:22,  2.84s/it]\n",
      "   825/834        0G       2.9     0.101         0         3         9       416:  87%|########7 | 47/54 [03:29<00:19,  2.83s/it]\n",
      "   825/834        0G      2.86     0.101         0      2.96        13       416:  87%|########7 | 47/54 [03:32<00:19,  2.83s/it]\n",
      "   825/834        0G      2.86     0.101         0      2.96        13       416:  89%|########8 | 48/54 [03:32<00:16,  2.81s/it]\n",
      "   825/834        0G      2.83     0.102         0      2.93         9       416:  89%|########8 | 48/54 [03:35<00:16,  2.81s/it]\n",
      "   825/834        0G      2.83     0.102         0      2.93         9       416:  91%|######### | 49/54 [03:35<00:14,  2.82s/it]\n",
      "   825/834        0G       2.8     0.102         0       2.9        11       416:  91%|######### | 49/54 [03:37<00:14,  2.82s/it]\n",
      "   825/834        0G       2.8     0.102         0       2.9        11       416:  93%|#########2| 50/54 [03:37<00:11,  2.84s/it]\n",
      "   825/834        0G      2.77     0.102         0      2.87         9       416:  93%|#########2| 50/54 [03:40<00:11,  2.84s/it]\n",
      "   825/834        0G      2.77     0.102         0      2.87         9       416:  94%|#########4| 51/54 [03:40<00:08,  2.84s/it]\n",
      "   825/834        0G      2.74     0.102         0      2.84         8       416:  94%|#########4| 51/54 [03:43<00:08,  2.84s/it]\n",
      "   825/834        0G      2.74     0.102         0      2.84         8       416:  96%|#########6| 52/54 [03:43<00:05,  2.85s/it]\n",
      "   825/834        0G      2.71     0.102         0      2.81         9       416:  96%|#########6| 52/54 [03:46<00:05,  2.85s/it]\n",
      "   825/834        0G      2.71     0.102         0      2.81         9       416:  98%|#########8| 53/54 [03:46<00:02,  2.87s/it]\n",
      "   825/834        0G      2.68     0.105         0      2.78         6       416:  98%|#########8| 53/54 [03:47<00:02,  2.87s/it]\n",
      "   825/834        0G      2.68     0.105         0      2.78         6       416: 100%|##########| 54/54 [03:47<00:00,  2.36s/it]\n",
      "   825/834        0G      2.68     0.105         0      2.78         6       416: 100%|##########| 54/54 [03:48<00:00,  4.24s/it]\n",
      "\n",
      "               Class    Images   Targets         P         R   mAP@0.5        F1:   0%|          | 0/14 [00:00<?, ?it/s]2024-03-04 16:34:42.251215: I tensorflow/core/util/port.cc:113] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
      "WARNING:tensorflow:From C:\\Users\\mit017\\anaconda3\\Lib\\site-packages\\keras\\src\\losses.py:2976: The name tf.losses.sparse_softmax_cross_entropy is deprecated. Please use tf.compat.v1.losses.sparse_softmax_cross_entropy instead.\n",
      "\n",
      "2024-03-04 16:34:52.650488: I tensorflow/core/util/port.cc:113] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
      "WARNING:tensorflow:From C:\\Users\\mit017\\anaconda3\\Lib\\site-packages\\keras\\src\\losses.py:2976: The name tf.losses.sparse_softmax_cross_entropy is deprecated. Please use tf.compat.v1.losses.sparse_softmax_cross_entropy instead.\n",
      "\n",
      "2024-03-04 16:35:03.092013: I tensorflow/core/util/port.cc:113] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
      "WARNING:tensorflow:From C:\\Users\\mit017\\anaconda3\\Lib\\site-packages\\keras\\src\\losses.py:2976: The name tf.losses.sparse_softmax_cross_entropy is deprecated. Please use tf.compat.v1.losses.sparse_softmax_cross_entropy instead.\n",
      "\n",
      "\n",
      "               Class    Images   Targets         P         R   mAP@0.5        F1:   7%|7         | 1/14 [00:33<07:15, 33.50s/it]\n",
      "               Class    Images   Targets         P         R   mAP@0.5        F1:  14%|#4        | 2/14 [00:35<03:00, 15.04s/it]\n",
      "               Class    Images   Targets         P         R   mAP@0.5        F1:  21%|##1       | 3/14 [00:37<01:40,  9.13s/it]\n",
      "               Class    Images   Targets         P         R   mAP@0.5        F1:  29%|##8       | 4/14 [00:39<01:03,  6.36s/it]\n",
      "               Class    Images   Targets         P         R   mAP@0.5        F1:  36%|###5      | 5/14 [00:41<00:43,  4.81s/it]\n",
      "               Class    Images   Targets         P         R   mAP@0.5        F1:  43%|####2     | 6/14 [00:43<00:30,  3.87s/it]\n",
      "               Class    Images   Targets         P         R   mAP@0.5        F1:  50%|#####     | 7/14 [00:45<00:22,  3.27s/it]\n",
      "               Class    Images   Targets         P         R   mAP@0.5        F1:  57%|#####7    | 8/14 [00:48<00:17,  2.90s/it]\n",
      "               Class    Images   Targets         P         R   mAP@0.5        F1:  64%|######4   | 9/14 [00:50<00:13,  2.65s/it]\n",
      "               Class    Images   Targets         P         R   mAP@0.5        F1:  71%|#######1  | 10/14 [00:52<00:09,  2.47s/it]\n",
      "               Class    Images   Targets         P         R   mAP@0.5        F1:  79%|#######8  | 11/14 [00:54<00:07,  2.34s/it]\n",
      "               Class    Images   Targets         P         R   mAP@0.5        F1:  86%|########5 | 12/14 [00:56<00:04,  2.25s/it]\n",
      "               Class    Images   Targets         P         R   mAP@0.5        F1:  93%|#########2| 13/14 [00:58<00:02,  2.16s/it]\n",
      "               Class    Images   Targets         P         R   mAP@0.5        F1: 100%|##########| 14/14 [00:59<00:00,  1.73s/it]\n",
      "               Class    Images   Targets         P         R   mAP@0.5        F1: 100%|##########| 14/14 [00:59<00:00,  4.29s/it]\n",
      "2024-03-04 16:35:42.244539: I tensorflow/core/util/port.cc:113] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
      "WARNING:tensorflow:From C:\\Users\\mit017\\anaconda3\\Lib\\site-packages\\keras\\src\\losses.py:2976: The name tf.losses.sparse_softmax_cross_entropy is deprecated. Please use tf.compat.v1.losses.sparse_softmax_cross_entropy instead.\n",
      "\n",
      "2024-03-04 16:35:52.565905: I tensorflow/core/util/port.cc:113] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
      "WARNING:tensorflow:From C:\\Users\\mit017\\anaconda3\\Lib\\site-packages\\keras\\src\\losses.py:2976: The name tf.losses.sparse_softmax_cross_entropy is deprecated. Please use tf.compat.v1.losses.sparse_softmax_cross_entropy instead.\n",
      "\n",
      "2024-03-04 16:36:02.688724: I tensorflow/core/util/port.cc:113] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
      "WARNING:tensorflow:From C:\\Users\\mit017\\anaconda3\\Lib\\site-packages\\keras\\src\\losses.py:2976: The name tf.losses.sparse_softmax_cross_entropy is deprecated. Please use tf.compat.v1.losses.sparse_softmax_cross_entropy instead.\n",
      "\n",
      "\n",
      "  0%|          | 0/54 [00:00<?, ?it/s]\n",
      "   826/834        0G      1.41    0.0793         0      1.49         9       576:   0%|          | 0/54 [00:06<?, ?it/s]\n",
      "   826/834        0G      1.41    0.0793         0      1.49         9       576:   2%|1         | 1/54 [00:06<05:27,  6.18s/it]\n",
      "   826/834        0G      2.54    0.0832         0      2.62         9       576:   2%|1         | 1/54 [00:11<05:27,  6.18s/it]\n",
      "   826/834        0G      2.54    0.0832         0      2.62         9       576:   4%|3         | 2/54 [00:11<04:57,  5.71s/it]\n",
      "   826/834        0G      2.06    0.0832         0      2.14         9       576:   4%|3         | 2/54 [00:16<04:57,  5.71s/it]\n",
      "   826/834        0G      2.06    0.0832         0      2.14         9       576:   6%|5         | 3/54 [00:16<04:41,  5.51s/it]\n",
      "   826/834        0G      2.53    0.0862         0      2.62         9       576:   6%|5         | 3/54 [00:22<04:41,  5.51s/it]\n",
      "   826/834        0G      2.53    0.0862         0      2.62         9       576:   7%|7         | 4/54 [00:22<04:32,  5.45s/it]\n",
      "   826/834        0G      2.82     0.086         0       2.9         9       576:   7%|7         | 4/54 [00:27<04:32,  5.45s/it]\n",
      "   826/834        0G      2.82     0.086         0       2.9         9       576:   9%|9         | 5/54 [00:27<04:25,  5.41s/it]\n",
      "   826/834        0G      2.54    0.0844         0      2.62         9       576:   9%|9         | 5/54 [00:32<04:25,  5.41s/it]\n",
      "   826/834        0G      2.54    0.0844         0      2.62         9       576:  11%|#1        | 6/54 [00:32<04:18,  5.38s/it]\n",
      "   826/834        0G      2.69    0.0853         0      2.78         9       576:  11%|#1        | 6/54 [00:38<04:18,  5.38s/it]\n",
      "   826/834        0G      2.69    0.0853         0      2.78         9       576:  13%|#2        | 7/54 [00:38<04:10,  5.32s/it]\n",
      "   826/834        0G      2.83    0.0873         0      2.92         9       576:  13%|#2        | 7/54 [00:43<04:10,  5.32s/it]\n",
      "   826/834        0G      2.83    0.0873         0      2.92         9       576:  15%|#4        | 8/54 [00:43<04:03,  5.30s/it]\n",
      "   826/834        0G      2.95    0.0912         0      3.04         9       576:  15%|#4        | 8/54 [00:48<04:03,  5.30s/it]\n",
      "   826/834        0G      2.95    0.0912         0      3.04         9       576:  17%|#6        | 9/54 [00:48<03:57,  5.28s/it]\n",
      "   826/834        0G      2.76    0.0908         0      2.85         9       576:  17%|#6        | 9/54 [00:53<03:57,  5.28s/it]\n",
      "   826/834        0G      2.76    0.0908         0      2.85         9       576:  19%|#8        | 10/54 [00:53<03:53,  5.32s/it]\n",
      "   826/834        0G      2.61     0.091         0      2.71        10       576:  19%|#8        | 10/54 [00:59<03:53,  5.32s/it]\n",
      "   826/834        0G      2.61     0.091         0      2.71        10       576:  20%|##        | 11/54 [00:59<03:48,  5.32s/it]\n",
      "   826/834        0G      2.72    0.0926         0      2.81         9       576:  20%|##        | 11/54 [01:04<03:48,  5.32s/it]\n",
      "   826/834        0G      2.72    0.0926         0      2.81         9       576:  22%|##2       | 12/54 [01:04<03:44,  5.35s/it]\n",
      "   826/834        0G      2.58    0.0928         0      2.67         9       576:  22%|##2       | 12/54 [01:10<03:44,  5.35s/it]\n",
      "   826/834        0G      2.58    0.0928         0      2.67         9       576:  24%|##4       | 13/54 [01:10<03:39,  5.35s/it]\n",
      "   826/834        0G      2.65    0.0938         0      2.75         9       576:  24%|##4       | 13/54 [01:15<03:39,  5.35s/it]\n",
      "   826/834        0G      2.65    0.0938         0      2.75         9       576:  26%|##5       | 14/54 [01:15<03:33,  5.34s/it]\n",
      "   826/834        0G      2.76    0.0927         0      2.85         9       576:  26%|##5       | 14/54 [01:20<03:33,  5.34s/it]\n",
      "   826/834        0G      2.76    0.0927         0      2.85         9       576:  28%|##7       | 15/54 [01:20<03:28,  5.34s/it]\n",
      "   826/834        0G      2.83    0.0926         0      2.93         9       576:  28%|##7       | 15/54 [01:26<03:28,  5.34s/it]\n",
      "   826/834        0G      2.83    0.0926         0      2.93         9       576:  30%|##9       | 16/54 [01:26<03:22,  5.34s/it]\n",
      "   826/834        0G      2.88     0.095         0      2.98         9       576:  30%|##9       | 16/54 [01:31<03:22,  5.34s/it]\n",
      "   826/834        0G      2.88     0.095         0      2.98         9       576:  31%|###1      | 17/54 [01:31<03:16,  5.32s/it]\n",
      "   826/834        0G      2.77    0.0951         0      2.87        10       576:  31%|###1      | 17/54 [01:36<03:16,  5.32s/it]\n",
      "   826/834        0G      2.77    0.0951         0      2.87        10       576:  33%|###3      | 18/54 [01:36<03:12,  5.34s/it]\n",
      "   826/834        0G      2.83    0.0959         0      2.93         9       576:  33%|###3      | 18/54 [01:42<03:12,  5.34s/it]\n",
      "   826/834        0G      2.83    0.0959         0      2.93         9       576:  35%|###5      | 19/54 [01:42<03:06,  5.33s/it]\n",
      "   826/834        0G      2.89     0.097         0      2.99         9       576:  35%|###5      | 19/54 [01:47<03:06,  5.33s/it]\n",
      "   826/834        0G      2.89     0.097         0      2.99         9       576:  37%|###7      | 20/54 [01:47<03:02,  5.36s/it]\n",
      "   826/834        0G      2.94    0.0974         0      3.04        12       576:  37%|###7      | 20/54 [01:52<03:02,  5.36s/it]\n",
      "   826/834        0G      2.94    0.0974         0      3.04        12       576:  39%|###8      | 21/54 [01:52<02:58,  5.40s/it]\n",
      "   826/834        0G      2.87    0.0975         0      2.96         8       384:  39%|###8      | 21/54 [01:55<02:58,  5.40s/it]\n",
      "   826/834        0G      2.87    0.0975         0      2.96         8       384:  41%|####      | 22/54 [01:55<02:28,  4.63s/it]\n",
      "   826/834        0G      2.79    0.0965         0      2.89         9       384:  41%|####      | 22/54 [01:58<02:28,  4.63s/it]\n",
      "   826/834        0G      2.79    0.0965         0      2.89         9       384:  43%|####2     | 23/54 [01:58<02:03,  3.97s/it]\n",
      "   826/834        0G      2.73    0.0953         0      2.82         9       384:  43%|####2     | 23/54 [02:00<02:03,  3.97s/it]\n",
      "   826/834        0G      2.73    0.0953         0      2.82         9       384:  44%|####4     | 24/54 [02:00<01:45,  3.51s/it]\n",
      "   826/834        0G      2.67    0.0978         0      2.77        10       384:  44%|####4     | 24/54 [02:03<01:45,  3.51s/it]\n",
      "   826/834        0G      2.67    0.0978         0      2.77        10       384:  46%|####6     | 25/54 [02:03<01:32,  3.18s/it]\n",
      "   826/834        0G      2.61    0.0992         0      2.71        12       384:  46%|####6     | 25/54 [02:05<01:32,  3.18s/it]\n",
      "   826/834        0G      2.61    0.0992         0      2.71        12       384:  48%|####8     | 26/54 [02:05<01:22,  2.94s/it]\n",
      "   826/834        0G      2.56       0.1         0      2.66        12       384:  48%|####8     | 26/54 [02:07<01:22,  2.94s/it]\n",
      "   826/834        0G      2.56       0.1         0      2.66        12       384:  50%|#####     | 27/54 [02:07<01:15,  2.78s/it]\n",
      "   826/834        0G      2.52     0.101         0      2.62        10       384:  50%|#####     | 27/54 [02:10<01:15,  2.78s/it]\n",
      "   826/834        0G      2.52     0.101         0      2.62        10       384:  52%|#####1    | 28/54 [02:10<01:09,  2.67s/it]\n",
      "   826/834        0G      2.47     0.103         0      2.57        12       384:  52%|#####1    | 28/54 [02:12<01:09,  2.67s/it]\n",
      "   826/834        0G      2.47     0.103         0      2.57        12       384:  54%|#####3    | 29/54 [02:12<01:05,  2.61s/it]\n",
      "   826/834        0G      2.43     0.104         0      2.54        12       384:  54%|#####3    | 29/54 [02:15<01:05,  2.61s/it]\n",
      "   826/834        0G      2.43     0.104         0      2.54        12       384:  56%|#####5    | 30/54 [02:15<01:01,  2.57s/it]\n",
      "   826/834        0G      2.39     0.104         0       2.5         9       384:  56%|#####5    | 30/54 [02:17<01:01,  2.57s/it]\n",
      "   826/834        0G      2.39     0.104         0       2.5         9       384:  57%|#####7    | 31/54 [02:17<00:58,  2.54s/it]\n",
      "   826/834        0G      2.36     0.106         0      2.46        13       384:  57%|#####7    | 31/54 [02:20<00:58,  2.54s/it]\n",
      "   826/834        0G      2.36     0.106         0      2.46        13       384:  59%|#####9    | 32/54 [02:20<00:55,  2.52s/it]\n",
      "   826/834        0G      2.32     0.107         0      2.43        11       384:  59%|#####9    | 32/54 [02:22<00:55,  2.52s/it]\n",
      "   826/834        0G      2.32     0.107         0      2.43        11       384:  61%|######1   | 33/54 [02:22<00:52,  2.51s/it]\n",
      "   826/834        0G      2.29     0.108         0       2.4        12       384:  61%|######1   | 33/54 [02:25<00:52,  2.51s/it]\n",
      "   826/834        0G      2.29     0.108         0       2.4        12       384:  63%|######2   | 34/54 [02:25<00:50,  2.50s/it]\n",
      "   826/834        0G      2.26     0.107         0      2.36         8       384:  63%|######2   | 34/54 [02:27<00:50,  2.50s/it]\n",
      "   826/834        0G      2.26     0.107         0      2.36         8       384:  65%|######4   | 35/54 [02:27<00:47,  2.48s/it]\n",
      "   826/834        0G      2.23     0.107         0      2.33         9       384:  65%|######4   | 35/54 [02:29<00:47,  2.48s/it]\n",
      "   826/834        0G      2.23     0.107         0      2.33         9       384:  67%|######6   | 36/54 [02:29<00:44,  2.45s/it]\n",
      "   826/834        0G       2.2     0.107         0       2.3         9       384:  67%|######6   | 36/54 [02:32<00:44,  2.45s/it]\n",
      "   826/834        0G       2.2     0.107         0       2.3         9       384:  69%|######8   | 37/54 [02:32<00:41,  2.44s/it]\n",
      "   826/834        0G      2.17     0.107         0      2.28        10       384:  69%|######8   | 37/54 [02:34<00:41,  2.44s/it]\n",
      "   826/834        0G      2.17     0.107         0      2.28        10       384:  70%|#######   | 38/54 [02:34<00:39,  2.44s/it]\n",
      "   826/834        0G      2.15     0.106         0      2.26         9       384:  70%|#######   | 38/54 [02:37<00:39,  2.44s/it]\n",
      "   826/834        0G      2.15     0.106         0      2.26         9       384:  72%|#######2  | 39/54 [02:37<00:36,  2.44s/it]\n",
      "   826/834        0G      2.13     0.106         0      2.23         8       384:  72%|#######2  | 39/54 [02:39<00:36,  2.44s/it]\n",
      "   826/834        0G      2.13     0.106         0      2.23         8       384:  74%|#######4  | 40/54 [02:39<00:34,  2.45s/it]\n",
      "   826/834        0G       2.1     0.106         0      2.21        10       384:  74%|#######4  | 40/54 [02:42<00:34,  2.45s/it]\n",
      "   826/834        0G       2.1     0.106         0      2.21        10       384:  76%|#######5  | 41/54 [02:42<00:31,  2.44s/it]\n",
      "   826/834        0G      2.08     0.106         0      2.19        11       384:  76%|#######5  | 41/54 [02:44<00:31,  2.44s/it]\n",
      "   826/834        0G      2.08     0.106         0      2.19        11       384:  78%|#######7  | 42/54 [02:44<00:29,  2.44s/it]\n",
      "   826/834        0G      2.06     0.106         0      2.17         9       448:  78%|#######7  | 42/54 [02:48<00:29,  2.44s/it]\n",
      "   826/834        0G      2.06     0.106         0      2.17         9       448:  80%|#######9  | 43/54 [02:48<00:30,  2.79s/it]\n",
      "   826/834        0G      2.04     0.106         0      2.14         9       448:  80%|#######9  | 43/54 [02:51<00:30,  2.79s/it]\n",
      "   826/834        0G      2.04     0.106         0      2.14         9       448:  81%|########1 | 44/54 [02:51<00:29,  2.92s/it]\n",
      "   826/834        0G      2.02     0.106         0      2.12        10       448:  81%|########1 | 44/54 [02:54<00:29,  2.92s/it]\n",
      "   826/834        0G      2.02     0.106         0      2.12        10       448:  83%|########3 | 45/54 [02:54<00:27,  3.04s/it]\n",
      "   826/834        0G         2     0.106         0       2.1         9       448:  83%|########3 | 45/54 [02:57<00:27,  3.04s/it]\n",
      "   826/834        0G         2     0.106         0       2.1         9       448:  85%|########5 | 46/54 [02:57<00:24,  3.12s/it]\n",
      "   826/834        0G      1.98     0.105         0      2.09         9       448:  85%|########5 | 46/54 [03:01<00:24,  3.12s/it]\n",
      "   826/834        0G      1.98     0.105         0      2.09         9       448:  87%|########7 | 47/54 [03:01<00:22,  3.15s/it]\n",
      "   826/834        0G      1.96     0.105         0      2.07         8       448:  87%|########7 | 47/54 [03:04<00:22,  3.15s/it]\n",
      "   826/834        0G      1.96     0.105         0      2.07         8       448:  89%|########8 | 48/54 [03:04<00:18,  3.16s/it]\n",
      "   826/834        0G      1.94     0.105         0      2.05         9       448:  89%|########8 | 48/54 [03:07<00:18,  3.16s/it]\n",
      "   826/834        0G      1.94     0.105         0      2.05         9       448:  91%|######### | 49/54 [03:07<00:16,  3.20s/it]\n",
      "   826/834        0G      1.93     0.106         0      2.03        12       448:  91%|######### | 49/54 [03:11<00:16,  3.20s/it]\n",
      "   826/834        0G      1.93     0.106         0      2.03        12       448:  93%|#########2| 50/54 [03:11<00:12,  3.23s/it]\n",
      "   826/834        0G      1.91     0.106         0      2.02         8       448:  93%|#########2| 50/54 [03:14<00:12,  3.23s/it]\n",
      "   826/834        0G      1.91     0.106         0      2.02         8       448:  94%|#########4| 51/54 [03:14<00:09,  3.26s/it]\n",
      "   826/834        0G       1.9     0.106         0         2        10       448:  94%|#########4| 51/54 [03:17<00:09,  3.26s/it]\n",
      "   826/834        0G       1.9     0.106         0         2        10       448:  96%|#########6| 52/54 [03:17<00:06,  3.29s/it]\n",
      "   826/834        0G      1.88     0.106         0      1.99        10       448:  96%|#########6| 52/54 [03:21<00:06,  3.29s/it]\n",
      "   826/834        0G      1.88     0.106         0      1.99        10       448:  98%|#########8| 53/54 [03:21<00:03,  3.32s/it]\n",
      "   826/834        0G      1.87     0.106         0      1.98         3       448:  98%|#########8| 53/54 [03:22<00:03,  3.32s/it]\n",
      "   826/834        0G      1.87     0.106         0      1.98         3       448: 100%|##########| 54/54 [03:22<00:00,  2.71s/it]\n",
      "   826/834        0G      1.87     0.106         0      1.98         3       448: 100%|##########| 54/54 [03:23<00:00,  3.77s/it]\n",
      "\n",
      "               Class    Images   Targets         P         R   mAP@0.5        F1:   0%|          | 0/14 [00:00<?, ?it/s]2024-03-04 16:39:44.891017: I tensorflow/core/util/port.cc:113] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
      "WARNING:tensorflow:From C:\\Users\\mit017\\anaconda3\\Lib\\site-packages\\keras\\src\\losses.py:2976: The name tf.losses.sparse_softmax_cross_entropy is deprecated. Please use tf.compat.v1.losses.sparse_softmax_cross_entropy instead.\n",
      "\n",
      "2024-03-04 16:40:20.830850: I tensorflow/core/util/port.cc:113] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
      "WARNING:tensorflow:From C:\\Users\\mit017\\anaconda3\\Lib\\site-packages\\keras\\src\\losses.py:2976: The name tf.losses.sparse_softmax_cross_entropy is deprecated. Please use tf.compat.v1.losses.sparse_softmax_cross_entropy instead.\n",
      "\n",
      "2024-03-04 16:40:37.670241: I tensorflow/core/util/port.cc:113] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
      "WARNING:tensorflow:From C:\\Users\\mit017\\anaconda3\\Lib\\site-packages\\keras\\src\\losses.py:2976: The name tf.losses.sparse_softmax_cross_entropy is deprecated. Please use tf.compat.v1.losses.sparse_softmax_cross_entropy instead.\n",
      "\n",
      "\n",
      "               Class    Images   Targets         P         R   mAP@0.5        F1:   7%|7         | 1/14 [01:13<15:55, 73.53s/it]\n",
      "               Class    Images   Targets         P         R   mAP@0.5        F1:  14%|#4        | 2/14 [01:15<06:17, 31.45s/it]\n",
      "               Class    Images   Targets         P         R   mAP@0.5        F1:  21%|##1       | 3/14 [01:17<03:17, 17.98s/it]\n",
      "               Class    Images   Targets         P         R   mAP@0.5        F1:  29%|##8       | 4/14 [01:19<01:56, 11.68s/it]\n",
      "               Class    Images   Targets         P         R   mAP@0.5        F1:  36%|###5      | 5/14 [01:21<01:13,  8.19s/it]\n",
      "               Class    Images   Targets         P         R   mAP@0.5        F1:  43%|####2     | 6/14 [01:23<00:48,  6.06s/it]\n",
      "               Class    Images   Targets         P         R   mAP@0.5        F1:  50%|#####     | 7/14 [01:25<00:33,  4.75s/it]\n",
      "               Class    Images   Targets         P         R   mAP@0.5        F1:  57%|#####7    | 8/14 [01:27<00:23,  3.89s/it]\n",
      "               Class    Images   Targets         P         R   mAP@0.5        F1:  64%|######4   | 9/14 [01:29<00:16,  3.32s/it]\n",
      "               Class    Images   Targets         P         R   mAP@0.5        F1:  71%|#######1  | 10/14 [01:31<00:11,  2.92s/it]\n",
      "               Class    Images   Targets         P         R   mAP@0.5        F1:  79%|#######8  | 11/14 [01:33<00:07,  2.64s/it]\n",
      "               Class    Images   Targets         P         R   mAP@0.5        F1:  86%|########5 | 12/14 [01:35<00:04,  2.46s/it]\n",
      "               Class    Images   Targets         P         R   mAP@0.5        F1:  93%|#########2| 13/14 [01:37<00:02,  2.33s/it]\n",
      "               Class    Images   Targets         P         R   mAP@0.5        F1: 100%|##########| 14/14 [01:38<00:00,  1.85s/it]\n",
      "               Class    Images   Targets         P         R   mAP@0.5        F1: 100%|##########| 14/14 [01:39<00:00,  7.11s/it]\n",
      "2024-03-04 16:41:16.291059: I tensorflow/core/util/port.cc:113] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
      "WARNING:tensorflow:From C:\\Users\\mit017\\anaconda3\\Lib\\site-packages\\keras\\src\\losses.py:2976: The name tf.losses.sparse_softmax_cross_entropy is deprecated. Please use tf.compat.v1.losses.sparse_softmax_cross_entropy instead.\n",
      "\n",
      "2024-03-04 16:41:26.965457: I tensorflow/core/util/port.cc:113] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
      "WARNING:tensorflow:From C:\\Users\\mit017\\anaconda3\\Lib\\site-packages\\keras\\src\\losses.py:2976: The name tf.losses.sparse_softmax_cross_entropy is deprecated. Please use tf.compat.v1.losses.sparse_softmax_cross_entropy instead.\n",
      "\n",
      "2024-03-04 16:41:37.147845: I tensorflow/core/util/port.cc:113] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
      "WARNING:tensorflow:From C:\\Users\\mit017\\anaconda3\\Lib\\site-packages\\keras\\src\\losses.py:2976: The name tf.losses.sparse_softmax_cross_entropy is deprecated. Please use tf.compat.v1.losses.sparse_softmax_cross_entropy instead.\n",
      "\n",
      "\n",
      "  0%|          | 0/54 [00:00<?, ?it/s]\n",
      "   827/834        0G      1.34    0.0849         0      1.43        10       448:   0%|          | 0/54 [00:03<?, ?it/s]\n",
      "   827/834        0G      1.34    0.0849         0      1.43        10       448:   2%|1         | 1/54 [00:03<03:13,  3.66s/it]\n",
      "   827/834        0G      1.24     0.106         0      1.34        11       448:   2%|1         | 1/54 [00:06<03:13,  3.66s/it]\n",
      "   827/834        0G      1.24     0.106         0      1.34        11       448:   4%|3         | 2/54 [00:06<02:57,  3.41s/it]\n",
      "   827/834        0G      2.05     0.113         0      2.16        10       448:   4%|3         | 2/54 [00:10<02:57,  3.41s/it]\n",
      "   827/834        0G      2.05     0.113         0      2.16        10       448:   6%|5         | 3/54 [00:10<02:50,  3.34s/it]\n",
      "   827/834        0G       1.8     0.111         0      1.91         9       448:   6%|5         | 3/54 [00:13<02:50,  3.34s/it]\n",
      "   827/834        0G       1.8     0.111         0      1.91         9       448:   7%|7         | 4/54 [00:13<02:45,  3.30s/it]\n",
      "   827/834        0G      1.68     0.109         0      1.79         9       448:   7%|7         | 4/54 [00:16<02:45,  3.30s/it]\n",
      "   827/834        0G      1.68     0.109         0      1.79         9       448:   9%|9         | 5/54 [00:16<02:41,  3.30s/it]\n",
      "   827/834        0G       1.6     0.108         0      1.71         9       448:   9%|9         | 5/54 [00:20<02:41,  3.30s/it]\n",
      "   827/834        0G       1.6     0.108         0      1.71         9       448:  11%|#1        | 6/54 [00:20<02:39,  3.32s/it]\n",
      "   827/834        0G      1.55     0.109         0      1.65        11       448:  11%|#1        | 6/54 [00:23<02:39,  3.32s/it]\n",
      "   827/834        0G      1.55     0.109         0      1.65        11       448:  13%|#2        | 7/54 [00:23<02:36,  3.33s/it]\n",
      "   827/834        0G       1.5     0.109         0      1.61        12       448:  13%|#2        | 7/54 [00:26<02:36,  3.33s/it]\n",
      "   827/834        0G       1.5     0.109         0      1.61        12       448:  15%|#4        | 8/54 [00:26<02:34,  3.35s/it]\n",
      "   827/834        0G      1.47     0.109         0      1.58        10       448:  15%|#4        | 8/54 [00:30<02:34,  3.35s/it]\n",
      "   827/834        0G      1.47     0.109         0      1.58        10       448:  17%|#6        | 9/54 [00:30<02:31,  3.36s/it]\n",
      "   827/834        0G      1.46     0.106         0      1.56         9       384:  17%|#6        | 9/54 [00:32<02:31,  3.36s/it]\n",
      "   827/834        0G      1.46     0.106         0      1.56         9       384:  19%|#8        | 10/54 [00:32<02:19,  3.17s/it]\n",
      "   827/834        0G      1.43     0.109         0      1.54         9       384:  19%|#8        | 10/54 [00:35<02:19,  3.17s/it]\n",
      "   827/834        0G      1.43     0.109         0      1.54         9       384:  20%|##        | 11/54 [00:35<02:06,  2.94s/it]\n",
      "   827/834        0G      1.42     0.107         0      1.53         9       384:  20%|##        | 11/54 [00:37<02:06,  2.94s/it]\n",
      "   827/834        0G      1.42     0.107         0      1.53         9       384:  22%|##2       | 12/54 [00:37<01:57,  2.79s/it]\n",
      "   827/834        0G       1.4     0.106         0      1.51         9       384:  22%|##2       | 12/54 [00:40<01:57,  2.79s/it]\n",
      "   827/834        0G       1.4     0.106         0      1.51         9       384:  24%|##4       | 13/54 [00:40<01:49,  2.68s/it]\n",
      "   827/834        0G       1.4     0.105         0      1.51         9       384:  24%|##4       | 13/54 [00:42<01:49,  2.68s/it]\n",
      "   827/834        0G       1.4     0.105         0      1.51         9       384:  26%|##5       | 14/54 [00:42<01:44,  2.61s/it]\n",
      "   827/834        0G      1.39     0.104         0       1.5         9       384:  26%|##5       | 14/54 [00:45<01:44,  2.61s/it]\n",
      "   827/834        0G      1.39     0.104         0       1.5         9       384:  28%|##7       | 15/54 [00:45<01:40,  2.58s/it]\n",
      "   827/834        0G      1.38     0.105         0      1.49         9       384:  28%|##7       | 15/54 [00:47<01:40,  2.58s/it]\n",
      "   827/834        0G      1.38     0.105         0      1.49         9       384:  30%|##9       | 16/54 [00:47<01:36,  2.54s/it]\n",
      "   827/834        0G      1.38     0.109         0      1.49        14       384:  30%|##9       | 16/54 [00:50<01:36,  2.54s/it]\n",
      "   827/834        0G      1.38     0.109         0      1.49        14       384:  31%|###1      | 17/54 [00:50<01:33,  2.52s/it]\n",
      "   827/834        0G      1.38      0.11         0      1.49        10       384:  31%|###1      | 17/54 [00:52<01:33,  2.52s/it]\n",
      "   827/834        0G      1.38      0.11         0      1.49        10       384:  33%|###3      | 18/54 [00:52<01:29,  2.49s/it]\n",
      "   827/834        0G      1.36      0.11         0      1.47        10       384:  33%|###3      | 18/54 [00:54<01:29,  2.49s/it]\n",
      "   827/834        0G      1.36      0.11         0      1.47        10       384:  35%|###5      | 19/54 [00:54<01:26,  2.47s/it]\n",
      "   827/834        0G      1.37     0.109         0      1.47         9       384:  35%|###5      | 19/54 [00:57<01:26,  2.47s/it]\n",
      "   827/834        0G      1.37     0.109         0      1.47         9       384:  37%|###7      | 20/54 [00:57<01:23,  2.46s/it]\n",
      "   827/834        0G      1.36     0.108         0      1.46         9       384:  37%|###7      | 20/54 [00:59<01:23,  2.46s/it]\n",
      "   827/834        0G      1.36     0.108         0      1.46         9       384:  39%|###8      | 21/54 [00:59<01:20,  2.45s/it]\n",
      "   827/834        0G      1.35     0.107         0      1.46         9       384:  39%|###8      | 21/54 [01:02<01:20,  2.45s/it]\n",
      "   827/834        0G      1.35     0.107         0      1.46         9       384:  41%|####      | 22/54 [01:02<01:17,  2.44s/it]\n",
      "   827/834        0G      1.34     0.109         0      1.45         9       384:  41%|####      | 22/54 [01:04<01:17,  2.44s/it]\n",
      "   827/834        0G      1.34     0.109         0      1.45         9       384:  43%|####2     | 23/54 [01:04<01:15,  2.44s/it]\n",
      "   827/834        0G      1.34     0.108         0      1.45        10       384:  43%|####2     | 23/54 [01:07<01:15,  2.44s/it]\n",
      "   827/834        0G      1.34     0.108         0      1.45        10       384:  44%|####4     | 24/54 [01:07<01:13,  2.45s/it]\n",
      "   827/834        0G      1.33     0.108         0      1.44         9       384:  44%|####4     | 24/54 [01:09<01:13,  2.45s/it]\n",
      "   827/834        0G      1.33     0.108         0      1.44         9       384:  46%|####6     | 25/54 [01:09<01:11,  2.46s/it]\n",
      "   827/834        0G      1.32     0.109         0      1.43        11       384:  46%|####6     | 25/54 [01:12<01:11,  2.46s/it]\n",
      "   827/834        0G      1.32     0.109         0      1.43        11       384:  48%|####8     | 26/54 [01:12<01:08,  2.46s/it]\n",
      "   827/834        0G      1.32      0.11         0      1.43        12       384:  48%|####8     | 26/54 [01:14<01:08,  2.46s/it]\n",
      "   827/834        0G      1.32      0.11         0      1.43        12       384:  50%|#####     | 27/54 [01:14<01:06,  2.46s/it]\n",
      "   827/834        0G      1.31     0.109         0      1.42         9       384:  50%|#####     | 27/54 [01:16<01:06,  2.46s/it]\n",
      "   827/834        0G      1.31     0.109         0      1.42         9       384:  52%|#####1    | 28/54 [01:16<01:03,  2.46s/it]\n",
      "   827/834        0G       1.3     0.109         0      1.41         9       384:  52%|#####1    | 28/54 [01:19<01:03,  2.46s/it]\n",
      "   827/834        0G       1.3     0.109         0      1.41         9       384:  54%|#####3    | 29/54 [01:19<01:01,  2.46s/it]\n",
      "   827/834        0G      1.31     0.109         0      1.42        13       384:  54%|#####3    | 29/54 [01:21<01:01,  2.46s/it]\n",
      "   827/834        0G      1.31     0.109         0      1.42        13       384:  56%|#####5    | 30/54 [01:21<00:59,  2.46s/it]\n",
      "   827/834        0G       1.3      0.11         0      1.41         9       352:  56%|#####5    | 30/54 [01:24<00:59,  2.46s/it]\n",
      "   827/834        0G       1.3      0.11         0      1.41         9       352:  57%|#####7    | 31/54 [01:24<00:56,  2.44s/it]\n",
      "   827/834        0G       1.3     0.109         0       1.4         9       352:  57%|#####7    | 31/54 [01:26<00:56,  2.44s/it]\n",
      "   827/834        0G       1.3     0.109         0       1.4         9       352:  59%|#####9    | 32/54 [01:26<00:51,  2.33s/it]\n",
      "   827/834        0G      1.29      0.11         0       1.4         9       352:  59%|#####9    | 32/54 [01:28<00:51,  2.33s/it]\n",
      "   827/834        0G      1.29      0.11         0       1.4         9       352:  61%|######1   | 33/54 [01:28<00:47,  2.25s/it]\n",
      "   827/834        0G      1.28      0.11         0      1.39         9       352:  61%|######1   | 33/54 [01:30<00:47,  2.25s/it]\n",
      "   827/834        0G      1.28      0.11         0      1.39         9       352:  63%|######2   | 34/54 [01:30<00:44,  2.21s/it]\n",
      "   827/834        0G      1.28     0.109         0      1.39         9       352:  63%|######2   | 34/54 [01:32<00:44,  2.21s/it]\n",
      "   827/834        0G      1.28     0.109         0      1.39         9       352:  65%|######4   | 35/54 [01:32<00:41,  2.19s/it]\n",
      "   827/834        0G      1.28      0.11         0      1.39         9       352:  65%|######4   | 35/54 [01:34<00:41,  2.19s/it]\n",
      "   827/834        0G      1.28      0.11         0      1.39         9       352:  67%|######6   | 36/54 [01:34<00:38,  2.16s/it]\n",
      "   827/834        0G      1.28     0.111         0      1.39        12       352:  67%|######6   | 36/54 [01:36<00:38,  2.16s/it]\n",
      "   827/834        0G      1.28     0.111         0      1.39        12       352:  69%|######8   | 37/54 [01:36<00:36,  2.14s/it]\n",
      "   827/834        0G      1.28     0.111         0      1.39         9       352:  69%|######8   | 37/54 [01:38<00:36,  2.14s/it]\n",
      "   827/834        0G      1.28     0.111         0      1.39         9       352:  70%|#######   | 38/54 [01:38<00:34,  2.13s/it]\n",
      "   827/834        0G      1.27     0.112         0      1.39        12       352:  70%|#######   | 38/54 [01:41<00:34,  2.13s/it]\n",
      "   827/834        0G      1.27     0.112         0      1.39        12       352:  72%|#######2  | 39/54 [01:41<00:31,  2.12s/it]\n",
      "   827/834        0G      1.27     0.113         0      1.38        10       352:  72%|#######2  | 39/54 [01:43<00:31,  2.12s/it]\n",
      "   827/834        0G      1.27     0.113         0      1.38        10       352:  74%|#######4  | 40/54 [01:43<00:29,  2.11s/it]\n",
      "   827/834        0G      1.27     0.113         0      1.38         9       352:  74%|#######4  | 40/54 [01:45<00:29,  2.11s/it]\n",
      "   827/834        0G      1.27     0.113         0      1.38         9       352:  76%|#######5  | 41/54 [01:45<00:27,  2.11s/it]\n",
      "   827/834        0G      1.27     0.113         0      1.39         8       352:  76%|#######5  | 41/54 [01:47<00:27,  2.11s/it]\n",
      "   827/834        0G      1.27     0.113         0      1.39         8       352:  78%|#######7  | 42/54 [01:47<00:25,  2.11s/it]\n",
      "   827/834        0G      1.27     0.113         0      1.39         9       352:  78%|#######7  | 42/54 [01:49<00:25,  2.11s/it]\n",
      "   827/834        0G      1.27     0.113         0      1.39         9       352:  80%|#######9  | 43/54 [01:49<00:23,  2.10s/it]\n",
      "   827/834        0G      1.27     0.113         0      1.39         9       352:  80%|#######9  | 43/54 [01:51<00:23,  2.10s/it]\n",
      "   827/834        0G      1.27     0.113         0      1.39         9       352:  81%|########1 | 44/54 [01:51<00:21,  2.10s/it]\n",
      "   827/834        0G      1.28     0.112         0      1.39         9       352:  81%|########1 | 44/54 [01:53<00:21,  2.10s/it]\n",
      "   827/834        0G      1.28     0.112         0      1.39         9       352:  83%|########3 | 45/54 [01:53<00:18,  2.09s/it]\n",
      "   827/834        0G      1.28     0.113         0      1.39         9       352:  83%|########3 | 45/54 [01:55<00:18,  2.09s/it]\n",
      "   827/834        0G      1.28     0.113         0      1.39         9       352:  85%|########5 | 46/54 [01:55<00:16,  2.10s/it]\n",
      "   827/834        0G      1.28     0.113         0      1.39         9       352:  85%|########5 | 46/54 [01:57<00:16,  2.10s/it]\n",
      "   827/834        0G      1.28     0.113         0      1.39         9       352:  87%|########7 | 47/54 [01:57<00:14,  2.11s/it]\n",
      "   827/834        0G      1.28     0.114         0       1.4        12       352:  87%|########7 | 47/54 [02:00<00:14,  2.11s/it]\n",
      "   827/834        0G      1.28     0.114         0       1.4        12       352:  89%|########8 | 48/54 [02:00<00:13,  2.18s/it]\n",
      "   827/834        0G      1.28     0.114         0      1.39         9       352:  89%|########8 | 48/54 [02:02<00:13,  2.18s/it]\n",
      "   827/834        0G      1.28     0.114         0      1.39         9       352:  91%|######### | 49/54 [02:02<00:10,  2.18s/it]\n",
      "   827/834        0G      1.28     0.114         0      1.39        11       352:  91%|######### | 49/54 [02:04<00:10,  2.18s/it]\n",
      "   827/834        0G      1.28     0.114         0      1.39        11       352:  93%|#########2| 50/54 [02:04<00:08,  2.16s/it]\n",
      "   827/834        0G      1.28     0.115         0      1.39        10       352:  93%|#########2| 50/54 [02:06<00:08,  2.16s/it]\n",
      "   827/834        0G      1.28     0.115         0      1.39        10       352:  94%|#########4| 51/54 [02:06<00:06,  2.21s/it]\n",
      "   827/834        0G      1.28     0.114         0      1.39         9       608:  94%|#########4| 51/54 [02:13<00:06,  2.21s/it]\n",
      "   827/834        0G      1.28     0.114         0      1.39         9       608:  96%|#########6| 52/54 [02:13<00:07,  3.67s/it]\n",
      "   827/834        0G      1.33     0.114         0      1.45         9       608:  96%|#########6| 52/54 [02:19<00:07,  3.67s/it]\n",
      "   827/834        0G      1.33     0.114         0      1.45         9       608:  98%|#########8| 53/54 [02:19<00:04,  4.38s/it]\n",
      "   827/834        0G      1.39     0.113         0       1.5         4       608:  98%|#########8| 53/54 [02:22<00:04,  4.38s/it]\n",
      "   827/834        0G      1.39     0.113         0       1.5         4       608: 100%|##########| 54/54 [02:22<00:00,  3.73s/it]\n",
      "   827/834        0G      1.39     0.113         0       1.5         4       608: 100%|##########| 54/54 [02:23<00:00,  2.65s/it]\n",
      "\n",
      "               Class    Images   Targets         P         R   mAP@0.5        F1:   0%|          | 0/14 [00:00<?, ?it/s]2024-03-04 16:44:10.671879: I tensorflow/core/util/port.cc:113] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
      "WARNING:tensorflow:From C:\\Users\\mit017\\anaconda3\\Lib\\site-packages\\keras\\src\\losses.py:2976: The name tf.losses.sparse_softmax_cross_entropy is deprecated. Please use tf.compat.v1.losses.sparse_softmax_cross_entropy instead.\n",
      "\n",
      "2024-03-04 16:44:21.242101: I tensorflow/core/util/port.cc:113] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
      "WARNING:tensorflow:From C:\\Users\\mit017\\anaconda3\\Lib\\site-packages\\keras\\src\\losses.py:2976: The name tf.losses.sparse_softmax_cross_entropy is deprecated. Please use tf.compat.v1.losses.sparse_softmax_cross_entropy instead.\n",
      "\n",
      "2024-03-04 16:44:31.352279: I tensorflow/core/util/port.cc:113] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
      "WARNING:tensorflow:From C:\\Users\\mit017\\anaconda3\\Lib\\site-packages\\keras\\src\\losses.py:2976: The name tf.losses.sparse_softmax_cross_entropy is deprecated. Please use tf.compat.v1.losses.sparse_softmax_cross_entropy instead.\n",
      "\n",
      "\n",
      "               Class    Images   Targets         P         R   mAP@0.5        F1:   7%|7         | 1/14 [00:33<07:10, 33.10s/it]\n",
      "               Class    Images   Targets         P         R   mAP@0.5        F1:  14%|#4        | 2/14 [00:35<02:58, 14.90s/it]\n",
      "               Class    Images   Targets         P         R   mAP@0.5        F1:  21%|##1       | 3/14 [00:37<01:39,  9.05s/it]\n",
      "               Class    Images   Targets         P         R   mAP@0.5        F1:  29%|##8       | 4/14 [00:39<01:03,  6.32s/it]\n",
      "               Class    Images   Targets         P         R   mAP@0.5        F1:  36%|###5      | 5/14 [00:41<00:43,  4.83s/it]\n",
      "               Class    Images   Targets         P         R   mAP@0.5        F1:  43%|####2     | 6/14 [00:43<00:31,  3.89s/it]\n",
      "               Class    Images   Targets         P         R   mAP@0.5        F1:  50%|#####     | 7/14 [00:45<00:23,  3.33s/it]\n",
      "               Class    Images   Targets         P         R   mAP@0.5        F1:  57%|#####7    | 8/14 [00:47<00:17,  2.91s/it]\n",
      "               Class    Images   Targets         P         R   mAP@0.5        F1:  64%|######4   | 9/14 [00:49<00:13,  2.63s/it]\n",
      "               Class    Images   Targets         P         R   mAP@0.5        F1:  71%|#######1  | 10/14 [00:51<00:09,  2.45s/it]\n",
      "               Class    Images   Targets         P         R   mAP@0.5        F1:  79%|#######8  | 11/14 [00:53<00:06,  2.31s/it]\n",
      "               Class    Images   Targets         P         R   mAP@0.5        F1:  86%|########5 | 12/14 [00:55<00:04,  2.21s/it]\n",
      "               Class    Images   Targets         P         R   mAP@0.5        F1:  93%|#########2| 13/14 [00:58<00:02,  2.17s/it]\n",
      "               Class    Images   Targets         P         R   mAP@0.5        F1: 100%|##########| 14/14 [00:58<00:00,  1.76s/it]\n",
      "               Class    Images   Targets         P         R   mAP@0.5        F1: 100%|##########| 14/14 [00:59<00:00,  4.28s/it]\n",
      "2024-03-04 16:45:10.671710: I tensorflow/core/util/port.cc:113] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
      "WARNING:tensorflow:From C:\\Users\\mit017\\anaconda3\\Lib\\site-packages\\keras\\src\\losses.py:2976: The name tf.losses.sparse_softmax_cross_entropy is deprecated. Please use tf.compat.v1.losses.sparse_softmax_cross_entropy instead.\n",
      "\n",
      "2024-03-04 16:45:21.098946: I tensorflow/core/util/port.cc:113] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
      "WARNING:tensorflow:From C:\\Users\\mit017\\anaconda3\\Lib\\site-packages\\keras\\src\\losses.py:2976: The name tf.losses.sparse_softmax_cross_entropy is deprecated. Please use tf.compat.v1.losses.sparse_softmax_cross_entropy instead.\n",
      "\n",
      "2024-03-04 16:45:31.621251: I tensorflow/core/util/port.cc:113] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
      "WARNING:tensorflow:From C:\\Users\\mit017\\anaconda3\\Lib\\site-packages\\keras\\src\\losses.py:2976: The name tf.losses.sparse_softmax_cross_entropy is deprecated. Please use tf.compat.v1.losses.sparse_softmax_cross_entropy instead.\n",
      "\n",
      "\n",
      "  0%|          | 0/54 [00:00<?, ?it/s]\n",
      "   828/834        0G      4.11      0.12         0      4.23         9       608:   0%|          | 0/54 [00:06<?, ?it/s]\n",
      "   828/834        0G      4.11      0.12         0      4.23         9       608:   2%|1         | 1/54 [00:06<06:05,  6.89s/it]\n",
      "   828/834        0G      4.32    0.0971         0      4.41         9       608:   2%|1         | 1/54 [00:14<06:05,  6.89s/it]\n",
      "   828/834        0G      4.32    0.0971         0      4.41         9       608:   4%|3         | 2/54 [00:14<06:07,  7.07s/it]\n",
      "   828/834        0G      4.16     0.107         0      4.27        12       608:   4%|3         | 2/54 [00:20<06:07,  7.07s/it]\n",
      "   828/834        0G      4.16     0.107         0      4.27        12       608:   6%|5         | 3/54 [00:20<05:55,  6.96s/it]\n",
      "   828/834        0G       4.2     0.103         0       4.3         9       608:   6%|5         | 3/54 [00:27<05:55,  6.96s/it]\n",
      "   828/834        0G       4.2     0.103         0       4.3         9       608:   7%|7         | 4/54 [00:27<05:35,  6.72s/it]\n",
      "   828/834        0G      4.18     0.102         0      4.28         9       608:   7%|7         | 4/54 [00:33<05:35,  6.72s/it]\n",
      "   828/834        0G      4.18     0.102         0      4.28         9       608:   9%|9         | 5/54 [00:33<05:14,  6.41s/it]\n",
      "   828/834        0G      4.24    0.0996         0      4.34        10       608:   9%|9         | 5/54 [00:38<05:14,  6.41s/it]\n",
      "   828/834        0G      4.24    0.0996         0      4.34        10       608:  11%|#1        | 6/54 [00:38<04:58,  6.22s/it]\n",
      "   828/834        0G      4.17    0.0977         0      4.27        10       608:  11%|#1        | 6/54 [00:44<04:58,  6.22s/it]\n",
      "   828/834        0G      4.17    0.0977         0      4.27        10       608:  13%|#2        | 7/54 [00:44<04:48,  6.14s/it]\n",
      "   828/834        0G      4.16    0.0964         0      4.25         9       608:  13%|#2        | 7/54 [00:51<04:48,  6.14s/it]\n",
      "   828/834        0G      4.16    0.0964         0      4.25         9       608:  15%|#4        | 8/54 [00:51<04:41,  6.12s/it]\n",
      "   828/834        0G      4.12    0.0982         0      4.22        10       608:  15%|#4        | 8/54 [00:57<04:41,  6.12s/it]\n",
      "   828/834        0G      4.12    0.0982         0      4.22        10       608:  17%|#6        | 9/54 [00:57<04:33,  6.08s/it]\n",
      "   828/834        0G      3.83    0.0957         0      3.93         8       608:  17%|#6        | 9/54 [01:03<04:33,  6.08s/it]\n",
      "   828/834        0G      3.83    0.0957         0      3.93         8       608:  19%|#8        | 10/54 [01:03<04:26,  6.07s/it]\n",
      "   828/834        0G      3.79    0.0997         0      3.89        12       608:  19%|#8        | 10/54 [01:09<04:26,  6.07s/it]\n",
      "   828/834        0G      3.79    0.0997         0      3.89        12       608:  20%|##        | 11/54 [01:09<04:24,  6.15s/it]\n",
      "   828/834        0G      3.59    0.0994         0      3.68        11       608:  20%|##        | 11/54 [01:16<04:24,  6.15s/it]\n",
      "   828/834        0G      3.59    0.0994         0      3.68        11       608:  22%|##2       | 12/54 [01:16<04:25,  6.31s/it]\n",
      "   828/834        0G      3.62    0.0979         0      3.72        10       608:  22%|##2       | 12/54 [01:22<04:25,  6.31s/it]\n",
      "   828/834        0G      3.62    0.0979         0      3.72        10       608:  24%|##4       | 13/54 [01:22<04:21,  6.37s/it]\n",
      "   828/834        0G      3.65    0.0971         0      3.75         9       608:  24%|##4       | 13/54 [01:29<04:21,  6.37s/it]\n",
      "   828/834        0G      3.65    0.0971         0      3.75         9       608:  26%|##5       | 14/54 [01:29<04:17,  6.43s/it]\n",
      "   828/834        0G       3.7    0.0956         0       3.8         9       608:  26%|##5       | 14/54 [01:36<04:17,  6.43s/it]\n",
      "   828/834        0G       3.7    0.0956         0       3.8         9       608:  28%|##7       | 15/54 [01:36<04:20,  6.68s/it]\n",
      "   828/834        0G       3.7    0.0969         0      3.79        11       608:  28%|##7       | 15/54 [01:42<04:20,  6.68s/it]\n",
      "   828/834        0G       3.7    0.0969         0      3.79        11       608:  30%|##9       | 16/54 [01:42<04:09,  6.56s/it]\n",
      "   828/834        0G      3.74    0.0965         0      3.83        10       608:  30%|##9       | 16/54 [01:49<04:09,  6.56s/it]\n",
      "   828/834        0G      3.74    0.0965         0      3.83        10       608:  31%|###1      | 17/54 [01:49<04:03,  6.58s/it]\n",
      "   828/834        0G      3.77    0.0956         0      3.87         9       608:  31%|###1      | 17/54 [01:55<04:03,  6.58s/it]\n",
      "   828/834        0G      3.77    0.0956         0      3.87         9       608:  33%|###3      | 18/54 [01:55<03:56,  6.58s/it]\n",
      "   828/834        0G      3.62    0.0951         0      3.72         8       448:  33%|###3      | 18/54 [01:59<03:56,  6.58s/it]\n",
      "   828/834        0G      3.62    0.0951         0      3.72         8       448:  35%|###5      | 19/54 [01:59<03:22,  5.79s/it]\n",
      "   828/834        0G      3.51    0.0958         0       3.6        12       448:  35%|###5      | 19/54 [02:03<03:22,  5.79s/it]\n",
      "   828/834        0G      3.51    0.0958         0       3.6        12       448:  37%|###7      | 20/54 [02:03<02:54,  5.12s/it]\n",
      "   828/834        0G       3.4     0.095         0      3.49         8       448:  37%|###7      | 20/54 [02:06<02:54,  5.12s/it]\n",
      "   828/834        0G       3.4     0.095         0      3.49         8       448:  39%|###8      | 21/54 [02:06<02:32,  4.63s/it]\n",
      "   828/834        0G      3.29    0.0956         0      3.39         9       448:  39%|###8      | 21/54 [02:10<02:32,  4.63s/it]\n",
      "   828/834        0G      3.29    0.0956         0      3.39         9       448:  41%|####      | 22/54 [02:10<02:14,  4.22s/it]\n",
      "   828/834        0G      3.19    0.0964         0      3.29         9       448:  41%|####      | 22/54 [02:13<02:14,  4.22s/it]\n",
      "   828/834        0G      3.19    0.0964         0      3.29         9       448:  43%|####2     | 23/54 [02:13<02:01,  3.92s/it]\n",
      "   828/834        0G      3.11    0.0971         0      3.21         9       448:  43%|####2     | 23/54 [02:16<02:01,  3.92s/it]\n",
      "   828/834        0G      3.11    0.0971         0      3.21         9       448:  44%|####4     | 24/54 [02:16<01:50,  3.70s/it]\n",
      "   828/834        0G      3.03     0.097         0      3.13         9       448:  44%|####4     | 24/54 [02:19<01:50,  3.70s/it]\n",
      "   828/834        0G      3.03     0.097         0      3.13         9       448:  46%|####6     | 25/54 [02:19<01:43,  3.56s/it]\n",
      "   828/834        0G      2.95    0.0987         0      3.05        11       448:  46%|####6     | 25/54 [02:23<01:43,  3.56s/it]\n",
      "   828/834        0G      2.95    0.0987         0      3.05        11       448:  48%|####8     | 26/54 [02:23<01:36,  3.46s/it]\n",
      "   828/834        0G      2.88     0.101         0      2.99        14       448:  48%|####8     | 26/54 [02:26<01:36,  3.46s/it]\n",
      "   828/834        0G      2.88     0.101         0      2.99        14       448:  50%|#####     | 27/54 [02:26<01:31,  3.38s/it]\n",
      "   828/834        0G      2.83     0.101         0      2.93         9       448:  50%|#####     | 27/54 [02:29<01:31,  3.38s/it]\n",
      "   828/834        0G      2.83     0.101         0      2.93         9       448:  52%|#####1    | 28/54 [02:29<01:27,  3.36s/it]\n",
      "   828/834        0G      2.77     0.101         0      2.88        11       448:  52%|#####1    | 28/54 [02:32<01:27,  3.36s/it]\n",
      "   828/834        0G      2.77     0.101         0      2.88        11       448:  54%|#####3    | 29/54 [02:32<01:22,  3.30s/it]\n",
      "   828/834        0G      2.72     0.101         0      2.82        10       448:  54%|#####3    | 29/54 [02:35<01:22,  3.30s/it]\n",
      "   828/834        0G      2.72     0.101         0      2.82        10       448:  56%|#####5    | 30/54 [02:35<01:19,  3.30s/it]\n",
      "   828/834        0G      2.67     0.103         0      2.77        14       448:  56%|#####5    | 30/54 [02:39<01:19,  3.30s/it]\n",
      "   828/834        0G      2.67     0.103         0      2.77        14       448:  57%|#####7    | 31/54 [02:39<01:15,  3.30s/it]\n",
      "   828/834        0G      2.63     0.102         0      2.73         9       448:  57%|#####7    | 31/54 [02:42<01:15,  3.30s/it]\n",
      "   828/834        0G      2.63     0.102         0      2.73         9       448:  59%|#####9    | 32/54 [02:42<01:13,  3.33s/it]\n",
      "   828/834        0G      2.59     0.101         0      2.69         9       448:  59%|#####9    | 32/54 [02:46<01:13,  3.33s/it]\n",
      "   828/834        0G      2.59     0.101         0      2.69         9       448:  61%|######1   | 33/54 [02:46<01:12,  3.47s/it]\n",
      "   828/834        0G      2.55     0.101         0      2.65        10       448:  61%|######1   | 33/54 [02:49<01:12,  3.47s/it]\n",
      "   828/834        0G      2.55     0.101         0      2.65        10       448:  63%|######2   | 34/54 [02:49<01:09,  3.46s/it]\n",
      "   828/834        0G      2.51     0.101         0      2.62        10       448:  63%|######2   | 34/54 [02:53<01:09,  3.46s/it]\n",
      "   828/834        0G      2.51     0.101         0      2.62        10       448:  65%|######4   | 35/54 [02:53<01:06,  3.47s/it]\n",
      "   828/834        0G      2.48     0.101         0      2.58        10       448:  65%|######4   | 35/54 [02:57<01:06,  3.47s/it]\n",
      "   828/834        0G      2.48     0.101         0      2.58        10       448:  67%|######6   | 36/54 [02:57<01:03,  3.51s/it]\n",
      "   828/834        0G      2.44     0.101         0      2.54         9       448:  67%|######6   | 36/54 [03:00<01:03,  3.51s/it]\n",
      "   828/834        0G      2.44     0.101         0      2.54         9       448:  69%|######8   | 37/54 [03:00<01:00,  3.58s/it]\n",
      "   828/834        0G       2.4     0.101         0      2.51         8       448:  69%|######8   | 37/54 [03:04<01:00,  3.58s/it]\n",
      "   828/834        0G       2.4     0.101         0      2.51         8       448:  70%|#######   | 38/54 [03:04<00:56,  3.52s/it]\n",
      "   828/834        0G      2.37     0.102         0      2.47        11       448:  70%|#######   | 38/54 [03:07<00:56,  3.52s/it]\n",
      "   828/834        0G      2.37     0.102         0      2.47        11       448:  72%|#######2  | 39/54 [03:07<00:52,  3.51s/it]\n",
      "   828/834        0G      2.41     0.102         0      2.51        12       576:  72%|#######2  | 39/54 [03:13<00:52,  3.51s/it]\n",
      "   828/834        0G      2.41     0.102         0      2.51        12       576:  74%|#######4  | 40/54 [03:13<00:58,  4.16s/it]\n",
      "   828/834        0G      2.44     0.103         0      2.54        12       576:  74%|#######4  | 40/54 [03:19<00:58,  4.16s/it]\n",
      "   828/834        0G      2.44     0.103         0      2.54        12       576:  76%|#######5  | 41/54 [03:19<01:00,  4.64s/it]\n",
      "   828/834        0G      2.41     0.102         0      2.51         9       576:  76%|#######5  | 41/54 [03:24<01:00,  4.64s/it]\n",
      "   828/834        0G      2.41     0.102         0      2.51         9       576:  78%|#######7  | 42/54 [03:24<00:59,  5.00s/it]\n",
      "   828/834        0G      2.44     0.102         0      2.54        10       576:  78%|#######7  | 42/54 [03:30<00:59,  5.00s/it]\n",
      "   828/834        0G      2.44     0.102         0      2.54        10       576:  80%|#######9  | 43/54 [03:30<00:57,  5.21s/it]\n",
      "   828/834        0G      2.47     0.103         0      2.57        10       576:  80%|#######9  | 43/54 [03:36<00:57,  5.21s/it]\n",
      "   828/834        0G      2.47     0.103         0      2.57        10       576:  81%|########1 | 44/54 [03:36<00:53,  5.34s/it]\n",
      "   828/834        0G      2.43     0.102         0      2.53         9       576:  81%|########1 | 44/54 [03:42<00:53,  5.34s/it]\n",
      "   828/834        0G      2.43     0.102         0      2.53         9       576:  83%|########3 | 45/54 [03:42<00:50,  5.64s/it]\n",
      "   828/834        0G      2.46     0.102         0      2.56         9       576:  83%|########3 | 45/54 [03:47<00:50,  5.64s/it]\n",
      "   828/834        0G      2.46     0.102         0      2.56         9       576:  85%|########5 | 46/54 [03:47<00:44,  5.57s/it]\n",
      "   828/834        0G      2.49     0.101         0      2.59         9       576:  85%|########5 | 46/54 [03:53<00:44,  5.57s/it]\n",
      "   828/834        0G      2.49     0.101         0      2.59         9       576:  87%|########7 | 47/54 [03:53<00:39,  5.60s/it]\n",
      "   828/834        0G      2.46     0.101         0      2.56         9       576:  87%|########7 | 47/54 [03:59<00:39,  5.60s/it]\n",
      "   828/834        0G      2.46     0.101         0      2.56         9       576:  89%|########8 | 48/54 [03:59<00:33,  5.65s/it]\n",
      "   828/834        0G      2.48     0.102         0      2.58        11       576:  89%|########8 | 48/54 [04:05<00:33,  5.65s/it]\n",
      "   828/834        0G      2.48     0.102         0      2.58        11       576:  91%|######### | 49/54 [04:05<00:28,  5.66s/it]\n",
      "   828/834        0G      2.46     0.101         0      2.56         9       576:  91%|######### | 49/54 [04:10<00:28,  5.66s/it]\n",
      "   828/834        0G      2.46     0.101         0      2.56         9       576:  93%|#########2| 50/54 [04:10<00:21,  5.50s/it]\n",
      "   828/834        0G      2.49     0.101         0      2.59        12       576:  93%|#########2| 50/54 [04:15<00:21,  5.50s/it]\n",
      "   828/834        0G      2.49     0.101         0      2.59        12       576:  94%|#########4| 51/54 [04:15<00:16,  5.52s/it]\n",
      "   828/834        0G      2.46     0.101         0      2.56        11       576:  94%|#########4| 51/54 [04:21<00:16,  5.52s/it]\n",
      "   828/834        0G      2.46     0.101         0      2.56        11       576:  96%|#########6| 52/54 [04:21<00:11,  5.55s/it]\n",
      "   828/834        0G      2.47     0.102         0      2.57         9       576:  96%|#########6| 52/54 [04:27<00:11,  5.55s/it]\n",
      "   828/834        0G      2.47     0.102         0      2.57         9       576:  98%|#########8| 53/54 [04:27<00:05,  5.65s/it]\n",
      "   828/834        0G      2.48     0.103         0      2.59         3       576:  98%|#########8| 53/54 [04:29<00:05,  5.65s/it]\n",
      "   828/834        0G      2.48     0.103         0      2.59         3       576: 100%|##########| 54/54 [04:29<00:00,  4.57s/it]\n",
      "   828/834        0G      2.48     0.103         0      2.59         3       576: 100%|##########| 54/54 [04:30<00:00,  5.01s/it]\n",
      "\n",
      "               Class    Images   Targets         P         R   mAP@0.5        F1:   0%|          | 0/14 [00:00<?, ?it/s]2024-03-04 16:50:14.035099: I tensorflow/core/util/port.cc:113] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
      "WARNING:tensorflow:From C:\\Users\\mit017\\anaconda3\\Lib\\site-packages\\keras\\src\\losses.py:2976: The name tf.losses.sparse_softmax_cross_entropy is deprecated. Please use tf.compat.v1.losses.sparse_softmax_cross_entropy instead.\n",
      "\n",
      "2024-03-04 16:50:24.865554: I tensorflow/core/util/port.cc:113] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
      "WARNING:tensorflow:From C:\\Users\\mit017\\anaconda3\\Lib\\site-packages\\keras\\src\\losses.py:2976: The name tf.losses.sparse_softmax_cross_entropy is deprecated. Please use tf.compat.v1.losses.sparse_softmax_cross_entropy instead.\n",
      "\n",
      "2024-03-04 16:50:36.037001: I tensorflow/core/util/port.cc:113] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
      "WARNING:tensorflow:From C:\\Users\\mit017\\anaconda3\\Lib\\site-packages\\keras\\src\\losses.py:2976: The name tf.losses.sparse_softmax_cross_entropy is deprecated. Please use tf.compat.v1.losses.sparse_softmax_cross_entropy instead.\n",
      "\n",
      "\n",
      "               Class    Images   Targets         P         R   mAP@0.5        F1:   7%|7         | 1/14 [00:35<07:39, 35.36s/it]\n",
      "               Class    Images   Targets         P         R   mAP@0.5        F1:  14%|#4        | 2/14 [00:37<03:09, 15.82s/it]\n",
      "               Class    Images   Targets         P         R   mAP@0.5        F1:  21%|##1       | 3/14 [00:39<01:44,  9.54s/it]\n",
      "               Class    Images   Targets         P         R   mAP@0.5        F1:  29%|##8       | 4/14 [00:41<01:06,  6.67s/it]\n",
      "               Class    Images   Targets         P         R   mAP@0.5        F1:  36%|###5      | 5/14 [00:43<00:45,  5.01s/it]\n",
      "               Class    Images   Targets         P         R   mAP@0.5        F1:  43%|####2     | 6/14 [00:45<00:32,  4.00s/it]\n",
      "               Class    Images   Targets         P         R   mAP@0.5        F1:  50%|#####     | 7/14 [00:48<00:23,  3.40s/it]\n",
      "               Class    Images   Targets         P         R   mAP@0.5        F1:  57%|#####7    | 8/14 [00:50<00:18,  3.02s/it]\n",
      "               Class    Images   Targets         P         R   mAP@0.5        F1:  64%|######4   | 9/14 [00:52<00:13,  2.73s/it]\n",
      "               Class    Images   Targets         P         R   mAP@0.5        F1:  71%|#######1  | 10/14 [00:54<00:10,  2.54s/it]\n",
      "               Class    Images   Targets         P         R   mAP@0.5        F1:  79%|#######8  | 11/14 [00:56<00:07,  2.40s/it]\n",
      "               Class    Images   Targets         P         R   mAP@0.5        F1:  86%|########5 | 12/14 [00:58<00:04,  2.29s/it]\n",
      "               Class    Images   Targets         P         R   mAP@0.5        F1:  93%|#########2| 13/14 [01:00<00:02,  2.23s/it]\n",
      "               Class    Images   Targets         P         R   mAP@0.5        F1: 100%|##########| 14/14 [01:01<00:00,  1.79s/it]\n",
      "               Class    Images   Targets         P         R   mAP@0.5        F1: 100%|##########| 14/14 [01:02<00:00,  4.48s/it]\n",
      "2024-03-04 16:51:16.538443: I tensorflow/core/util/port.cc:113] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
      "WARNING:tensorflow:From C:\\Users\\mit017\\anaconda3\\Lib\\site-packages\\keras\\src\\losses.py:2976: The name tf.losses.sparse_softmax_cross_entropy is deprecated. Please use tf.compat.v1.losses.sparse_softmax_cross_entropy instead.\n",
      "\n",
      "2024-03-04 16:51:27.509229: I tensorflow/core/util/port.cc:113] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
      "WARNING:tensorflow:From C:\\Users\\mit017\\anaconda3\\Lib\\site-packages\\keras\\src\\losses.py:2976: The name tf.losses.sparse_softmax_cross_entropy is deprecated. Please use tf.compat.v1.losses.sparse_softmax_cross_entropy instead.\n",
      "\n",
      "2024-03-04 16:51:38.073138: I tensorflow/core/util/port.cc:113] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
      "WARNING:tensorflow:From C:\\Users\\mit017\\anaconda3\\Lib\\site-packages\\keras\\src\\losses.py:2976: The name tf.losses.sparse_softmax_cross_entropy is deprecated. Please use tf.compat.v1.losses.sparse_softmax_cross_entropy instead.\n",
      "\n",
      "\n",
      "  0%|          | 0/54 [00:00<?, ?it/s]\n",
      "   829/834        0G      1.16     0.107         0      1.27        13       576:   0%|          | 0/54 [00:05<?, ?it/s]\n",
      "   829/834        0G      1.16     0.107         0      1.27        13       576:   2%|1         | 1/54 [00:05<05:11,  5.87s/it]\n",
      "   829/834        0G      2.32     0.119         0      2.44        12       576:   2%|1         | 1/54 [00:12<05:11,  5.87s/it]\n",
      "   829/834        0G      2.32     0.119         0      2.44        12       576:   4%|3         | 2/54 [00:12<05:24,  6.24s/it]\n",
      "   829/834        0G      2.59     0.108         0       2.7         8       576:   4%|3         | 2/54 [00:18<05:24,  6.24s/it]\n",
      "   829/834        0G      2.59     0.108         0       2.7         8       576:   6%|5         | 3/54 [00:18<05:19,  6.26s/it]\n",
      "   829/834        0G       2.8     0.103         0      2.91         9       576:   6%|5         | 3/54 [00:24<05:19,  6.26s/it]\n",
      "   829/834        0G       2.8     0.103         0      2.91         9       576:   7%|7         | 4/54 [00:24<05:05,  6.10s/it]\n",
      "   829/834        0G      2.97     0.101         0      3.07        10       576:   7%|7         | 4/54 [00:30<05:05,  6.10s/it]\n",
      "   829/834        0G      2.97     0.101         0      3.07        10       576:   9%|9         | 5/54 [00:30<04:53,  5.99s/it]\n",
      "   829/834        0G      3.08     0.101         0      3.18         9       576:   9%|9         | 5/54 [00:36<04:53,  5.99s/it]\n",
      "   829/834        0G      3.08     0.101         0      3.18         9       576:  11%|#1        | 6/54 [00:36<04:49,  6.02s/it]\n",
      "   829/834        0G      3.11     0.101         0      3.21         9       608:  11%|#1        | 6/54 [00:44<04:49,  6.02s/it]\n",
      "   829/834        0G      3.11     0.101         0      3.21         9       608:  13%|#2        | 7/54 [00:44<05:13,  6.67s/it]\n",
      "   829/834        0G      3.12     0.108         0      3.23         9       608:  13%|#2        | 7/54 [00:50<05:13,  6.67s/it]\n",
      "   829/834        0G      3.12     0.108         0      3.23         9       608:  15%|#4        | 8/54 [00:50<05:04,  6.62s/it]\n",
      "   829/834        0G      3.14     0.106         0      3.24         9       608:  15%|#4        | 8/54 [00:57<05:04,  6.62s/it]\n",
      "   829/834        0G      3.14     0.106         0      3.24         9       608:  17%|#6        | 9/54 [00:57<04:52,  6.50s/it]\n",
      "   829/834        0G      3.18     0.107         0      3.28        12       608:  17%|#6        | 9/54 [01:03<04:52,  6.50s/it]\n",
      "   829/834        0G      3.18     0.107         0      3.28        12       608:  19%|#8        | 10/54 [01:03<04:45,  6.49s/it]\n",
      "   829/834        0G      3.22     0.106         0      3.32        10       608:  19%|#8        | 10/54 [01:09<04:45,  6.49s/it]\n",
      "   829/834        0G      3.22     0.106         0      3.32        10       608:  20%|##        | 11/54 [01:09<04:35,  6.40s/it]\n",
      "   829/834        0G      3.25     0.108         0      3.36         9       608:  20%|##        | 11/54 [01:16<04:35,  6.40s/it]\n",
      "   829/834        0G      3.25     0.108         0      3.36         9       608:  22%|##2       | 12/54 [01:16<04:26,  6.35s/it]\n",
      "   829/834        0G      3.24     0.107         0      3.35        10       608:  22%|##2       | 12/54 [01:22<04:26,  6.35s/it]\n",
      "   829/834        0G      3.24     0.107         0      3.35        10       608:  24%|##4       | 13/54 [01:22<04:18,  6.30s/it]\n",
      "   829/834        0G       3.2     0.107         0      3.31        10       608:  24%|##4       | 13/54 [01:28<04:18,  6.30s/it]\n",
      "   829/834        0G       3.2     0.107         0      3.31        10       608:  26%|##5       | 14/54 [01:28<04:08,  6.21s/it]\n",
      "   829/834        0G      3.19     0.109         0       3.3         9       608:  26%|##5       | 14/54 [01:34<04:08,  6.21s/it]\n",
      "   829/834        0G      3.19     0.109         0       3.3         9       608:  28%|##7       | 15/54 [01:34<04:02,  6.21s/it]\n",
      "   829/834        0G      3.21     0.109         0      3.32         9       608:  28%|##7       | 15/54 [01:40<04:02,  6.21s/it]\n",
      "   829/834        0G      3.21     0.109         0      3.32         9       608:  30%|##9       | 16/54 [01:40<03:59,  6.31s/it]\n",
      "   829/834        0G       3.2     0.111         0      3.31        12       608:  30%|##9       | 16/54 [01:47<03:59,  6.31s/it]\n",
      "   829/834        0G       3.2     0.111         0      3.31        12       608:  31%|###1      | 17/54 [01:47<03:54,  6.34s/it]\n",
      "   829/834        0G      3.09     0.109         0       3.2         9       608:  31%|###1      | 17/54 [01:53<03:54,  6.34s/it]\n",
      "   829/834        0G      3.09     0.109         0       3.2         9       608:  33%|###3      | 18/54 [01:53<03:48,  6.35s/it]\n",
      "   829/834        0G      3.11     0.109         0      3.22         9       608:  33%|###3      | 18/54 [02:00<03:48,  6.35s/it]\n",
      "   829/834        0G      3.11     0.109         0      3.22         9       608:  35%|###5      | 19/54 [02:00<03:47,  6.51s/it]\n",
      "   829/834        0G      3.02     0.108         0      3.13        11       608:  35%|###5      | 19/54 [02:07<03:47,  6.51s/it]\n",
      "   829/834        0G      3.02     0.108         0      3.13        11       608:  37%|###7      | 20/54 [02:07<03:46,  6.67s/it]\n",
      "   829/834        0G      3.05     0.107         0      3.16        10       608:  37%|###7      | 20/54 [02:14<03:46,  6.67s/it]\n",
      "   829/834        0G      3.05     0.107         0      3.16        10       608:  39%|###8      | 21/54 [02:14<03:41,  6.71s/it]\n",
      "   829/834        0G      3.05     0.106         0      3.16         9       608:  39%|###8      | 21/54 [02:20<03:41,  6.71s/it]\n",
      "   829/834        0G      3.05     0.106         0      3.16         9       608:  41%|####      | 22/54 [02:20<03:28,  6.51s/it]\n",
      "   829/834        0G      3.05     0.106         0      3.16         9       608:  41%|####      | 22/54 [02:26<03:28,  6.51s/it]\n",
      "   829/834        0G      3.05     0.106         0      3.16         9       608:  43%|####2     | 23/54 [02:26<03:17,  6.38s/it]\n",
      "   829/834        0G      3.07     0.106         0      3.18         9       608:  43%|####2     | 23/54 [02:33<03:17,  6.38s/it]\n",
      "   829/834        0G      3.07     0.106         0      3.18         9       608:  44%|####4     | 24/54 [02:33<03:11,  6.38s/it]\n",
      "   829/834        0G      3.08     0.106         0      3.18        10       608:  44%|####4     | 24/54 [02:39<03:11,  6.38s/it]\n",
      "   829/834        0G      3.08     0.106         0      3.18        10       608:  46%|####6     | 25/54 [02:39<03:09,  6.52s/it]\n",
      "   829/834        0G      3.09     0.105         0       3.2         9       608:  46%|####6     | 25/54 [02:46<03:09,  6.52s/it]\n",
      "   829/834        0G      3.09     0.105         0       3.2         9       608:  48%|####8     | 26/54 [02:46<03:04,  6.60s/it]\n",
      "   829/834        0G      3.11     0.104         0      3.21         9       608:  48%|####8     | 26/54 [02:55<03:04,  6.60s/it]\n",
      "   829/834        0G      3.11     0.104         0      3.21         9       608:  50%|#####     | 27/54 [02:55<03:15,  7.24s/it]\n",
      "   829/834        0G      3.04     0.105         0      3.14        11       384:  50%|#####     | 27/54 [02:58<03:15,  7.24s/it]\n",
      "   829/834        0G      3.04     0.105         0      3.14        11       384:  52%|#####1    | 28/54 [02:58<02:34,  5.93s/it]\n",
      "   829/834        0G      2.97     0.107         0      3.07        11       384:  52%|#####1    | 28/54 [03:00<02:34,  5.93s/it]\n",
      "   829/834        0G      2.97     0.107         0      3.07        11       384:  54%|#####3    | 29/54 [03:00<02:03,  4.94s/it]\n",
      "   829/834        0G      2.91     0.108         0      3.02         9       384:  54%|#####3    | 29/54 [03:04<02:03,  4.94s/it]\n",
      "   829/834        0G      2.91     0.108         0      3.02         9       384:  56%|#####5    | 30/54 [03:04<01:49,  4.55s/it]\n",
      "   829/834        0G      2.85     0.108         0      2.95        10       384:  56%|#####5    | 30/54 [03:07<01:49,  4.55s/it]\n",
      "   829/834        0G      2.85     0.108         0      2.95        10       384:  57%|#####7    | 31/54 [03:07<01:32,  4.00s/it]\n",
      "   829/834        0G      2.79     0.108         0       2.9        10       384:  57%|#####7    | 31/54 [03:09<01:32,  4.00s/it]\n",
      "   829/834        0G      2.79     0.108         0       2.9        10       384:  59%|#####9    | 32/54 [03:09<01:18,  3.58s/it]\n",
      "   829/834        0G      2.74     0.109         0      2.85        12       384:  59%|#####9    | 32/54 [03:12<01:18,  3.58s/it]\n",
      "   829/834        0G      2.74     0.109         0      2.85        12       384:  61%|######1   | 33/54 [03:12<01:08,  3.24s/it]\n",
      "   829/834        0G       2.7     0.108         0       2.8         9       384:  61%|######1   | 33/54 [03:14<01:08,  3.24s/it]\n",
      "   829/834        0G       2.7     0.108         0       2.8         9       384:  63%|######2   | 34/54 [03:14<01:00,  3.01s/it]\n",
      "   829/834        0G      2.66     0.108         0      2.77         9       384:  63%|######2   | 34/54 [03:17<01:00,  3.01s/it]\n",
      "   829/834        0G      2.66     0.108         0      2.77         9       384:  65%|######4   | 35/54 [03:17<00:54,  2.84s/it]\n",
      "   829/834        0G      2.62     0.108         0      2.72         9       384:  65%|######4   | 35/54 [03:19<00:54,  2.84s/it]\n",
      "   829/834        0G      2.62     0.108         0      2.72         9       384:  67%|######6   | 36/54 [03:19<00:49,  2.73s/it]\n",
      "   829/834        0G      2.58     0.108         0      2.68        11       384:  67%|######6   | 36/54 [03:22<00:49,  2.73s/it]\n",
      "   829/834        0G      2.58     0.108         0      2.68        11       384:  69%|######8   | 37/54 [03:22<00:44,  2.63s/it]\n",
      "   829/834        0G      2.54     0.107         0      2.65         9       384:  69%|######8   | 37/54 [03:24<00:44,  2.63s/it]\n",
      "   829/834        0G      2.54     0.107         0      2.65         9       384:  70%|#######   | 38/54 [03:24<00:41,  2.58s/it]\n",
      "   829/834        0G      2.51     0.106         0      2.62        10       384:  70%|#######   | 38/54 [03:27<00:41,  2.58s/it]\n",
      "   829/834        0G      2.51     0.106         0      2.62        10       384:  72%|#######2  | 39/54 [03:27<00:38,  2.57s/it]\n",
      "   829/834        0G      2.47     0.106         0      2.58        10       384:  72%|#######2  | 39/54 [03:29<00:38,  2.57s/it]\n",
      "   829/834        0G      2.47     0.106         0      2.58        10       384:  74%|#######4  | 40/54 [03:29<00:35,  2.56s/it]\n",
      "   829/834        0G      2.44     0.107         0      2.55         9       384:  74%|#######4  | 40/54 [03:32<00:35,  2.56s/it]\n",
      "   829/834        0G      2.44     0.107         0      2.55         9       384:  76%|#######5  | 41/54 [03:32<00:33,  2.54s/it]\n",
      "   829/834        0G      2.42     0.107         0      2.52        10       384:  76%|#######5  | 41/54 [03:34<00:33,  2.54s/it]\n",
      "   829/834        0G      2.42     0.107         0      2.52        10       384:  78%|#######7  | 42/54 [03:34<00:31,  2.58s/it]\n",
      "   829/834        0G      2.38     0.107         0      2.49        10       384:  78%|#######7  | 42/54 [03:37<00:31,  2.58s/it]\n",
      "   829/834        0G      2.38     0.107         0      2.49        10       384:  80%|#######9  | 43/54 [03:37<00:28,  2.60s/it]\n",
      "   829/834        0G      2.35     0.107         0      2.46         9       384:  80%|#######9  | 43/54 [03:40<00:28,  2.60s/it]\n",
      "   829/834        0G      2.35     0.107         0      2.46         9       384:  81%|########1 | 44/54 [03:40<00:27,  2.71s/it]\n",
      "   829/834        0G      2.32     0.106         0      2.43         8       384:  81%|########1 | 44/54 [03:43<00:27,  2.71s/it]\n",
      "   829/834        0G      2.32     0.106         0      2.43         8       384:  83%|########3 | 45/54 [03:43<00:24,  2.71s/it]\n",
      "   829/834        0G      2.29     0.106         0       2.4         9       384:  83%|########3 | 45/54 [03:45<00:24,  2.71s/it]\n",
      "   829/834        0G      2.29     0.106         0       2.4         9       384:  85%|########5 | 46/54 [03:45<00:21,  2.65s/it]\n",
      "   829/834        0G      2.27     0.107         0      2.38        12       384:  85%|########5 | 46/54 [03:48<00:21,  2.65s/it]\n",
      "   829/834        0G      2.27     0.107         0      2.38        12       384:  87%|########7 | 47/54 [03:48<00:18,  2.68s/it]\n",
      "   829/834        0G      2.25     0.108         0      2.36        11       384:  87%|########7 | 47/54 [03:51<00:18,  2.68s/it]\n",
      "   829/834        0G      2.25     0.108         0      2.36        11       384:  89%|########8 | 48/54 [03:51<00:16,  2.67s/it]\n",
      "   829/834        0G      2.23     0.108         0      2.34         9       448:  89%|########8 | 48/54 [03:54<00:16,  2.67s/it]\n",
      "   829/834        0G      2.23     0.108         0      2.34         9       448:  91%|######### | 49/54 [03:54<00:14,  2.98s/it]\n",
      "   829/834        0G      2.21     0.108         0      2.32         9       448:  91%|######### | 49/54 [03:58<00:14,  2.98s/it]\n",
      "   829/834        0G      2.21     0.108         0      2.32         9       448:  93%|#########2| 50/54 [03:58<00:12,  3.08s/it]\n",
      "   829/834        0G      2.19     0.107         0       2.3         8       448:  93%|#########2| 50/54 [04:01<00:12,  3.08s/it]\n",
      "   829/834        0G      2.19     0.107         0       2.3         8       448:  94%|#########4| 51/54 [04:01<00:09,  3.21s/it]\n",
      "   829/834        0G      2.17     0.107         0      2.28         9       448:  94%|#########4| 51/54 [04:05<00:09,  3.21s/it]\n",
      "   829/834        0G      2.17     0.107         0      2.28         9       448:  96%|#########6| 52/54 [04:05<00:06,  3.30s/it]\n",
      "   829/834        0G      2.15     0.107         0      2.26         9       448:  96%|#########6| 52/54 [04:08<00:06,  3.30s/it]\n",
      "   829/834        0G      2.15     0.107         0      2.26         9       448:  98%|#########8| 53/54 [04:08<00:03,  3.37s/it]\n",
      "   829/834        0G      2.13     0.107         0      2.23         3       448:  98%|#########8| 53/54 [04:09<00:03,  3.37s/it]\n",
      "   829/834        0G      2.13     0.107         0      2.23         3       448: 100%|##########| 54/54 [04:09<00:00,  2.73s/it]\n",
      "   829/834        0G      2.13     0.107         0      2.23         3       448: 100%|##########| 54/54 [04:10<00:00,  4.65s/it]\n",
      "\n",
      "               Class    Images   Targets         P         R   mAP@0.5        F1:   0%|          | 0/14 [00:00<?, ?it/s]2024-03-04 16:56:00.569731: I tensorflow/core/util/port.cc:113] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
      "WARNING:tensorflow:From C:\\Users\\mit017\\anaconda3\\Lib\\site-packages\\keras\\src\\losses.py:2976: The name tf.losses.sparse_softmax_cross_entropy is deprecated. Please use tf.compat.v1.losses.sparse_softmax_cross_entropy instead.\n",
      "\n",
      "2024-03-04 16:56:13.805531: I tensorflow/core/util/port.cc:113] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
      "WARNING:tensorflow:From C:\\Users\\mit017\\anaconda3\\Lib\\site-packages\\keras\\src\\losses.py:2976: The name tf.losses.sparse_softmax_cross_entropy is deprecated. Please use tf.compat.v1.losses.sparse_softmax_cross_entropy instead.\n",
      "\n",
      "2024-03-04 16:56:24.561283: I tensorflow/core/util/port.cc:113] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
      "WARNING:tensorflow:From C:\\Users\\mit017\\anaconda3\\Lib\\site-packages\\keras\\src\\losses.py:2976: The name tf.losses.sparse_softmax_cross_entropy is deprecated. Please use tf.compat.v1.losses.sparse_softmax_cross_entropy instead.\n",
      "\n",
      "\n",
      "               Class    Images   Targets         P         R   mAP@0.5        F1:   7%|7         | 1/14 [00:37<08:06, 37.39s/it]\n",
      "               Class    Images   Targets         P         R   mAP@0.5        F1:  14%|#4        | 2/14 [00:39<03:19, 16.63s/it]\n",
      "               Class    Images   Targets         P         R   mAP@0.5        F1:  21%|##1       | 3/14 [00:41<01:50, 10.01s/it]\n",
      "               Class    Images   Targets         P         R   mAP@0.5        F1:  29%|##8       | 4/14 [00:43<01:08,  6.89s/it]\n",
      "               Class    Images   Targets         P         R   mAP@0.5        F1:  36%|###5      | 5/14 [00:46<00:47,  5.23s/it]\n",
      "               Class    Images   Targets         P         R   mAP@0.5        F1:  43%|####2     | 6/14 [00:48<00:33,  4.20s/it]\n",
      "               Class    Images   Targets         P         R   mAP@0.5        F1:  50%|#####     | 7/14 [00:50<00:24,  3.55s/it]\n",
      "               Class    Images   Targets         P         R   mAP@0.5        F1:  57%|#####7    | 8/14 [00:52<00:18,  3.09s/it]\n",
      "               Class    Images   Targets         P         R   mAP@0.5        F1:  64%|######4   | 9/14 [00:54<00:13,  2.75s/it]\n",
      "               Class    Images   Targets         P         R   mAP@0.5        F1:  71%|#######1  | 10/14 [00:56<00:10,  2.53s/it]\n",
      "               Class    Images   Targets         P         R   mAP@0.5        F1:  79%|#######8  | 11/14 [00:58<00:07,  2.39s/it]\n",
      "               Class    Images   Targets         P         R   mAP@0.5        F1:  86%|########5 | 12/14 [01:00<00:04,  2.29s/it]\n",
      "               Class    Images   Targets         P         R   mAP@0.5        F1:  93%|#########2| 13/14 [01:02<00:02,  2.21s/it]\n",
      "               Class    Images   Targets         P         R   mAP@0.5        F1: 100%|##########| 14/14 [01:03<00:00,  1.76s/it]\n",
      "               Class    Images   Targets         P         R   mAP@0.5        F1: 100%|##########| 14/14 [01:04<00:00,  4.60s/it]\n",
      "2024-03-04 16:57:04.400377: I tensorflow/core/util/port.cc:113] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
      "WARNING:tensorflow:From C:\\Users\\mit017\\anaconda3\\Lib\\site-packages\\keras\\src\\losses.py:2976: The name tf.losses.sparse_softmax_cross_entropy is deprecated. Please use tf.compat.v1.losses.sparse_softmax_cross_entropy instead.\n",
      "\n",
      "2024-03-04 16:57:14.740335: I tensorflow/core/util/port.cc:113] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
      "WARNING:tensorflow:From C:\\Users\\mit017\\anaconda3\\Lib\\site-packages\\keras\\src\\losses.py:2976: The name tf.losses.sparse_softmax_cross_entropy is deprecated. Please use tf.compat.v1.losses.sparse_softmax_cross_entropy instead.\n",
      "\n",
      "2024-03-04 16:57:25.186673: I tensorflow/core/util/port.cc:113] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
      "WARNING:tensorflow:From C:\\Users\\mit017\\anaconda3\\Lib\\site-packages\\keras\\src\\losses.py:2976: The name tf.losses.sparse_softmax_cross_entropy is deprecated. Please use tf.compat.v1.losses.sparse_softmax_cross_entropy instead.\n",
      "\n",
      "\n",
      "  0%|          | 0/54 [00:00<?, ?it/s]\n",
      "   830/834        0G      1.23     0.112         0      1.34         9       448:   0%|          | 0/54 [00:03<?, ?it/s]\n",
      "   830/834        0G      1.23     0.112         0      1.34         9       448:   2%|1         | 1/54 [00:03<03:25,  3.88s/it]\n",
      "   830/834        0G      1.19     0.113         0       1.3        11       448:   2%|1         | 1/54 [00:07<03:25,  3.88s/it]\n",
      "   830/834        0G      1.19     0.113         0       1.3        11       448:   4%|3         | 2/54 [00:07<03:02,  3.51s/it]\n",
      "   830/834        0G      1.13     0.112         0      1.25        10       448:   4%|3         | 2/54 [00:10<03:02,  3.51s/it]\n",
      "   830/834        0G      1.13     0.112         0      1.25        10       448:   6%|5         | 3/54 [00:10<02:55,  3.43s/it]\n",
      "   830/834        0G      1.07     0.122         0       1.2        11       448:   6%|5         | 3/54 [00:13<02:55,  3.43s/it]\n",
      "   830/834        0G      1.07     0.122         0       1.2        11       448:   7%|7         | 4/54 [00:13<02:49,  3.38s/it]\n",
      "   830/834        0G      1.06     0.121         0      1.18         9       448:   7%|7         | 4/54 [00:17<02:49,  3.38s/it]\n",
      "   830/834        0G      1.06     0.121         0      1.18         9       448:   9%|9         | 5/54 [00:17<02:44,  3.35s/it]\n",
      "   830/834        0G      1.09     0.113         0       1.2         9       448:   9%|9         | 5/54 [00:20<02:44,  3.35s/it]\n",
      "   830/834        0G      1.09     0.113         0       1.2         9       448:  11%|#1        | 6/54 [00:20<02:40,  3.33s/it]\n",
      "   830/834        0G      1.09     0.112         0       1.2         9       448:  11%|#1        | 6/54 [00:23<02:40,  3.33s/it]\n",
      "   830/834        0G      1.09     0.112         0       1.2         9       448:  13%|#2        | 7/54 [00:23<02:37,  3.35s/it]\n",
      "   830/834        0G       1.1     0.112         0      1.21         9       448:  13%|#2        | 7/54 [00:27<02:37,  3.35s/it]\n",
      "   830/834        0G       1.1     0.112         0      1.21         9       448:  15%|#4        | 8/54 [00:27<02:35,  3.38s/it]\n",
      "   830/834        0G       1.1      0.11         0      1.21         9       448:  15%|#4        | 8/54 [00:30<02:35,  3.38s/it]\n",
      "   830/834        0G       1.1      0.11         0      1.21         9       448:  17%|#6        | 9/54 [00:30<02:34,  3.43s/it]\n",
      "   830/834        0G      1.11      0.11         0      1.22        11       448:  17%|#6        | 9/54 [00:34<02:34,  3.43s/it]\n",
      "   830/834        0G      1.11      0.11         0      1.22        11       448:  19%|#8        | 10/54 [00:34<02:31,  3.44s/it]\n",
      "   830/834        0G       1.1     0.115         0      1.22        12       448:  19%|#8        | 10/54 [00:37<02:31,  3.44s/it]\n",
      "   830/834        0G       1.1     0.115         0      1.22        12       448:  20%|##        | 11/54 [00:37<02:27,  3.42s/it]\n",
      "   830/834        0G      1.13      0.11         0      1.24         9       448:  20%|##        | 11/54 [00:40<02:27,  3.42s/it]\n",
      "   830/834        0G      1.13      0.11         0      1.24         9       448:  22%|##2       | 12/54 [00:40<02:22,  3.40s/it]\n",
      "   830/834        0G      1.14      0.11         0      1.25         9       448:  22%|##2       | 12/54 [00:44<02:22,  3.40s/it]\n",
      "   830/834        0G      1.14      0.11         0      1.25         9       448:  24%|##4       | 13/54 [00:44<02:18,  3.39s/it]\n",
      "   830/834        0G      1.14     0.107         0      1.25         9       448:  24%|##4       | 13/54 [00:47<02:18,  3.39s/it]\n",
      "   830/834        0G      1.14     0.107         0      1.25         9       448:  26%|##5       | 14/54 [00:47<02:15,  3.39s/it]\n",
      "   830/834        0G      1.14     0.107         0      1.25        10       448:  26%|##5       | 14/54 [00:51<02:15,  3.39s/it]\n",
      "   830/834        0G      1.14     0.107         0      1.25        10       448:  28%|##7       | 15/54 [00:51<02:12,  3.39s/it]\n",
      "   830/834        0G      1.15     0.105         0      1.25         8       352:  28%|##7       | 15/54 [00:53<02:12,  3.39s/it]\n",
      "   830/834        0G      1.15     0.105         0      1.25         8       352:  30%|##9       | 16/54 [00:53<01:57,  3.10s/it]\n",
      "   830/834        0G      1.15     0.104         0      1.25         9       352:  30%|##9       | 16/54 [00:55<01:57,  3.10s/it]\n",
      "   830/834        0G      1.15     0.104         0      1.25         9       352:  31%|###1      | 17/54 [00:55<01:43,  2.79s/it]\n",
      "   830/834        0G      1.16     0.107         0      1.27        13       352:  31%|###1      | 17/54 [00:57<01:43,  2.79s/it]\n",
      "   830/834        0G      1.16     0.107         0      1.27        13       352:  33%|###3      | 18/54 [00:57<01:32,  2.58s/it]\n",
      "   830/834        0G      1.16     0.108         0      1.27        12       352:  33%|###3      | 18/54 [00:59<01:32,  2.58s/it]\n",
      "   830/834        0G      1.16     0.108         0      1.27        12       352:  35%|###5      | 19/54 [00:59<01:25,  2.44s/it]\n",
      "   830/834        0G      1.16     0.107         0      1.26        10       352:  35%|###5      | 19/54 [01:01<01:25,  2.44s/it]\n",
      "   830/834        0G      1.16     0.107         0      1.26        10       352:  37%|###7      | 20/54 [01:01<01:19,  2.35s/it]\n",
      "   830/834        0G      1.17     0.107         0      1.27         9       352:  37%|###7      | 20/54 [01:04<01:19,  2.35s/it]\n",
      "   830/834        0G      1.17     0.107         0      1.27         9       352:  39%|###8      | 21/54 [01:04<01:16,  2.32s/it]\n",
      "   830/834        0G      1.18     0.106         0      1.28        11       352:  39%|###8      | 21/54 [01:06<01:16,  2.32s/it]\n",
      "   830/834        0G      1.18     0.106         0      1.28        11       352:  41%|####      | 22/54 [01:06<01:12,  2.26s/it]\n",
      "   830/834        0G      1.19     0.107         0      1.29        12       352:  41%|####      | 22/54 [01:08<01:12,  2.26s/it]\n",
      "   830/834        0G      1.19     0.107         0      1.29        12       352:  43%|####2     | 23/54 [01:08<01:09,  2.23s/it]\n",
      "   830/834        0G      1.18     0.109         0      1.29        14       352:  43%|####2     | 23/54 [01:10<01:09,  2.23s/it]\n",
      "   830/834        0G      1.18     0.109         0      1.29        14       352:  44%|####4     | 24/54 [01:10<01:07,  2.26s/it]\n",
      "   830/834        0G      1.19     0.108         0      1.29         9       352:  44%|####4     | 24/54 [01:12<01:07,  2.26s/it]\n",
      "   830/834        0G      1.19     0.108         0      1.29         9       352:  46%|####6     | 25/54 [01:12<01:04,  2.24s/it]\n",
      "   830/834        0G      1.18      0.11         0      1.29        10       352:  46%|####6     | 25/54 [01:15<01:04,  2.24s/it]\n",
      "   830/834        0G      1.18      0.11         0      1.29        10       352:  48%|####8     | 26/54 [01:15<01:01,  2.21s/it]\n",
      "   830/834        0G      1.17      0.11         0      1.28        10       352:  48%|####8     | 26/54 [01:17<01:01,  2.21s/it]\n",
      "   830/834        0G      1.17      0.11         0      1.28        10       352:  50%|#####     | 27/54 [01:17<00:58,  2.17s/it]\n",
      "   830/834        0G      1.18     0.109         0      1.29        10       352:  50%|#####     | 27/54 [01:19<00:58,  2.17s/it]\n",
      "   830/834        0G      1.18     0.109         0      1.29        10       352:  52%|#####1    | 28/54 [01:19<00:56,  2.16s/it]\n",
      "   830/834        0G      1.18     0.108         0      1.29         9       352:  52%|#####1    | 28/54 [01:21<00:56,  2.16s/it]\n",
      "   830/834        0G      1.18     0.108         0      1.29         9       352:  54%|#####3    | 29/54 [01:21<00:53,  2.16s/it]\n",
      "   830/834        0G      1.18     0.108         0      1.28         9       352:  54%|#####3    | 29/54 [01:23<00:53,  2.16s/it]\n",
      "   830/834        0G      1.18     0.108         0      1.28         9       352:  56%|#####5    | 30/54 [01:23<00:51,  2.15s/it]\n",
      "   830/834        0G      1.17     0.109         0      1.28         9       352:  56%|#####5    | 30/54 [01:25<00:51,  2.15s/it]\n",
      "   830/834        0G      1.17     0.109         0      1.28         9       352:  57%|#####7    | 31/54 [01:25<00:49,  2.16s/it]\n",
      "   830/834        0G      1.17     0.109         0      1.28        11       352:  57%|#####7    | 31/54 [01:27<00:49,  2.16s/it]\n",
      "   830/834        0G      1.17     0.109         0      1.28        11       352:  59%|#####9    | 32/54 [01:27<00:47,  2.14s/it]\n",
      "   830/834        0G      1.17     0.108         0      1.28         8       352:  59%|#####9    | 32/54 [01:29<00:47,  2.14s/it]\n",
      "   830/834        0G      1.17     0.108         0      1.28         8       352:  61%|######1   | 33/54 [01:29<00:44,  2.12s/it]\n",
      "   830/834        0G      1.17     0.108         0      1.28         9       352:  61%|######1   | 33/54 [01:32<00:44,  2.12s/it]\n",
      "   830/834        0G      1.17     0.108         0      1.28         9       352:  63%|######2   | 34/54 [01:32<00:41,  2.10s/it]\n",
      "   830/834        0G      1.17     0.108         0      1.28         9       352:  63%|######2   | 34/54 [01:34<00:41,  2.10s/it]\n",
      "   830/834        0G      1.17     0.108         0      1.28         9       352:  65%|######4   | 35/54 [01:34<00:40,  2.13s/it]\n",
      "   830/834        0G      1.17     0.108         0      1.28         9       352:  65%|######4   | 35/54 [01:36<00:40,  2.13s/it]\n",
      "   830/834        0G      1.17     0.108         0      1.28         9       352:  67%|######6   | 36/54 [01:36<00:38,  2.15s/it]\n",
      "   830/834        0G      1.18     0.109         0      1.29        12       352:  67%|######6   | 36/54 [01:38<00:38,  2.15s/it]\n",
      "   830/834        0G      1.18     0.109         0      1.29        12       352:  69%|######8   | 37/54 [01:38<00:37,  2.21s/it]\n",
      "   830/834        0G      1.17      0.11         0      1.28        12       352:  69%|######8   | 37/54 [01:41<00:37,  2.21s/it]\n",
      "   830/834        0G      1.17      0.11         0      1.28        12       352:  70%|#######   | 38/54 [01:41<00:35,  2.22s/it]\n",
      "   830/834        0G      1.17     0.109         0      1.28         9       352:  70%|#######   | 38/54 [01:43<00:35,  2.22s/it]\n",
      "   830/834        0G      1.17     0.109         0      1.28         9       352:  72%|#######2  | 39/54 [01:43<00:33,  2.23s/it]\n",
      "   830/834        0G      1.17     0.109         0      1.27         9       352:  72%|#######2  | 39/54 [01:45<00:33,  2.23s/it]\n",
      "   830/834        0G      1.17     0.109         0      1.27         9       352:  74%|#######4  | 40/54 [01:45<00:30,  2.19s/it]\n",
      "   830/834        0G      1.16     0.109         0      1.27         8       352:  74%|#######4  | 40/54 [01:47<00:30,  2.19s/it]\n",
      "   830/834        0G      1.16     0.109         0      1.27         8       352:  76%|#######5  | 41/54 [01:47<00:28,  2.16s/it]\n",
      "   830/834        0G      1.16     0.108         0      1.27         9       352:  76%|#######5  | 41/54 [01:49<00:28,  2.16s/it]\n",
      "   830/834        0G      1.16     0.108         0      1.27         9       352:  78%|#######7  | 42/54 [01:49<00:25,  2.15s/it]\n",
      "   830/834        0G      1.16     0.109         0      1.27        10       352:  78%|#######7  | 42/54 [01:51<00:25,  2.15s/it]\n",
      "   830/834        0G      1.16     0.109         0      1.27        10       352:  80%|#######9  | 43/54 [01:51<00:23,  2.14s/it]\n",
      "   830/834        0G      1.17     0.108         0      1.27        10       352:  80%|#######9  | 43/54 [01:53<00:23,  2.14s/it]\n",
      "   830/834        0G      1.17     0.108         0      1.27        10       352:  81%|########1 | 44/54 [01:53<00:21,  2.13s/it]\n",
      "   830/834        0G      1.16     0.109         0      1.27        10       352:  81%|########1 | 44/54 [01:55<00:21,  2.13s/it]\n",
      "   830/834        0G      1.16     0.109         0      1.27        10       352:  83%|########3 | 45/54 [01:55<00:19,  2.11s/it]\n",
      "   830/834        0G      1.17     0.109         0      1.27         9       352:  83%|########3 | 45/54 [01:57<00:19,  2.11s/it]\n",
      "   830/834        0G      1.17     0.109         0      1.27         9       352:  85%|########5 | 46/54 [01:57<00:16,  2.11s/it]\n",
      "   830/834        0G      1.16     0.109         0      1.27         9       352:  85%|########5 | 46/54 [02:00<00:16,  2.11s/it]\n",
      "   830/834        0G      1.16     0.109         0      1.27         9       352:  87%|########7 | 47/54 [02:00<00:14,  2.12s/it]\n",
      "   830/834        0G      1.17     0.108         0      1.28         9       352:  87%|########7 | 47/54 [02:02<00:14,  2.12s/it]\n",
      "   830/834        0G      1.17     0.108         0      1.28         9       352:  89%|########8 | 48/54 [02:02<00:12,  2.13s/it]\n",
      "   830/834        0G      1.16     0.108         0      1.27        10       352:  89%|########8 | 48/54 [02:04<00:12,  2.13s/it]\n",
      "   830/834        0G      1.16     0.108         0      1.27        10       352:  91%|######### | 49/54 [02:04<00:10,  2.17s/it]\n",
      "   830/834        0G      1.17     0.109         0      1.28        12       352:  91%|######### | 49/54 [02:06<00:10,  2.17s/it]\n",
      "   830/834        0G      1.17     0.109         0      1.28        12       352:  93%|#########2| 50/54 [02:06<00:08,  2.22s/it]\n",
      "   830/834        0G      1.17     0.109         0      1.27         9       352:  93%|#########2| 50/54 [02:08<00:08,  2.22s/it]\n",
      "   830/834        0G      1.17     0.109         0      1.27         9       352:  94%|#########4| 51/54 [02:08<00:06,  2.19s/it]\n",
      "   830/834        0G      1.16     0.109         0      1.27         9       352:  94%|#########4| 51/54 [02:11<00:06,  2.19s/it]\n",
      "   830/834        0G      1.16     0.109         0      1.27         9       352:  96%|#########6| 52/54 [02:11<00:04,  2.16s/it]\n",
      "   830/834        0G      1.16      0.11         0      1.27        12       352:  96%|#########6| 52/54 [02:13<00:04,  2.16s/it]\n",
      "   830/834        0G      1.16      0.11         0      1.27        12       352:  98%|#########8| 53/54 [02:13<00:02,  2.15s/it]\n",
      "   830/834        0G      1.16      0.11         0      1.28         3       352:  98%|#########8| 53/54 [02:14<00:02,  2.15s/it]\n",
      "   830/834        0G      1.16      0.11         0      1.28         3       352: 100%|##########| 54/54 [02:14<00:00,  1.78s/it]\n",
      "   830/834        0G      1.16      0.11         0      1.28         3       352: 100%|##########| 54/54 [02:15<00:00,  2.50s/it]\n",
      "\n",
      "               Class    Images   Targets         P         R   mAP@0.5        F1:   0%|          | 0/14 [00:00<?, ?it/s]2024-03-04 16:59:50.858562: I tensorflow/core/util/port.cc:113] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
      "WARNING:tensorflow:From C:\\Users\\mit017\\anaconda3\\Lib\\site-packages\\keras\\src\\losses.py:2976: The name tf.losses.sparse_softmax_cross_entropy is deprecated. Please use tf.compat.v1.losses.sparse_softmax_cross_entropy instead.\n",
      "\n",
      "2024-03-04 17:00:01.953674: I tensorflow/core/util/port.cc:113] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
      "WARNING:tensorflow:From C:\\Users\\mit017\\anaconda3\\Lib\\site-packages\\keras\\src\\losses.py:2976: The name tf.losses.sparse_softmax_cross_entropy is deprecated. Please use tf.compat.v1.losses.sparse_softmax_cross_entropy instead.\n",
      "\n",
      "2024-03-04 17:00:12.375509: I tensorflow/core/util/port.cc:113] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
      "WARNING:tensorflow:From C:\\Users\\mit017\\anaconda3\\Lib\\site-packages\\keras\\src\\losses.py:2976: The name tf.losses.sparse_softmax_cross_entropy is deprecated. Please use tf.compat.v1.losses.sparse_softmax_cross_entropy instead.\n",
      "\n",
      "\n",
      "               Class    Images   Targets         P         R   mAP@0.5        F1:   7%|7         | 1/14 [00:34<07:26, 34.38s/it]\n",
      "               Class    Images   Targets         P         R   mAP@0.5        F1:  14%|#4        | 2/14 [00:36<03:05, 15.47s/it]\n",
      "               Class    Images   Targets         P         R   mAP@0.5        F1:  21%|##1       | 3/14 [00:38<01:43,  9.37s/it]\n",
      "               Class    Images   Targets         P         R   mAP@0.5        F1:  29%|##8       | 4/14 [00:40<01:05,  6.51s/it]\n",
      "               Class    Images   Targets         P         R   mAP@0.5        F1:  36%|###5      | 5/14 [00:42<00:44,  4.93s/it]\n",
      "               Class    Images   Targets         P         R   mAP@0.5        F1:  43%|####2     | 6/14 [00:45<00:32,  4.00s/it]\n",
      "               Class    Images   Targets         P         R   mAP@0.5        F1:  50%|#####     | 7/14 [00:47<00:23,  3.39s/it]\n",
      "               Class    Images   Targets         P         R   mAP@0.5        F1:  57%|#####7    | 8/14 [00:49<00:17,  2.99s/it]\n",
      "               Class    Images   Targets         P         R   mAP@0.5        F1:  64%|######4   | 9/14 [00:51<00:13,  2.71s/it]\n",
      "               Class    Images   Targets         P         R   mAP@0.5        F1:  71%|#######1  | 10/14 [00:53<00:10,  2.51s/it]\n",
      "               Class    Images   Targets         P         R   mAP@0.5        F1:  79%|#######8  | 11/14 [00:55<00:07,  2.39s/it]\n",
      "               Class    Images   Targets         P         R   mAP@0.5        F1:  86%|########5 | 12/14 [00:57<00:04,  2.31s/it]\n",
      "               Class    Images   Targets         P         R   mAP@0.5        F1:  93%|#########2| 13/14 [01:00<00:02,  2.30s/it]\n",
      "               Class    Images   Targets         P         R   mAP@0.5        F1: 100%|##########| 14/14 [01:00<00:00,  1.85s/it]\n",
      "               Class    Images   Targets         P         R   mAP@0.5        F1: 100%|##########| 14/14 [01:02<00:00,  4.43s/it]\n",
      "2024-03-04 17:00:53.116145: I tensorflow/core/util/port.cc:113] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
      "WARNING:tensorflow:From C:\\Users\\mit017\\anaconda3\\Lib\\site-packages\\keras\\src\\losses.py:2976: The name tf.losses.sparse_softmax_cross_entropy is deprecated. Please use tf.compat.v1.losses.sparse_softmax_cross_entropy instead.\n",
      "\n",
      "2024-03-04 17:01:03.406366: I tensorflow/core/util/port.cc:113] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
      "WARNING:tensorflow:From C:\\Users\\mit017\\anaconda3\\Lib\\site-packages\\keras\\src\\losses.py:2976: The name tf.losses.sparse_softmax_cross_entropy is deprecated. Please use tf.compat.v1.losses.sparse_softmax_cross_entropy instead.\n",
      "\n",
      "2024-03-04 17:01:13.615990: I tensorflow/core/util/port.cc:113] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
      "WARNING:tensorflow:From C:\\Users\\mit017\\anaconda3\\Lib\\site-packages\\keras\\src\\losses.py:2976: The name tf.losses.sparse_softmax_cross_entropy is deprecated. Please use tf.compat.v1.losses.sparse_softmax_cross_entropy instead.\n",
      "\n",
      "\n",
      "  0%|          | 0/54 [00:00<?, ?it/s]\n",
      "   831/834        0G      1.26    0.0915         0      1.35         9       352:   0%|          | 0/54 [00:02<?, ?it/s]\n",
      "   831/834        0G      1.26    0.0915         0      1.35         9       352:   2%|1         | 1/54 [00:02<02:03,  2.32s/it]\n",
      "   831/834        0G      1.16     0.132         0      1.29        16       352:   2%|1         | 1/54 [00:04<02:03,  2.32s/it]\n",
      "   831/834        0G      1.16     0.132         0      1.29        16       352:   4%|3         | 2/54 [00:04<01:56,  2.24s/it]\n",
      "   831/834        0G      1.22     0.121         0      1.34        12       352:   4%|3         | 2/54 [00:06<01:56,  2.24s/it]\n",
      "   831/834        0G      1.22     0.121         0      1.34        12       352:   6%|5         | 3/54 [00:06<01:51,  2.19s/it]\n",
      "   831/834        0G      1.89     0.116         0      2.01        10       640:   6%|5         | 3/54 [00:14<01:51,  2.19s/it]\n",
      "   831/834        0G      1.89     0.116         0      2.01        10       640:   7%|7         | 4/54 [00:14<03:32,  4.24s/it]\n",
      "   831/834        0G      2.29     0.115         0       2.4        11       640:   7%|7         | 4/54 [00:21<03:32,  4.24s/it]\n",
      "   831/834        0G      2.29     0.115         0       2.4        11       640:   9%|9         | 5/54 [00:21<04:27,  5.46s/it]\n",
      "   831/834        0G      2.68     0.107         0      2.79         9       640:   9%|9         | 5/54 [00:28<04:27,  5.46s/it]\n",
      "   831/834        0G      2.68     0.107         0      2.79         9       640:  11%|#1        | 6/54 [00:28<04:48,  6.00s/it]\n",
      "   831/834        0G      2.96    0.0999         0      3.06         8       640:  11%|#1        | 6/54 [00:35<04:48,  6.00s/it]\n",
      "   831/834        0G      2.96    0.0999         0      3.06         8       640:  13%|#2        | 7/54 [00:35<04:54,  6.26s/it]\n",
      "   831/834        0G      3.08     0.105         0      3.19        14       640:  13%|#2        | 7/54 [00:42<04:54,  6.26s/it]\n",
      "   831/834        0G      3.08     0.105         0      3.19        14       640:  15%|#4        | 8/54 [00:42<04:53,  6.39s/it]\n",
      "   831/834        0G      3.15     0.105         0      3.26        10       640:  15%|#4        | 8/54 [00:48<04:53,  6.39s/it]\n",
      "   831/834        0G      3.15     0.105         0      3.26        10       640:  17%|#6        | 9/54 [00:48<04:52,  6.51s/it]\n",
      "   831/834        0G      3.18     0.104         0      3.28         9       640:  17%|#6        | 9/54 [00:55<04:52,  6.51s/it]\n",
      "   831/834        0G      3.18     0.104         0      3.28         9       640:  19%|#8        | 10/54 [00:55<04:50,  6.61s/it]\n",
      "   831/834        0G      3.27     0.104         0      3.37         9       640:  19%|#8        | 10/54 [01:02<04:50,  6.61s/it]\n",
      "   831/834        0G      3.27     0.104         0      3.37         9       640:  20%|##        | 11/54 [01:02<04:49,  6.73s/it]\n",
      "   831/834        0G       3.3     0.104         0      3.41         9       640:  20%|##        | 11/54 [01:09<04:49,  6.73s/it]\n",
      "   831/834        0G       3.3     0.104         0      3.41         9       640:  22%|##2       | 12/54 [01:09<04:47,  6.85s/it]\n",
      "   831/834        0G      3.41     0.103         0      3.51        11       640:  22%|##2       | 12/54 [01:16<04:47,  6.85s/it]\n",
      "   831/834        0G      3.41     0.103         0      3.51        11       640:  24%|##4       | 13/54 [01:16<04:38,  6.78s/it]\n",
      "   831/834        0G      3.52       0.1         0      3.62         9       640:  24%|##4       | 13/54 [01:23<04:38,  6.78s/it]\n",
      "   831/834        0G      3.52       0.1         0      3.62         9       640:  26%|##5       | 14/54 [01:23<04:31,  6.78s/it]\n",
      "   831/834        0G      3.53     0.103         0      3.63         9       640:  26%|##5       | 14/54 [01:30<04:31,  6.78s/it]\n",
      "   831/834        0G      3.53     0.103         0      3.63         9       640:  28%|##7       | 15/54 [01:30<04:33,  7.00s/it]\n",
      "   831/834        0G      3.55     0.101         0      3.66         9       640:  28%|##7       | 15/54 [01:37<04:33,  7.00s/it]\n",
      "   831/834        0G      3.55     0.101         0      3.66         9       640:  30%|##9       | 16/54 [01:37<04:22,  6.90s/it]\n",
      "   831/834        0G      3.55     0.101         0      3.65         9       640:  30%|##9       | 16/54 [01:44<04:22,  6.90s/it]\n",
      "   831/834        0G      3.55     0.101         0      3.65         9       640:  31%|###1      | 17/54 [01:44<04:12,  6.83s/it]\n",
      "   831/834        0G      3.57       0.1         0      3.67         9       640:  31%|###1      | 17/54 [01:51<04:12,  6.83s/it]\n",
      "   831/834        0G      3.57       0.1         0      3.67         9       640:  33%|###3      | 18/54 [01:51<04:09,  6.93s/it]\n",
      "   831/834        0G      3.59    0.0999         0      3.69         8       640:  33%|###3      | 18/54 [01:58<04:09,  6.93s/it]\n",
      "   831/834        0G      3.59    0.0999         0      3.69         8       640:  35%|###5      | 19/54 [01:58<04:03,  6.96s/it]\n",
      "   831/834        0G       3.6       0.1         0       3.7         9       640:  35%|###5      | 19/54 [02:05<04:03,  6.96s/it]\n",
      "   831/834        0G       3.6       0.1         0       3.7         9       640:  37%|###7      | 20/54 [02:05<03:57,  6.99s/it]\n",
      "   831/834        0G      3.62     0.101         0      3.72         9       640:  37%|###7      | 20/54 [02:12<03:57,  6.99s/it]\n",
      "   831/834        0G      3.62     0.101         0      3.72         9       640:  39%|###8      | 21/54 [02:12<03:49,  6.96s/it]\n",
      "   831/834        0G      3.63     0.101         0      3.73        10       640:  39%|###8      | 21/54 [02:19<03:49,  6.96s/it]\n",
      "   831/834        0G      3.63     0.101         0      3.73        10       640:  41%|####      | 22/54 [02:19<03:42,  6.95s/it]\n",
      "   831/834        0G      3.64     0.101         0      3.75         9       640:  41%|####      | 22/54 [02:26<03:42,  6.95s/it]\n",
      "   831/834        0G      3.64     0.101         0      3.75         9       640:  43%|####2     | 23/54 [02:26<03:42,  7.16s/it]\n",
      "   831/834        0G      3.66     0.101         0      3.76        10       640:  43%|####2     | 23/54 [02:33<03:42,  7.16s/it]\n",
      "   831/834        0G      3.66     0.101         0      3.76        10       640:  44%|####4     | 24/54 [02:33<03:33,  7.11s/it]\n",
      "   831/834        0G      3.56     0.101         0      3.66        10       480:  44%|####4     | 24/54 [02:38<03:33,  7.11s/it]\n",
      "   831/834        0G      3.56     0.101         0      3.66        10       480:  46%|####6     | 25/54 [02:38<03:01,  6.25s/it]\n",
      "   831/834        0G      3.47    0.0998         0      3.57         9       480:  46%|####6     | 25/54 [02:41<03:01,  6.25s/it]\n",
      "   831/834        0G      3.47    0.0998         0      3.57         9       480:  48%|####8     | 26/54 [02:41<02:33,  5.49s/it]\n",
      "   831/834        0G      3.38    0.0994         0      3.48         9       480:  48%|####8     | 26/54 [02:45<02:33,  5.49s/it]\n",
      "   831/834        0G      3.38    0.0994         0      3.48         9       480:  50%|#####     | 27/54 [02:45<02:13,  4.95s/it]\n",
      "   831/834        0G       3.3     0.101         0       3.4        13       480:  50%|#####     | 27/54 [02:49<02:13,  4.95s/it]\n",
      "   831/834        0G       3.3     0.101         0       3.4        13       480:  52%|#####1    | 28/54 [02:49<01:58,  4.57s/it]\n",
      "   831/834        0G      3.23    0.0997         0      3.33         9       480:  52%|#####1    | 28/54 [02:52<01:58,  4.57s/it]\n",
      "   831/834        0G      3.23    0.0997         0      3.33         9       480:  54%|#####3    | 29/54 [02:52<01:47,  4.31s/it]\n",
      "   831/834        0G      3.17       0.1         0      3.27        12       480:  54%|#####3    | 29/54 [02:56<01:47,  4.31s/it]\n",
      "   831/834        0G      3.17       0.1         0      3.27        12       480:  56%|#####5    | 30/54 [02:56<01:39,  4.14s/it]\n",
      "   831/834        0G      3.11    0.0991         0      3.21        11       480:  56%|#####5    | 30/54 [03:00<01:39,  4.14s/it]\n",
      "   831/834        0G      3.11    0.0991         0      3.21        11       480:  57%|#####7    | 31/54 [03:00<01:32,  4.00s/it]\n",
      "   831/834        0G      3.05    0.0984         0      3.15        10       480:  57%|#####7    | 31/54 [03:04<01:32,  4.00s/it]\n",
      "   831/834        0G      3.05    0.0984         0      3.15        10       480:  59%|#####9    | 32/54 [03:04<01:26,  3.91s/it]\n",
      "   831/834        0G      2.99    0.0989         0      3.09        12       480:  59%|#####9    | 32/54 [03:07<01:26,  3.91s/it]\n",
      "   831/834        0G      2.99    0.0989         0      3.09        12       480:  61%|######1   | 33/54 [03:07<01:20,  3.85s/it]\n",
      "   831/834        0G      2.94    0.0985         0      3.04         9       480:  61%|######1   | 33/54 [03:11<01:20,  3.85s/it]\n",
      "   831/834        0G      2.94    0.0985         0      3.04         9       480:  63%|######2   | 34/54 [03:11<01:15,  3.80s/it]\n",
      "   831/834        0G      2.89    0.0977         0      2.98         9       480:  63%|######2   | 34/54 [03:15<01:15,  3.80s/it]\n",
      "   831/834        0G      2.89    0.0977         0      2.98         9       480:  65%|######4   | 35/54 [03:15<01:12,  3.82s/it]\n",
      "   831/834        0G      2.84     0.098         0      2.94        10       480:  65%|######4   | 35/54 [03:19<01:12,  3.82s/it]\n",
      "   831/834        0G      2.84     0.098         0      2.94        10       480:  67%|######6   | 36/54 [03:19<01:09,  3.88s/it]\n",
      "   831/834        0G      2.79    0.0984         0      2.89        10       480:  67%|######6   | 36/54 [03:23<01:09,  3.88s/it]\n",
      "   831/834        0G      2.79    0.0984         0      2.89        10       480:  69%|######8   | 37/54 [03:23<01:05,  3.86s/it]\n",
      "   831/834        0G      2.75    0.0978         0      2.84         9       480:  69%|######8   | 37/54 [03:26<01:05,  3.86s/it]\n",
      "   831/834        0G      2.75    0.0978         0      2.84         9       480:  70%|#######   | 38/54 [03:26<01:01,  3.82s/it]\n",
      "   831/834        0G       2.7    0.0985         0       2.8        12       480:  70%|#######   | 38/54 [03:30<01:01,  3.82s/it]\n",
      "   831/834        0G       2.7    0.0985         0       2.8        12       480:  72%|#######2  | 39/54 [03:30<00:57,  3.81s/it]\n",
      "   831/834        0G      2.67    0.0986         0      2.76        10       480:  72%|#######2  | 39/54 [03:34<00:57,  3.81s/it]\n",
      "   831/834        0G      2.67    0.0986         0      2.76        10       480:  74%|#######4  | 40/54 [03:34<00:52,  3.78s/it]\n",
      "   831/834        0G      2.69    0.0987         0      2.79         9       480:  74%|#######4  | 40/54 [03:38<00:52,  3.78s/it]\n",
      "   831/834        0G      2.69    0.0987         0      2.79         9       480:  76%|#######5  | 41/54 [03:38<00:48,  3.76s/it]\n",
      "   831/834        0G      2.65    0.0986         0      2.75        10       480:  76%|#######5  | 41/54 [03:41<00:48,  3.76s/it]\n",
      "   831/834        0G      2.65    0.0986         0      2.75        10       480:  78%|#######7  | 42/54 [03:41<00:45,  3.75s/it]\n",
      "   831/834        0G      2.61    0.0984         0      2.71        10       480:  78%|#######7  | 42/54 [03:45<00:45,  3.75s/it]\n",
      "   831/834        0G      2.61    0.0984         0      2.71        10       480:  80%|#######9  | 43/54 [03:45<00:41,  3.77s/it]\n",
      "   831/834        0G      2.58    0.0985         0      2.67        10       480:  80%|#######9  | 43/54 [03:49<00:41,  3.77s/it]\n",
      "   831/834        0G      2.58    0.0985         0      2.67        10       480:  81%|########1 | 44/54 [03:49<00:37,  3.78s/it]\n",
      "   831/834        0G      2.55     0.099         0      2.64        12       480:  81%|########1 | 44/54 [03:53<00:37,  3.78s/it]\n",
      "   831/834        0G      2.55     0.099         0      2.64        12       480:  83%|########3 | 45/54 [03:53<00:34,  3.78s/it]\n",
      "   831/834        0G      2.57    0.0986         0      2.66         9       544:  83%|########3 | 45/54 [03:58<00:34,  3.78s/it]\n",
      "   831/834        0G      2.57    0.0986         0      2.66         9       544:  85%|########5 | 46/54 [03:58<00:33,  4.18s/it]\n",
      "   831/834        0G      2.53    0.0985         0      2.63         9       544:  85%|########5 | 46/54 [04:02<00:33,  4.18s/it]\n",
      "   831/834        0G      2.53    0.0985         0      2.63         9       544:  87%|########7 | 47/54 [04:02<00:30,  4.32s/it]\n",
      "   831/834        0G      2.55    0.0984         0      2.65         9       544:  87%|########7 | 47/54 [04:07<00:30,  4.32s/it]\n",
      "   831/834        0G      2.55    0.0984         0      2.65         9       544:  89%|########8 | 48/54 [04:07<00:26,  4.45s/it]\n",
      "   831/834        0G      2.53     0.098         0      2.63        11       544:  89%|########8 | 48/54 [04:12<00:26,  4.45s/it]\n",
      "   831/834        0G      2.53     0.098         0      2.63        11       544:  91%|######### | 49/54 [04:12<00:22,  4.52s/it]\n",
      "   831/834        0G       2.5    0.0975         0       2.6         9       544:  91%|######### | 49/54 [04:17<00:22,  4.52s/it]\n",
      "   831/834        0G       2.5    0.0975         0       2.6         9       544:  93%|#########2| 50/54 [04:17<00:18,  4.62s/it]\n",
      "   831/834        0G      2.48    0.0969         0      2.57         9       544:  93%|#########2| 50/54 [04:22<00:18,  4.62s/it]\n",
      "   831/834        0G      2.48    0.0969         0      2.57         9       544:  94%|#########4| 51/54 [04:22<00:14,  4.68s/it]\n",
      "   831/834        0G      2.45    0.0968         0      2.55        13       544:  94%|#########4| 51/54 [04:26<00:14,  4.68s/it]\n",
      "   831/834        0G      2.45    0.0968         0      2.55        13       544:  96%|#########6| 52/54 [04:26<00:09,  4.71s/it]\n",
      "   831/834        0G      2.43    0.0967         0      2.52         9       544:  96%|#########6| 52/54 [04:31<00:09,  4.71s/it]\n",
      "   831/834        0G      2.43    0.0967         0      2.52         9       544:  98%|#########8| 53/54 [04:31<00:04,  4.71s/it]\n",
      "   831/834        0G       2.4    0.0964         0       2.5         4       544:  98%|#########8| 53/54 [04:33<00:04,  4.71s/it]\n",
      "   831/834        0G       2.4    0.0964         0       2.5         4       544: 100%|##########| 54/54 [04:33<00:00,  3.81s/it]\n",
      "   831/834        0G       2.4    0.0964         0       2.5         4       544: 100%|##########| 54/54 [04:34<00:00,  5.08s/it]\n",
      "\n",
      "               Class    Images   Targets         P         R   mAP@0.5        F1:   0%|          | 0/14 [00:00<?, ?it/s]2024-03-04 17:05:58.343375: I tensorflow/core/util/port.cc:113] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
      "WARNING:tensorflow:From C:\\Users\\mit017\\anaconda3\\Lib\\site-packages\\keras\\src\\losses.py:2976: The name tf.losses.sparse_softmax_cross_entropy is deprecated. Please use tf.compat.v1.losses.sparse_softmax_cross_entropy instead.\n",
      "\n",
      "2024-03-04 17:06:08.572065: I tensorflow/core/util/port.cc:113] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
      "WARNING:tensorflow:From C:\\Users\\mit017\\anaconda3\\Lib\\site-packages\\keras\\src\\losses.py:2976: The name tf.losses.sparse_softmax_cross_entropy is deprecated. Please use tf.compat.v1.losses.sparse_softmax_cross_entropy instead.\n",
      "\n",
      "2024-03-04 17:06:18.751780: I tensorflow/core/util/port.cc:113] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
      "WARNING:tensorflow:From C:\\Users\\mit017\\anaconda3\\Lib\\site-packages\\keras\\src\\losses.py:2976: The name tf.losses.sparse_softmax_cross_entropy is deprecated. Please use tf.compat.v1.losses.sparse_softmax_cross_entropy instead.\n",
      "\n",
      "\n",
      "               Class    Images   Targets         P         R   mAP@0.5        F1:   7%|7         | 1/14 [00:32<07:07, 32.87s/it]\n",
      "               Class    Images   Targets         P         R   mAP@0.5        F1:  14%|#4        | 2/14 [00:34<02:56, 14.74s/it]\n",
      "               Class    Images   Targets         P         R   mAP@0.5        F1:  21%|##1       | 3/14 [00:37<01:38,  8.97s/it]\n",
      "               Class    Images   Targets         P         R   mAP@0.5        F1:  29%|##8       | 4/14 [00:39<01:02,  6.22s/it]\n",
      "               Class    Images   Targets         P         R   mAP@0.5        F1:  36%|###5      | 5/14 [00:41<00:42,  4.71s/it]\n",
      "               Class    Images   Targets         P         R   mAP@0.5        F1:  43%|####2     | 6/14 [00:43<00:30,  3.79s/it]\n",
      "               Class    Images   Targets         P         R   mAP@0.5        F1:  50%|#####     | 7/14 [00:45<00:22,  3.23s/it]\n",
      "               Class    Images   Targets         P         R   mAP@0.5        F1:  57%|#####7    | 8/14 [00:47<00:17,  2.86s/it]\n",
      "               Class    Images   Targets         P         R   mAP@0.5        F1:  64%|######4   | 9/14 [00:49<00:13,  2.62s/it]\n",
      "               Class    Images   Targets         P         R   mAP@0.5        F1:  71%|#######1  | 10/14 [00:51<00:09,  2.45s/it]\n",
      "               Class    Images   Targets         P         R   mAP@0.5        F1:  79%|#######8  | 11/14 [00:53<00:06,  2.33s/it]\n",
      "               Class    Images   Targets         P         R   mAP@0.5        F1:  86%|########5 | 12/14 [00:55<00:04,  2.25s/it]\n",
      "               Class    Images   Targets         P         R   mAP@0.5        F1:  93%|#########2| 13/14 [00:57<00:02,  2.20s/it]\n",
      "               Class    Images   Targets         P         R   mAP@0.5        F1: 100%|##########| 14/14 [00:58<00:00,  1.75s/it]\n",
      "               Class    Images   Targets         P         R   mAP@0.5        F1: 100%|##########| 14/14 [00:59<00:00,  4.23s/it]\n",
      "2024-03-04 17:06:57.545435: I tensorflow/core/util/port.cc:113] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
      "WARNING:tensorflow:From C:\\Users\\mit017\\anaconda3\\Lib\\site-packages\\keras\\src\\losses.py:2976: The name tf.losses.sparse_softmax_cross_entropy is deprecated. Please use tf.compat.v1.losses.sparse_softmax_cross_entropy instead.\n",
      "\n",
      "2024-03-04 17:07:07.712259: I tensorflow/core/util/port.cc:113] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
      "WARNING:tensorflow:From C:\\Users\\mit017\\anaconda3\\Lib\\site-packages\\keras\\src\\losses.py:2976: The name tf.losses.sparse_softmax_cross_entropy is deprecated. Please use tf.compat.v1.losses.sparse_softmax_cross_entropy instead.\n",
      "\n",
      "2024-03-04 17:07:17.892674: I tensorflow/core/util/port.cc:113] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
      "WARNING:tensorflow:From C:\\Users\\mit017\\anaconda3\\Lib\\site-packages\\keras\\src\\losses.py:2976: The name tf.losses.sparse_softmax_cross_entropy is deprecated. Please use tf.compat.v1.losses.sparse_softmax_cross_entropy instead.\n",
      "\n",
      "\n",
      "  0%|          | 0/54 [00:00<?, ?it/s]\n",
      "   832/834        0G      1.15    0.0924         0      1.24         9       544:   0%|          | 0/54 [00:05<?, ?it/s]\n",
      "   832/834        0G      1.15    0.0924         0      1.24         9       544:   2%|1         | 1/54 [00:05<04:32,  5.15s/it]\n",
      "   832/834        0G      1.16    0.0888         0      1.25        11       544:   2%|1         | 1/54 [00:10<04:32,  5.15s/it]\n",
      "   832/834        0G      1.16    0.0888         0      1.25        11       544:   4%|3         | 2/54 [00:10<04:19,  4.99s/it]\n",
      "   832/834        0G       1.7    0.0875         0      1.79         9       544:   4%|3         | 2/54 [00:14<04:19,  4.99s/it]\n",
      "   832/834        0G       1.7    0.0875         0      1.79         9       544:   6%|5         | 3/54 [00:14<04:07,  4.85s/it]\n",
      "   832/834        0G      1.56    0.0858         0      1.65        10       544:   6%|5         | 3/54 [00:19<04:07,  4.85s/it]\n",
      "   832/834        0G      1.56    0.0858         0      1.65        10       544:   7%|7         | 4/54 [00:19<04:01,  4.82s/it]\n",
      "   832/834        0G      1.95    0.0869         0      2.03        10       544:   7%|7         | 4/54 [00:24<04:01,  4.82s/it]\n",
      "   832/834        0G      1.95    0.0869         0      2.03        10       544:   9%|9         | 5/54 [00:24<03:56,  4.82s/it]\n",
      "   832/834        0G      2.22     0.086         0      2.31        10       544:   9%|9         | 5/54 [00:29<03:56,  4.82s/it]\n",
      "   832/834        0G      2.22     0.086         0      2.31        10       544:  11%|#1        | 6/54 [00:29<03:51,  4.83s/it]\n",
      "   832/834        0G      2.36    0.0864         0      2.44         9       544:  11%|#1        | 6/54 [00:33<03:51,  4.83s/it]\n",
      "   832/834        0G      2.36    0.0864         0      2.44         9       544:  13%|#2        | 7/54 [00:33<03:46,  4.82s/it]\n",
      "   832/834        0G      2.41    0.0937         0      2.51         9       544:  13%|#2        | 7/54 [00:38<03:46,  4.82s/it]\n",
      "   832/834        0G      2.41    0.0937         0      2.51         9       544:  15%|#4        | 8/54 [00:38<03:40,  4.80s/it]\n",
      "   832/834        0G      2.27    0.0938         0      2.36        11       544:  15%|#4        | 8/54 [00:43<03:40,  4.80s/it]\n",
      "   832/834        0G      2.27    0.0938         0      2.36        11       544:  17%|#6        | 9/54 [00:43<03:35,  4.79s/it]\n",
      "   832/834        0G      2.37    0.0956         0      2.46         9       544:  17%|#6        | 9/54 [00:48<03:35,  4.79s/it]\n",
      "   832/834        0G      2.37    0.0956         0      2.46         9       544:  19%|#8        | 10/54 [00:48<03:31,  4.80s/it]\n",
      "   832/834        0G      2.26    0.0938         0      2.35         9       544:  19%|#8        | 10/54 [00:53<03:31,  4.80s/it]\n",
      "   832/834        0G      2.26    0.0938         0      2.35         9       544:  20%|##        | 11/54 [00:53<03:25,  4.77s/it]\n",
      "   832/834        0G      2.37    0.0939         0      2.47        11       544:  20%|##        | 11/54 [00:57<03:25,  4.77s/it]\n",
      "   832/834        0G      2.37    0.0939         0      2.47        11       544:  22%|##2       | 12/54 [00:57<03:21,  4.79s/it]\n",
      "   832/834        0G      2.47    0.0929         0      2.56         9       576:  22%|##2       | 12/54 [01:03<03:21,  4.79s/it]\n",
      "   832/834        0G      2.47    0.0929         0      2.56         9       576:  24%|##4       | 13/54 [01:03<03:25,  5.02s/it]\n",
      "   832/834        0G      2.49    0.0939         0      2.58        11       576:  24%|##4       | 13/54 [01:08<03:25,  5.02s/it]\n",
      "   832/834        0G      2.49    0.0939         0      2.58        11       576:  26%|##5       | 14/54 [01:08<03:26,  5.15s/it]\n",
      "   832/834        0G       2.4    0.0922         0      2.49        10       576:  26%|##5       | 14/54 [01:14<03:26,  5.15s/it]\n",
      "   832/834        0G       2.4    0.0922         0      2.49        10       576:  28%|##7       | 15/54 [01:14<03:24,  5.25s/it]\n",
      "   832/834        0G      2.32    0.0904         0      2.41         9       576:  28%|##7       | 15/54 [01:20<03:24,  5.25s/it]\n",
      "   832/834        0G      2.32    0.0904         0      2.41         9       576:  30%|##9       | 16/54 [01:20<03:24,  5.38s/it]\n",
      "   832/834        0G       2.4      0.09         0      2.49         9       576:  30%|##9       | 16/54 [01:25<03:24,  5.38s/it]\n",
      "   832/834        0G       2.4      0.09         0      2.49         9       576:  31%|###1      | 17/54 [01:25<03:18,  5.38s/it]\n",
      "   832/834        0G      2.47    0.0901         0      2.56        10       576:  31%|###1      | 17/54 [01:30<03:18,  5.38s/it]\n",
      "   832/834        0G      2.47    0.0901         0      2.56        10       576:  33%|###3      | 18/54 [01:30<03:14,  5.40s/it]\n",
      "   832/834        0G      2.49    0.0912         0      2.58        10       576:  33%|###3      | 18/54 [01:36<03:14,  5.40s/it]\n",
      "   832/834        0G      2.49    0.0912         0      2.58        10       576:  35%|###5      | 19/54 [01:36<03:11,  5.49s/it]\n",
      "   832/834        0G      2.49    0.0914         0      2.58         9       576:  35%|###5      | 19/54 [01:41<03:11,  5.49s/it]\n",
      "   832/834        0G      2.49    0.0914         0      2.58         9       576:  37%|###7      | 20/54 [01:41<03:06,  5.48s/it]\n",
      "   832/834        0G      2.41    0.0902         0       2.5         9       576:  37%|###7      | 20/54 [01:47<03:06,  5.48s/it]\n",
      "   832/834        0G      2.41    0.0902         0       2.5         9       576:  39%|###8      | 21/54 [01:47<02:59,  5.45s/it]\n",
      "   832/834        0G      2.35    0.0909         0      2.45        12       576:  39%|###8      | 21/54 [01:52<02:59,  5.45s/it]\n",
      "   832/834        0G      2.35    0.0909         0      2.45        12       576:  41%|####      | 22/54 [01:52<02:54,  5.46s/it]\n",
      "   832/834        0G       2.3    0.0899         0      2.39         9       576:  41%|####      | 22/54 [01:58<02:54,  5.46s/it]\n",
      "   832/834        0G       2.3    0.0899         0      2.39         9       576:  43%|####2     | 23/54 [01:58<02:49,  5.48s/it]\n",
      "   832/834        0G      2.26    0.0908         0      2.35        11       576:  43%|####2     | 23/54 [02:03<02:49,  5.48s/it]\n",
      "   832/834        0G      2.26    0.0908         0      2.35        11       576:  44%|####4     | 24/54 [02:03<02:44,  5.50s/it]\n",
      "   832/834        0G      2.28    0.0906         0      2.37         9       576:  44%|####4     | 24/54 [02:09<02:44,  5.50s/it]\n",
      "   832/834        0G      2.28    0.0906         0      2.37         9       576:  46%|####6     | 25/54 [02:09<02:41,  5.56s/it]\n",
      "   832/834        0G      2.32    0.0911         0      2.41         9       576:  46%|####6     | 25/54 [02:15<02:41,  5.56s/it]\n",
      "   832/834        0G      2.32    0.0911         0      2.41         9       576:  48%|####8     | 26/54 [02:15<02:36,  5.58s/it]\n",
      "   832/834        0G      2.27    0.0904         0      2.36         9       576:  48%|####8     | 26/54 [02:20<02:36,  5.58s/it]\n",
      "   832/834        0G      2.27    0.0904         0      2.36         9       576:  50%|#####     | 27/54 [02:20<02:31,  5.60s/it]\n",
      "   832/834        0G      2.31    0.0915         0       2.4         9       576:  50%|#####     | 27/54 [02:26<02:31,  5.60s/it]\n",
      "   832/834        0G      2.31    0.0915         0       2.4         9       576:  52%|#####1    | 28/54 [02:26<02:24,  5.56s/it]\n",
      "   832/834        0G      2.27    0.0908         0      2.36         9       576:  52%|#####1    | 28/54 [02:31<02:24,  5.56s/it]\n",
      "   832/834        0G      2.27    0.0908         0      2.36         9       576:  54%|#####3    | 29/54 [02:31<02:18,  5.53s/it]\n",
      "   832/834        0G      2.22    0.0903         0      2.32         9       576:  54%|#####3    | 29/54 [02:37<02:18,  5.53s/it]\n",
      "   832/834        0G      2.22    0.0903         0      2.32         9       576:  56%|#####5    | 30/54 [02:37<02:11,  5.47s/it]\n",
      "   832/834        0G      2.27    0.0901         0      2.36         9       576:  56%|#####5    | 30/54 [02:42<02:11,  5.47s/it]\n",
      "   832/834        0G      2.27    0.0901         0      2.36         9       576:  57%|#####7    | 31/54 [02:42<02:04,  5.42s/it]\n",
      "   832/834        0G      2.24    0.0895         0      2.33         9       576:  57%|#####7    | 31/54 [02:47<02:04,  5.42s/it]\n",
      "   832/834        0G      2.24    0.0895         0      2.33         9       576:  59%|#####9    | 32/54 [02:47<01:58,  5.38s/it]\n",
      "   832/834        0G      2.26    0.0915         0      2.35         9       576:  59%|#####9    | 32/54 [02:53<01:58,  5.38s/it]\n",
      "   832/834        0G      2.26    0.0915         0      2.35         9       576:  61%|######1   | 33/54 [02:53<01:52,  5.37s/it]\n",
      "   832/834        0G      2.22     0.092         0      2.32        10       352:  61%|######1   | 33/54 [02:55<01:52,  5.37s/it]\n",
      "   832/834        0G      2.22     0.092         0      2.32        10       352:  63%|######2   | 34/54 [02:55<01:29,  4.49s/it]\n",
      "   832/834        0G       2.2    0.0933         0      2.29        12       352:  63%|######2   | 34/54 [02:57<01:29,  4.49s/it]\n",
      "   832/834        0G       2.2    0.0933         0      2.29        12       352:  65%|######4   | 35/54 [02:57<01:11,  3.75s/it]\n",
      "   832/834        0G      2.16    0.0939         0      2.26         9       352:  65%|######4   | 35/54 [02:59<01:11,  3.75s/it]\n",
      "   832/834        0G      2.16    0.0939         0      2.26         9       352:  67%|######6   | 36/54 [02:59<00:58,  3.24s/it]\n",
      "   832/834        0G      2.14    0.0949         0      2.23         9       352:  67%|######6   | 36/54 [03:01<00:58,  3.24s/it]\n",
      "   832/834        0G      2.14    0.0949         0      2.23         9       352:  69%|######8   | 37/54 [03:01<00:49,  2.90s/it]\n",
      "   832/834        0G      2.12    0.0949         0      2.21        10       352:  69%|######8   | 37/54 [03:03<00:49,  2.90s/it]\n",
      "   832/834        0G      2.12    0.0949         0      2.21        10       352:  70%|#######   | 38/54 [03:03<00:42,  2.65s/it]\n",
      "   832/834        0G       2.1    0.0943         0       2.2         9       352:  70%|#######   | 38/54 [03:05<00:42,  2.65s/it]\n",
      "   832/834        0G       2.1    0.0943         0       2.2         9       352:  72%|#######2  | 39/54 [03:05<00:37,  2.47s/it]\n",
      "   832/834        0G      2.08    0.0938         0      2.17         9       352:  72%|#######2  | 39/54 [03:07<00:37,  2.47s/it]\n",
      "   832/834        0G      2.08    0.0938         0      2.17         9       352:  74%|#######4  | 40/54 [03:07<00:32,  2.35s/it]\n",
      "   832/834        0G      2.06    0.0947         0      2.15        12       352:  74%|#######4  | 40/54 [03:09<00:32,  2.35s/it]\n",
      "   832/834        0G      2.06    0.0947         0      2.15        12       352:  76%|#######5  | 41/54 [03:09<00:29,  2.26s/it]\n",
      "   832/834        0G      2.03     0.095         0      2.13         9       352:  76%|#######5  | 41/54 [03:11<00:29,  2.26s/it]\n",
      "   832/834        0G      2.03     0.095         0      2.13         9       352:  78%|#######7  | 42/54 [03:11<00:26,  2.20s/it]\n",
      "   832/834        0G      2.01    0.0952         0       2.1        10       352:  78%|#######7  | 42/54 [03:14<00:26,  2.20s/it]\n",
      "   832/834        0G      2.01    0.0952         0       2.1        10       352:  80%|#######9  | 43/54 [03:14<00:23,  2.16s/it]\n",
      "   832/834        0G      2.01    0.0944         0       2.1         9       352:  80%|#######9  | 43/54 [03:16<00:23,  2.16s/it]\n",
      "   832/834        0G      2.01    0.0944         0       2.1         9       352:  81%|########1 | 44/54 [03:16<00:21,  2.13s/it]\n",
      "   832/834        0G      1.99    0.0943         0      2.08         9       352:  81%|########1 | 44/54 [03:18<00:21,  2.13s/it]\n",
      "   832/834        0G      1.99    0.0943         0      2.08         9       352:  83%|########3 | 45/54 [03:18<00:18,  2.11s/it]\n",
      "   832/834        0G      1.97    0.0943         0      2.07        10       352:  83%|########3 | 45/54 [03:20<00:18,  2.11s/it]\n",
      "   832/834        0G      1.97    0.0943         0      2.07        10       352:  85%|########5 | 46/54 [03:20<00:16,  2.09s/it]\n",
      "   832/834        0G      1.96    0.0946         0      2.05        11       352:  85%|########5 | 46/54 [03:22<00:16,  2.09s/it]\n",
      "   832/834        0G      1.96    0.0946         0      2.05        11       352:  87%|########7 | 47/54 [03:22<00:14,  2.09s/it]\n",
      "   832/834        0G      1.94    0.0946         0      2.04         9       352:  87%|########7 | 47/54 [03:24<00:14,  2.09s/it]\n",
      "   832/834        0G      1.94    0.0946         0      2.04         9       352:  89%|########8 | 48/54 [03:24<00:12,  2.08s/it]\n",
      "   832/834        0G      1.93    0.0943         0      2.02         9       352:  89%|########8 | 48/54 [03:26<00:12,  2.08s/it]\n",
      "   832/834        0G      1.93    0.0943         0      2.02         9       352:  91%|######### | 49/54 [03:26<00:10,  2.07s/it]\n",
      "   832/834        0G      1.92    0.0938         0      2.01        11       352:  91%|######### | 49/54 [03:28<00:10,  2.07s/it]\n",
      "   832/834        0G      1.92    0.0938         0      2.01        11       352:  93%|#########2| 50/54 [03:28<00:08,  2.06s/it]\n",
      "   832/834        0G       1.9    0.0941         0         2        11       352:  93%|#########2| 50/54 [03:30<00:08,  2.06s/it]\n",
      "   832/834        0G       1.9    0.0941         0         2        11       352:  94%|#########4| 51/54 [03:30<00:06,  2.07s/it]\n",
      "   832/834        0G      1.89    0.0948         0      1.99        10       352:  94%|#########4| 51/54 [03:32<00:06,  2.07s/it]\n",
      "   832/834        0G      1.89    0.0948         0      1.99        10       352:  96%|#########6| 52/54 [03:32<00:04,  2.06s/it]\n",
      "   832/834        0G      1.88     0.095         0      1.98        12       352:  96%|#########6| 52/54 [03:34<00:04,  2.06s/it]\n",
      "   832/834        0G      1.88     0.095         0      1.98        12       352:  98%|#########8| 53/54 [03:34<00:02,  2.08s/it]\n",
      "   832/834        0G      1.87    0.0944         0      1.97         3       352:  98%|#########8| 53/54 [03:35<00:02,  2.08s/it]\n",
      "   832/834        0G      1.87    0.0944         0      1.97         3       352: 100%|##########| 54/54 [03:35<00:00,  1.70s/it]\n",
      "   832/834        0G      1.87    0.0944         0      1.97         3       352: 100%|##########| 54/54 [03:36<00:00,  4.01s/it]\n",
      "\n",
      "               Class    Images   Targets         P         R   mAP@0.5        F1:   0%|          | 0/14 [00:00<?, ?it/s]2024-03-04 17:11:05.261979: I tensorflow/core/util/port.cc:113] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
      "WARNING:tensorflow:From C:\\Users\\mit017\\anaconda3\\Lib\\site-packages\\keras\\src\\losses.py:2976: The name tf.losses.sparse_softmax_cross_entropy is deprecated. Please use tf.compat.v1.losses.sparse_softmax_cross_entropy instead.\n",
      "\n",
      "2024-03-04 17:11:16.846939: I tensorflow/core/util/port.cc:113] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
      "WARNING:tensorflow:From C:\\Users\\mit017\\anaconda3\\Lib\\site-packages\\keras\\src\\losses.py:2976: The name tf.losses.sparse_softmax_cross_entropy is deprecated. Please use tf.compat.v1.losses.sparse_softmax_cross_entropy instead.\n",
      "\n",
      "2024-03-04 17:11:26.968078: I tensorflow/core/util/port.cc:113] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
      "WARNING:tensorflow:From C:\\Users\\mit017\\anaconda3\\Lib\\site-packages\\keras\\src\\losses.py:2976: The name tf.losses.sparse_softmax_cross_entropy is deprecated. Please use tf.compat.v1.losses.sparse_softmax_cross_entropy instead.\n",
      "\n",
      "\n",
      "               Class    Images   Targets         P         R   mAP@0.5        F1:   7%|7         | 1/14 [00:34<07:32, 34.80s/it]\n",
      "               Class    Images   Targets         P         R   mAP@0.5        F1:  14%|#4        | 2/14 [00:36<03:06, 15.54s/it]\n",
      "               Class    Images   Targets         P         R   mAP@0.5        F1:  21%|##1       | 3/14 [00:38<01:43,  9.41s/it]\n",
      "               Class    Images   Targets         P         R   mAP@0.5        F1:  29%|##8       | 4/14 [00:41<01:05,  6.51s/it]\n",
      "               Class    Images   Targets         P         R   mAP@0.5        F1:  36%|###5      | 5/14 [00:43<00:44,  4.93s/it]\n",
      "               Class    Images   Targets         P         R   mAP@0.5        F1:  43%|####2     | 6/14 [00:45<00:31,  3.98s/it]\n",
      "               Class    Images   Targets         P         R   mAP@0.5        F1:  50%|#####     | 7/14 [00:47<00:23,  3.39s/it]\n",
      "               Class    Images   Targets         P         R   mAP@0.5        F1:  57%|#####7    | 8/14 [00:49<00:18,  3.01s/it]\n",
      "               Class    Images   Targets         P         R   mAP@0.5        F1:  64%|######4   | 9/14 [00:51<00:13,  2.73s/it]\n",
      "               Class    Images   Targets         P         R   mAP@0.5        F1:  71%|#######1  | 10/14 [00:53<00:10,  2.54s/it]\n",
      "               Class    Images   Targets         P         R   mAP@0.5        F1:  79%|#######8  | 11/14 [00:56<00:07,  2.40s/it]\n",
      "               Class    Images   Targets         P         R   mAP@0.5        F1:  86%|########5 | 12/14 [00:58<00:04,  2.33s/it]\n",
      "               Class    Images   Targets         P         R   mAP@0.5        F1:  93%|#########2| 13/14 [01:00<00:02,  2.25s/it]\n",
      "               Class    Images   Targets         P         R   mAP@0.5        F1: 100%|##########| 14/14 [01:00<00:00,  1.78s/it]\n",
      "               Class    Images   Targets         P         R   mAP@0.5        F1: 100%|##########| 14/14 [01:01<00:00,  4.42s/it]\n",
      "2024-03-04 17:12:06.731875: I tensorflow/core/util/port.cc:113] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
      "WARNING:tensorflow:From C:\\Users\\mit017\\anaconda3\\Lib\\site-packages\\keras\\src\\losses.py:2976: The name tf.losses.sparse_softmax_cross_entropy is deprecated. Please use tf.compat.v1.losses.sparse_softmax_cross_entropy instead.\n",
      "\n",
      "2024-03-04 17:12:16.817840: I tensorflow/core/util/port.cc:113] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
      "WARNING:tensorflow:From C:\\Users\\mit017\\anaconda3\\Lib\\site-packages\\keras\\src\\losses.py:2976: The name tf.losses.sparse_softmax_cross_entropy is deprecated. Please use tf.compat.v1.losses.sparse_softmax_cross_entropy instead.\n",
      "\n",
      "2024-03-04 17:12:27.176727: I tensorflow/core/util/port.cc:113] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
      "WARNING:tensorflow:From C:\\Users\\mit017\\anaconda3\\Lib\\site-packages\\keras\\src\\losses.py:2976: The name tf.losses.sparse_softmax_cross_entropy is deprecated. Please use tf.compat.v1.losses.sparse_softmax_cross_entropy instead.\n",
      "\n",
      "\n",
      "  0%|          | 0/54 [00:00<?, ?it/s]\n",
      "   833/834        0G      1.45    0.0826         0      1.53        11       480:   0%|          | 0/54 [00:04<?, ?it/s]\n",
      "   833/834        0G      1.45    0.0826         0      1.53        11       480:   2%|1         | 1/54 [00:04<03:36,  4.09s/it]\n",
      "   833/834        0G      2.32    0.0948         0      2.42        10       480:   2%|1         | 1/54 [00:07<03:36,  4.09s/it]\n",
      "   833/834        0G      2.32    0.0948         0      2.42        10       480:   4%|3         | 2/54 [00:07<03:19,  3.84s/it]\n",
      "   833/834        0G      2.31     0.127         0      2.44        12       480:   4%|3         | 2/54 [00:11<03:19,  3.84s/it]\n",
      "   833/834        0G      2.31     0.127         0      2.44        12       480:   6%|5         | 3/54 [00:11<03:12,  3.77s/it]\n",
      "   833/834        0G      2.01     0.119         0      2.12        10       480:   6%|5         | 3/54 [00:15<03:12,  3.77s/it]\n",
      "   833/834        0G      2.01     0.119         0      2.12        10       480:   7%|7         | 4/54 [00:15<03:07,  3.74s/it]\n",
      "   833/834        0G      1.87     0.113         0      1.98         9       480:   7%|7         | 4/54 [00:18<03:07,  3.74s/it]\n",
      "   833/834        0G      1.87     0.113         0      1.98         9       480:   9%|9         | 5/54 [00:18<03:02,  3.73s/it]\n",
      "   833/834        0G      1.74     0.114         0      1.86        12       480:   9%|9         | 5/54 [00:22<03:02,  3.73s/it]\n",
      "   833/834        0G      1.74     0.114         0      1.86        12       480:  11%|#1        | 6/54 [00:22<02:58,  3.72s/it]\n",
      "   833/834        0G      1.67     0.111         0      1.78        10       480:  11%|#1        | 6/54 [00:26<02:58,  3.72s/it]\n",
      "   833/834        0G      1.67     0.111         0      1.78        10       480:  13%|#2        | 7/54 [00:26<02:55,  3.73s/it]\n",
      "   833/834        0G      1.61     0.105         0      1.72         8       480:  13%|#2        | 7/54 [00:29<02:55,  3.73s/it]\n",
      "   833/834        0G      1.61     0.105         0      1.72         8       480:  15%|#4        | 8/54 [00:29<02:50,  3.71s/it]\n",
      "   833/834        0G      1.55     0.101         0      1.65         8       480:  15%|#4        | 8/54 [00:33<02:50,  3.71s/it]\n",
      "   833/834        0G      1.55     0.101         0      1.65         8       480:  17%|#6        | 9/54 [00:33<02:46,  3.70s/it]\n",
      "   833/834        0G      1.49    0.0983         0      1.59         9       480:  17%|#6        | 9/54 [00:37<02:46,  3.70s/it]\n",
      "   833/834        0G      1.49    0.0983         0      1.59         9       480:  19%|#8        | 10/54 [00:37<02:42,  3.70s/it]\n",
      "   833/834        0G      1.46    0.0962         0      1.55         9       480:  19%|#8        | 10/54 [00:41<02:42,  3.70s/it]\n",
      "   833/834        0G      1.46    0.0962         0      1.55         9       480:  20%|##        | 11/54 [00:41<02:38,  3.69s/it]\n",
      "   833/834        0G       1.6    0.0969         0      1.69         9       480:  20%|##        | 11/54 [00:44<02:38,  3.69s/it]\n",
      "   833/834        0G       1.6    0.0969         0      1.69         9       480:  22%|##2       | 12/54 [00:44<02:34,  3.69s/it]\n",
      "   833/834        0G      1.57     0.097         0      1.66        11       480:  22%|##2       | 12/54 [00:48<02:34,  3.69s/it]\n",
      "   833/834        0G      1.57     0.097         0      1.66        11       480:  24%|##4       | 13/54 [00:48<02:31,  3.69s/it]\n",
      "   833/834        0G      1.55    0.0956         0      1.65        10       480:  24%|##4       | 13/54 [00:52<02:31,  3.69s/it]\n",
      "   833/834        0G      1.55    0.0956         0      1.65        10       480:  26%|##5       | 14/54 [00:52<02:27,  3.70s/it]\n",
      "   833/834        0G      1.53    0.0943         0      1.62         9       480:  26%|##5       | 14/54 [00:55<02:27,  3.70s/it]\n",
      "   833/834        0G      1.53    0.0943         0      1.62         9       480:  28%|##7       | 15/54 [00:55<02:23,  3.69s/it]\n",
      "   833/834        0G      1.51    0.0931         0       1.6         9       480:  28%|##7       | 15/54 [00:59<02:23,  3.69s/it]\n",
      "   833/834        0G      1.51    0.0931         0       1.6         9       480:  30%|##9       | 16/54 [00:59<02:20,  3.70s/it]\n",
      "   833/834        0G      1.61    0.0946         0       1.7        11       480:  30%|##9       | 16/54 [01:03<02:20,  3.70s/it]\n",
      "   833/834        0G      1.61    0.0946         0       1.7        11       480:  31%|###1      | 17/54 [01:03<02:16,  3.68s/it]\n",
      "   833/834        0G      1.58    0.0928         0      1.67         8       480:  31%|###1      | 17/54 [01:06<02:16,  3.68s/it]\n",
      "   833/834        0G      1.58    0.0928         0      1.67         8       480:  33%|###3      | 18/54 [01:06<02:12,  3.68s/it]\n",
      "   833/834        0G      1.56    0.0931         0      1.65        12       480:  33%|###3      | 18/54 [01:10<02:12,  3.68s/it]\n",
      "   833/834        0G      1.56    0.0931         0      1.65        12       480:  35%|###5      | 19/54 [01:10<02:08,  3.68s/it]\n",
      "   833/834        0G      1.55    0.0915         0      1.64         9       480:  35%|###5      | 19/54 [01:14<02:08,  3.68s/it]\n",
      "   833/834        0G      1.55    0.0915         0      1.64         9       480:  37%|###7      | 20/54 [01:14<02:04,  3.67s/it]\n",
      "   833/834        0G      1.54    0.0925         0      1.63        12       480:  37%|###7      | 20/54 [01:17<02:04,  3.67s/it]\n",
      "   833/834        0G      1.54    0.0925         0      1.63        12       480:  39%|###8      | 21/54 [01:17<02:01,  3.67s/it]\n",
      "   833/834        0G      1.52    0.0932         0      1.62        13       512:  39%|###8      | 21/54 [01:22<02:01,  3.67s/it]\n",
      "   833/834        0G      1.52    0.0932         0      1.62        13       512:  41%|####      | 22/54 [01:22<02:05,  3.91s/it]\n",
      "   833/834        0G      1.57     0.094         0      1.66         9       512:  41%|####      | 22/54 [01:26<02:05,  3.91s/it]\n",
      "   833/834        0G      1.57     0.094         0      1.66         9       512:  43%|####2     | 23/54 [01:26<02:04,  4.01s/it]\n",
      "   833/834        0G      1.54    0.0936         0      1.64         9       512:  43%|####2     | 23/54 [01:30<02:04,  4.01s/it]\n",
      "   833/834        0G      1.54    0.0936         0      1.64         9       512:  44%|####4     | 24/54 [01:30<02:01,  4.06s/it]\n",
      "   833/834        0G      1.52    0.0931         0      1.62        10       512:  44%|####4     | 24/54 [01:34<02:01,  4.06s/it]\n",
      "   833/834        0G      1.52    0.0931         0      1.62        10       512:  46%|####6     | 25/54 [01:34<01:58,  4.09s/it]\n",
      "   833/834        0G      1.56    0.0944         0      1.65        10       512:  46%|####6     | 25/54 [01:39<01:58,  4.09s/it]\n",
      "   833/834        0G      1.56    0.0944         0      1.65        10       512:  48%|####8     | 26/54 [01:39<01:55,  4.12s/it]\n",
      "   833/834        0G      1.54    0.0947         0      1.64        12       512:  48%|####8     | 26/54 [01:43<01:55,  4.12s/it]\n",
      "   833/834        0G      1.54    0.0947         0      1.64        12       512:  50%|#####     | 27/54 [01:43<01:51,  4.14s/it]\n",
      "   833/834        0G      1.53    0.0934         0      1.62         9       512:  50%|#####     | 27/54 [01:47<01:51,  4.14s/it]\n",
      "   833/834        0G      1.53    0.0934         0      1.62         9       512:  52%|#####1    | 28/54 [01:47<01:47,  4.15s/it]\n",
      "   833/834        0G      1.62    0.0937         0      1.71         9       512:  52%|#####1    | 28/54 [01:51<01:47,  4.15s/it]\n",
      "   833/834        0G      1.62    0.0937         0      1.71         9       512:  54%|#####3    | 29/54 [01:51<01:44,  4.16s/it]\n",
      "   833/834        0G       1.6     0.093         0      1.69         9       512:  54%|#####3    | 29/54 [01:55<01:44,  4.16s/it]\n",
      "   833/834        0G       1.6     0.093         0      1.69         9       512:  56%|#####5    | 30/54 [01:55<01:39,  4.17s/it]\n",
      "   833/834        0G      1.66    0.0945         0      1.75        12       512:  56%|#####5    | 30/54 [02:00<01:39,  4.17s/it]\n",
      "   833/834        0G      1.66    0.0945         0      1.75        12       512:  57%|#####7    | 31/54 [02:00<01:36,  4.19s/it]\n",
      "   833/834        0G      1.65    0.0935         0      1.74         9       512:  57%|#####7    | 31/54 [02:04<01:36,  4.19s/it]\n",
      "   833/834        0G      1.65    0.0935         0      1.74         9       512:  59%|#####9    | 32/54 [02:04<01:32,  4.19s/it]\n",
      "   833/834        0G      1.71    0.0934         0      1.81         9       512:  59%|#####9    | 32/54 [02:08<01:32,  4.19s/it]\n",
      "   833/834        0G      1.71    0.0934         0      1.81         9       512:  61%|######1   | 33/54 [02:08<01:28,  4.20s/it]\n",
      "   833/834        0G      1.74    0.0943         0      1.84        10       512:  61%|######1   | 33/54 [02:12<01:28,  4.20s/it]\n",
      "   833/834        0G      1.74    0.0943         0      1.84        10       512:  63%|######2   | 34/54 [02:12<01:23,  4.20s/it]\n",
      "   833/834        0G      1.72    0.0937         0      1.82         9       512:  63%|######2   | 34/54 [02:16<01:23,  4.20s/it]\n",
      "   833/834        0G      1.72    0.0937         0      1.82         9       512:  65%|######4   | 35/54 [02:16<01:19,  4.19s/it]\n",
      "   833/834        0G      1.77    0.0939         0      1.86         9       512:  65%|######4   | 35/54 [02:21<01:19,  4.19s/it]\n",
      "   833/834        0G      1.77    0.0939         0      1.86         9       512:  67%|######6   | 36/54 [02:21<01:15,  4.20s/it]\n",
      "   833/834        0G      1.75    0.0932         0      1.84         8       512:  67%|######6   | 36/54 [02:25<01:15,  4.20s/it]\n",
      "   833/834        0G      1.75    0.0932         0      1.84         8       512:  69%|######8   | 37/54 [02:25<01:11,  4.20s/it]\n",
      "   833/834        0G      1.73    0.0925         0      1.83         9       512:  69%|######8   | 37/54 [02:29<01:11,  4.20s/it]\n",
      "   833/834        0G      1.73    0.0925         0      1.83         9       512:  70%|#######   | 38/54 [02:29<01:07,  4.20s/it]\n",
      "   833/834        0G      1.72     0.092         0      1.81         9       512:  70%|#######   | 38/54 [02:33<01:07,  4.20s/it]\n",
      "   833/834        0G      1.72     0.092         0      1.81         9       512:  72%|#######2  | 39/54 [02:33<01:02,  4.19s/it]\n",
      "   833/834        0G      1.71    0.0916         0       1.8        11       512:  72%|#######2  | 39/54 [02:37<01:02,  4.19s/it]\n",
      "   833/834        0G      1.71    0.0916         0       1.8        11       512:  74%|#######4  | 40/54 [02:37<00:58,  4.19s/it]\n",
      "   833/834        0G      1.73    0.0916         0      1.82         9       512:  74%|#######4  | 40/54 [02:41<00:58,  4.19s/it]\n",
      "   833/834        0G      1.73    0.0916         0      1.82         9       512:  76%|#######5  | 41/54 [02:41<00:54,  4.18s/it]\n",
      "   833/834        0G      1.72    0.0919         0      1.81         9       512:  76%|#######5  | 41/54 [02:46<00:54,  4.18s/it]\n",
      "   833/834        0G      1.72    0.0919         0      1.81         9       512:  78%|#######7  | 42/54 [02:46<00:50,  4.18s/it]\n",
      "   833/834        0G      1.71    0.0929         0       1.8        12       480:  78%|#######7  | 42/54 [02:50<00:50,  4.18s/it]\n",
      "   833/834        0G      1.71    0.0929         0       1.8        12       480:  80%|#######9  | 43/54 [02:50<00:45,  4.11s/it]\n",
      "   833/834        0G       1.7    0.0931         0      1.79        11       480:  80%|#######9  | 43/54 [02:53<00:45,  4.11s/it]\n",
      "   833/834        0G       1.7    0.0931         0      1.79        11       480:  81%|########1 | 44/54 [02:53<00:39,  3.97s/it]\n",
      "   833/834        0G      1.68    0.0931         0      1.78         9       480:  81%|########1 | 44/54 [02:57<00:39,  3.97s/it]\n",
      "   833/834        0G      1.68    0.0931         0      1.78         9       480:  83%|########3 | 45/54 [02:57<00:34,  3.86s/it]\n",
      "   833/834        0G      1.67     0.093         0      1.76         9       480:  83%|########3 | 45/54 [03:01<00:34,  3.86s/it]\n",
      "   833/834        0G      1.67     0.093         0      1.76         9       480:  85%|########5 | 46/54 [03:01<00:30,  3.82s/it]\n",
      "   833/834        0G      1.66    0.0927         0      1.76         9       480:  85%|########5 | 46/54 [03:04<00:30,  3.82s/it]\n",
      "   833/834        0G      1.66    0.0927         0      1.76         9       480:  87%|########7 | 47/54 [03:04<00:26,  3.77s/it]\n",
      "   833/834        0G      1.65    0.0925         0      1.74         9       480:  87%|########7 | 47/54 [03:08<00:26,  3.77s/it]\n",
      "   833/834        0G      1.65    0.0925         0      1.74         9       480:  89%|########8 | 48/54 [03:08<00:22,  3.73s/it]\n",
      "   833/834        0G      1.64    0.0924         0      1.73         9       480:  89%|########8 | 48/54 [03:11<00:22,  3.73s/it]\n",
      "   833/834        0G      1.64    0.0924         0      1.73         9       480:  91%|######### | 49/54 [03:11<00:18,  3.70s/it]\n",
      "   833/834        0G      1.63     0.092         0      1.73        11       480:  91%|######### | 49/54 [03:15<00:18,  3.70s/it]\n",
      "   833/834        0G      1.63     0.092         0      1.73        11       480:  93%|#########2| 50/54 [03:15<00:14,  3.68s/it]\n",
      "   833/834        0G      1.62    0.0924         0      1.72        12       480:  93%|#########2| 50/54 [03:19<00:14,  3.68s/it]\n",
      "   833/834        0G      1.62    0.0924         0      1.72        12       480:  94%|#########4| 51/54 [03:19<00:11,  3.67s/it]\n",
      "   833/834        0G      1.61    0.0922         0       1.7        10       480:  94%|#########4| 51/54 [03:22<00:11,  3.67s/it]\n",
      "   833/834        0G      1.61    0.0922         0       1.7        10       480:  96%|#########6| 52/54 [03:22<00:07,  3.67s/it]\n",
      "   833/834        0G       1.6    0.0927         0      1.69        12       480:  96%|#########6| 52/54 [03:26<00:07,  3.67s/it]\n",
      "   833/834        0G       1.6    0.0927         0      1.69        12       480:  98%|#########8| 53/54 [03:26<00:03,  3.69s/it]\n",
      "   833/834        0G      1.59    0.0921         0      1.68         3       480:  98%|#########8| 53/54 [03:28<00:03,  3.69s/it]\n",
      "   833/834        0G      1.59    0.0921         0      1.68         3       480: 100%|##########| 54/54 [03:28<00:00,  3.01s/it]\n",
      "   833/834        0G      1.59    0.0921         0      1.68         3       480: 100%|##########| 54/54 [03:29<00:00,  3.87s/it]\n",
      "\n",
      "               Class    Images   Targets         P         R   mAP@0.5        F1:   0%|          | 0/14 [00:00<?, ?it/s]2024-03-04 17:16:06.073335: I tensorflow/core/util/port.cc:113] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
      "WARNING:tensorflow:From C:\\Users\\mit017\\anaconda3\\Lib\\site-packages\\keras\\src\\losses.py:2976: The name tf.losses.sparse_softmax_cross_entropy is deprecated. Please use tf.compat.v1.losses.sparse_softmax_cross_entropy instead.\n",
      "\n",
      "2024-03-04 17:16:16.066369: I tensorflow/core/util/port.cc:113] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
      "WARNING:tensorflow:From C:\\Users\\mit017\\anaconda3\\Lib\\site-packages\\keras\\src\\losses.py:2976: The name tf.losses.sparse_softmax_cross_entropy is deprecated. Please use tf.compat.v1.losses.sparse_softmax_cross_entropy instead.\n",
      "\n",
      "2024-03-04 17:16:26.025586: I tensorflow/core/util/port.cc:113] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
      "WARNING:tensorflow:From C:\\Users\\mit017\\anaconda3\\Lib\\site-packages\\keras\\src\\losses.py:2976: The name tf.losses.sparse_softmax_cross_entropy is deprecated. Please use tf.compat.v1.losses.sparse_softmax_cross_entropy instead.\n",
      "\n",
      "\n",
      "               Class    Images   Targets         P         R   mAP@0.5        F1:   7%|7         | 1/14 [00:32<07:00, 32.35s/it]\n",
      "               Class    Images   Targets         P         R   mAP@0.5        F1:  14%|#4        | 2/14 [00:34<02:54, 14.53s/it]\n",
      "               Class    Images   Targets         P         R   mAP@0.5        F1:  21%|##1       | 3/14 [00:36<01:37,  8.84s/it]\n",
      "               Class    Images   Targets         P         R   mAP@0.5        F1:  29%|##8       | 4/14 [00:38<01:01,  6.17s/it]\n",
      "               Class    Images   Targets         P         R   mAP@0.5        F1:  36%|###5      | 5/14 [00:40<00:42,  4.70s/it]\n",
      "               Class    Images   Targets         P         R   mAP@0.5        F1:  43%|####2     | 6/14 [00:42<00:30,  3.81s/it]\n",
      "               Class    Images   Targets         P         R   mAP@0.5        F1:  50%|#####     | 7/14 [00:44<00:22,  3.25s/it]\n",
      "               Class    Images   Targets         P         R   mAP@0.5        F1:  57%|#####7    | 8/14 [00:46<00:17,  2.89s/it]\n",
      "               Class    Images   Targets         P         R   mAP@0.5        F1:  64%|######4   | 9/14 [00:49<00:13,  2.64s/it]\n",
      "               Class    Images   Targets         P         R   mAP@0.5        F1:  71%|#######1  | 10/14 [00:51<00:09,  2.46s/it]\n",
      "               Class    Images   Targets         P         R   mAP@0.5        F1:  79%|#######8  | 11/14 [00:53<00:07,  2.34s/it]\n",
      "               Class    Images   Targets         P         R   mAP@0.5        F1:  86%|########5 | 12/14 [00:55<00:04,  2.27s/it]\n",
      "               Class    Images   Targets         P         R   mAP@0.5        F1:  93%|#########2| 13/14 [00:57<00:02,  2.22s/it]\n",
      "               Class    Images   Targets         P         R   mAP@0.5        F1: 100%|##########| 14/14 [00:58<00:00,  1.78s/it]\n",
      "               Class    Images   Targets         P         R   mAP@0.5        F1: 100%|##########| 14/14 [00:59<00:00,  4.23s/it]\n",
      "2024-03-04 17:17:05.612291: I tensorflow/core/util/port.cc:113] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
      "WARNING:tensorflow:From C:\\Users\\mit017\\anaconda3\\Lib\\site-packages\\keras\\src\\losses.py:2976: The name tf.losses.sparse_softmax_cross_entropy is deprecated. Please use tf.compat.v1.losses.sparse_softmax_cross_entropy instead.\n",
      "\n",
      "2024-03-04 17:17:16.631384: I tensorflow/core/util/port.cc:113] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
      "WARNING:tensorflow:From C:\\Users\\mit017\\anaconda3\\Lib\\site-packages\\keras\\src\\losses.py:2976: The name tf.losses.sparse_softmax_cross_entropy is deprecated. Please use tf.compat.v1.losses.sparse_softmax_cross_entropy instead.\n",
      "\n",
      "2024-03-04 17:17:27.293432: I tensorflow/core/util/port.cc:113] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
      "WARNING:tensorflow:From C:\\Users\\mit017\\anaconda3\\Lib\\site-packages\\keras\\src\\losses.py:2976: The name tf.losses.sparse_softmax_cross_entropy is deprecated. Please use tf.compat.v1.losses.sparse_softmax_cross_entropy instead.\n",
      "\n",
      "\n",
      "  0%|          | 0/54 [00:00<?, ?it/s]\n",
      "   834/834        0G       1.1    0.0695         0      1.17         9       480:   0%|          | 0/54 [00:04<?, ?it/s]\n",
      "   834/834        0G       1.1    0.0695         0      1.17         9       480:   2%|1         | 1/54 [00:04<03:45,  4.25s/it]\n",
      "   834/834        0G      1.12    0.0733         0      1.19         9       480:   2%|1         | 1/54 [00:08<03:45,  4.25s/it]\n",
      "   834/834        0G      1.12    0.0733         0      1.19         9       480:   4%|3         | 2/54 [00:08<03:30,  4.05s/it]\n",
      "   834/834        0G      2.07    0.0782         0      2.15         9       480:   4%|3         | 2/54 [00:12<03:30,  4.05s/it]\n",
      "   834/834        0G      2.07    0.0782         0      2.15         9       480:   6%|5         | 3/54 [00:12<03:23,  3.99s/it]\n",
      "   834/834        0G      1.86    0.0778         0      1.94         9       480:   6%|5         | 3/54 [00:15<03:23,  3.99s/it]\n",
      "   834/834        0G      1.86    0.0778         0      1.94         9       480:   7%|7         | 4/54 [00:15<03:16,  3.94s/it]\n",
      "   834/834        0G      1.74    0.0759         0      1.82         9       480:   7%|7         | 4/54 [00:19<03:16,  3.94s/it]\n",
      "   834/834        0G      1.74    0.0759         0      1.82         9       480:   9%|9         | 5/54 [00:19<03:10,  3.89s/it]\n",
      "   834/834        0G      1.67    0.0796         0      1.75         9       480:   9%|9         | 5/54 [00:23<03:10,  3.89s/it]\n",
      "   834/834        0G      1.67    0.0796         0      1.75         9       480:  11%|#1        | 6/54 [00:23<03:04,  3.84s/it]\n",
      "   834/834        0G      1.58    0.0812         0      1.66        10       480:  11%|#1        | 6/54 [00:27<03:04,  3.84s/it]\n",
      "   834/834        0G      1.58    0.0812         0      1.66        10       480:  13%|#2        | 7/54 [00:27<03:00,  3.83s/it]\n",
      "   834/834        0G      1.55    0.0797         0      1.63         9       480:  13%|#2        | 7/54 [00:31<03:00,  3.83s/it]\n",
      "   834/834        0G      1.55    0.0797         0      1.63         9       480:  15%|#4        | 8/54 [00:31<02:55,  3.82s/it]\n",
      "   834/834        0G      1.52     0.084         0       1.6        13       480:  15%|#4        | 8/54 [00:34<02:55,  3.82s/it]\n",
      "   834/834        0G      1.52     0.084         0       1.6        13       480:  17%|#6        | 9/54 [00:34<02:50,  3.79s/it]\n",
      "   834/834        0G      1.71    0.0849         0       1.8         9       608:  17%|#6        | 9/54 [00:41<02:50,  3.79s/it]\n",
      "   834/834        0G      1.71    0.0849         0       1.8         9       608:  19%|#8        | 10/54 [00:41<03:22,  4.61s/it]\n",
      "   834/834        0G      1.87    0.0844         0      1.96        10       608:  19%|#8        | 10/54 [00:47<03:22,  4.61s/it]\n",
      "   834/834        0G      1.87    0.0844         0      1.96        10       608:  20%|##        | 11/54 [00:47<03:36,  5.03s/it]\n",
      "   834/834        0G      1.82    0.0841         0       1.9        12       608:  20%|##        | 11/54 [00:53<03:36,  5.03s/it]\n",
      "   834/834        0G      1.82    0.0841         0       1.9        12       608:  22%|##2       | 12/54 [00:53<03:43,  5.32s/it]\n",
      "   834/834        0G      1.92    0.0853         0         2         9       608:  22%|##2       | 12/54 [00:59<03:43,  5.32s/it]\n",
      "   834/834        0G      1.92    0.0853         0         2         9       608:  24%|##4       | 13/54 [00:59<03:47,  5.54s/it]\n",
      "   834/834        0G      1.98    0.0869         0      2.07         9       608:  24%|##4       | 13/54 [01:05<03:47,  5.54s/it]\n",
      "   834/834        0G      1.98    0.0869         0      2.07         9       608:  26%|##5       | 14/54 [01:05<03:49,  5.73s/it]\n",
      "   834/834        0G      2.06    0.0883         0      2.15        12       608:  26%|##5       | 14/54 [01:11<03:49,  5.73s/it]\n",
      "   834/834        0G      2.06    0.0883         0      2.15        12       608:  28%|##7       | 15/54 [01:11<03:46,  5.80s/it]\n",
      "   834/834        0G      2.14    0.0933         0      2.23        10       608:  28%|##7       | 15/54 [01:17<03:46,  5.80s/it]\n",
      "   834/834        0G      2.14    0.0933         0      2.23        10       608:  30%|##9       | 16/54 [01:17<03:41,  5.84s/it]\n",
      "   834/834        0G       2.2    0.0949         0      2.29        11       608:  30%|##9       | 16/54 [01:23<03:41,  5.84s/it]\n",
      "   834/834        0G       2.2    0.0949         0      2.29        11       608:  31%|###1      | 17/54 [01:23<03:37,  5.87s/it]\n",
      "   834/834        0G      2.24    0.0979         0      2.34        10       608:  31%|###1      | 17/54 [01:29<03:37,  5.87s/it]\n",
      "   834/834        0G      2.24    0.0979         0      2.34        10       608:  33%|###3      | 18/54 [01:29<03:32,  5.91s/it]\n",
      "   834/834        0G      2.28     0.101         0      2.38         9       608:  33%|###3      | 18/54 [01:35<03:32,  5.91s/it]\n",
      "   834/834        0G      2.28     0.101         0      2.38         9       608:  35%|###5      | 19/54 [01:35<03:28,  5.96s/it]\n",
      "   834/834        0G      2.29     0.101         0      2.39        12       608:  35%|###5      | 19/54 [01:41<03:28,  5.96s/it]\n",
      "   834/834        0G      2.29     0.101         0      2.39        12       608:  37%|###7      | 20/54 [01:41<03:22,  5.95s/it]\n",
      "   834/834        0G      2.23    0.0997         0      2.33        10       608:  37%|###7      | 20/54 [01:47<03:22,  5.95s/it]\n",
      "   834/834        0G      2.23    0.0997         0      2.33        10       608:  39%|###8      | 21/54 [01:47<03:17,  5.98s/it]\n",
      "   834/834        0G      2.18    0.0993         0      2.28        11       608:  39%|###8      | 21/54 [01:53<03:17,  5.98s/it]\n",
      "   834/834        0G      2.18    0.0993         0      2.28        11       608:  41%|####      | 22/54 [01:53<03:11,  5.97s/it]\n",
      "   834/834        0G      2.22    0.0994         0      2.31         9       608:  41%|####      | 22/54 [01:59<03:11,  5.97s/it]\n",
      "   834/834        0G      2.22    0.0994         0      2.31         9       608:  43%|####2     | 23/54 [01:59<03:05,  5.99s/it]\n",
      "   834/834        0G      2.28    0.0988         0      2.38         9       608:  43%|####2     | 23/54 [02:05<03:05,  5.99s/it]\n",
      "   834/834        0G      2.28    0.0988         0      2.38         9       608:  44%|####4     | 24/54 [02:05<02:59,  5.98s/it]\n",
      "   834/834        0G      2.23    0.0977         0      2.32         9       608:  44%|####4     | 24/54 [02:11<02:59,  5.98s/it]\n",
      "   834/834        0G      2.23    0.0977         0      2.32         9       608:  46%|####6     | 25/54 [02:11<02:53,  5.99s/it]\n",
      "   834/834        0G      2.27    0.0969         0      2.37        10       608:  46%|####6     | 25/54 [02:17<02:53,  5.99s/it]\n",
      "   834/834        0G      2.27    0.0969         0      2.37        10       608:  48%|####8     | 26/54 [02:17<02:47,  5.97s/it]\n",
      "   834/834        0G      2.32    0.0974         0      2.41        10       608:  48%|####8     | 26/54 [02:23<02:47,  5.97s/it]\n",
      "   834/834        0G      2.32    0.0974         0      2.41        10       608:  50%|#####     | 27/54 [02:23<02:41,  5.98s/it]\n",
      "   834/834        0G      2.37    0.0969         0      2.47         9       608:  50%|#####     | 27/54 [02:29<02:41,  5.98s/it]\n",
      "   834/834        0G      2.37    0.0969         0      2.47         9       608:  52%|#####1    | 28/54 [02:29<02:35,  5.98s/it]\n",
      "   834/834        0G      2.39    0.0978         0      2.49        11       608:  52%|#####1    | 28/54 [02:35<02:35,  5.98s/it]\n",
      "   834/834        0G      2.39    0.0978         0      2.49        11       608:  54%|#####3    | 29/54 [02:35<02:29,  5.97s/it]\n",
      "   834/834        0G      2.43    0.0979         0      2.53        10       608:  54%|#####3    | 29/54 [02:41<02:29,  5.97s/it]\n",
      "   834/834        0G      2.43    0.0979         0      2.53        10       608:  56%|#####5    | 30/54 [02:41<02:23,  5.97s/it]\n",
      "   834/834        0G      2.44    0.0984         0      2.54         9       640:  56%|#####5    | 30/54 [02:48<02:23,  5.97s/it]\n",
      "   834/834        0G      2.44    0.0984         0      2.54         9       640:  57%|#####7    | 31/54 [02:48<02:23,  6.26s/it]\n",
      "   834/834        0G      2.46       0.1         0      2.56         9       640:  57%|#####7    | 31/54 [02:54<02:23,  6.26s/it]\n",
      "   834/834        0G      2.46       0.1         0      2.56         9       640:  59%|#####9    | 32/54 [02:54<02:19,  6.35s/it]\n",
      "   834/834        0G      2.48       0.1         0      2.58         9       640:  59%|#####9    | 32/54 [03:01<02:19,  6.35s/it]\n",
      "   834/834        0G      2.48       0.1         0      2.58         9       640:  61%|######1   | 33/54 [03:01<02:14,  6.43s/it]\n",
      "   834/834        0G      2.51     0.101         0      2.61         9       640:  61%|######1   | 33/54 [03:07<02:14,  6.43s/it]\n",
      "   834/834        0G      2.51     0.101         0      2.61         9       640:  63%|######2   | 34/54 [03:07<02:09,  6.50s/it]\n",
      "   834/834        0G      2.53     0.102         0      2.64        12       640:  63%|######2   | 34/54 [03:14<02:09,  6.50s/it]\n",
      "   834/834        0G      2.53     0.102         0      2.64        12       640:  65%|######4   | 35/54 [03:14<02:03,  6.52s/it]\n",
      "   834/834        0G      2.55     0.103         0      2.65         9       640:  65%|######4   | 35/54 [03:21<02:03,  6.52s/it]\n",
      "   834/834        0G      2.55     0.103         0      2.65         9       640:  67%|######6   | 36/54 [03:21<01:58,  6.56s/it]\n",
      "   834/834        0G      2.57     0.105         0      2.67        12       640:  67%|######6   | 36/54 [03:27<01:58,  6.56s/it]\n",
      "   834/834        0G      2.57     0.105         0      2.67        12       640:  69%|######8   | 37/54 [03:27<01:51,  6.57s/it]\n",
      "   834/834        0G      2.59     0.105         0       2.7         9       640:  69%|######8   | 37/54 [03:34<01:51,  6.57s/it]\n",
      "   834/834        0G      2.59     0.105         0       2.7         9       640:  70%|#######   | 38/54 [03:34<01:44,  6.56s/it]\n",
      "   834/834        0G      2.59     0.105         0       2.7        10       640:  70%|#######   | 38/54 [03:40<01:44,  6.56s/it]\n",
      "   834/834        0G      2.59     0.105         0       2.7        10       640:  72%|#######2  | 39/54 [03:40<01:38,  6.58s/it]\n",
      "   834/834        0G      2.61     0.106         0      2.71        10       640:  72%|#######2  | 39/54 [03:47<01:38,  6.58s/it]\n",
      "   834/834        0G      2.61     0.106         0      2.71        10       640:  74%|#######4  | 40/54 [03:47<01:32,  6.60s/it]\n",
      "   834/834        0G      2.61     0.107         0      2.71         9       640:  74%|#######4  | 40/54 [03:54<01:32,  6.60s/it]\n",
      "   834/834        0G      2.61     0.107         0      2.71         9       640:  76%|#######5  | 41/54 [03:54<01:26,  6.64s/it]\n",
      "   834/834        0G      2.63     0.108         0      2.74         9       640:  76%|#######5  | 41/54 [04:00<01:26,  6.64s/it]\n",
      "   834/834        0G      2.63     0.108         0      2.74         9       640:  78%|#######7  | 42/54 [04:00<01:19,  6.66s/it]\n",
      "   834/834        0G      2.66     0.107         0      2.77         9       640:  78%|#######7  | 42/54 [04:07<01:19,  6.66s/it]\n",
      "   834/834        0G      2.66     0.107         0      2.77         9       640:  80%|#######9  | 43/54 [04:07<01:13,  6.66s/it]\n",
      "   834/834        0G      2.67     0.108         0      2.78         9       640:  80%|#######9  | 43/54 [04:14<01:13,  6.66s/it]\n",
      "   834/834        0G      2.67     0.108         0      2.78         9       640:  81%|########1 | 44/54 [04:14<01:06,  6.67s/it]\n",
      "   834/834        0G       2.7     0.108         0      2.81        10       640:  81%|########1 | 44/54 [04:20<01:06,  6.67s/it]\n",
      "   834/834        0G       2.7     0.108         0      2.81        10       640:  83%|########3 | 45/54 [04:20<00:59,  6.66s/it]\n",
      "   834/834        0G      2.72      0.11         0      2.83        12       640:  83%|########3 | 45/54 [04:27<00:59,  6.66s/it]\n",
      "   834/834        0G      2.72      0.11         0      2.83        12       640:  85%|########5 | 46/54 [04:27<00:53,  6.66s/it]\n",
      "   834/834        0G      2.72     0.111         0      2.84         9       640:  85%|########5 | 46/54 [04:34<00:53,  6.66s/it]\n",
      "   834/834        0G      2.72     0.111         0      2.84         9       640:  87%|########7 | 47/54 [04:34<00:46,  6.67s/it]\n",
      "   834/834        0G       2.7      0.11         0      2.81        12       640:  87%|########7 | 47/54 [04:40<00:46,  6.67s/it]\n",
      "   834/834        0G       2.7      0.11         0      2.81        12       640:  89%|########8 | 48/54 [04:40<00:39,  6.64s/it]\n",
      "   834/834        0G      2.71     0.111         0      2.82        12       640:  89%|########8 | 48/54 [04:47<00:39,  6.64s/it]\n",
      "   834/834        0G      2.71     0.111         0      2.82        12       640:  91%|######### | 49/54 [04:47<00:33,  6.64s/it]\n",
      "   834/834        0G      2.71     0.111         0      2.82         9       640:  91%|######### | 49/54 [04:54<00:33,  6.64s/it]\n",
      "   834/834        0G      2.71     0.111         0      2.82         9       640:  93%|#########2| 50/54 [04:54<00:26,  6.62s/it]\n",
      "   834/834        0G      2.72     0.111         0      2.83         9       640:  93%|#########2| 50/54 [05:00<00:26,  6.62s/it]\n",
      "   834/834        0G      2.72     0.111         0      2.83         9       640:  94%|#########4| 51/54 [05:00<00:19,  6.62s/it]\n",
      "   834/834        0G      2.69      0.11         0       2.8         9       416:  94%|#########4| 51/54 [05:03<00:19,  6.62s/it]\n",
      "   834/834        0G      2.69      0.11         0       2.8         9       416:  96%|#########6| 52/54 [05:03<00:11,  5.62s/it]\n",
      "   834/834        0G      2.66     0.109         0      2.77         8       416:  96%|#########6| 52/54 [05:06<00:11,  5.62s/it]\n",
      "   834/834        0G      2.66     0.109         0      2.77         8       416:  98%|#########8| 53/54 [05:06<00:04,  4.77s/it]\n",
      "   834/834        0G      2.63      0.11         0      2.74         3       416:  98%|#########8| 53/54 [05:07<00:04,  4.77s/it]\n",
      "   834/834        0G      2.63      0.11         0      2.74         3       416: 100%|##########| 54/54 [05:07<00:00,  3.67s/it]\n",
      "   834/834        0G      2.63      0.11         0      2.74         3       416: 100%|##########| 54/54 [05:08<00:00,  5.72s/it]\n",
      "\n",
      "               Class    Images   Targets         P         R   mAP@0.5        F1:   0%|          | 0/14 [00:00<?, ?it/s]2024-03-04 17:22:47.132172: I tensorflow/core/util/port.cc:113] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
      "WARNING:tensorflow:From C:\\Users\\mit017\\anaconda3\\Lib\\site-packages\\keras\\src\\losses.py:2976: The name tf.losses.sparse_softmax_cross_entropy is deprecated. Please use tf.compat.v1.losses.sparse_softmax_cross_entropy instead.\n",
      "\n",
      "2024-03-04 17:22:57.185482: I tensorflow/core/util/port.cc:113] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
      "WARNING:tensorflow:From C:\\Users\\mit017\\anaconda3\\Lib\\site-packages\\keras\\src\\losses.py:2976: The name tf.losses.sparse_softmax_cross_entropy is deprecated. Please use tf.compat.v1.losses.sparse_softmax_cross_entropy instead.\n",
      "\n",
      "2024-03-04 17:23:07.043658: I tensorflow/core/util/port.cc:113] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
      "WARNING:tensorflow:From C:\\Users\\mit017\\anaconda3\\Lib\\site-packages\\keras\\src\\losses.py:2976: The name tf.losses.sparse_softmax_cross_entropy is deprecated. Please use tf.compat.v1.losses.sparse_softmax_cross_entropy instead.\n",
      "\n",
      "\n",
      "               Class    Images   Targets         P         R   mAP@0.5        F1:   7%|7         | 1/14 [00:32<06:56, 32.07s/it]\n",
      "               Class    Images   Targets         P         R   mAP@0.5        F1:  14%|#4        | 2/14 [00:34<02:52, 14.37s/it]\n",
      "               Class    Images   Targets         P         R   mAP@0.5        F1:  21%|##1       | 3/14 [00:36<01:35,  8.73s/it]\n",
      "               Class    Images   Targets         P         R   mAP@0.5        F1:  29%|##8       | 4/14 [00:38<01:00,  6.07s/it]\n",
      "               Class    Images   Targets         P         R   mAP@0.5        F1:  36%|###5      | 5/14 [00:40<00:41,  4.61s/it]\n",
      "               Class    Images   Targets         P         R   mAP@0.5        F1:  43%|####2     | 6/14 [00:42<00:29,  3.73s/it]\n",
      "               Class    Images   Targets         P         R   mAP@0.5        F1:  50%|#####     | 7/14 [00:44<00:22,  3.15s/it]\n",
      "               Class    Images   Targets         P         R   mAP@0.5        F1:  57%|#####7    | 8/14 [00:46<00:16,  2.80s/it]\n",
      "               Class    Images   Targets         P         R   mAP@0.5        F1:  64%|######4   | 9/14 [00:48<00:12,  2.57s/it]\n",
      "               Class    Images   Targets         P         R   mAP@0.5        F1:  71%|#######1  | 10/14 [00:50<00:09,  2.39s/it]\n",
      "               Class    Images   Targets         P         R   mAP@0.5        F1:  79%|#######8  | 11/14 [00:52<00:06,  2.28s/it]\n",
      "               Class    Images   Targets         P         R   mAP@0.5        F1:  86%|########5 | 12/14 [00:54<00:04,  2.20s/it]\n",
      "               Class    Images   Targets         P         R   mAP@0.5        F1:  93%|#########2| 13/14 [00:56<00:02,  2.15s/it]\n",
      "               Class    Images   Targets         P         R   mAP@0.5        F1: 100%|##########| 14/14 [00:56<00:00,  1.72s/it]\n",
      "               Class    Images   Targets         P         R   mAP@0.5        F1: 100%|##########| 14/14 [00:57<00:00,  4.14s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Namespace(epochs=15, batch_size=3, cfg='yolov3-spp.cfg', data='custom.data', multi_scale=False, img_size=[320, 640], rect=False, resume=False, nosave=True, notest=False, evolve=False, bucket='', cache_images=False, weights='weights/last.pt', name='', device='cpu', adam=False, single_cls=False, freeze_layers=False)\n",
      "Using CPU\n",
      "\n",
      "Start Tensorboard with \"tensorboard --logdir=runs\", view at http://localhost:6006/\n",
      "WARNING: smart bias initialization failure.\n",
      "WARNING: smart bias initialization failure.\n",
      "WARNING: smart bias initialization failure.\n",
      "Model Summary: 225 layers, 6.25733e+07 parameters, 6.25733e+07 gradients\n",
      "Optimizer groups: 76 .bias, 76 Conv2d.weight, 73 other\n",
      "weights/last.pt has been trained for 820 epochs. Fine-tuning for 15 additional epochs.\n",
      "Image sizes 320 - 640 train, 640 test\n",
      "Using 3 dataloader workers\n",
      "Starting training for 835 epochs...\n",
      "\n",
      "     Epoch   gpu_mem      GIoU       obj       cls     total   targets  img_size\n",
      "Apex recommended for faster mixed precision training: https://github.com/NVIDIA/apex\n",
      "Apex recommended for faster mixed precision training: https://github.com/NVIDIA/apex\n",
      "Apex recommended for faster mixed precision training: https://github.com/NVIDIA/apex\n",
      "Apex recommended for faster mixed precision training: https://github.com/NVIDIA/apex\n",
      "Apex recommended for faster mixed precision training: https://github.com/NVIDIA/apex\n",
      "Apex recommended for faster mixed precision training: https://github.com/NVIDIA/apex\n",
      "                 all        40       120      0.56   0.00833      0.78    0.0164\n",
      "\n",
      "     Epoch   gpu_mem      GIoU       obj       cls     total   targets  img_size\n",
      "Apex recommended for faster mixed precision training: https://github.com/NVIDIA/apex\n",
      "Apex recommended for faster mixed precision training: https://github.com/NVIDIA/apex\n",
      "Apex recommended for faster mixed precision training: https://github.com/NVIDIA/apex\n",
      "Apex recommended for faster mixed precision training: https://github.com/NVIDIA/apex\n",
      "Apex recommended for faster mixed precision training: https://github.com/NVIDIA/apex\n",
      "Apex recommended for faster mixed precision training: https://github.com/NVIDIA/apex\n",
      "                 all        40       120         1   0.00833     0.827    0.0165\n",
      "\n",
      "     Epoch   gpu_mem      GIoU       obj       cls     total   targets  img_size\n",
      "Apex recommended for faster mixed precision training: https://github.com/NVIDIA/apex\n",
      "Apex recommended for faster mixed precision training: https://github.com/NVIDIA/apex\n",
      "Apex recommended for faster mixed precision training: https://github.com/NVIDIA/apex\n",
      "Apex recommended for faster mixed precision training: https://github.com/NVIDIA/apex\n",
      "Apex recommended for faster mixed precision training: https://github.com/NVIDIA/apex\n",
      "Apex recommended for faster mixed precision training: https://github.com/NVIDIA/apex\n",
      "                 all        40       120         1    0.0249     0.855    0.0487\n",
      "\n",
      "     Epoch   gpu_mem      GIoU       obj       cls     total   targets  img_size\n",
      "Apex recommended for faster mixed precision training: https://github.com/NVIDIA/apex\n",
      "Apex recommended for faster mixed precision training: https://github.com/NVIDIA/apex\n",
      "Apex recommended for faster mixed precision training: https://github.com/NVIDIA/apex\n",
      "Apex recommended for faster mixed precision training: https://github.com/NVIDIA/apex\n",
      "Apex recommended for faster mixed precision training: https://github.com/NVIDIA/apex\n",
      "Apex recommended for faster mixed precision training: https://github.com/NVIDIA/apex\n",
      "                 all        40       120         1     0.062     0.815     0.117\n",
      "\n",
      "     Epoch   gpu_mem      GIoU       obj       cls     total   targets  img_size\n",
      "Apex recommended for faster mixed precision training: https://github.com/NVIDIA/apex\n",
      "Apex recommended for faster mixed precision training: https://github.com/NVIDIA/apex\n",
      "Apex recommended for faster mixed precision training: https://github.com/NVIDIA/apex\n",
      "Apex recommended for faster mixed precision training: https://github.com/NVIDIA/apex\n",
      "Apex recommended for faster mixed precision training: https://github.com/NVIDIA/apex\n",
      "Apex recommended for faster mixed precision training: https://github.com/NVIDIA/apex\n",
      "                 all        40       120      0.88     0.123     0.833     0.215\n",
      "\n",
      "     Epoch   gpu_mem      GIoU       obj       cls     total   targets  img_size\n",
      "Apex recommended for faster mixed precision training: https://github.com/NVIDIA/apex\n",
      "Apex recommended for faster mixed precision training: https://github.com/NVIDIA/apex\n",
      "Apex recommended for faster mixed precision training: https://github.com/NVIDIA/apex\n",
      "Apex recommended for faster mixed precision training: https://github.com/NVIDIA/apex\n",
      "Apex recommended for faster mixed precision training: https://github.com/NVIDIA/apex\n",
      "Apex recommended for faster mixed precision training: https://github.com/NVIDIA/apex\n",
      "                 all        40       120         1     0.058      0.78      0.11\n",
      "\n",
      "     Epoch   gpu_mem      GIoU       obj       cls     total   targets  img_size\n",
      "Apex recommended for faster mixed precision training: https://github.com/NVIDIA/apex\n",
      "Apex recommended for faster mixed precision training: https://github.com/NVIDIA/apex\n",
      "Apex recommended for faster mixed precision training: https://github.com/NVIDIA/apex\n",
      "Apex recommended for faster mixed precision training: https://github.com/NVIDIA/apex\n",
      "Apex recommended for faster mixed precision training: https://github.com/NVIDIA/apex\n",
      "Apex recommended for faster mixed precision training: https://github.com/NVIDIA/apex\n",
      "                 all        40       120         1    0.0246     0.757     0.048\n",
      "\n",
      "     Epoch   gpu_mem      GIoU       obj       cls     total   targets  img_size\n",
      "Apex recommended for faster mixed precision training: https://github.com/NVIDIA/apex\n",
      "Apex recommended for faster mixed precision training: https://github.com/NVIDIA/apex\n",
      "Apex recommended for faster mixed precision training: https://github.com/NVIDIA/apex\n",
      "Apex recommended for faster mixed precision training: https://github.com/NVIDIA/apex\n",
      "Apex recommended for faster mixed precision training: https://github.com/NVIDIA/apex\n",
      "Apex recommended for faster mixed precision training: https://github.com/NVIDIA/apex\n",
      "                 all        40       120     0.857      0.15     0.771     0.255\n",
      "\n",
      "     Epoch   gpu_mem      GIoU       obj       cls     total   targets  img_size\n",
      "Apex recommended for faster mixed precision training: https://github.com/NVIDIA/apex\n",
      "Apex recommended for faster mixed precision training: https://github.com/NVIDIA/apex\n",
      "Apex recommended for faster mixed precision training: https://github.com/NVIDIA/apex\n",
      "Apex recommended for faster mixed precision training: https://github.com/NVIDIA/apex\n",
      "Apex recommended for faster mixed precision training: https://github.com/NVIDIA/apex\n",
      "Apex recommended for faster mixed precision training: https://github.com/NVIDIA/apex\n",
      "                 all        40       120     0.844     0.181     0.759     0.298\n",
      "\n",
      "     Epoch   gpu_mem      GIoU       obj       cls     total   targets  img_size\n",
      "Apex recommended for faster mixed precision training: https://github.com/NVIDIA/apex\n",
      "Apex recommended for faster mixed precision training: https://github.com/NVIDIA/apex\n",
      "Apex recommended for faster mixed precision training: https://github.com/NVIDIA/apex\n",
      "Apex recommended for faster mixed precision training: https://github.com/NVIDIA/apex\n",
      "Apex recommended for faster mixed precision training: https://github.com/NVIDIA/apex\n",
      "Apex recommended for faster mixed precision training: https://github.com/NVIDIA/apex\n",
      "                 all        40       120      0.86     0.154     0.743     0.261\n",
      "\n",
      "     Epoch   gpu_mem      GIoU       obj       cls     total   targets  img_size\n",
      "Apex recommended for faster mixed precision training: https://github.com/NVIDIA/apex\n",
      "Apex recommended for faster mixed precision training: https://github.com/NVIDIA/apex\n",
      "Apex recommended for faster mixed precision training: https://github.com/NVIDIA/apex\n",
      "Apex recommended for faster mixed precision training: https://github.com/NVIDIA/apex\n",
      "Apex recommended for faster mixed precision training: https://github.com/NVIDIA/apex\n",
      "Apex recommended for faster mixed precision training: https://github.com/NVIDIA/apex\n",
      "                 all        40       120     0.859     0.356     0.793     0.503\n",
      "\n",
      "     Epoch   gpu_mem      GIoU       obj       cls     total   targets  img_size\n",
      "Apex recommended for faster mixed precision training: https://github.com/NVIDIA/apex\n",
      "Apex recommended for faster mixed precision training: https://github.com/NVIDIA/apex\n",
      "Apex recommended for faster mixed precision training: https://github.com/NVIDIA/apex\n",
      "Apex recommended for faster mixed precision training: https://github.com/NVIDIA/apex\n",
      "Apex recommended for faster mixed precision training: https://github.com/NVIDIA/apex\n",
      "Apex recommended for faster mixed precision training: https://github.com/NVIDIA/apex\n",
      "                 all        40       120     0.922     0.588     0.839     0.718\n",
      "\n",
      "     Epoch   gpu_mem      GIoU       obj       cls     total   targets  img_size\n",
      "Apex recommended for faster mixed precision training: https://github.com/NVIDIA/apex\n",
      "Apex recommended for faster mixed precision training: https://github.com/NVIDIA/apex\n",
      "Apex recommended for faster mixed precision training: https://github.com/NVIDIA/apex\n",
      "Apex recommended for faster mixed precision training: https://github.com/NVIDIA/apex\n",
      "Apex recommended for faster mixed precision training: https://github.com/NVIDIA/apex\n",
      "Apex recommended for faster mixed precision training: https://github.com/NVIDIA/apex\n",
      "                 all        40       120     0.911     0.513     0.831     0.656\n",
      "\n",
      "     Epoch   gpu_mem      GIoU       obj       cls     total   targets  img_size\n",
      "Apex recommended for faster mixed precision training: https://github.com/NVIDIA/apex\n",
      "Apex recommended for faster mixed precision training: https://github.com/NVIDIA/apex\n",
      "Apex recommended for faster mixed precision training: https://github.com/NVIDIA/apex\n",
      "Apex recommended for faster mixed precision training: https://github.com/NVIDIA/apex\n",
      "Apex recommended for faster mixed precision training: https://github.com/NVIDIA/apex\n",
      "Apex recommended for faster mixed precision training: https://github.com/NVIDIA/apex\n",
      "                 all        40       120     0.913     0.704     0.856     0.795\n",
      "14 epochs completed in 1.267 hours.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "!python train.py --epochs 15 --weights weights/last.pt --batch-size 3 --cfg yolov3-spp.cfg --data custom.data --nosave --device cpu"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "fda574bb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Namespace(cfg='yolov3-spp.cfg', names='classes.names', weights='weights/last.pt', source='images', output='result', img_size=512, conf_thres=0.3, iou_thres=0.6, fourcc='mp4v', half=False, device='', view_img=False, save_txt=False, classes=None, agnostic_nms=False, augment=False)\n",
      "Using CPU\n",
      "\n",
      "Model Summary: 225 layers, 6.25733e+07 parameters, 6.25733e+07 gradients\n",
      "image 1/200 images\\002_20200622_203136(3).jpg: 512x512 3 defects, Done. (0.518s)\n",
      "image 2/200 images\\002_20200622_203140(8).jpg: 512x512 3 defects, Done. (0.483s)\n",
      "image 3/200 images\\002_20200622_203145(3).jpg: 512x512 3 defects, Done. (0.504s)\n",
      "image 4/200 images\\002_20200622_203149(8).jpg: 512x512 3 defects, Done. (0.489s)\n",
      "image 5/200 images\\002_20200622_203154(3).jpg: 512x512 3 defects, Done. (0.487s)\n",
      "image 6/200 images\\002_20200622_203158(8).jpg: 512x512 2 defects, Done. (0.463s)\n",
      "image 7/200 images\\002_20200623_003351(2).jpg: 512x512 3 defects, Done. (0.499s)\n",
      "image 8/200 images\\002_20200623_003355(7).jpg: 512x512 2 defects, Done. (0.480s)\n",
      "image 9/200 images\\002_20200623_003400(2).jpg: 512x512 2 defects, Done. (0.480s)\n",
      "image 10/200 images\\002_20200623_003404(7).jpg: 512x512 2 defects, Done. (0.512s)\n",
      "image 11/200 images\\002_20200623_003409(2).jpg: 512x512 2 defects, Done. (0.485s)\n",
      "image 12/200 images\\002_20200623_003413(7).jpg: 512x512 3 defects, Done. (0.480s)\n",
      "image 13/200 images\\002_20200623_043056(0).jpg: 512x512 3 defects, Done. (0.498s)\n",
      "image 14/200 images\\002_20200623_043100(6).jpg: 512x512 3 defects, Done. (0.490s)\n",
      "image 15/200 images\\002_20200623_043105(0).jpg: 512x512 3 defects, Done. (0.500s)\n",
      "image 16/200 images\\002_20200623_043109(4).jpg: 512x512 2 defects, Done. (0.483s)\n",
      "image 17/200 images\\002_20200623_043115(4).jpg: 512x512 3 defects, Done. (0.487s)\n",
      "image 18/200 images\\002_20200623_043120(0).jpg: 512x512 3 defects, Done. (0.484s)\n",
      "image 19/200 images\\002_20200623_082249(3).jpg: 512x512 3 defects, Done. (0.490s)\n",
      "image 20/200 images\\002_20200623_082253(8).jpg: 512x512 2 defects, Done. (0.473s)\n",
      "image 21/200 images\\002_20200623_082258(4).jpg: 512x512 3 defects, Done. (0.496s)\n",
      "image 22/200 images\\002_20200623_082302(7).jpg: 512x512 3 defects, Done. (0.489s)\n",
      "image 23/200 images\\002_20200623_082307(2).jpg: 512x512 3 defects, Done. (0.487s)\n",
      "image 24/200 images\\002_20200623_082311(8).jpg: 512x512 3 defects, Done. (0.500s)\n",
      "image 25/200 images\\002_20200623_123042(0).jpg: 512x512 3 defects, Done. (0.499s)\n",
      "image 26/200 images\\002_20200623_123046(4).jpg: 512x512 2 defects, Done. (0.516s)\n",
      "image 27/200 images\\002_20200623_123051(1).jpg: 512x512 3 defects, Done. (0.502s)\n",
      "image 28/200 images\\002_20200623_123055(5).jpg: 512x512 3 defects, Done. (0.500s)\n",
      "image 29/200 images\\002_20200623_123100(0).jpg: 512x512 3 defects, Done. (0.522s)\n",
      "image 30/200 images\\002_20200623_123104(5).jpg: 512x512 3 defects, Done. (0.500s)\n",
      "image 31/200 images\\002_20200623_163020(3).jpg: 512x512 3 defects, Done. (0.507s)\n",
      "image 32/200 images\\002_20200623_163023(3).jpg: 512x512 2 defects, Done. (0.527s)\n",
      "image 33/200 images\\002_20200623_163026(3).jpg: 512x512 3 defects, Done. (0.507s)\n",
      "image 34/200 images\\002_20200623_163029(6).jpg: 512x512 3 defects, Done. (0.490s)\n",
      "image 35/200 images\\002_20200623_163032(5).jpg: 512x512 2 defects, Done. (0.502s)\n",
      "image 36/200 images\\002_20200623_163035(5).jpg: 512x512 3 defects, Done. (0.513s)\n",
      "image 37/200 images\\002_20200623_203033(6).jpg: 512x512 3 defects, Done. (0.507s)\n",
      "image 38/200 images\\002_20200623_203038(0).jpg: 512x512 2 defects, Done. (0.494s)\n",
      "image 39/200 images\\002_20200623_203042(5).jpg: 512x512 3 defects, Done. (0.494s)\n",
      "image 40/200 images\\002_20200623_203047(0).jpg: 512x512 2 defects, Done. (0.503s)\n",
      "image 41/200 images\\002_20200623_203050(0).jpg: 512x512 2 defects, Done. (0.494s)\n",
      "image 42/200 images\\002_20200623_203054(6).jpg: 512x512 3 defects, Done. (0.507s)\n",
      "image 43/200 images\\002_20200624_003115(6).jpg: 512x512 3 defects, Done. (0.492s)\n",
      "image 44/200 images\\002_20200624_003118(6).jpg: 512x512 3 defects, Done. (0.495s)\n",
      "image 45/200 images\\002_20200624_003123(0).jpg: 512x512 3 defects, Done. (0.513s)\n",
      "image 46/200 images\\002_20200624_003127(5).jpg: 512x512 3 defects, Done. (0.510s)\n",
      "image 47/200 images\\002_20200624_003132(0).jpg: 512x512 3 defects, Done. (0.504s)\n",
      "image 48/200 images\\002_20200624_003136(5).jpg: 512x512 3 defects, Done. (0.494s)\n",
      "image 49/200 images\\002_20200624_043136(9).jpg: 512x512 3 defects, Done. (0.506s)\n",
      "image 50/200 images\\002_20200624_043141(4).jpg: 512x512 2 defects, Done. (0.482s)\n",
      "image 51/200 images\\002_20200624_043145(8).jpg: 512x512 3 defects, Done. (0.497s)\n",
      "image 52/200 images\\002_20200624_043150(3).jpg: 512x512 3 defects, Done. (0.500s)\n",
      "image 53/200 images\\002_20200624_043154(8).jpg: 512x512 3 defects, Done. (0.499s)\n",
      "image 54/200 images\\002_20200624_043159(4).jpg: 512x512 3 defects, Done. (0.513s)\n",
      "image 55/200 images\\002_20200624_083032(4).jpg: 512x512 3 defects, Done. (0.497s)\n",
      "image 56/200 images\\002_20200624_083036(9).jpg: 512x512 3 defects, Done. (0.488s)\n",
      "image 57/200 images\\002_20200624_083041(3).jpg: 512x512 3 defects, Done. (0.490s)\n",
      "image 58/200 images\\002_20200624_083045(8).jpg: 512x512 3 defects, Done. (0.495s)\n",
      "image 59/200 images\\002_20200624_083050(4).jpg: 512x512 2 defects, Done. (0.493s)\n",
      "image 60/200 images\\002_20200624_083054(9).jpg: 512x512 3 defects, Done. (0.499s)\n",
      "image 61/200 images\\002_20200624_123144(0).jpg: 512x512 3 defects, Done. (0.485s)\n",
      "image 62/200 images\\002_20200624_123148(2).jpg: 512x512 3 defects, Done. (0.485s)\n",
      "image 63/200 images\\002_20200624_123152(7).jpg: 512x512 3 defects, Done. (0.511s)\n",
      "image 64/200 images\\002_20200624_123157(4).jpg: 512x512 3 defects, Done. (0.500s)\n",
      "image 65/200 images\\002_20200624_123201(7).jpg: 512x512 3 defects, Done. (0.506s)\n",
      "image 66/200 images\\002_20200624_123206(2).jpg: 512x512 3 defects, Done. (0.495s)\n",
      "image 67/200 images\\002_20200624_162708(9).jpg: 512x512 3 defects, Done. (0.494s)\n",
      "image 68/200 images\\002_20200624_162713(4).jpg: 512x512 3 defects, Done. (0.499s)\n",
      "image 69/200 images\\002_20200624_162717(9).jpg: 512x512 3 defects, Done. (0.481s)\n",
      "image 70/200 images\\002_20200624_162722(4).jpg: 512x512 3 defects, Done. (0.494s)\n",
      "image 71/200 images\\002_20200624_162726(9).jpg: 512x512 3 defects, Done. (0.500s)\n",
      "image 72/200 images\\002_20200624_162737(5).jpg: 512x512 3 defects, Done. (0.505s)\n",
      "image 73/200 images\\002_20200624_203111(4).jpg: 512x512 3 defects, Done. (0.490s)\n",
      "image 74/200 images\\002_20200624_203114(3).jpg: 512x512 1 defects, Done. (0.499s)\n",
      "image 75/200 images\\002_20200624_203117(3).jpg: 512x512 3 defects, Done. (0.477s)\n",
      "image 76/200 images\\002_20200624_203120(3).jpg: 512x512 3 defects, Done. (0.500s)\n",
      "image 77/200 images\\002_20200624_203123(3).jpg: 512x512 1 defects, Done. (0.499s)\n",
      "image 78/200 images\\002_20200624_203126(3).jpg: 512x512 3 defects, Done. (0.486s)\n",
      "image 79/200 images\\002_20200625_003352(9).jpg: 512x512 3 defects, Done. (0.497s)\n",
      "image 80/200 images\\002_20200625_003357(4).jpg: 512x512 3 defects, Done. (0.497s)\n",
      "image 81/200 images\\002_20200625_003401(8).jpg: 512x512 3 defects, Done. (0.505s)\n",
      "image 82/200 images\\002_20200625_003406(3).jpg: 512x512 3 defects, Done. (0.505s)\n",
      "image 83/200 images\\002_20200625_003410(8).jpg: 512x512 3 defects, Done. (0.503s)\n",
      "image 84/200 images\\002_20200625_003415(4).jpg: 512x512 3 defects, Done. (0.490s)\n",
      "image 85/200 images\\002_20200629_082823(5).jpg: 512x512 3 defects, Done. (0.491s)\n",
      "image 86/200 images\\002_20200629_082828(5).jpg: 512x512 2 defects, Done. (0.510s)\n",
      "image 87/200 images\\002_20200629_082831(3).jpg: 512x512 3 defects, Done. (0.491s)\n",
      "image 88/200 images\\002_20200629_082834(2).jpg: 512x512 3 defects, Done. (0.487s)\n",
      "image 89/200 images\\002_20200629_082837(0).jpg: 512x512 2 defects, Done. (0.476s)\n",
      "image 90/200 images\\002_20200629_082839(9).jpg: 512x512 2 defects, Done. (0.469s)\n",
      "image 91/200 images\\002_20200629_123442(5).jpg: 512x512 3 defects, Done. (0.499s)\n",
      "image 92/200 images\\002_20200629_123447(0).jpg: 512x512 3 defects, Done. (0.471s)\n",
      "image 93/200 images\\002_20200629_123451(5).jpg: 512x512 3 defects, Done. (0.488s)\n",
      "image 94/200 images\\002_20200629_123456(0).jpg: 512x512 2 defects, Done. (0.505s)\n",
      "image 95/200 images\\002_20200629_123500(5).jpg: 512x512 3 defects, Done. (0.496s)\n",
      "image 96/200 images\\002_20200629_123505(0).jpg: 512x512 2 defects, Done. (0.531s)\n",
      "image 97/200 images\\002_20200629_163656(7).jpg: 512x512 2 defects, Done. (0.490s)\n",
      "image 98/200 images\\002_20200629_163659(7).jpg: 512x512 3 defects, Done. (0.462s)\n",
      "image 99/200 images\\002_20200629_163702(8).jpg: 512x512 3 defects, Done. (0.480s)\n",
      "image 100/200 images\\002_20200629_163705(8).jpg: 512x512 3 defects, Done. (0.503s)\n",
      "image 101/200 images\\002_20200629_163708(9).jpg: 512x512 3 defects, Done. (0.492s)\n",
      "image 102/200 images\\002_20200629_163711(8).jpg: 512x512 3 defects, Done. (0.489s)\n",
      "image 103/200 images\\002_20200629_202727(4).jpg: 512x512 2 defects, Done. (0.487s)\n",
      "image 104/200 images\\002_20200629_202731(9).jpg: 512x512 3 defects, Done. (0.484s)\n",
      "image 105/200 images\\002_20200629_202736(4).jpg: 512x512 3 defects, Done. (0.487s)\n",
      "image 106/200 images\\002_20200629_202741(1).jpg: 512x512 3 defects, Done. (0.474s)\n",
      "image 107/200 images\\002_20200629_202745(5).jpg: 512x512 3 defects, Done. (0.522s)\n",
      "image 108/200 images\\002_20200629_202750(0).jpg: 512x512 3 defects, Done. (0.529s)\n",
      "image 109/200 images\\002_20200630_002937(6).jpg: 512x512 3 defects, Done. (0.514s)\n",
      "image 110/200 images\\002_20200630_002942(1).jpg: 512x512 3 defects, Done. (0.524s)\n",
      "image 111/200 images\\002_20200630_002946(4).jpg: 512x512 3 defects, Done. (0.516s)\n",
      "image 112/200 images\\002_20200630_002951(2).jpg: 512x512 3 defects, Done. (0.533s)\n",
      "image 113/200 images\\002_20200630_002955(6).jpg: 512x512 3 defects, Done. (0.513s)\n",
      "image 114/200 images\\002_20200630_003000(0).jpg: 512x512 3 defects, Done. (0.810s)\n",
      "image 115/200 images\\002_20200630_043222(4).jpg: 512x512 3 defects, Done. (0.602s)\n",
      "image 116/200 images\\002_20200630_043226(7).jpg: 512x512 3 defects, Done. (0.492s)\n",
      "image 117/200 images\\002_20200630_043231(3).jpg: 512x512 3 defects, Done. (0.484s)\n",
      "image 118/200 images\\002_20200630_043235(6).jpg: 512x512 3 defects, Done. (0.484s)\n",
      "image 119/200 images\\002_20200630_043240(2).jpg: 512x512 3 defects, Done. (0.485s)\n",
      "image 120/200 images\\002_20200630_043244(6).jpg: 512x512 2 defects, Done. (0.487s)\n",
      "image 121/200 images\\002_20200630_083221(8).jpg: 512x512 3 defects, Done. (0.498s)\n",
      "image 122/200 images\\002_20200630_083224(8).jpg: 512x512 3 defects, Done. (0.540s)\n",
      "image 123/200 images\\002_20200630_083227(8).jpg: 512x512 3 defects, Done. (0.581s)\n",
      "image 124/200 images\\002_20200630_083230(8).jpg: 512x512 3 defects, Done. (0.516s)\n",
      "image 125/200 images\\002_20200630_083233(8).jpg: 512x512 3 defects, Done. (0.500s)\n",
      "image 126/200 images\\002_20200630_083236(8).jpg: 512x512 3 defects, Done. (0.503s)\n",
      "image 127/200 images\\002_20200630_123159(3).jpg: 512x512 3 defects, Done. (0.585s)\n",
      "image 128/200 images\\002_20200630_123203(6).jpg: 512x512 3 defects, Done. (0.484s)\n",
      "image 129/200 images\\002_20200630_123232(0).jpg: 512x512 3 defects, Done. (0.478s)\n",
      "image 130/200 images\\002_20200630_123235(0).jpg: 512x512 3 defects, Done. (0.508s)\n",
      "image 131/200 images\\002_20200630_123238(0).jpg: 512x512 3 defects, Done. (0.580s)\n",
      "image 132/200 images\\002_20200630_123241(0).jpg: 512x512 3 defects, Done. (0.493s)\n",
      "image 133/200 images\\002_20200630_163105(7).jpg: 512x512 3 defects, Done. (0.539s)\n",
      "image 134/200 images\\002_20200630_163108(9).jpg: 512x512 2 defects, Done. (0.564s)\n",
      "image 135/200 images\\002_20200630_163112(5).jpg: 512x512 3 defects, Done. (0.471s)\n",
      "image 136/200 images\\002_20200630_163116(0).jpg: 512x512 3 defects, Done. (0.572s)\n",
      "image 137/200 images\\002_20200630_163119(5).jpg: 512x512 3 defects, Done. (0.618s)\n",
      "image 138/200 images\\002_20200630_163122(8).jpg: 512x512 2 defects, Done. (0.633s)\n",
      "image 139/200 images\\002_20200630_203013(9).jpg: 512x512 3 defects, Done. (0.565s)\n",
      "image 140/200 images\\002_20200630_203018(4).jpg: 512x512 3 defects, Done. (0.526s)\n",
      "image 141/200 images\\002_20200630_203022(9).jpg: 512x512 3 defects, Done. (0.526s)\n",
      "image 142/200 images\\002_20200630_203027(4).jpg: 512x512 3 defects, Done. (0.512s)\n",
      "image 143/200 images\\002_20200630_203031(8).jpg: 512x512 3 defects, Done. (0.499s)\n",
      "image 144/200 images\\002_20200630_203036(4).jpg: 512x512 3 defects, Done. (0.500s)\n",
      "image 145/200 images\\002_20200701_004107(2).jpg: 512x512 3 defects, Done. (0.497s)\n",
      "image 146/200 images\\002_20200701_004111(5).jpg: 512x512 3 defects, Done. (0.472s)\n",
      "image 147/200 images\\002_20200701_004116(1).jpg: 512x512 3 defects, Done. (0.481s)\n",
      "image 148/200 images\\002_20200701_004120(5).jpg: 512x512 3 defects, Done. (0.484s)\n",
      "image 149/200 images\\002_20200701_004125(0).jpg: 512x512 3 defects, Done. (0.484s)\n",
      "image 150/200 images\\002_20200701_004129(6).jpg: 512x512 2 defects, Done. (0.495s)\n",
      "image 151/200 images\\002_20200701_043204(8).jpg: 512x512 3 defects, Done. (0.478s)\n",
      "image 152/200 images\\002_20200701_043209(5).jpg: 512x512 3 defects, Done. (0.469s)\n",
      "image 153/200 images\\002_20200701_043213(9).jpg: 512x512 3 defects, Done. (0.469s)\n",
      "image 154/200 images\\002_20200701_043218(4).jpg: 512x512 3 defects, Done. (0.493s)\n",
      "image 155/200 images\\002_20200701_043222(8).jpg: 512x512 2 defects, Done. (0.495s)\n",
      "image 156/200 images\\002_20200701_043227(2).jpg: 512x512 3 defects, Done. (0.503s)\n",
      "image 157/200 images\\002_20200701_083102(9).jpg: 512x512 3 defects, Done. (0.498s)\n",
      "image 158/200 images\\002_20200701_083105(7).jpg: 512x512 3 defects, Done. (0.492s)\n",
      "image 159/200 images\\002_20200701_083108(8).jpg: 512x512 3 defects, Done. (0.482s)\n",
      "image 160/200 images\\002_20200701_083111(8).jpg: 512x512 3 defects, Done. (0.495s)\n",
      "image 161/200 images\\002_20200701_083114(8).jpg: 512x512 3 defects, Done. (0.488s)\n",
      "image 162/200 images\\002_20200701_083117(8).jpg: 512x512 3 defects, Done. (0.551s)\n",
      "image 163/200 images\\002_20200701_123502(6).jpg: 512x512 3 defects, Done. (0.744s)\n",
      "image 164/200 images\\002_20200701_123505(9).jpg: 512x512 3 defects, Done. (0.556s)\n",
      "image 165/200 images\\002_20200701_123508(7).jpg: 512x512 2 defects, Done. (0.519s)\n",
      "image 166/200 images\\002_20200701_123511(5).jpg: 512x512 3 defects, Done. (0.502s)\n",
      "image 167/200 images\\002_20200701_123514(1).jpg: 512x512 2 defects, Done. (0.486s)\n",
      "image 168/200 images\\002_20200701_123516(7).jpg: 512x512 3 defects, Done. (0.498s)\n",
      "image 169/200 images\\002_20200701_163100(6).jpg: 512x512 3 defects, Done. (0.481s)\n",
      "image 170/200 images\\002_20200701_163104(5).jpg: 512x512 3 defects, Done. (0.505s)\n",
      "image 171/200 images\\002_20200701_163108(4).jpg: 512x512 3 defects, Done. (0.466s)\n",
      "image 172/200 images\\002_20200701_163112(3).jpg: 512x512 3 defects, Done. (0.502s)\n",
      "image 173/200 images\\002_20200701_163116(3).jpg: 512x512 3 defects, Done. (0.497s)\n",
      "image 174/200 images\\002_20200701_163120(4).jpg: 512x512 3 defects, Done. (0.505s)\n",
      "image 175/200 images\\002_20200701_203449(7).jpg: 512x512 3 defects, Done. (0.498s)\n",
      "image 176/200 images\\002_20200701_203454(3).jpg: 512x512 3 defects, Done. (0.491s)\n",
      "image 177/200 images\\002_20200701_203458(5).jpg: 512x512 2 defects, Done. (0.478s)\n",
      "image 178/200 images\\002_20200701_203503(2).jpg: 512x512 3 defects, Done. (0.507s)\n",
      "image 179/200 images\\002_20200701_203507(7).jpg: 512x512 3 defects, Done. (0.489s)\n",
      "image 180/200 images\\002_20200701_203512(1).jpg: 512x512 3 defects, Done. (0.498s)\n",
      "image 181/200 images\\002_20200702_002959(7).jpg: 512x512 3 defects, Done. (0.481s)\n",
      "image 182/200 images\\002_20200702_003004(2).jpg: 512x512 3 defects, Done. (0.495s)\n",
      "image 183/200 images\\002_20200702_003008(7).jpg: 512x512 2 defects, Done. (0.493s)\n",
      "image 184/200 images\\002_20200702_003011(7).jpg: 512x512 2 defects, Done. (0.484s)\n",
      "image 185/200 images\\002_20200702_003016(3).jpg: 512x512 2 defects, Done. (0.490s)\n",
      "image 186/200 images\\002_20200702_003020(8).jpg: 512x512 2 defects, Done. (0.496s)\n",
      "image 187/200 images\\002_20200702_043936(2).jpg: 512x512 3 defects, Done. (0.471s)\n",
      "image 188/200 images\\002_20200702_043940(7).jpg: 512x512 3 defects, Done. (0.500s)\n",
      "image 189/200 images\\002_20200702_043945(1).jpg: 512x512 3 defects, Done. (0.481s)\n",
      "image 190/200 images\\002_20200702_043949(6).jpg: 512x512 3 defects, Done. (0.495s)\n",
      "image 191/200 images\\002_20200702_043954(0).jpg: 512x512 2 defects, Done. (0.497s)\n",
      "image 192/200 images\\002_20200702_043958(5).jpg: 512x512 2 defects, Done. (0.485s)\n",
      "image 193/200 images\\002_20200706_083210(1).jpg: 512x512 3 defects, Done. (0.478s)\n",
      "image 194/200 images\\002_20200706_083227(7).jpg: 512x512 3 defects, Done. (0.506s)\n",
      "image 195/200 images\\002_20200706_083231(8).jpg: 512x512 3 defects, Done. (0.493s)\n",
      "image 196/200 images\\002_20200706_083234(7).jpg: 512x512 3 defects, Done. (0.472s)\n",
      "image 197/200 images\\002_20200706_083237(9).jpg: 512x512 3 defects, Done. (0.484s)\n",
      "image 198/200 images\\002_20200706_083241(0).jpg: 512x512 3 defects, Done. (0.492s)\n",
      "image 199/200 images\\002_20200706_123239(6).jpg: 512x512 2 defects, Done. (0.497s)\n",
      "image 200/200 images\\002_20200706_123242(9).jpg: 512x512 3 defects, Done. (0.489s)\n",
      "Results saved to C:\\Users\\mit017\\Desktop\\myproject\\XRAY_PROJECT\\XrayInspection\\dataset\\test1\\yolov3\\result\n",
      "Done. (101.973s)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\mit017\\anaconda3\\Lib\\site-packages\\torch\\functional.py:507: UserWarning: torch.meshgrid: in an upcoming release, it will be required to pass the indexing argument. (Triggered internally at ..\\aten\\src\\ATen\\native\\TensorShape.cpp:3550.)\n",
      "  return _VF.meshgrid(tensors, **kwargs)  # type: ignore[attr-defined]\n"
     ]
    }
   ],
   "source": [
    "!python detect.py --weights weights/last.pt --source images --cfg yolov3-spp.cfg --names classes.names --output result "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "62a8e7ea",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Namespace(cfg='yolov3-spp.cfg', data='custom.data', weights='weights/last.pt', batch_size=16, img_size=512, conf_thres=0.001, iou_thres=0.6, save_json=False, task='test', device='', single_cls=False, augment=False)\n",
      "Using CPU\n",
      "\n",
      "WARNING: smart bias initialization failure.\n",
      "WARNING: smart bias initialization failure.\n",
      "WARNING: smart bias initialization failure.\n",
      "Model Summary: 225 layers, 6.25733e+07 parameters, 6.25733e+07 gradients\n",
      "Fusing layers...\n",
      "Model Summary: 152 layers, 6.25465e+07 parameters, 6.25465e+07 gradients\n",
      "                 all        40       120     0.881     0.933     0.885     0.907\n",
      "Speed: 441.4/3.6/445.0 ms inference/NMS/total per 512x512 image at batch-size 16\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "  0%|          | 0/40 [00:00<?, ?it/s]\n",
      "Caching labels C:\\Users\\mit017\\Desktop\\myproject\\XRAY_PROJECT\\XrayInspection\\dataset\\test1\\yolov3\\test.txt (40 found, 0 missing, 0 empty, 0 duplicate, for 40 images): 100%|##########| 40/40 [00:00<00:00, 1442.78it/s]\n",
      "\n",
      "               Class    Images   Targets         P         R   mAP@0.5        F1:   0%|          | 0/3 [00:00<?, ?it/s]C:\\Users\\mit017\\anaconda3\\Lib\\site-packages\\torch\\functional.py:507: UserWarning: torch.meshgrid: in an upcoming release, it will be required to pass the indexing argument. (Triggered internally at ..\\aten\\src\\ATen\\native\\TensorShape.cpp:3550.)\n",
      "  return _VF.meshgrid(tensors, **kwargs)  # type: ignore[attr-defined]\n",
      "\n",
      "               Class    Images   Targets         P         R   mAP@0.5        F1:  33%|###3      | 1/3 [00:40<01:21, 40.59s/it]\n",
      "               Class    Images   Targets         P         R   mAP@0.5        F1:  67%|######6   | 2/3 [00:47<00:20, 20.97s/it]\n",
      "               Class    Images   Targets         P         R   mAP@0.5        F1: 100%|##########| 3/3 [00:51<00:00, 13.03s/it]\n",
      "               Class    Images   Targets         P         R   mAP@0.5        F1: 100%|##########| 3/3 [00:52<00:00, 17.44s/it]\n"
     ]
    }
   ],
   "source": [
    "!python test.py --cfg yolov3-spp.cfg --data custom.data --weights weights/last.pt "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4f11c185",
   "metadata": {},
   "source": [
    "## 50개"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "61f9cca1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-> Please ignore this error message\n",
      "\n",
      "Showing image 0/49, path: input\\002_20200622_203136(3).bmp\n",
      "Welcome!\n",
      " Press [h] for help.\n",
      "Showing image 1/49, path: input\\002_20200622_203140(8).bmp\n",
      "Showing image 1/49, path: input\\002_20200622_203140(8).bmp\n",
      "Showing image 2/49, path: input\\002_20200622_203145(3).bmp\n",
      "Showing image 2/49, path: input\\002_20200622_203145(3).bmp\n",
      "Showing image 3/49, path: input\\002_20200622_203149(8).bmp\n",
      "Showing image 3/49, path: input\\002_20200622_203149(8).bmp\n",
      "Showing image 4/49, path: input\\002_20200622_203154(3).bmp\n",
      "Showing image 4/49, path: input\\002_20200622_203154(3).bmp\n",
      "Showing image 5/49, path: input\\002_20200622_203158(8).bmp\n",
      "Showing image 5/49, path: input\\002_20200622_203158(8).bmp\n",
      "Showing image 6/49, path: input\\002_20200623_003351(2).bmp\n",
      "Showing image 6/49, path: input\\002_20200623_003351(2).bmp\n",
      "Showing image 7/49, path: input\\002_20200623_003355(7).bmp\n",
      "Showing image 7/49, path: input\\002_20200623_003355(7).bmp\n",
      "Showing image 8/49, path: input\\002_20200623_003400(2).bmp\n",
      "Showing image 8/49, path: input\\002_20200623_003400(2).bmp\n",
      "Showing image 9/49, path: input\\002_20200623_003404(7).bmp\n",
      "Showing image 9/49, path: input\\002_20200623_003404(7).bmp\n",
      "Showing image 10/49, path: input\\002_20200623_003409(2).bmp\n",
      "Showing image 10/49, path: input\\002_20200623_003409(2).bmp\n",
      "Showing image 11/49, path: input\\002_20200623_003413(7).bmp\n",
      "Showing image 11/49, path: input\\002_20200623_003413(7).bmp\n",
      "Showing image 12/49, path: input\\002_20200623_043056(0).bmp\n",
      "Showing image 12/49, path: input\\002_20200623_043056(0).bmp\n",
      "Showing image 13/49, path: input\\002_20200623_043100(6).bmp\n",
      "Showing image 13/49, path: input\\002_20200623_043100(6).bmp\n",
      "Showing image 14/49, path: input\\002_20200623_043105(0).bmp\n",
      "Showing image 14/49, path: input\\002_20200623_043105(0).bmp\n",
      "Showing image 15/49, path: input\\002_20200623_043109(4).bmp\n",
      "Showing image 15/49, path: input\\002_20200623_043109(4).bmp\n",
      "Showing image 16/49, path: input\\002_20200623_043115(4).bmp\n",
      "Showing image 16/49, path: input\\002_20200623_043115(4).bmp\n",
      "Showing image 17/49, path: input\\002_20200623_043120(0).bmp\n",
      "Showing image 17/49, path: input\\002_20200623_043120(0).bmp\n",
      "Showing image 18/49, path: input\\002_20200623_082249(3).bmp\n",
      "Showing image 18/49, path: input\\002_20200623_082249(3).bmp\n",
      "Showing image 19/49, path: input\\002_20200623_082253(8).bmp\n",
      "Showing image 19/49, path: input\\002_20200623_082253(8).bmp\n",
      "Showing image 20/49, path: input\\002_20200623_082258(4).bmp\n",
      "Showing image 20/49, path: input\\002_20200623_082258(4).bmp\n",
      "Showing image 21/49, path: input\\002_20200623_082302(7).bmp\n",
      "Showing image 21/49, path: input\\002_20200623_082302(7).bmp\n",
      "Showing image 22/49, path: input\\002_20200623_082307(2).bmp\n",
      "Showing image 22/49, path: input\\002_20200623_082307(2).bmp\n",
      "Showing image 23/49, path: input\\002_20200623_082311(8).bmp\n",
      "Showing image 23/49, path: input\\002_20200623_082311(8).bmp\n",
      "Showing image 24/49, path: input\\002_20200623_123042(0).bmp\n",
      "Showing image 24/49, path: input\\002_20200623_123042(0).bmp\n",
      "Showing image 25/49, path: input\\002_20200623_123046(4).bmp\n",
      "Showing image 25/49, path: input\\002_20200623_123046(4).bmp\n",
      "Showing image 26/49, path: input\\002_20200623_123051(1).bmp\n",
      "Showing image 26/49, path: input\\002_20200623_123051(1).bmp\n",
      "Showing image 27/49, path: input\\002_20200623_123055(5).bmp\n",
      "Showing image 27/49, path: input\\002_20200623_123055(5).bmp\n",
      "Showing image 28/49, path: input\\002_20200623_123100(0).bmp\n",
      "Showing image 28/49, path: input\\002_20200623_123100(0).bmp\n",
      "Showing image 29/49, path: input\\002_20200623_123104(5).bmp\n",
      "Showing image 29/49, path: input\\002_20200623_123104(5).bmp\n",
      "Showing image 30/49, path: input\\002_20200623_163020(3).bmp\n",
      "Showing image 30/49, path: input\\002_20200623_163020(3).bmp\n",
      "Showing image 31/49, path: input\\002_20200623_163023(3).bmp\n",
      "Showing image 31/49, path: input\\002_20200623_163023(3).bmp\n",
      "Showing image 32/49, path: input\\002_20200623_163026(3).bmp\n",
      "Showing image 32/49, path: input\\002_20200623_163026(3).bmp\n",
      "Showing image 33/49, path: input\\002_20200623_163029(6).bmp\n",
      "Showing image 33/49, path: input\\002_20200623_163029(6).bmp\n",
      "Showing image 34/49, path: input\\002_20200623_163032(5).bmp\n",
      "Showing image 34/49, path: input\\002_20200623_163032(5).bmp\n",
      "Showing image 35/49, path: input\\002_20200623_163035(5).bmp\n",
      "Showing image 35/49, path: input\\002_20200623_163035(5).bmp\n",
      "Showing image 36/49, path: input\\002_20200623_203033(6).bmp\n",
      "Showing image 36/49, path: input\\002_20200623_203033(6).bmp\n",
      "Showing image 37/49, path: input\\002_20200623_203038(0).bmp\n",
      "Showing image 37/49, path: input\\002_20200623_203038(0).bmp\n",
      "Showing image 38/49, path: input\\002_20200623_203042(5).bmp\n",
      "Showing image 38/49, path: input\\002_20200623_203042(5).bmp\n",
      "Showing image 39/49, path: input\\002_20200623_203047(0).bmp\n",
      "Showing image 39/49, path: input\\002_20200623_203047(0).bmp\n",
      "Showing image 40/49, path: input\\002_20200623_203050(0).bmp\n",
      "Showing image 40/49, path: input\\002_20200623_203050(0).bmp\n",
      "Showing image 41/49, path: input\\002_20200623_203054(6).bmp\n",
      "Showing image 41/49, path: input\\002_20200623_203054(6).bmp\n",
      "Showing image 42/49, path: input\\002_20200624_003115(6).bmp\n",
      "Showing image 42/49, path: input\\002_20200624_003115(6).bmp\n",
      "Showing image 43/49, path: input\\002_20200624_003118(6).bmp\n",
      "Showing image 43/49, path: input\\002_20200624_003118(6).bmp\n",
      "Showing image 44/49, path: input\\002_20200624_003123(0).bmp\n",
      "Showing image 44/49, path: input\\002_20200624_003123(0).bmp\n",
      "Showing image 45/49, path: input\\002_20200624_003127(5).bmp\n",
      "Showing image 45/49, path: input\\002_20200624_003127(5).bmp\n",
      "Showing image 46/49, path: input\\002_20200624_003132(0).bmp\n",
      "Showing image 46/49, path: input\\002_20200624_003132(0).bmp\n",
      "Showing image 47/49, path: input\\002_20200624_003136(5).bmp\n",
      "Showing image 47/49, path: input\\002_20200624_003136(5).bmp\n",
      "Showing image 48/49, path: input\\002_20200624_043136(9).bmp\n",
      "Showing image 48/49, path: input\\002_20200624_043136(9).bmp\n",
      "Showing image 49/49, path: input\\002_20200624_043141(4).bmp\n",
      "Showing image 49/49, path: input\\002_20200624_043141(4).bmp\n",
      "Showing image 0/49, path: input\\002_20200622_203136(3).bmp\n",
      "Showing image 0/49, path: input\\002_20200622_203136(3).bmp\n",
      "Showing image 1/49, path: input\\002_20200622_203140(8).bmp\n",
      "Showing image 1/49, path: input\\002_20200622_203140(8).bmp\n",
      "Showing image 2/49, path: input\\002_20200622_203145(3).bmp\n",
      "Showing image 2/49, path: input\\002_20200622_203145(3).bmp\n",
      "Showing image 3/49, path: input\\002_20200622_203149(8).bmp\n",
      "Showing image 3/49, path: input\\002_20200622_203149(8).bmp\n",
      "Showing image 4/49, path: input\\002_20200622_203154(3).bmp\n",
      "Showing image 4/49, path: input\\002_20200622_203154(3).bmp\n",
      "Showing image 5/49, path: input\\002_20200622_203158(8).bmp\n",
      "Showing image 5/49, path: input\\002_20200622_203158(8).bmp\n",
      "Showing image 6/49, path: input\\002_20200623_003351(2).bmp\n",
      "Showing image 6/49, path: input\\002_20200623_003351(2).bmp\n",
      "Showing image 7/49, path: input\\002_20200623_003355(7).bmp\n",
      "Showing image 7/49, path: input\\002_20200623_003355(7).bmp\n",
      "Showing image 8/49, path: input\\002_20200623_003400(2).bmp\n",
      "Showing image 8/49, path: input\\002_20200623_003400(2).bmp\n",
      "Showing image 9/49, path: input\\002_20200623_003404(7).bmp\n",
      "Showing image 9/49, path: input\\002_20200623_003404(7).bmp\n",
      "Showing image 10/49, path: input\\002_20200623_003409(2).bmp\n",
      "Showing image 10/49, path: input\\002_20200623_003409(2).bmp\n",
      "Showing image 11/49, path: input\\002_20200623_003413(7).bmp\n",
      "Showing image 11/49, path: input\\002_20200623_003413(7).bmp\n",
      "Showing image 12/49, path: input\\002_20200623_043056(0).bmp\n",
      "Showing image 12/49, path: input\\002_20200623_043056(0).bmp\n",
      "Showing image 13/49, path: input\\002_20200623_043100(6).bmp\n",
      "Showing image 13/49, path: input\\002_20200623_043100(6).bmp\n",
      "Showing image 14/49, path: input\\002_20200623_043105(0).bmp\n",
      "Showing image 14/49, path: input\\002_20200623_043105(0).bmp\n",
      "Showing image 15/49, path: input\\002_20200623_043109(4).bmp\n",
      "Showing image 15/49, path: input\\002_20200623_043109(4).bmp\n",
      "Showing image 16/49, path: input\\002_20200623_043115(4).bmp\n",
      "Showing image 16/49, path: input\\002_20200623_043115(4).bmp\n",
      "Showing image 17/49, path: input\\002_20200623_043120(0).bmp\n",
      "Showing image 17/49, path: input\\002_20200623_043120(0).bmp\n",
      "Showing image 18/49, path: input\\002_20200623_082249(3).bmp\n",
      "Showing image 18/49, path: input\\002_20200623_082249(3).bmp\n",
      "Showing image 19/49, path: input\\002_20200623_082253(8).bmp\n",
      "Showing image 19/49, path: input\\002_20200623_082253(8).bmp\n",
      "Showing image 20/49, path: input\\002_20200623_082258(4).bmp\n",
      "Showing image 20/49, path: input\\002_20200623_082258(4).bmp\n",
      "Showing image 21/49, path: input\\002_20200623_082302(7).bmp\n",
      "Showing image 21/49, path: input\\002_20200623_082302(7).bmp\n",
      "Showing image 22/49, path: input\\002_20200623_082307(2).bmp\n",
      "Showing image 22/49, path: input\\002_20200623_082307(2).bmp\n",
      "Showing image 23/49, path: input\\002_20200623_082311(8).bmp\n",
      "Showing image 23/49, path: input\\002_20200623_082311(8).bmp\n",
      "Showing image 24/49, path: input\\002_20200623_123042(0).bmp\n",
      "Showing image 24/49, path: input\\002_20200623_123042(0).bmp\n",
      "Showing image 25/49, path: input\\002_20200623_123046(4).bmp\n",
      "Showing image 25/49, path: input\\002_20200623_123046(4).bmp\n",
      "Showing image 26/49, path: input\\002_20200623_123051(1).bmp\n",
      "Showing image 26/49, path: input\\002_20200623_123051(1).bmp\n",
      "Showing image 27/49, path: input\\002_20200623_123055(5).bmp\n",
      "Showing image 27/49, path: input\\002_20200623_123055(5).bmp\n",
      "Showing image 28/49, path: input\\002_20200623_123100(0).bmp\n",
      "Showing image 28/49, path: input\\002_20200623_123100(0).bmp\n",
      "Showing image 29/49, path: input\\002_20200623_123104(5).bmp\n",
      "Showing image 29/49, path: input\\002_20200623_123104(5).bmp\n",
      "Showing image 30/49, path: input\\002_20200623_163020(3).bmp\n",
      "Showing image 30/49, path: input\\002_20200623_163020(3).bmp\n",
      "Showing image 31/49, path: input\\002_20200623_163023(3).bmp\n",
      "Showing image 31/49, path: input\\002_20200623_163023(3).bmp\n",
      "Showing image 32/49, path: input\\002_20200623_163026(3).bmp\n",
      "Showing image 32/49, path: input\\002_20200623_163026(3).bmp\n",
      "Showing image 33/49, path: input\\002_20200623_163029(6).bmp\n",
      "Showing image 33/49, path: input\\002_20200623_163029(6).bmp\n",
      "Showing image 34/49, path: input\\002_20200623_163032(5).bmp\n",
      "Showing image 34/49, path: input\\002_20200623_163032(5).bmp\n",
      "Showing image 35/49, path: input\\002_20200623_163035(5).bmp\n",
      "Showing image 35/49, path: input\\002_20200623_163035(5).bmp\n",
      "Showing image 36/49, path: input\\002_20200623_203033(6).bmp\n",
      "Showing image 36/49, path: input\\002_20200623_203033(6).bmp\n",
      "Showing image 37/49, path: input\\002_20200623_203038(0).bmp\n",
      "Showing image 37/49, path: input\\002_20200623_203038(0).bmp\n",
      "Showing image 38/49, path: input\\002_20200623_203042(5).bmp\n",
      "Showing image 38/49, path: input\\002_20200623_203042(5).bmp\n",
      "Showing image 39/49, path: input\\002_20200623_203047(0).bmp\n",
      "Showing image 39/49, path: input\\002_20200623_203047(0).bmp\n",
      "Showing image 40/49, path: input\\002_20200623_203050(0).bmp\n",
      "Showing image 40/49, path: input\\002_20200623_203050(0).bmp\n",
      "Showing image 41/49, path: input\\002_20200623_203054(6).bmp\n",
      "Showing image 41/49, path: input\\002_20200623_203054(6).bmp\n",
      "Showing image 42/49, path: input\\002_20200624_003115(6).bmp\n",
      "Showing image 42/49, path: input\\002_20200624_003115(6).bmp\n",
      "Showing image 43/49, path: input\\002_20200624_003118(6).bmp\n",
      "Showing image 43/49, path: input\\002_20200624_003118(6).bmp\n",
      "Showing image 44/49, path: input\\002_20200624_003123(0).bmp\n",
      "Showing image 44/49, path: input\\002_20200624_003123(0).bmp\n",
      "Showing image 45/49, path: input\\002_20200624_003127(5).bmp\n",
      "Showing image 45/49, path: input\\002_20200624_003127(5).bmp\n",
      "Showing image 46/49, path: input\\002_20200624_003132(0).bmp\n",
      "Showing image 46/49, path: input\\002_20200624_003132(0).bmp\n",
      "Showing image 47/49, path: input\\002_20200624_003136(5).bmp\n",
      "Showing image 47/49, path: input\\002_20200624_003136(5).bmp\n",
      "Showing image 48/49, path: input\\002_20200624_043136(9).bmp\n",
      "Showing image 48/49, path: input\\002_20200624_043136(9).bmp\n",
      "Showing image 49/49, path: input\\002_20200624_043141(4).bmp\n",
      "Showing image 49/49, path: input\\002_20200624_043141(4).bmp\n",
      "Showing image 0/49, path: input\\002_20200622_203136(3).bmp\n",
      "Showing image 0/49, path: input\\002_20200622_203136(3).bmp\n"
     ]
    }
   ],
   "source": [
    "!python C:/Users/mit017/Desktop/myproject/XRAY_PROJECT/XrayInspection/dataset/OpenLabeling-master/main/main.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "2eba9de8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "C:\\Users\\mit017\\Desktop\\myproject\\XRAY_PROJECT\\XrayInspection\\dataset\\test1\\yolov3\n"
     ]
    }
   ],
   "source": [
    "%cd C:/Users/mit017/Desktop/myproject/XRAY_PROJECT/XrayInspection/dataset/test1/yolov3/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "c8c4455d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "import os\n",
    "import subprocess\n",
    "import sys\n",
    "\n",
    "def split_data_set(image_dir):\n",
    "    # 테스트 세트와 훈련 세트 파일을 열기\n",
    "    f_val = open('test.txt', 'w')\n",
    "    f_train = open('train.txt', 'w')\n",
    "    \n",
    "    # 주어진 디렉토리에서 파일 목록을 얻기\n",
    "    path, dirs, files = next(os.walk(image_dir))\n",
    "    data_size = len(files)\n",
    "    \n",
    "    # 데이터 세트의 크기를 기반으로 테스트 세트의 크기를 결정\n",
    "    ind = 0\n",
    "    data_test_size = int(0.2 * data_size)\n",
    "    test_array = random.sample(range(data_size), k=data_test_size)\n",
    "    \n",
    "    for f in os.listdir(image_dir):\n",
    "        # 파일이 JPEG 이미지인지 확인\n",
    "        if f.endswith(\".jpg\"):\n",
    "            ind += 1\n",
    "            \n",
    "            # 파일 인덱스가 테스트 배열에 있는 경우, 테스트 세트에 추가\n",
    "            if ind in test_array:\n",
    "                f_val.write(image_dir + \"/\" + f + '\\n')\n",
    "            else:\n",
    "                # 그렇지 않으면 훈련 세트에 추가\n",
    "                f_train.write(image_dir + '/' + f + '\\n')\n",
    "\n",
    "    # 파일 닫기\n",
    "    f_val.close()\n",
    "    f_train.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "9d76fc8a",
   "metadata": {},
   "outputs": [],
   "source": [
    "image_dir='C:/Users/mit017/Desktop/myproject/XRAY_PROJECT/XrayInspection/dataset/test1/yolov3/images'\n",
    "\n",
    "import random\n",
    "import os\n",
    "import subprocess\n",
    "import sys\n",
    "\n",
    "split_data_set(image_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "e83b8631",
   "metadata": {},
   "outputs": [],
   "source": [
    "os.environ['KMP_DUPLICATE_LIB_OK']='True'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "3f33bff9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Apex recommended for faster mixed precision training: https://github.com/NVIDIA/apex\n",
      "Namespace(epochs=15, batch_size=3, cfg='yolov3-spp.cfg', data='custom.data', multi_scale=False, img_size=[320, 640], rect=False, resume=False, nosave=True, notest=False, evolve=False, bucket='', cache_images=False, weights='weights/last.pt', name='', device='cpu', adam=False, single_cls=False, freeze_layers=False)\n",
      "Using CPU\n",
      "\n",
      "Start Tensorboard with \"tensorboard --logdir=runs\", view at http://localhost:6006/\n",
      "WARNING: smart bias initialization failure.\n",
      "WARNING: smart bias initialization failure.\n",
      "WARNING: smart bias initialization failure.\n",
      "Model Summary: 225 layers, 6.25733e+07 parameters, 6.25733e+07 gradients\n",
      "Optimizer groups: 76 .bias, 76 Conv2d.weight, 73 other\n",
      "weights/last.pt has been trained for 834 epochs. Fine-tuning for 15 additional epochs.\n",
      "Image sizes 320 - 640 train, 640 test\n",
      "Using 3 dataloader workers\n",
      "Starting training for 849 epochs...\n",
      "\n",
      "     Epoch   gpu_mem      GIoU       obj       cls     total   targets  img_size\n",
      "Apex recommended for faster mixed precision training: https://github.com/NVIDIA/apex\n",
      "Apex recommended for faster mixed precision training: https://github.com/NVIDIA/apex\n",
      "Apex recommended for faster mixed precision training: https://github.com/NVIDIA/apex\n",
      "Apex recommended for faster mixed precision training: https://github.com/NVIDIA/apex\n",
      "Apex recommended for faster mixed precision training: https://github.com/NVIDIA/apex\n",
      "Apex recommended for faster mixed precision training: https://github.com/NVIDIA/apex\n",
      "                 all        10        30     0.853     0.775      0.85     0.812\n",
      "\n",
      "     Epoch   gpu_mem      GIoU       obj       cls     total   targets  img_size\n",
      "Apex recommended for faster mixed precision training: https://github.com/NVIDIA/apex\n",
      "Apex recommended for faster mixed precision training: https://github.com/NVIDIA/apex\n",
      "Apex recommended for faster mixed precision training: https://github.com/NVIDIA/apex\n",
      "Apex recommended for faster mixed precision training: https://github.com/NVIDIA/apex\n",
      "Apex recommended for faster mixed precision training: https://github.com/NVIDIA/apex\n",
      "Apex recommended for faster mixed precision training: https://github.com/NVIDIA/apex\n",
      "                 all        10        30     0.853     0.775      0.85     0.812\n",
      "\n",
      "     Epoch   gpu_mem      GIoU       obj       cls     total   targets  img_size\n",
      "Apex recommended for faster mixed precision training: https://github.com/NVIDIA/apex\n",
      "Apex recommended for faster mixed precision training: https://github.com/NVIDIA/apex\n",
      "Apex recommended for faster mixed precision training: https://github.com/NVIDIA/apex\n",
      "Apex recommended for faster mixed precision training: https://github.com/NVIDIA/apex\n",
      "Apex recommended for faster mixed precision training: https://github.com/NVIDIA/apex\n",
      "Apex recommended for faster mixed precision training: https://github.com/NVIDIA/apex\n",
      "                 all        10        30     0.776     0.733     0.796     0.754\n",
      "\n",
      "     Epoch   gpu_mem      GIoU       obj       cls     total   targets  img_size\n",
      "Apex recommended for faster mixed precision training: https://github.com/NVIDIA/apex\n",
      "Apex recommended for faster mixed precision training: https://github.com/NVIDIA/apex\n",
      "Apex recommended for faster mixed precision training: https://github.com/NVIDIA/apex\n",
      "Apex recommended for faster mixed precision training: https://github.com/NVIDIA/apex\n",
      "Apex recommended for faster mixed precision training: https://github.com/NVIDIA/apex\n",
      "Apex recommended for faster mixed precision training: https://github.com/NVIDIA/apex\n",
      "                 all        10        30     0.835     0.733     0.797     0.781\n",
      "\n",
      "     Epoch   gpu_mem      GIoU       obj       cls     total   targets  img_size\n",
      "Apex recommended for faster mixed precision training: https://github.com/NVIDIA/apex\n",
      "Apex recommended for faster mixed precision training: https://github.com/NVIDIA/apex\n",
      "Apex recommended for faster mixed precision training: https://github.com/NVIDIA/apex\n",
      "Apex recommended for faster mixed precision training: https://github.com/NVIDIA/apex\n",
      "Apex recommended for faster mixed precision training: https://github.com/NVIDIA/apex\n",
      "Apex recommended for faster mixed precision training: https://github.com/NVIDIA/apex\n",
      "                 all        10        30     0.835     0.733     0.797     0.781\n",
      "\n",
      "     Epoch   gpu_mem      GIoU       obj       cls     total   targets  img_size\n",
      "Apex recommended for faster mixed precision training: https://github.com/NVIDIA/apex\n",
      "Apex recommended for faster mixed precision training: https://github.com/NVIDIA/apex\n",
      "Apex recommended for faster mixed precision training: https://github.com/NVIDIA/apex\n",
      "Apex recommended for faster mixed precision training: https://github.com/NVIDIA/apex\n",
      "Apex recommended for faster mixed precision training: https://github.com/NVIDIA/apex\n",
      "Apex recommended for faster mixed precision training: https://github.com/NVIDIA/apex\n",
      "                 all        10        30     0.831     0.493     0.771     0.619\n",
      "\n",
      "     Epoch   gpu_mem      GIoU       obj       cls     total   targets  img_size\n",
      "Apex recommended for faster mixed precision training: https://github.com/NVIDIA/apex\n",
      "Apex recommended for faster mixed precision training: https://github.com/NVIDIA/apex\n",
      "Apex recommended for faster mixed precision training: https://github.com/NVIDIA/apex\n",
      "Apex recommended for faster mixed precision training: https://github.com/NVIDIA/apex\n",
      "Apex recommended for faster mixed precision training: https://github.com/NVIDIA/apex\n",
      "Apex recommended for faster mixed precision training: https://github.com/NVIDIA/apex\n",
      "                 all        10        30     0.801     0.536     0.776     0.642\n",
      "\n",
      "     Epoch   gpu_mem      GIoU       obj       cls     total   targets  img_size\n",
      "Apex recommended for faster mixed precision training: https://github.com/NVIDIA/apex\n",
      "Apex recommended for faster mixed precision training: https://github.com/NVIDIA/apex\n",
      "Apex recommended for faster mixed precision training: https://github.com/NVIDIA/apex\n",
      "Apex recommended for faster mixed precision training: https://github.com/NVIDIA/apex\n",
      "Apex recommended for faster mixed precision training: https://github.com/NVIDIA/apex\n",
      "Apex recommended for faster mixed precision training: https://github.com/NVIDIA/apex\n",
      "                 all        10        30     0.801     0.536     0.776     0.642\n",
      "\n",
      "     Epoch   gpu_mem      GIoU       obj       cls     total   targets  img_size\n",
      "Apex recommended for faster mixed precision training: https://github.com/NVIDIA/apex\n",
      "Apex recommended for faster mixed precision training: https://github.com/NVIDIA/apex\n",
      "Apex recommended for faster mixed precision training: https://github.com/NVIDIA/apex\n",
      "Apex recommended for faster mixed precision training: https://github.com/NVIDIA/apex\n",
      "Apex recommended for faster mixed precision training: https://github.com/NVIDIA/apex\n",
      "Apex recommended for faster mixed precision training: https://github.com/NVIDIA/apex\n",
      "                 all        10        30     0.839     0.733     0.839     0.783\n",
      "\n",
      "     Epoch   gpu_mem      GIoU       obj       cls     total   targets  img_size\n",
      "Apex recommended for faster mixed precision training: https://github.com/NVIDIA/apex\n",
      "Apex recommended for faster mixed precision training: https://github.com/NVIDIA/apex\n",
      "Apex recommended for faster mixed precision training: https://github.com/NVIDIA/apex\n",
      "Apex recommended for faster mixed precision training: https://github.com/NVIDIA/apex\n",
      "Apex recommended for faster mixed precision training: https://github.com/NVIDIA/apex\n",
      "Apex recommended for faster mixed precision training: https://github.com/NVIDIA/apex\n",
      "                 all        10        30     0.888     0.796     0.886     0.839\n",
      "\n",
      "     Epoch   gpu_mem      GIoU       obj       cls     total   targets  img_size\n",
      "Apex recommended for faster mixed precision training: https://github.com/NVIDIA/apex\n",
      "Apex recommended for faster mixed precision training: https://github.com/NVIDIA/apex\n",
      "Apex recommended for faster mixed precision training: https://github.com/NVIDIA/apex\n",
      "Apex recommended for faster mixed precision training: https://github.com/NVIDIA/apex\n",
      "Apex recommended for faster mixed precision training: https://github.com/NVIDIA/apex\n",
      "Apex recommended for faster mixed precision training: https://github.com/NVIDIA/apex\n",
      "                 all        10        30     0.888     0.796     0.886     0.839\n",
      "\n",
      "     Epoch   gpu_mem      GIoU       obj       cls     total   targets  img_size\n",
      "Apex recommended for faster mixed precision training: https://github.com/NVIDIA/apex\n",
      "Apex recommended for faster mixed precision training: https://github.com/NVIDIA/apex\n",
      "Apex recommended for faster mixed precision training: https://github.com/NVIDIA/apex\n",
      "Apex recommended for faster mixed precision training: https://github.com/NVIDIA/apex\n",
      "Apex recommended for faster mixed precision training: https://github.com/NVIDIA/apex\n",
      "Apex recommended for faster mixed precision training: https://github.com/NVIDIA/apex\n",
      "                 all        10        30      0.79     0.753     0.826     0.771\n",
      "\n",
      "     Epoch   gpu_mem      GIoU       obj       cls     total   targets  img_size\n",
      "Apex recommended for faster mixed precision training: https://github.com/NVIDIA/apex\n",
      "Apex recommended for faster mixed precision training: https://github.com/NVIDIA/apex\n",
      "Apex recommended for faster mixed precision training: https://github.com/NVIDIA/apex\n",
      "Apex recommended for faster mixed precision training: https://github.com/NVIDIA/apex\n",
      "Apex recommended for faster mixed precision training: https://github.com/NVIDIA/apex\n",
      "Apex recommended for faster mixed precision training: https://github.com/NVIDIA/apex\n",
      "                 all        10        30     0.815       0.7      0.82     0.753\n",
      "\n",
      "     Epoch   gpu_mem      GIoU       obj       cls     total   targets  img_size\n",
      "Apex recommended for faster mixed precision training: https://github.com/NVIDIA/apex\n",
      "Apex recommended for faster mixed precision training: https://github.com/NVIDIA/apex\n",
      "Apex recommended for faster mixed precision training: https://github.com/NVIDIA/apex\n",
      "Apex recommended for faster mixed precision training: https://github.com/NVIDIA/apex\n",
      "Apex recommended for faster mixed precision training: https://github.com/NVIDIA/apex\n",
      "Apex recommended for faster mixed precision training: https://github.com/NVIDIA/apex\n",
      "                 all        10        30     0.815       0.7      0.82     0.753\n",
      "14 epochs completed in 0.414 hours.\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-03-05 09:23:58.983323: I tensorflow/core/util/port.cc:113] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
      "WARNING:tensorflow:From C:\\Users\\mit017\\anaconda3\\Lib\\site-packages\\keras\\src\\losses.py:2976: The name tf.losses.sparse_softmax_cross_entropy is deprecated. Please use tf.compat.v1.losses.sparse_softmax_cross_entropy instead.\n",
      "\n",
      "\n",
      "Reading image shapes:   0%|          | 0/40 [00:00<?, ?it/s]\n",
      "Reading image shapes: 100%|##########| 40/40 [00:00<00:00, 535.80it/s]\n",
      "\n",
      "  0%|          | 0/40 [00:00<?, ?it/s]\n",
      "Caching labels C:\\Users\\mit017\\Desktop\\myproject\\XRAY_PROJECT\\XrayInspection\\dataset\\test1\\yolov3\\train.txt (40 found, 0 missing, 0 empty, 0 duplicate, for 40 images): 100%|##########| 40/40 [00:00<00:00, 594.22it/s]\n",
      "\n",
      "Reading image shapes:   0%|          | 0/10 [00:00<?, ?it/s]\n",
      "Reading image shapes: 100%|##########| 10/10 [00:00<00:00, 509.01it/s]\n",
      "\n",
      "  0%|          | 0/10 [00:00<?, ?it/s]\n",
      "Caching labels C:\\Users\\mit017\\Desktop\\myproject\\XRAY_PROJECT\\XrayInspection\\dataset\\test1\\yolov3\\test.txt (10 found, 0 missing, 0 empty, 0 duplicate, for 10 images): 100%|##########| 10/10 [00:00<00:00, 408.51it/s]\n",
      "2024-03-05 09:24:15.786544: I tensorflow/core/util/port.cc:113] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
      "WARNING:tensorflow:From C:\\Users\\mit017\\anaconda3\\Lib\\site-packages\\keras\\src\\losses.py:2976: The name tf.losses.sparse_softmax_cross_entropy is deprecated. Please use tf.compat.v1.losses.sparse_softmax_cross_entropy instead.\n",
      "\n",
      "2024-03-05 09:24:26.136208: I tensorflow/core/util/port.cc:113] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
      "WARNING:tensorflow:From C:\\Users\\mit017\\anaconda3\\Lib\\site-packages\\keras\\src\\losses.py:2976: The name tf.losses.sparse_softmax_cross_entropy is deprecated. Please use tf.compat.v1.losses.sparse_softmax_cross_entropy instead.\n",
      "\n",
      "2024-03-05 09:24:36.616854: I tensorflow/core/util/port.cc:113] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
      "WARNING:tensorflow:From C:\\Users\\mit017\\anaconda3\\Lib\\site-packages\\keras\\src\\losses.py:2976: The name tf.losses.sparse_softmax_cross_entropy is deprecated. Please use tf.compat.v1.losses.sparse_softmax_cross_entropy instead.\n",
      "\n",
      "\n",
      "  0%|          | 0/14 [00:00<?, ?it/s]\n",
      "   835/848        0G      2.71     0.133         0      2.85         9       640:   0%|          | 0/14 [00:07<?, ?it/s]\n",
      "   835/848        0G      2.71     0.133         0      2.85         9       640:   7%|7         | 1/14 [00:07<01:31,  7.05s/it]\n",
      "   835/848        0G      2.11     0.094         0      2.21         9       640:   7%|7         | 1/14 [00:13<01:31,  7.05s/it]\n",
      "   835/848        0G      2.11     0.094         0      2.21         9       640:  14%|#4        | 2/14 [00:13<01:21,  6.77s/it]\n",
      "   835/848        0G      2.53     0.098         0      2.63         9       640:  14%|#4        | 2/14 [00:20<01:21,  6.77s/it]\n",
      "   835/848        0G      2.53     0.098         0      2.63         9       640:  21%|##1       | 3/14 [00:20<01:14,  6.76s/it]\n",
      "   835/848        0G      2.59    0.0945         0      2.69         9       640:  21%|##1       | 3/14 [00:27<01:14,  6.76s/it]\n",
      "   835/848        0G      2.59    0.0945         0      2.69         9       640:  29%|##8       | 4/14 [00:27<01:07,  6.73s/it]\n",
      "   835/848        0G      2.47    0.0973         0      2.57        10       640:  29%|##8       | 4/14 [00:33<01:07,  6.73s/it]\n",
      "   835/848        0G      2.47    0.0973         0      2.57        10       640:  36%|###5      | 5/14 [00:33<01:00,  6.71s/it]\n",
      "   835/848        0G      2.69    0.0935         0      2.78         9       640:  36%|###5      | 5/14 [00:40<01:00,  6.71s/it]\n",
      "   835/848        0G      2.69    0.0935         0      2.78         9       640:  43%|####2     | 6/14 [00:40<00:54,  6.78s/it]\n",
      "   835/848        0G      2.51    0.0881         0       2.6         9       640:  43%|####2     | 6/14 [00:47<00:54,  6.78s/it]\n",
      "   835/848        0G      2.51    0.0881         0       2.6         9       640:  50%|#####     | 7/14 [00:47<00:47,  6.76s/it]\n",
      "   835/848        0G      2.36     0.085         0      2.44         9       512:  50%|#####     | 7/14 [00:51<00:47,  6.76s/it]\n",
      "   835/848        0G      2.36     0.085         0      2.44         9       512:  57%|#####7    | 8/14 [00:51<00:36,  6.07s/it]\n",
      "   835/848        0G      2.23    0.0838         0      2.32         9       512:  57%|#####7    | 8/14 [00:56<00:36,  6.07s/it]\n",
      "   835/848        0G      2.23    0.0838         0      2.32         9       512:  64%|######4   | 9/14 [00:56<00:27,  5.46s/it]\n",
      "   835/848        0G      2.15    0.0832         0      2.23         9       512:  64%|######4   | 9/14 [01:00<00:27,  5.46s/it]\n",
      "   835/848        0G      2.15    0.0832         0      2.23         9       512:  71%|#######1  | 10/14 [01:00<00:20,  5.07s/it]\n",
      "   835/848        0G      2.05    0.0825         0      2.13         9       512:  71%|#######1  | 10/14 [01:04<00:20,  5.07s/it]\n",
      "   835/848        0G      2.05    0.0825         0      2.13         9       512:  79%|#######8  | 11/14 [01:04<00:14,  4.79s/it]\n",
      "   835/848        0G      1.98    0.0805         0      2.06         9       512:  79%|#######8  | 11/14 [01:08<00:14,  4.79s/it]\n",
      "   835/848        0G      1.98    0.0805         0      2.06         9       512:  86%|########5 | 12/14 [01:08<00:09,  4.60s/it]\n",
      "   835/848        0G      1.93    0.0796         0      2.01         9       512:  86%|########5 | 12/14 [01:12<00:09,  4.60s/it]\n",
      "   835/848        0G      1.93    0.0796         0      2.01         9       512:  93%|#########2| 13/14 [01:12<00:04,  4.49s/it]\n",
      "   835/848        0G      1.87    0.0778         0      1.95         3       512:  93%|#########2| 13/14 [01:14<00:04,  4.49s/it]\n",
      "   835/848        0G      1.87    0.0778         0      1.95         3       512: 100%|##########| 14/14 [01:14<00:00,  3.59s/it]\n",
      "   835/848        0G      1.87    0.0778         0      1.95         3       512: 100%|##########| 14/14 [01:15<00:00,  5.38s/it]\n",
      "\n",
      "               Class    Images   Targets         P         R   mAP@0.5        F1:   0%|          | 0/4 [00:00<?, ?it/s]2024-03-05 09:26:02.422239: I tensorflow/core/util/port.cc:113] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
      "2024-03-05 09:26:02.473613: I tensorflow/core/util/port.cc:113] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
      "2024-03-05 09:26:02.567556: I tensorflow/core/util/port.cc:113] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
      "WARNING:tensorflow:From C:\\Users\\mit017\\anaconda3\\Lib\\site-packages\\keras\\src\\losses.py:2976: The name tf.losses.sparse_softmax_cross_entropy is deprecated. Please use tf.compat.v1.losses.sparse_softmax_cross_entropy instead.\n",
      "\n",
      "WARNING:tensorflow:From C:\\Users\\mit017\\anaconda3\\Lib\\site-packages\\keras\\src\\losses.py:2976: The name tf.losses.sparse_softmax_cross_entropy is deprecated. Please use tf.compat.v1.losses.sparse_softmax_cross_entropy instead.\n",
      "\n",
      "WARNING:tensorflow:From C:\\Users\\mit017\\anaconda3\\Lib\\site-packages\\keras\\src\\losses.py:2976: The name tf.losses.sparse_softmax_cross_entropy is deprecated. Please use tf.compat.v1.losses.sparse_softmax_cross_entropy instead.\n",
      "\n",
      "C:\\Users\\mit017\\anaconda3\\Lib\\site-packages\\torch\\functional.py:507: UserWarning: torch.meshgrid: in an upcoming release, it will be required to pass the indexing argument. (Triggered internally at ..\\aten\\src\\ATen\\native\\TensorShape.cpp:3550.)\n",
      "  return _VF.meshgrid(tensors, **kwargs)  # type: ignore[attr-defined]\n",
      "\n",
      "               Class    Images   Targets         P         R   mAP@0.5        F1:  25%|##5       | 1/4 [00:13<00:41, 13.76s/it]\n",
      "               Class    Images   Targets         P         R   mAP@0.5        F1:  50%|#####     | 2/4 [00:15<00:13,  6.87s/it]\n",
      "               Class    Images   Targets         P         R   mAP@0.5        F1:  75%|#######5  | 3/4 [00:17<00:04,  4.66s/it]\n",
      "               Class    Images   Targets         P         R   mAP@0.5        F1: 100%|##########| 4/4 [00:18<00:00,  3.10s/it]\n",
      "               Class    Images   Targets         P         R   mAP@0.5        F1: 100%|##########| 4/4 [00:19<00:00,  4.88s/it]\n",
      "2024-03-05 09:26:21.770058: I tensorflow/core/util/port.cc:113] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
      "WARNING:tensorflow:From C:\\Users\\mit017\\anaconda3\\Lib\\site-packages\\keras\\src\\losses.py:2976: The name tf.losses.sparse_softmax_cross_entropy is deprecated. Please use tf.compat.v1.losses.sparse_softmax_cross_entropy instead.\n",
      "\n",
      "2024-03-05 09:26:31.907035: I tensorflow/core/util/port.cc:113] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
      "WARNING:tensorflow:From C:\\Users\\mit017\\anaconda3\\Lib\\site-packages\\keras\\src\\losses.py:2976: The name tf.losses.sparse_softmax_cross_entropy is deprecated. Please use tf.compat.v1.losses.sparse_softmax_cross_entropy instead.\n",
      "\n",
      "2024-03-05 09:26:42.031307: I tensorflow/core/util/port.cc:113] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
      "WARNING:tensorflow:From C:\\Users\\mit017\\anaconda3\\Lib\\site-packages\\keras\\src\\losses.py:2976: The name tf.losses.sparse_softmax_cross_entropy is deprecated. Please use tf.compat.v1.losses.sparse_softmax_cross_entropy instead.\n",
      "\n",
      "\n",
      "  0%|          | 0/14 [00:00<?, ?it/s]\n",
      "   836/848        0G      1.15    0.0737         0      1.23         9       512:   0%|          | 0/14 [00:04<?, ?it/s]\n",
      "   836/848        0G      1.15    0.0737         0      1.23         9       512:   7%|7         | 1/14 [00:04<00:57,  4.46s/it]\n",
      "   836/848        0G      1.22    0.0788         0       1.3        12       512:   7%|7         | 1/14 [00:08<00:57,  4.46s/it]\n",
      "   836/848        0G      1.22    0.0788         0       1.3        12       512:  14%|#4        | 2/14 [00:08<00:52,  4.38s/it]\n",
      "   836/848        0G      1.16    0.0804         0      1.24        12       512:  14%|#4        | 2/14 [00:13<00:52,  4.38s/it]\n",
      "   836/848        0G      1.16    0.0804         0      1.24        12       512:  21%|##1       | 3/14 [00:13<00:49,  4.54s/it]\n",
      "   836/848        0G      1.35    0.0896         0      1.44        10       512:  21%|##1       | 3/14 [00:18<00:49,  4.54s/it]\n",
      "   836/848        0G      1.35    0.0896         0      1.44        10       512:  29%|##8       | 4/14 [00:18<00:47,  4.73s/it]\n",
      "   836/848        0G      1.26     0.085         0      1.35         8       512:  29%|##8       | 4/14 [00:22<00:47,  4.73s/it]\n",
      "   836/848        0G      1.26     0.085         0      1.35         8       512:  36%|###5      | 5/14 [00:22<00:41,  4.58s/it]\n",
      "   836/848        0G      1.18    0.0861         0      1.26         9       512:  36%|###5      | 5/14 [00:27<00:41,  4.58s/it]\n",
      "   836/848        0G      1.18    0.0861         0      1.26         9       512:  43%|####2     | 6/14 [00:27<00:35,  4.50s/it]\n",
      "   836/848        0G       1.2    0.0843         0      1.28         9       512:  43%|####2     | 6/14 [00:31<00:35,  4.50s/it]\n",
      "   836/848        0G       1.2    0.0843         0      1.28         9       512:  50%|#####     | 7/14 [00:31<00:31,  4.44s/it]\n",
      "   836/848        0G       1.2    0.0826         0      1.29         9       512:  50%|#####     | 7/14 [00:35<00:31,  4.44s/it]\n",
      "   836/848        0G       1.2    0.0826         0      1.29         9       512:  57%|#####7    | 8/14 [00:35<00:26,  4.40s/it]\n",
      "   836/848        0G      1.41    0.0866         0       1.5         9       512:  57%|#####7    | 8/14 [00:40<00:26,  4.40s/it]\n",
      "   836/848        0G      1.41    0.0866         0       1.5         9       512:  64%|######4   | 9/14 [00:40<00:21,  4.36s/it]\n",
      "   836/848        0G      1.39    0.0853         0      1.48        10       512:  64%|######4   | 9/14 [00:44<00:21,  4.36s/it]\n",
      "   836/848        0G      1.39    0.0853         0      1.48        10       512:  71%|#######1  | 10/14 [00:44<00:17,  4.33s/it]\n",
      "   836/848        0G      1.38    0.0844         0      1.46         9       512:  71%|#######1  | 10/14 [00:48<00:17,  4.33s/it]\n",
      "   836/848        0G      1.38    0.0844         0      1.46         9       512:  79%|#######8  | 11/14 [00:48<00:12,  4.30s/it]\n",
      "   836/848        0G      1.41    0.0884         0       1.5        11       512:  79%|#######8  | 11/14 [00:52<00:12,  4.30s/it]\n",
      "   836/848        0G      1.41    0.0884         0       1.5        11       512:  86%|########5 | 12/14 [00:52<00:08,  4.25s/it]\n",
      "   836/848        0G      1.38    0.0877         0      1.47         9       512:  86%|########5 | 12/14 [00:57<00:08,  4.25s/it]\n",
      "   836/848        0G      1.38    0.0877         0      1.47         9       512:  93%|#########2| 13/14 [00:57<00:04,  4.28s/it]\n",
      "   836/848        0G      1.43     0.084         0      1.51         3       512:  93%|#########2| 13/14 [00:58<00:04,  4.28s/it]\n",
      "   836/848        0G      1.43     0.084         0      1.51         3       512: 100%|##########| 14/14 [00:58<00:00,  3.46s/it]\n",
      "   836/848        0G      1.43     0.084         0      1.51         3       512: 100%|##########| 14/14 [00:59<00:00,  4.26s/it]\n",
      "\n",
      "               Class    Images   Targets         P         R   mAP@0.5        F1:   0%|          | 0/4 [00:00<?, ?it/s]2024-03-05 09:27:52.031781: I tensorflow/core/util/port.cc:113] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
      "2024-03-05 09:27:52.086347: I tensorflow/core/util/port.cc:113] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
      "2024-03-05 09:27:52.169256: I tensorflow/core/util/port.cc:113] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
      "WARNING:tensorflow:From C:\\Users\\mit017\\anaconda3\\Lib\\site-packages\\keras\\src\\losses.py:2976: The name tf.losses.sparse_softmax_cross_entropy is deprecated. Please use tf.compat.v1.losses.sparse_softmax_cross_entropy instead.\n",
      "\n",
      "WARNING:tensorflow:From C:\\Users\\mit017\\anaconda3\\Lib\\site-packages\\keras\\src\\losses.py:2976: The name tf.losses.sparse_softmax_cross_entropy is deprecated. Please use tf.compat.v1.losses.sparse_softmax_cross_entropy instead.\n",
      "\n",
      "WARNING:tensorflow:From C:\\Users\\mit017\\anaconda3\\Lib\\site-packages\\keras\\src\\losses.py:2976: The name tf.losses.sparse_softmax_cross_entropy is deprecated. Please use tf.compat.v1.losses.sparse_softmax_cross_entropy instead.\n",
      "\n",
      "\n",
      "               Class    Images   Targets         P         R   mAP@0.5        F1:  25%|##5       | 1/4 [00:13<00:40, 13.62s/it]\n",
      "               Class    Images   Targets         P         R   mAP@0.5        F1:  50%|#####     | 2/4 [00:15<00:13,  6.84s/it]\n",
      "               Class    Images   Targets         P         R   mAP@0.5        F1:  75%|#######5  | 3/4 [00:17<00:04,  4.65s/it]\n",
      "               Class    Images   Targets         P         R   mAP@0.5        F1: 100%|##########| 4/4 [00:18<00:00,  3.11s/it]\n",
      "               Class    Images   Targets         P         R   mAP@0.5        F1: 100%|##########| 4/4 [00:19<00:00,  4.87s/it]\n",
      "2024-03-05 09:28:11.326832: I tensorflow/core/util/port.cc:113] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
      "WARNING:tensorflow:From C:\\Users\\mit017\\anaconda3\\Lib\\site-packages\\keras\\src\\losses.py:2976: The name tf.losses.sparse_softmax_cross_entropy is deprecated. Please use tf.compat.v1.losses.sparse_softmax_cross_entropy instead.\n",
      "\n",
      "2024-03-05 09:28:21.519227: I tensorflow/core/util/port.cc:113] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
      "WARNING:tensorflow:From C:\\Users\\mit017\\anaconda3\\Lib\\site-packages\\keras\\src\\losses.py:2976: The name tf.losses.sparse_softmax_cross_entropy is deprecated. Please use tf.compat.v1.losses.sparse_softmax_cross_entropy instead.\n",
      "\n",
      "2024-03-05 09:28:31.840795: I tensorflow/core/util/port.cc:113] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
      "WARNING:tensorflow:From C:\\Users\\mit017\\anaconda3\\Lib\\site-packages\\keras\\src\\losses.py:2976: The name tf.losses.sparse_softmax_cross_entropy is deprecated. Please use tf.compat.v1.losses.sparse_softmax_cross_entropy instead.\n",
      "\n",
      "\n",
      "  0%|          | 0/14 [00:00<?, ?it/s]\n",
      "   837/848        0G      1.17     0.067         0      1.24         8       512:   0%|          | 0/14 [00:04<?, ?it/s]\n",
      "   837/848        0G      1.17     0.067         0      1.24         8       512:   7%|7         | 1/14 [00:04<00:59,  4.56s/it]\n",
      "   837/848        0G       1.1    0.0755         0      1.18         9       512:   7%|7         | 1/14 [00:08<00:59,  4.56s/it]\n",
      "   837/848        0G       1.1    0.0755         0      1.18         9       512:  14%|#4        | 2/14 [00:08<00:51,  4.28s/it]\n",
      "   837/848        0G      1.17    0.0735         0      1.24         9       512:  14%|#4        | 2/14 [00:12<00:51,  4.28s/it]\n",
      "   837/848        0G      1.17    0.0735         0      1.24         9       512:  21%|##1       | 3/14 [00:12<00:46,  4.23s/it]\n",
      "   837/848        0G      1.12    0.0766         0       1.2        10       512:  21%|##1       | 3/14 [00:17<00:46,  4.23s/it]\n",
      "   837/848        0G      1.12    0.0766         0       1.2        10       512:  29%|##8       | 4/14 [00:17<00:42,  4.23s/it]\n",
      "   837/848        0G      1.12    0.0773         0       1.2        10       512:  29%|##8       | 4/14 [00:21<00:42,  4.23s/it]\n",
      "   837/848        0G      1.12    0.0773         0       1.2        10       512:  36%|###5      | 5/14 [00:21<00:37,  4.21s/it]\n",
      "   837/848        0G       1.1    0.0765         0      1.17         9       512:  36%|###5      | 5/14 [00:25<00:37,  4.21s/it]\n",
      "   837/848        0G       1.1    0.0765         0      1.17         9       512:  43%|####2     | 6/14 [00:25<00:33,  4.21s/it]\n",
      "   837/848        0G       1.1    0.0754         0      1.17         9       512:  43%|####2     | 6/14 [00:29<00:33,  4.21s/it]\n",
      "   837/848        0G       1.1    0.0754         0      1.17         9       512:  50%|#####     | 7/14 [00:29<00:29,  4.20s/it]\n",
      "   837/848        0G      1.08    0.0791         0      1.16         9       512:  50%|#####     | 7/14 [00:33<00:29,  4.20s/it]\n",
      "   837/848        0G      1.08    0.0791         0      1.16         9       512:  57%|#####7    | 8/14 [00:33<00:25,  4.18s/it]\n",
      "   837/848        0G      1.11    0.0793         0      1.19         9       512:  57%|#####7    | 8/14 [00:37<00:25,  4.18s/it]\n",
      "   837/848        0G      1.11    0.0793         0      1.19         9       512:  64%|######4   | 9/14 [00:37<00:20,  4.18s/it]\n",
      "   837/848        0G      1.11    0.0778         0      1.19         9       512:  64%|######4   | 9/14 [00:42<00:20,  4.18s/it]\n",
      "   837/848        0G      1.11    0.0778         0      1.19         9       512:  71%|#######1  | 10/14 [00:42<00:16,  4.16s/it]\n",
      "   837/848        0G      1.12    0.0775         0      1.19        10       512:  71%|#######1  | 10/14 [00:46<00:16,  4.16s/it]\n",
      "   837/848        0G      1.12    0.0775         0      1.19        10       512:  79%|#######8  | 11/14 [00:46<00:12,  4.18s/it]\n",
      "   837/848        0G      1.11    0.0769         0      1.19        10       512:  79%|#######8  | 11/14 [00:50<00:12,  4.18s/it]\n",
      "   837/848        0G      1.11    0.0769         0      1.19        10       512:  86%|########5 | 12/14 [00:50<00:08,  4.21s/it]\n",
      "   837/848        0G      1.12    0.0782         0       1.2        11       512:  86%|########5 | 12/14 [00:54<00:08,  4.21s/it]\n",
      "   837/848        0G      1.12    0.0782         0       1.2        11       512:  93%|#########2| 13/14 [00:54<00:04,  4.22s/it]\n",
      "   837/848        0G      1.11    0.0767         0      1.19         3       512:  93%|#########2| 13/14 [00:56<00:04,  4.22s/it]\n",
      "   837/848        0G      1.11    0.0767         0      1.19         3       512: 100%|##########| 14/14 [00:56<00:00,  3.40s/it]\n",
      "   837/848        0G      1.11    0.0767         0      1.19         3       512: 100%|##########| 14/14 [00:57<00:00,  4.09s/it]\n",
      "\n",
      "               Class    Images   Targets         P         R   mAP@0.5        F1:   0%|          | 0/4 [00:00<?, ?it/s]2024-03-05 09:29:39.483537: I tensorflow/core/util/port.cc:113] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
      "2024-03-05 09:29:39.580373: I tensorflow/core/util/port.cc:113] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
      "2024-03-05 09:29:39.676160: I tensorflow/core/util/port.cc:113] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
      "WARNING:tensorflow:From C:\\Users\\mit017\\anaconda3\\Lib\\site-packages\\keras\\src\\losses.py:2976: The name tf.losses.sparse_softmax_cross_entropy is deprecated. Please use tf.compat.v1.losses.sparse_softmax_cross_entropy instead.\n",
      "\n",
      "WARNING:tensorflow:From C:\\Users\\mit017\\anaconda3\\Lib\\site-packages\\keras\\src\\losses.py:2976: The name tf.losses.sparse_softmax_cross_entropy is deprecated. Please use tf.compat.v1.losses.sparse_softmax_cross_entropy instead.\n",
      "\n",
      "WARNING:tensorflow:From C:\\Users\\mit017\\anaconda3\\Lib\\site-packages\\keras\\src\\losses.py:2976: The name tf.losses.sparse_softmax_cross_entropy is deprecated. Please use tf.compat.v1.losses.sparse_softmax_cross_entropy instead.\n",
      "\n",
      "\n",
      "               Class    Images   Targets         P         R   mAP@0.5        F1:  25%|##5       | 1/4 [00:13<00:40, 13.37s/it]\n",
      "               Class    Images   Targets         P         R   mAP@0.5        F1:  50%|#####     | 2/4 [00:15<00:13,  6.69s/it]\n",
      "               Class    Images   Targets         P         R   mAP@0.5        F1:  75%|#######5  | 3/4 [00:17<00:04,  4.54s/it]\n",
      "               Class    Images   Targets         P         R   mAP@0.5        F1: 100%|##########| 4/4 [00:18<00:00,  3.03s/it]\n",
      "               Class    Images   Targets         P         R   mAP@0.5        F1: 100%|##########| 4/4 [00:19<00:00,  4.76s/it]\n",
      "2024-03-05 09:29:58.326695: I tensorflow/core/util/port.cc:113] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
      "WARNING:tensorflow:From C:\\Users\\mit017\\anaconda3\\Lib\\site-packages\\keras\\src\\losses.py:2976: The name tf.losses.sparse_softmax_cross_entropy is deprecated. Please use tf.compat.v1.losses.sparse_softmax_cross_entropy instead.\n",
      "\n",
      "2024-03-05 09:30:08.381888: I tensorflow/core/util/port.cc:113] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
      "WARNING:tensorflow:From C:\\Users\\mit017\\anaconda3\\Lib\\site-packages\\keras\\src\\losses.py:2976: The name tf.losses.sparse_softmax_cross_entropy is deprecated. Please use tf.compat.v1.losses.sparse_softmax_cross_entropy instead.\n",
      "\n",
      "2024-03-05 09:30:18.500782: I tensorflow/core/util/port.cc:113] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
      "WARNING:tensorflow:From C:\\Users\\mit017\\anaconda3\\Lib\\site-packages\\keras\\src\\losses.py:2976: The name tf.losses.sparse_softmax_cross_entropy is deprecated. Please use tf.compat.v1.losses.sparse_softmax_cross_entropy instead.\n",
      "\n",
      "\n",
      "  0%|          | 0/14 [00:00<?, ?it/s]\n",
      "   838/848        0G      1.18    0.0854         0      1.27         9       512:   0%|          | 0/14 [00:04<?, ?it/s]\n",
      "   838/848        0G      1.18    0.0854         0      1.27         9       512:   7%|7         | 1/14 [00:04<00:56,  4.35s/it]\n",
      "   838/848        0G      1.14    0.0849         0      1.22         9       512:   7%|7         | 1/14 [00:08<00:56,  4.35s/it]\n",
      "   838/848        0G      1.14    0.0849         0      1.22         9       512:  14%|#4        | 2/14 [00:08<00:50,  4.23s/it]\n",
      "   838/848        0G      1.06    0.0835         0      1.15         9       512:  14%|#4        | 2/14 [00:12<00:50,  4.23s/it]\n",
      "   838/848        0G      1.06    0.0835         0      1.15         9       512:  21%|##1       | 3/14 [00:12<00:46,  4.20s/it]\n",
      "   838/848        0G      1.11    0.0784         0      1.19        10       512:  21%|##1       | 3/14 [00:16<00:46,  4.20s/it]\n",
      "   838/848        0G      1.11    0.0784         0      1.19        10       512:  29%|##8       | 4/14 [00:16<00:41,  4.18s/it]\n",
      "   838/848        0G      1.12    0.0758         0       1.2         9       512:  29%|##8       | 4/14 [00:20<00:41,  4.18s/it]\n",
      "   838/848        0G      1.12    0.0758         0       1.2         9       512:  36%|###5      | 5/14 [00:20<00:37,  4.15s/it]\n",
      "   838/848        0G      1.14    0.0744         0      1.22         9       512:  36%|###5      | 5/14 [00:25<00:37,  4.15s/it]\n",
      "   838/848        0G      1.14    0.0744         0      1.22         9       512:  43%|####2     | 6/14 [00:25<00:33,  4.16s/it]\n",
      "   838/848        0G      1.13    0.0826         0      1.22        12       512:  43%|####2     | 6/14 [00:29<00:33,  4.16s/it]\n",
      "   838/848        0G      1.13    0.0826         0      1.22        12       512:  50%|#####     | 7/14 [00:29<00:29,  4.18s/it]\n",
      "   838/848        0G      1.16    0.0828         0      1.24        10       320:  50%|#####     | 7/14 [00:31<00:29,  4.18s/it]\n",
      "   838/848        0G      1.16    0.0828         0      1.24        10       320:  57%|#####7    | 8/14 [00:31<00:20,  3.50s/it]\n",
      "   838/848        0G      1.17    0.0841         0      1.26        11       320:  57%|#####7    | 8/14 [00:33<00:20,  3.50s/it]\n",
      "   838/848        0G      1.17    0.0841         0      1.26        11       320:  64%|######4   | 9/14 [00:33<00:14,  2.94s/it]\n",
      "   838/848        0G      1.15    0.0888         0      1.24        11       320:  64%|######4   | 9/14 [00:34<00:14,  2.94s/it]\n",
      "   838/848        0G      1.15    0.0888         0      1.24        11       320:  71%|#######1  | 10/14 [00:34<00:10,  2.57s/it]\n",
      "   838/848        0G      1.16    0.0911         0      1.25        10       320:  71%|#######1  | 10/14 [00:36<00:10,  2.57s/it]\n",
      "   838/848        0G      1.16    0.0911         0      1.25        10       320:  79%|#######8  | 11/14 [00:36<00:06,  2.31s/it]\n",
      "   838/848        0G      1.15    0.0907         0      1.24         9       320:  79%|#######8  | 11/14 [00:38<00:06,  2.31s/it]\n",
      "   838/848        0G      1.15    0.0907         0      1.24         9       320:  86%|########5 | 12/14 [00:38<00:04,  2.13s/it]\n",
      "   838/848        0G      1.16     0.089         0      1.25         9       320:  86%|########5 | 12/14 [00:39<00:04,  2.13s/it]\n",
      "   838/848        0G      1.16     0.089         0      1.25         9       320:  93%|#########2| 13/14 [00:39<00:02,  2.00s/it]\n",
      "   838/848        0G      1.18    0.0886         0      1.27         3       320:  93%|#########2| 13/14 [00:40<00:02,  2.00s/it]\n",
      "   838/848        0G      1.18    0.0886         0      1.27         3       320: 100%|##########| 14/14 [00:40<00:00,  1.61s/it]\n",
      "   838/848        0G      1.18    0.0886         0      1.27         3       320: 100%|##########| 14/14 [00:41<00:00,  2.97s/it]\n",
      "\n",
      "               Class    Images   Targets         P         R   mAP@0.5        F1:   0%|          | 0/4 [00:00<?, ?it/s]2024-03-05 09:31:10.391823: I tensorflow/core/util/port.cc:113] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
      "2024-03-05 09:31:10.456039: I tensorflow/core/util/port.cc:113] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
      "2024-03-05 09:31:10.544806: I tensorflow/core/util/port.cc:113] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
      "WARNING:tensorflow:From C:\\Users\\mit017\\anaconda3\\Lib\\site-packages\\keras\\src\\losses.py:2976: The name tf.losses.sparse_softmax_cross_entropy is deprecated. Please use tf.compat.v1.losses.sparse_softmax_cross_entropy instead.\n",
      "\n",
      "WARNING:tensorflow:From C:\\Users\\mit017\\anaconda3\\Lib\\site-packages\\keras\\src\\losses.py:2976: The name tf.losses.sparse_softmax_cross_entropy is deprecated. Please use tf.compat.v1.losses.sparse_softmax_cross_entropy instead.\n",
      "\n",
      "WARNING:tensorflow:From C:\\Users\\mit017\\anaconda3\\Lib\\site-packages\\keras\\src\\losses.py:2976: The name tf.losses.sparse_softmax_cross_entropy is deprecated. Please use tf.compat.v1.losses.sparse_softmax_cross_entropy instead.\n",
      "\n",
      "\n",
      "               Class    Images   Targets         P         R   mAP@0.5        F1:  25%|##5       | 1/4 [00:13<00:39, 13.15s/it]\n",
      "               Class    Images   Targets         P         R   mAP@0.5        F1:  50%|#####     | 2/4 [00:15<00:13,  6.64s/it]\n",
      "               Class    Images   Targets         P         R   mAP@0.5        F1:  75%|#######5  | 3/4 [00:17<00:04,  4.55s/it]\n",
      "               Class    Images   Targets         P         R   mAP@0.5        F1: 100%|##########| 4/4 [00:18<00:00,  3.05s/it]\n",
      "               Class    Images   Targets         P         R   mAP@0.5        F1: 100%|##########| 4/4 [00:19<00:00,  4.75s/it]\n",
      "2024-03-05 09:31:29.285420: I tensorflow/core/util/port.cc:113] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
      "WARNING:tensorflow:From C:\\Users\\mit017\\anaconda3\\Lib\\site-packages\\keras\\src\\losses.py:2976: The name tf.losses.sparse_softmax_cross_entropy is deprecated. Please use tf.compat.v1.losses.sparse_softmax_cross_entropy instead.\n",
      "\n",
      "2024-03-05 09:31:39.516226: I tensorflow/core/util/port.cc:113] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
      "WARNING:tensorflow:From C:\\Users\\mit017\\anaconda3\\Lib\\site-packages\\keras\\src\\losses.py:2976: The name tf.losses.sparse_softmax_cross_entropy is deprecated. Please use tf.compat.v1.losses.sparse_softmax_cross_entropy instead.\n",
      "\n",
      "2024-03-05 09:31:49.864654: I tensorflow/core/util/port.cc:113] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
      "WARNING:tensorflow:From C:\\Users\\mit017\\anaconda3\\Lib\\site-packages\\keras\\src\\losses.py:2976: The name tf.losses.sparse_softmax_cross_entropy is deprecated. Please use tf.compat.v1.losses.sparse_softmax_cross_entropy instead.\n",
      "\n",
      "\n",
      "  0%|          | 0/14 [00:00<?, ?it/s]\n",
      "   839/848        0G      1.31    0.0875         0       1.4         9       320:   0%|          | 0/14 [00:01<?, ?it/s]\n",
      "   839/848        0G      1.31    0.0875         0       1.4         9       320:   7%|7         | 1/14 [00:01<00:25,  1.93s/it]\n",
      "   839/848        0G      1.35     0.089         0      1.44         9       320:   7%|7         | 1/14 [00:03<00:25,  1.93s/it]\n",
      "   839/848        0G      1.35     0.089         0      1.44         9       320:  14%|#4        | 2/14 [00:03<00:22,  1.83s/it]\n",
      "   839/848        0G      1.33     0.108         0      1.44        14       320:  14%|#4        | 2/14 [00:05<00:22,  1.83s/it]\n",
      "   839/848        0G      1.33     0.108         0      1.44        14       320:  21%|##1       | 3/14 [00:05<00:19,  1.78s/it]\n",
      "   839/848        0G      1.28     0.119         0       1.4        15       320:  21%|##1       | 3/14 [00:07<00:19,  1.78s/it]\n",
      "   839/848        0G      1.28     0.119         0       1.4        15       320:  29%|##8       | 4/14 [00:07<00:17,  1.75s/it]\n",
      "   839/848        0G      1.26     0.116         0      1.37        11       320:  29%|##8       | 4/14 [00:08<00:17,  1.75s/it]\n",
      "   839/848        0G      1.26     0.116         0      1.37        11       320:  36%|###5      | 5/14 [00:08<00:15,  1.74s/it]\n",
      "   839/848        0G      1.26      0.12         0      1.38        12       320:  36%|###5      | 5/14 [00:10<00:15,  1.74s/it]\n",
      "   839/848        0G      1.26      0.12         0      1.38        12       320:  43%|####2     | 6/14 [00:10<00:13,  1.73s/it]\n",
      "   839/848        0G      1.25     0.114         0      1.37         9       320:  43%|####2     | 6/14 [00:12<00:13,  1.73s/it]\n",
      "   839/848        0G      1.25     0.114         0      1.37         9       320:  50%|#####     | 7/14 [00:12<00:12,  1.75s/it]\n",
      "   839/848        0G      1.29     0.107         0       1.4         9       320:  50%|#####     | 7/14 [00:14<00:12,  1.75s/it]\n",
      "   839/848        0G      1.29     0.107         0       1.4         9       320:  57%|#####7    | 8/14 [00:14<00:10,  1.74s/it]\n",
      "   839/848        0G      1.31     0.106         0      1.42        13       320:  57%|#####7    | 8/14 [00:15<00:10,  1.74s/it]\n",
      "   839/848        0G      1.31     0.106         0      1.42        13       320:  64%|######4   | 9/14 [00:15<00:08,  1.74s/it]\n",
      "   839/848        0G      1.31     0.106         0      1.41        12       320:  64%|######4   | 9/14 [00:17<00:08,  1.74s/it]\n",
      "   839/848        0G      1.31     0.106         0      1.41        12       320:  71%|#######1  | 10/14 [00:17<00:06,  1.73s/it]\n",
      "   839/848        0G      1.32     0.109         0      1.43         9       320:  71%|#######1  | 10/14 [00:19<00:06,  1.73s/it]\n",
      "   839/848        0G      1.32     0.109         0      1.43         9       320:  79%|#######8  | 11/14 [00:19<00:05,  1.73s/it]\n",
      "   839/848        0G      1.32     0.107         0      1.42         9       320:  79%|#######8  | 11/14 [00:20<00:05,  1.73s/it]\n",
      "   839/848        0G      1.32     0.107         0      1.42         9       320:  86%|########5 | 12/14 [00:20<00:03,  1.73s/it]\n",
      "   839/848        0G      1.31     0.105         0      1.41         9       320:  86%|########5 | 12/14 [00:22<00:03,  1.73s/it]\n",
      "   839/848        0G      1.31     0.105         0      1.41         9       320:  93%|#########2| 13/14 [00:22<00:01,  1.72s/it]\n",
      "   839/848        0G      1.31     0.105         0      1.41         3       320:  93%|#########2| 13/14 [00:23<00:01,  1.72s/it]\n",
      "   839/848        0G      1.31     0.105         0      1.41         3       320: 100%|##########| 14/14 [00:23<00:00,  1.41s/it]\n",
      "   839/848        0G      1.31     0.105         0      1.41         3       320: 100%|##########| 14/14 [00:24<00:00,  1.73s/it]\n",
      "\n",
      "               Class    Images   Targets         P         R   mAP@0.5        F1:   0%|          | 0/4 [00:00<?, ?it/s]2024-03-05 09:32:24.449885: I tensorflow/core/util/port.cc:113] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
      "2024-03-05 09:32:24.522531: I tensorflow/core/util/port.cc:113] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
      "2024-03-05 09:32:24.623323: I tensorflow/core/util/port.cc:113] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
      "WARNING:tensorflow:From C:\\Users\\mit017\\anaconda3\\Lib\\site-packages\\keras\\src\\losses.py:2976: The name tf.losses.sparse_softmax_cross_entropy is deprecated. Please use tf.compat.v1.losses.sparse_softmax_cross_entropy instead.\n",
      "\n",
      "WARNING:tensorflow:From C:\\Users\\mit017\\anaconda3\\Lib\\site-packages\\keras\\src\\losses.py:2976: The name tf.losses.sparse_softmax_cross_entropy is deprecated. Please use tf.compat.v1.losses.sparse_softmax_cross_entropy instead.\n",
      "\n",
      "WARNING:tensorflow:From C:\\Users\\mit017\\anaconda3\\Lib\\site-packages\\keras\\src\\losses.py:2976: The name tf.losses.sparse_softmax_cross_entropy is deprecated. Please use tf.compat.v1.losses.sparse_softmax_cross_entropy instead.\n",
      "\n",
      "\n",
      "               Class    Images   Targets         P         R   mAP@0.5        F1:  25%|##5       | 1/4 [00:13<00:39, 13.14s/it]\n",
      "               Class    Images   Targets         P         R   mAP@0.5        F1:  50%|#####     | 2/4 [00:15<00:13,  6.59s/it]\n",
      "               Class    Images   Targets         P         R   mAP@0.5        F1:  75%|#######5  | 3/4 [00:17<00:04,  4.49s/it]\n",
      "               Class    Images   Targets         P         R   mAP@0.5        F1: 100%|##########| 4/4 [00:17<00:00,  2.98s/it]\n",
      "               Class    Images   Targets         P         R   mAP@0.5        F1: 100%|##########| 4/4 [00:18<00:00,  4.69s/it]\n",
      "2024-03-05 09:32:43.089899: I tensorflow/core/util/port.cc:113] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
      "WARNING:tensorflow:From C:\\Users\\mit017\\anaconda3\\Lib\\site-packages\\keras\\src\\losses.py:2976: The name tf.losses.sparse_softmax_cross_entropy is deprecated. Please use tf.compat.v1.losses.sparse_softmax_cross_entropy instead.\n",
      "\n",
      "2024-03-05 09:32:53.215228: I tensorflow/core/util/port.cc:113] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
      "WARNING:tensorflow:From C:\\Users\\mit017\\anaconda3\\Lib\\site-packages\\keras\\src\\losses.py:2976: The name tf.losses.sparse_softmax_cross_entropy is deprecated. Please use tf.compat.v1.losses.sparse_softmax_cross_entropy instead.\n",
      "\n",
      "2024-03-05 09:33:03.320826: I tensorflow/core/util/port.cc:113] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
      "WARNING:tensorflow:From C:\\Users\\mit017\\anaconda3\\Lib\\site-packages\\keras\\src\\losses.py:2976: The name tf.losses.sparse_softmax_cross_entropy is deprecated. Please use tf.compat.v1.losses.sparse_softmax_cross_entropy instead.\n",
      "\n",
      "\n",
      "  0%|          | 0/14 [00:00<?, ?it/s]\n",
      "   840/848        0G       1.2     0.106         0      1.31         9       448:   0%|          | 0/14 [00:03<?, ?it/s]\n",
      "   840/848        0G       1.2     0.106         0      1.31         9       448:   7%|7         | 1/14 [00:03<00:47,  3.66s/it]\n",
      "   840/848        0G      1.03    0.0913         0      1.12         9       448:   7%|7         | 1/14 [00:06<00:47,  3.66s/it]\n",
      "   840/848        0G      1.03    0.0913         0      1.12         9       448:  14%|#4        | 2/14 [00:06<00:40,  3.39s/it]\n",
      "   840/848        0G      1.03    0.0912         0      1.12         9       448:  14%|#4        | 2/14 [00:10<00:40,  3.39s/it]\n",
      "   840/848        0G      1.03    0.0912         0      1.12         9       448:  21%|##1       | 3/14 [00:10<00:36,  3.31s/it]\n",
      "   840/848        0G      1.13    0.0827         0      1.21         9       448:  21%|##1       | 3/14 [00:13<00:36,  3.31s/it]\n",
      "   840/848        0G      1.13    0.0827         0      1.21         9       448:  29%|##8       | 4/14 [00:13<00:32,  3.27s/it]\n",
      "   840/848        0G      1.15    0.0837         0      1.23         9       448:  29%|##8       | 4/14 [00:16<00:32,  3.27s/it]\n",
      "   840/848        0G      1.15    0.0837         0      1.23         9       448:  36%|###5      | 5/14 [00:16<00:29,  3.25s/it]\n",
      "   840/848        0G      1.15    0.0815         0      1.23         9       448:  36%|###5      | 5/14 [00:19<00:29,  3.25s/it]\n",
      "   840/848        0G      1.15    0.0815         0      1.23         9       448:  43%|####2     | 6/14 [00:19<00:25,  3.24s/it]\n",
      "   840/848        0G      1.14    0.0815         0      1.23         9       448:  43%|####2     | 6/14 [00:22<00:25,  3.24s/it]\n",
      "   840/848        0G      1.14    0.0815         0      1.23         9       448:  50%|#####     | 7/14 [00:22<00:22,  3.24s/it]\n",
      "   840/848        0G      1.16    0.0831         0      1.25         9       448:  50%|#####     | 7/14 [00:26<00:22,  3.24s/it]\n",
      "   840/848        0G      1.16    0.0831         0      1.25         9       448:  57%|#####7    | 8/14 [00:26<00:19,  3.22s/it]\n",
      "   840/848        0G      1.15    0.0867         0      1.24         9       448:  57%|#####7    | 8/14 [00:29<00:19,  3.22s/it]\n",
      "   840/848        0G      1.15    0.0867         0      1.24         9       448:  64%|######4   | 9/14 [00:29<00:16,  3.23s/it]\n",
      "   840/848        0G      1.14    0.0883         0      1.23         9       448:  64%|######4   | 9/14 [00:32<00:16,  3.23s/it]\n",
      "   840/848        0G      1.14    0.0883         0      1.23         9       448:  71%|#######1  | 10/14 [00:32<00:12,  3.21s/it]\n",
      "   840/848        0G      1.12     0.087         0      1.21         9       448:  71%|#######1  | 10/14 [00:35<00:12,  3.21s/it]\n",
      "   840/848        0G      1.12     0.087         0      1.21         9       448:  79%|#######8  | 11/14 [00:35<00:09,  3.21s/it]\n",
      "   840/848        0G       1.1    0.0869         0      1.19         9       448:  79%|#######8  | 11/14 [00:38<00:09,  3.21s/it]\n",
      "   840/848        0G       1.1    0.0869         0      1.19         9       448:  86%|########5 | 12/14 [00:38<00:06,  3.19s/it]\n",
      "   840/848        0G       1.1    0.0868         0      1.19         9       448:  86%|########5 | 12/14 [00:42<00:06,  3.19s/it]\n",
      "   840/848        0G       1.1    0.0868         0      1.19         9       448:  93%|#########2| 13/14 [00:42<00:03,  3.18s/it]\n",
      "   840/848        0G      1.09    0.0891         0      1.18         3       448:  93%|#########2| 13/14 [00:43<00:03,  3.18s/it]\n",
      "   840/848        0G      1.09    0.0891         0      1.18         3       448: 100%|##########| 14/14 [00:43<00:00,  2.59s/it]\n",
      "   840/848        0G      1.09    0.0891         0      1.18         3       448: 100%|##########| 14/14 [00:44<00:00,  3.16s/it]\n",
      "\n",
      "               Class    Images   Targets         P         R   mAP@0.5        F1:   0%|          | 0/4 [00:00<?, ?it/s]2024-03-05 09:33:57.859991: I tensorflow/core/util/port.cc:113] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
      "2024-03-05 09:33:57.913962: I tensorflow/core/util/port.cc:113] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
      "2024-03-05 09:33:58.000511: I tensorflow/core/util/port.cc:113] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
      "WARNING:tensorflow:From C:\\Users\\mit017\\anaconda3\\Lib\\site-packages\\keras\\src\\losses.py:2976: The name tf.losses.sparse_softmax_cross_entropy is deprecated. Please use tf.compat.v1.losses.sparse_softmax_cross_entropy instead.\n",
      "\n",
      "WARNING:tensorflow:From C:\\Users\\mit017\\anaconda3\\Lib\\site-packages\\keras\\src\\losses.py:2976: The name tf.losses.sparse_softmax_cross_entropy is deprecated. Please use tf.compat.v1.losses.sparse_softmax_cross_entropy instead.\n",
      "\n",
      "WARNING:tensorflow:From C:\\Users\\mit017\\anaconda3\\Lib\\site-packages\\keras\\src\\losses.py:2976: The name tf.losses.sparse_softmax_cross_entropy is deprecated. Please use tf.compat.v1.losses.sparse_softmax_cross_entropy instead.\n",
      "\n",
      "\n",
      "               Class    Images   Targets         P         R   mAP@0.5        F1:  25%|##5       | 1/4 [00:13<00:39, 13.21s/it]\n",
      "               Class    Images   Targets         P         R   mAP@0.5        F1:  50%|#####     | 2/4 [00:15<00:13,  6.61s/it]\n",
      "               Class    Images   Targets         P         R   mAP@0.5        F1:  75%|#######5  | 3/4 [00:17<00:04,  4.50s/it]\n",
      "               Class    Images   Targets         P         R   mAP@0.5        F1: 100%|##########| 4/4 [00:17<00:00,  3.01s/it]\n",
      "               Class    Images   Targets         P         R   mAP@0.5        F1: 100%|##########| 4/4 [00:18<00:00,  4.71s/it]\n",
      "2024-03-05 09:34:16.526869: I tensorflow/core/util/port.cc:113] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
      "WARNING:tensorflow:From C:\\Users\\mit017\\anaconda3\\Lib\\site-packages\\keras\\src\\losses.py:2976: The name tf.losses.sparse_softmax_cross_entropy is deprecated. Please use tf.compat.v1.losses.sparse_softmax_cross_entropy instead.\n",
      "\n",
      "2024-03-05 09:34:26.610803: I tensorflow/core/util/port.cc:113] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
      "WARNING:tensorflow:From C:\\Users\\mit017\\anaconda3\\Lib\\site-packages\\keras\\src\\losses.py:2976: The name tf.losses.sparse_softmax_cross_entropy is deprecated. Please use tf.compat.v1.losses.sparse_softmax_cross_entropy instead.\n",
      "\n",
      "2024-03-05 09:34:36.679810: I tensorflow/core/util/port.cc:113] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
      "WARNING:tensorflow:From C:\\Users\\mit017\\anaconda3\\Lib\\site-packages\\keras\\src\\losses.py:2976: The name tf.losses.sparse_softmax_cross_entropy is deprecated. Please use tf.compat.v1.losses.sparse_softmax_cross_entropy instead.\n",
      "\n",
      "\n",
      "  0%|          | 0/14 [00:00<?, ?it/s]\n",
      "   841/848        0G      1.07    0.0705         0      1.14         9       448:   0%|          | 0/14 [00:03<?, ?it/s]\n",
      "   841/848        0G      1.07    0.0705         0      1.14         9       448:   7%|7         | 1/14 [00:03<00:44,  3.42s/it]\n",
      "   841/848        0G      1.03    0.0853         0      1.11         9       448:   7%|7         | 1/14 [00:06<00:44,  3.42s/it]\n",
      "   841/848        0G      1.03    0.0853         0      1.11         9       448:  14%|#4        | 2/14 [00:06<00:39,  3.28s/it]\n",
      "   841/848        0G      1.05    0.0838         0      1.13         9       448:  14%|#4        | 2/14 [00:09<00:39,  3.28s/it]\n",
      "   841/848        0G      1.05    0.0838         0      1.13         9       448:  21%|##1       | 3/14 [00:09<00:35,  3.25s/it]\n",
      "   841/848        0G      1.09    0.0774         0      1.16         9       448:  21%|##1       | 3/14 [00:13<00:35,  3.25s/it]\n",
      "   841/848        0G      1.09    0.0774         0      1.16         9       448:  29%|##8       | 4/14 [00:13<00:32,  3.22s/it]\n",
      "   841/848        0G      1.05    0.0757         0      1.13         9       448:  29%|##8       | 4/14 [00:16<00:32,  3.22s/it]\n",
      "   841/848        0G      1.05    0.0757         0      1.13         9       448:  36%|###5      | 5/14 [00:16<00:28,  3.22s/it]\n",
      "   841/848        0G      1.05    0.0742         0      1.13         9       448:  36%|###5      | 5/14 [00:19<00:28,  3.22s/it]\n",
      "   841/848        0G      1.05    0.0742         0      1.13         9       448:  43%|####2     | 6/14 [00:19<00:25,  3.22s/it]\n",
      "   841/848        0G      1.05     0.076         0      1.13         9       448:  43%|####2     | 6/14 [00:22<00:25,  3.22s/it]\n",
      "   841/848        0G      1.05     0.076         0      1.13         9       448:  50%|#####     | 7/14 [00:22<00:22,  3.22s/it]\n",
      "   841/848        0G      1.06    0.0776         0      1.14        12       576:  50%|#####     | 7/14 [00:28<00:22,  3.22s/it]\n",
      "   841/848        0G      1.06    0.0776         0      1.14        12       576:  57%|#####7    | 8/14 [00:28<00:23,  3.93s/it]\n",
      "   841/848        0G      1.06    0.0754         0      1.14         9       576:  57%|#####7    | 8/14 [00:33<00:23,  3.93s/it]\n",
      "   841/848        0G      1.06    0.0754         0      1.14         9       576:  64%|######4   | 9/14 [00:33<00:21,  4.34s/it]\n",
      "   841/848        0G      1.28    0.0772         0      1.36         9       576:  64%|######4   | 9/14 [00:38<00:21,  4.34s/it]\n",
      "   841/848        0G      1.28    0.0772         0      1.36         9       576:  71%|#######1  | 10/14 [00:38<00:18,  4.63s/it]\n",
      "   841/848        0G      1.26    0.0766         0      1.34         9       576:  71%|#######1  | 10/14 [00:43<00:18,  4.63s/it]\n",
      "   841/848        0G      1.26    0.0766         0      1.34         9       576:  79%|#######8  | 11/14 [00:43<00:14,  4.82s/it]\n",
      "   841/848        0G      1.27    0.0749         0      1.34         9       576:  79%|#######8  | 11/14 [00:49<00:14,  4.82s/it]\n",
      "   841/848        0G      1.27    0.0749         0      1.34         9       576:  86%|########5 | 12/14 [00:49<00:09,  4.96s/it]\n",
      "   841/848        0G      1.25     0.075         0      1.32         9       576:  86%|########5 | 12/14 [00:54<00:09,  4.96s/it]\n",
      "   841/848        0G      1.25     0.075         0      1.32         9       576:  93%|#########2| 13/14 [00:54<00:05,  5.07s/it]\n",
      "   841/848        0G      1.23    0.0738         0      1.31         3       576:  93%|#########2| 13/14 [00:56<00:05,  5.07s/it]\n",
      "   841/848        0G      1.23    0.0738         0      1.31         3       576: 100%|##########| 14/14 [00:56<00:00,  4.12s/it]\n",
      "   841/848        0G      1.23    0.0738         0      1.31         3       576: 100%|##########| 14/14 [00:57<00:00,  4.10s/it]\n",
      "\n",
      "               Class    Images   Targets         P         R   mAP@0.5        F1:   0%|          | 0/4 [00:00<?, ?it/s]2024-03-05 09:35:44.227883: I tensorflow/core/util/port.cc:113] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
      "2024-03-05 09:35:44.289884: I tensorflow/core/util/port.cc:113] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
      "2024-03-05 09:35:44.383230: I tensorflow/core/util/port.cc:113] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
      "WARNING:tensorflow:From C:\\Users\\mit017\\anaconda3\\Lib\\site-packages\\keras\\src\\losses.py:2976: The name tf.losses.sparse_softmax_cross_entropy is deprecated. Please use tf.compat.v1.losses.sparse_softmax_cross_entropy instead.\n",
      "\n",
      "WARNING:tensorflow:From C:\\Users\\mit017\\anaconda3\\Lib\\site-packages\\keras\\src\\losses.py:2976: The name tf.losses.sparse_softmax_cross_entropy is deprecated. Please use tf.compat.v1.losses.sparse_softmax_cross_entropy instead.\n",
      "\n",
      "WARNING:tensorflow:From C:\\Users\\mit017\\anaconda3\\Lib\\site-packages\\keras\\src\\losses.py:2976: The name tf.losses.sparse_softmax_cross_entropy is deprecated. Please use tf.compat.v1.losses.sparse_softmax_cross_entropy instead.\n",
      "\n",
      "\n",
      "               Class    Images   Targets         P         R   mAP@0.5        F1:  25%|##5       | 1/4 [00:13<00:40, 13.36s/it]\n",
      "               Class    Images   Targets         P         R   mAP@0.5        F1:  50%|#####     | 2/4 [00:15<00:13,  6.72s/it]\n",
      "               Class    Images   Targets         P         R   mAP@0.5        F1:  75%|#######5  | 3/4 [00:17<00:04,  4.57s/it]\n",
      "               Class    Images   Targets         P         R   mAP@0.5        F1: 100%|##########| 4/4 [00:18<00:00,  3.04s/it]\n",
      "               Class    Images   Targets         P         R   mAP@0.5        F1: 100%|##########| 4/4 [00:19<00:00,  4.78s/it]\n",
      "2024-03-05 09:36:03.217261: I tensorflow/core/util/port.cc:113] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
      "WARNING:tensorflow:From C:\\Users\\mit017\\anaconda3\\Lib\\site-packages\\keras\\src\\losses.py:2976: The name tf.losses.sparse_softmax_cross_entropy is deprecated. Please use tf.compat.v1.losses.sparse_softmax_cross_entropy instead.\n",
      "\n",
      "2024-03-05 09:36:13.321957: I tensorflow/core/util/port.cc:113] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
      "WARNING:tensorflow:From C:\\Users\\mit017\\anaconda3\\Lib\\site-packages\\keras\\src\\losses.py:2976: The name tf.losses.sparse_softmax_cross_entropy is deprecated. Please use tf.compat.v1.losses.sparse_softmax_cross_entropy instead.\n",
      "\n",
      "2024-03-05 09:36:23.635738: I tensorflow/core/util/port.cc:113] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
      "WARNING:tensorflow:From C:\\Users\\mit017\\anaconda3\\Lib\\site-packages\\keras\\src\\losses.py:2976: The name tf.losses.sparse_softmax_cross_entropy is deprecated. Please use tf.compat.v1.losses.sparse_softmax_cross_entropy instead.\n",
      "\n",
      "\n",
      "  0%|          | 0/14 [00:00<?, ?it/s]\n",
      "   842/848        0G       1.6     0.105         0      1.71         9       576:   0%|          | 0/14 [00:05<?, ?it/s]\n",
      "   842/848        0G       1.6     0.105         0      1.71         9       576:   7%|7         | 1/14 [00:05<01:10,  5.39s/it]\n",
      "   842/848        0G      1.33    0.0824         0      1.41         9       576:   7%|7         | 1/14 [00:10<01:10,  5.39s/it]\n",
      "   842/848        0G      1.33    0.0824         0      1.41         9       576:  14%|#4        | 2/14 [00:10<01:04,  5.35s/it]\n",
      "   842/848        0G      1.91    0.0843         0      1.99        11       576:  14%|#4        | 2/14 [00:15<01:04,  5.35s/it]\n",
      "   842/848        0G      1.91    0.0843         0      1.99        11       576:  21%|##1       | 3/14 [00:15<00:58,  5.30s/it]\n",
      "   842/848        0G      1.74    0.0764         0      1.82         8       576:  21%|##1       | 3/14 [00:21<00:58,  5.30s/it]\n",
      "   842/848        0G      1.74    0.0764         0      1.82         8       576:  29%|##8       | 4/14 [00:21<00:52,  5.29s/it]\n",
      "   842/848        0G      1.87    0.0782         0      1.95        10       576:  29%|##8       | 4/14 [00:26<00:52,  5.29s/it]\n",
      "   842/848        0G      1.87    0.0782         0      1.95        10       576:  36%|###5      | 5/14 [00:26<00:47,  5.26s/it]\n",
      "   842/848        0G      1.77    0.0745         0      1.84         9       576:  36%|###5      | 5/14 [00:31<00:47,  5.26s/it]\n",
      "   842/848        0G      1.77    0.0745         0      1.84         9       576:  43%|####2     | 6/14 [00:31<00:42,  5.25s/it]\n",
      "   842/848        0G       1.7    0.0742         0      1.77        11       576:  43%|####2     | 6/14 [00:36<00:42,  5.25s/it]\n",
      "   842/848        0G       1.7    0.0742         0      1.77        11       576:  50%|#####     | 7/14 [00:36<00:36,  5.25s/it]\n",
      "   842/848        0G      1.88    0.0752         0      1.96         9       576:  50%|#####     | 7/14 [00:42<00:36,  5.25s/it]\n",
      "   842/848        0G      1.88    0.0752         0      1.96         9       576:  57%|#####7    | 8/14 [00:42<00:31,  5.31s/it]\n",
      "   842/848        0G      1.94    0.0777         0      2.02         9       576:  57%|#####7    | 8/14 [00:47<00:31,  5.31s/it]\n",
      "   842/848        0G      1.94    0.0777         0      2.02         9       576:  64%|######4   | 9/14 [00:47<00:26,  5.38s/it]\n",
      "   842/848        0G      1.85    0.0767         0      1.93         9       576:  64%|######4   | 9/14 [00:53<00:26,  5.38s/it]\n",
      "   842/848        0G      1.85    0.0767         0      1.93         9       576:  71%|#######1  | 10/14 [00:53<00:21,  5.42s/it]\n",
      "   842/848        0G      1.81    0.0768         0      1.88        10       576:  71%|#######1  | 10/14 [00:58<00:21,  5.42s/it]\n",
      "   842/848        0G      1.81    0.0768         0      1.88        10       576:  79%|#######8  | 11/14 [00:58<00:16,  5.42s/it]\n",
      "   842/848        0G      1.76    0.0771         0      1.84        10       576:  79%|#######8  | 11/14 [01:04<00:16,  5.42s/it]\n",
      "   842/848        0G      1.76    0.0771         0      1.84        10       576:  86%|########5 | 12/14 [01:04<00:10,  5.42s/it]\n",
      "   842/848        0G      1.71    0.0765         0      1.79         9       576:  86%|########5 | 12/14 [01:09<00:10,  5.42s/it]\n",
      "   842/848        0G      1.71    0.0765         0      1.79         9       576:  93%|#########2| 13/14 [01:09<00:05,  5.45s/it]\n",
      "   842/848        0G      1.68    0.0753         0      1.75         3       576:  93%|#########2| 13/14 [01:11<00:05,  5.45s/it]\n",
      "   842/848        0G      1.68    0.0753         0      1.75         3       576: 100%|##########| 14/14 [01:11<00:00,  4.40s/it]\n",
      "   842/848        0G      1.68    0.0753         0      1.75         3       576: 100%|##########| 14/14 [01:12<00:00,  5.19s/it]\n",
      "\n",
      "               Class    Images   Targets         P         R   mAP@0.5        F1:   0%|          | 0/4 [00:00<?, ?it/s]2024-03-05 09:37:46.730132: I tensorflow/core/util/port.cc:113] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
      "2024-03-05 09:37:46.839632: I tensorflow/core/util/port.cc:113] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
      "2024-03-05 09:37:46.934095: I tensorflow/core/util/port.cc:113] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
      "WARNING:tensorflow:From C:\\Users\\mit017\\anaconda3\\Lib\\site-packages\\keras\\src\\losses.py:2976: The name tf.losses.sparse_softmax_cross_entropy is deprecated. Please use tf.compat.v1.losses.sparse_softmax_cross_entropy instead.\n",
      "\n",
      "WARNING:tensorflow:From C:\\Users\\mit017\\anaconda3\\Lib\\site-packages\\keras\\src\\losses.py:2976: The name tf.losses.sparse_softmax_cross_entropy is deprecated. Please use tf.compat.v1.losses.sparse_softmax_cross_entropy instead.\n",
      "\n",
      "WARNING:tensorflow:From C:\\Users\\mit017\\anaconda3\\Lib\\site-packages\\keras\\src\\losses.py:2976: The name tf.losses.sparse_softmax_cross_entropy is deprecated. Please use tf.compat.v1.losses.sparse_softmax_cross_entropy instead.\n",
      "\n",
      "\n",
      "               Class    Images   Targets         P         R   mAP@0.5        F1:  25%|##5       | 1/4 [00:13<00:41, 13.76s/it]\n",
      "               Class    Images   Targets         P         R   mAP@0.5        F1:  50%|#####     | 2/4 [00:15<00:13,  6.88s/it]\n",
      "               Class    Images   Targets         P         R   mAP@0.5        F1:  75%|#######5  | 3/4 [00:17<00:04,  4.66s/it]\n",
      "               Class    Images   Targets         P         R   mAP@0.5        F1: 100%|##########| 4/4 [00:18<00:00,  3.10s/it]\n",
      "               Class    Images   Targets         P         R   mAP@0.5        F1: 100%|##########| 4/4 [00:19<00:00,  4.88s/it]\n",
      "2024-03-05 09:38:05.974916: I tensorflow/core/util/port.cc:113] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
      "WARNING:tensorflow:From C:\\Users\\mit017\\anaconda3\\Lib\\site-packages\\keras\\src\\losses.py:2976: The name tf.losses.sparse_softmax_cross_entropy is deprecated. Please use tf.compat.v1.losses.sparse_softmax_cross_entropy instead.\n",
      "\n",
      "2024-03-05 09:38:16.163230: I tensorflow/core/util/port.cc:113] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
      "WARNING:tensorflow:From C:\\Users\\mit017\\anaconda3\\Lib\\site-packages\\keras\\src\\losses.py:2976: The name tf.losses.sparse_softmax_cross_entropy is deprecated. Please use tf.compat.v1.losses.sparse_softmax_cross_entropy instead.\n",
      "\n",
      "2024-03-05 09:38:26.399325: I tensorflow/core/util/port.cc:113] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
      "WARNING:tensorflow:From C:\\Users\\mit017\\anaconda3\\Lib\\site-packages\\keras\\src\\losses.py:2976: The name tf.losses.sparse_softmax_cross_entropy is deprecated. Please use tf.compat.v1.losses.sparse_softmax_cross_entropy instead.\n",
      "\n",
      "\n",
      "  0%|          | 0/14 [00:00<?, ?it/s]\n",
      "   843/848        0G      1.04    0.0983         0      1.14         9       544:   0%|          | 0/14 [00:05<?, ?it/s]\n",
      "   843/848        0G      1.04    0.0983         0      1.14         9       544:   7%|7         | 1/14 [00:05<01:08,  5.25s/it]\n",
      "   843/848        0G      1.18    0.0778         0      1.26         9       544:   7%|7         | 1/14 [00:09<01:08,  5.25s/it]\n",
      "   843/848        0G      1.18    0.0778         0      1.26         9       544:  14%|#4        | 2/14 [00:09<00:58,  4.90s/it]\n",
      "   843/848        0G      1.41    0.0856         0       1.5         9       544:  14%|#4        | 2/14 [00:14<00:58,  4.90s/it]\n",
      "   843/848        0G      1.41    0.0856         0       1.5         9       544:  21%|##1       | 3/14 [00:14<00:52,  4.77s/it]\n",
      "   843/848        0G      1.36    0.0786         0      1.44         9       544:  21%|##1       | 3/14 [00:19<00:52,  4.77s/it]\n",
      "   843/848        0G      1.36    0.0786         0      1.44         9       544:  29%|##8       | 4/14 [00:19<00:47,  4.76s/it]\n",
      "   843/848        0G      1.84    0.0808         0      1.92         9       544:  29%|##8       | 4/14 [00:24<00:47,  4.76s/it]\n",
      "   843/848        0G      1.84    0.0808         0      1.92         9       544:  36%|###5      | 5/14 [00:24<00:42,  4.76s/it]\n",
      "   843/848        0G      1.73    0.0798         0      1.81         9       544:  36%|###5      | 5/14 [00:28<00:42,  4.76s/it]\n",
      "   843/848        0G      1.73    0.0798         0      1.81         9       544:  43%|####2     | 6/14 [00:28<00:37,  4.75s/it]\n",
      "   843/848        0G      1.69    0.0775         0      1.76         9       544:  43%|####2     | 6/14 [00:33<00:37,  4.75s/it]\n",
      "   843/848        0G      1.69    0.0775         0      1.76         9       544:  50%|#####     | 7/14 [00:33<00:33,  4.73s/it]\n",
      "   843/848        0G       1.9    0.0785         0      1.97         9       544:  50%|#####     | 7/14 [00:38<00:33,  4.73s/it]\n",
      "   843/848        0G       1.9    0.0785         0      1.97         9       544:  57%|#####7    | 8/14 [00:38<00:28,  4.69s/it]\n",
      "   843/848        0G      1.78    0.0776         0      1.86         9       544:  57%|#####7    | 8/14 [00:42<00:28,  4.69s/it]\n",
      "   843/848        0G      1.78    0.0776         0      1.86         9       544:  64%|######4   | 9/14 [00:42<00:23,  4.65s/it]\n",
      "   843/848        0G      1.73     0.078         0      1.81        12       544:  64%|######4   | 9/14 [00:47<00:23,  4.65s/it]\n",
      "   843/848        0G      1.73     0.078         0      1.81        12       544:  71%|#######1  | 10/14 [00:47<00:18,  4.64s/it]\n",
      "   843/848        0G      1.68    0.0785         0      1.76        10       544:  71%|#######1  | 10/14 [00:52<00:18,  4.64s/it]\n",
      "   843/848        0G      1.68    0.0785         0      1.76        10       544:  79%|#######8  | 11/14 [00:52<00:14,  4.70s/it]\n",
      "   843/848        0G      1.77    0.0784         0      1.85         9       544:  79%|#######8  | 11/14 [00:57<00:14,  4.70s/it]\n",
      "   843/848        0G      1.77    0.0784         0      1.85         9       544:  86%|########5 | 12/14 [00:57<00:09,  4.97s/it]\n",
      "   843/848        0G      1.71     0.077         0      1.79         9       544:  86%|########5 | 12/14 [01:02<00:09,  4.97s/it]\n",
      "   843/848        0G      1.71     0.077         0      1.79         9       544:  93%|#########2| 13/14 [01:02<00:04,  4.90s/it]\n",
      "   843/848        0G      1.67    0.0768         0      1.75         4       544:  93%|#########2| 13/14 [01:04<00:04,  4.90s/it]\n",
      "   843/848        0G      1.67    0.0768         0      1.75         4       544: 100%|##########| 14/14 [01:04<00:00,  3.98s/it]\n",
      "   843/848        0G      1.67    0.0768         0      1.75         4       544: 100%|##########| 14/14 [01:05<00:00,  4.66s/it]\n",
      "\n",
      "               Class    Images   Targets         P         R   mAP@0.5        F1:   0%|          | 0/4 [00:00<?, ?it/s]2024-03-05 09:39:42.361490: I tensorflow/core/util/port.cc:113] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
      "2024-03-05 09:39:42.438522: I tensorflow/core/util/port.cc:113] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
      "2024-03-05 09:39:42.571984: I tensorflow/core/util/port.cc:113] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
      "WARNING:tensorflow:From C:\\Users\\mit017\\anaconda3\\Lib\\site-packages\\keras\\src\\losses.py:2976: The name tf.losses.sparse_softmax_cross_entropy is deprecated. Please use tf.compat.v1.losses.sparse_softmax_cross_entropy instead.\n",
      "\n",
      "WARNING:tensorflow:From C:\\Users\\mit017\\anaconda3\\Lib\\site-packages\\keras\\src\\losses.py:2976: The name tf.losses.sparse_softmax_cross_entropy is deprecated. Please use tf.compat.v1.losses.sparse_softmax_cross_entropy instead.\n",
      "\n",
      "WARNING:tensorflow:From C:\\Users\\mit017\\anaconda3\\Lib\\site-packages\\keras\\src\\losses.py:2976: The name tf.losses.sparse_softmax_cross_entropy is deprecated. Please use tf.compat.v1.losses.sparse_softmax_cross_entropy instead.\n",
      "\n",
      "\n",
      "               Class    Images   Targets         P         R   mAP@0.5        F1:  25%|##5       | 1/4 [00:13<00:41, 13.93s/it]\n",
      "               Class    Images   Targets         P         R   mAP@0.5        F1:  50%|#####     | 2/4 [00:15<00:13,  6.92s/it]\n",
      "               Class    Images   Targets         P         R   mAP@0.5        F1:  75%|#######5  | 3/4 [00:17<00:04,  4.70s/it]\n",
      "               Class    Images   Targets         P         R   mAP@0.5        F1: 100%|##########| 4/4 [00:18<00:00,  3.13s/it]\n",
      "               Class    Images   Targets         P         R   mAP@0.5        F1: 100%|##########| 4/4 [00:19<00:00,  4.94s/it]\n",
      "2024-03-05 09:40:02.149058: I tensorflow/core/util/port.cc:113] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
      "WARNING:tensorflow:From C:\\Users\\mit017\\anaconda3\\Lib\\site-packages\\keras\\src\\losses.py:2976: The name tf.losses.sparse_softmax_cross_entropy is deprecated. Please use tf.compat.v1.losses.sparse_softmax_cross_entropy instead.\n",
      "\n",
      "2024-03-05 09:40:12.844130: I tensorflow/core/util/port.cc:113] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
      "WARNING:tensorflow:From C:\\Users\\mit017\\anaconda3\\Lib\\site-packages\\keras\\src\\losses.py:2976: The name tf.losses.sparse_softmax_cross_entropy is deprecated. Please use tf.compat.v1.losses.sparse_softmax_cross_entropy instead.\n",
      "\n",
      "2024-03-05 09:40:23.209717: I tensorflow/core/util/port.cc:113] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
      "WARNING:tensorflow:From C:\\Users\\mit017\\anaconda3\\Lib\\site-packages\\keras\\src\\losses.py:2976: The name tf.losses.sparse_softmax_cross_entropy is deprecated. Please use tf.compat.v1.losses.sparse_softmax_cross_entropy instead.\n",
      "\n",
      "\n",
      "  0%|          | 0/14 [00:00<?, ?it/s]\n",
      "   844/848        0G      1.14    0.0635         0       1.2         8       544:   0%|          | 0/14 [00:05<?, ?it/s]\n",
      "   844/848        0G      1.14    0.0635         0       1.2         8       544:   7%|7         | 1/14 [00:05<01:12,  5.55s/it]\n",
      "   844/848        0G      1.13    0.0734         0      1.21        10       544:   7%|7         | 1/14 [00:11<01:12,  5.55s/it]\n",
      "   844/848        0G      1.13    0.0734         0      1.21        10       544:  14%|#4        | 2/14 [00:11<01:08,  5.74s/it]\n",
      "   844/848        0G      1.77    0.0799         0      1.85         9       544:  14%|#4        | 2/14 [00:16<01:08,  5.74s/it]\n",
      "   844/848        0G      1.77    0.0799         0      1.85         9       544:  21%|##1       | 3/14 [00:16<00:59,  5.43s/it]\n",
      "   844/848        0G      2.02    0.0884         0      2.11        10       544:  21%|##1       | 3/14 [00:22<00:59,  5.43s/it]\n",
      "   844/848        0G      2.02    0.0884         0      2.11        10       544:  29%|##8       | 4/14 [00:22<00:54,  5.50s/it]\n",
      "   844/848        0G      1.83    0.0867         0      1.91         9       544:  29%|##8       | 4/14 [00:27<00:54,  5.50s/it]\n",
      "   844/848        0G      1.83    0.0867         0      1.91         9       544:  36%|###5      | 5/14 [00:27<00:48,  5.34s/it]\n",
      "   844/848        0G      1.72    0.0845         0       1.8         9       544:  36%|###5      | 5/14 [00:32<00:48,  5.34s/it]\n",
      "   844/848        0G      1.72    0.0845         0       1.8         9       544:  43%|####2     | 6/14 [00:32<00:41,  5.23s/it]\n",
      "   844/848        0G      1.61    0.0828         0      1.69         9       544:  43%|####2     | 6/14 [00:37<00:41,  5.23s/it]\n",
      "   844/848        0G      1.61    0.0828         0      1.69         9       544:  50%|#####     | 7/14 [00:37<00:35,  5.14s/it]\n",
      "   844/848        0G      1.57    0.0849         0      1.65         9       512:  50%|#####     | 7/14 [00:41<00:35,  5.14s/it]\n",
      "   844/848        0G      1.57    0.0849         0      1.65         9       512:  57%|#####7    | 8/14 [00:41<00:29,  4.93s/it]\n",
      "   844/848        0G      1.53     0.083         0      1.61         9       512:  57%|#####7    | 8/14 [00:45<00:29,  4.93s/it]\n",
      "   844/848        0G      1.53     0.083         0      1.61         9       512:  64%|######4   | 9/14 [00:45<00:23,  4.71s/it]\n",
      "   844/848        0G      1.48    0.0839         0      1.57         9       512:  64%|######4   | 9/14 [00:50<00:23,  4.71s/it]\n",
      "   844/848        0G      1.48    0.0839         0      1.57         9       512:  71%|#######1  | 10/14 [00:50<00:18,  4.60s/it]\n",
      "   844/848        0G      1.45    0.0889         0      1.54        13       512:  71%|#######1  | 10/14 [00:54<00:18,  4.60s/it]\n",
      "   844/848        0G      1.45    0.0889         0      1.54        13       512:  79%|#######8  | 11/14 [00:54<00:13,  4.50s/it]\n",
      "   844/848        0G      1.43    0.0874         0      1.52         9       512:  79%|#######8  | 11/14 [00:58<00:13,  4.50s/it]\n",
      "   844/848        0G      1.43    0.0874         0      1.52         9       512:  86%|########5 | 12/14 [00:58<00:08,  4.45s/it]\n",
      "   844/848        0G      1.41    0.0864         0      1.49        10       512:  86%|########5 | 12/14 [01:03<00:08,  4.45s/it]\n",
      "   844/848        0G      1.41    0.0864         0      1.49        10       512:  93%|#########2| 13/14 [01:03<00:04,  4.40s/it]\n",
      "   844/848        0G       1.4    0.0879         0      1.49         3       512:  93%|#########2| 13/14 [01:04<00:04,  4.40s/it]\n",
      "   844/848        0G       1.4    0.0879         0      1.49         3       512: 100%|##########| 14/14 [01:04<00:00,  3.56s/it]\n",
      "   844/848        0G       1.4    0.0879         0      1.49         3       512: 100%|##########| 14/14 [01:07<00:00,  4.79s/it]\n",
      "\n",
      "               Class    Images   Targets         P         R   mAP@0.5        F1:   0%|          | 0/4 [00:00<?, ?it/s]2024-03-05 09:41:42.381388: I tensorflow/core/util/port.cc:113] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
      "2024-03-05 09:41:42.381960: I tensorflow/core/util/port.cc:113] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
      "2024-03-05 09:41:42.382937: I tensorflow/core/util/port.cc:113] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
      "WARNING:tensorflow:From C:\\Users\\mit017\\anaconda3\\Lib\\site-packages\\keras\\src\\losses.py:2976: The name tf.losses.sparse_softmax_cross_entropy is deprecated. Please use tf.compat.v1.losses.sparse_softmax_cross_entropy instead.\n",
      "\n",
      "WARNING:tensorflow:From C:\\Users\\mit017\\anaconda3\\Lib\\site-packages\\keras\\src\\losses.py:2976: The name tf.losses.sparse_softmax_cross_entropy is deprecated. Please use tf.compat.v1.losses.sparse_softmax_cross_entropy instead.\n",
      "\n",
      "WARNING:tensorflow:From C:\\Users\\mit017\\anaconda3\\Lib\\site-packages\\keras\\src\\losses.py:2976: The name tf.losses.sparse_softmax_cross_entropy is deprecated. Please use tf.compat.v1.losses.sparse_softmax_cross_entropy instead.\n",
      "\n",
      "\n",
      "               Class    Images   Targets         P         R   mAP@0.5        F1:  25%|##5       | 1/4 [00:17<00:53, 17.76s/it]\n",
      "               Class    Images   Targets         P         R   mAP@0.5        F1:  50%|#####     | 2/4 [00:19<00:17,  8.54s/it]\n",
      "               Class    Images   Targets         P         R   mAP@0.5        F1:  75%|#######5  | 3/4 [00:21<00:05,  5.55s/it]\n",
      "               Class    Images   Targets         P         R   mAP@0.5        F1: 100%|##########| 4/4 [00:22<00:00,  3.64s/it]\n",
      "               Class    Images   Targets         P         R   mAP@0.5        F1: 100%|##########| 4/4 [00:23<00:00,  5.88s/it]\n",
      "2024-03-05 09:42:05.047334: I tensorflow/core/util/port.cc:113] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
      "WARNING:tensorflow:From C:\\Users\\mit017\\anaconda3\\Lib\\site-packages\\keras\\src\\losses.py:2976: The name tf.losses.sparse_softmax_cross_entropy is deprecated. Please use tf.compat.v1.losses.sparse_softmax_cross_entropy instead.\n",
      "\n",
      "2024-03-05 09:42:15.490857: I tensorflow/core/util/port.cc:113] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
      "WARNING:tensorflow:From C:\\Users\\mit017\\anaconda3\\Lib\\site-packages\\keras\\src\\losses.py:2976: The name tf.losses.sparse_softmax_cross_entropy is deprecated. Please use tf.compat.v1.losses.sparse_softmax_cross_entropy instead.\n",
      "\n",
      "2024-03-05 09:42:25.911245: I tensorflow/core/util/port.cc:113] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
      "WARNING:tensorflow:From C:\\Users\\mit017\\anaconda3\\Lib\\site-packages\\keras\\src\\losses.py:2976: The name tf.losses.sparse_softmax_cross_entropy is deprecated. Please use tf.compat.v1.losses.sparse_softmax_cross_entropy instead.\n",
      "\n",
      "\n",
      "  0%|          | 0/14 [00:00<?, ?it/s]\n",
      "   845/848        0G      1.27    0.0712         0      1.34         9       512:   0%|          | 0/14 [00:04<?, ?it/s]\n",
      "   845/848        0G      1.27    0.0712         0      1.34         9       512:   7%|7         | 1/14 [00:04<00:56,  4.34s/it]\n",
      "   845/848        0G      1.24    0.0826         0      1.32        11       512:   7%|7         | 1/14 [00:08<00:56,  4.34s/it]\n",
      "   845/848        0G      1.24    0.0826         0      1.32        11       512:  14%|#4        | 2/14 [00:08<00:50,  4.24s/it]\n",
      "   845/848        0G      1.17    0.0959         0      1.26        12       512:  14%|#4        | 2/14 [00:12<00:50,  4.24s/it]\n",
      "   845/848        0G      1.17    0.0959         0      1.26        12       512:  21%|##1       | 3/14 [00:12<00:47,  4.28s/it]\n",
      "   845/848        0G       1.2    0.0933         0      1.29        11       512:  21%|##1       | 3/14 [00:17<00:47,  4.28s/it]\n",
      "   845/848        0G       1.2    0.0933         0      1.29        11       512:  29%|##8       | 4/14 [00:17<00:44,  4.42s/it]\n",
      "   845/848        0G      1.22    0.0872         0       1.3         9       512:  29%|##8       | 4/14 [00:22<00:44,  4.42s/it]\n",
      "   845/848        0G      1.22    0.0872         0       1.3         9       512:  36%|###5      | 5/14 [00:22<00:40,  4.47s/it]\n",
      "   845/848        0G      1.17    0.0847         0      1.25         9       512:  36%|###5      | 5/14 [00:26<00:40,  4.47s/it]\n",
      "   845/848        0G      1.17    0.0847         0      1.25         9       512:  43%|####2     | 6/14 [00:26<00:35,  4.43s/it]\n",
      "   845/848        0G      1.18    0.0829         0      1.26        10       512:  43%|####2     | 6/14 [00:30<00:35,  4.43s/it]\n",
      "   845/848        0G      1.18    0.0829         0      1.26        10       512:  50%|#####     | 7/14 [00:30<00:30,  4.37s/it]\n",
      "   845/848        0G      1.16    0.0896         0      1.25        12       512:  50%|#####     | 7/14 [00:34<00:30,  4.37s/it]\n",
      "   845/848        0G      1.16    0.0896         0      1.25        12       512:  57%|#####7    | 8/14 [00:34<00:26,  4.35s/it]\n",
      "   845/848        0G      1.14    0.0916         0      1.23         9       512:  57%|#####7    | 8/14 [00:39<00:26,  4.35s/it]\n",
      "   845/848        0G      1.14    0.0916         0      1.23         9       512:  64%|######4   | 9/14 [00:39<00:21,  4.35s/it]\n",
      "   845/848        0G      1.37    0.0914         0      1.46         9       512:  64%|######4   | 9/14 [00:43<00:21,  4.35s/it]\n",
      "   845/848        0G      1.37    0.0914         0      1.46         9       512:  71%|#######1  | 10/14 [00:43<00:17,  4.30s/it]\n",
      "   845/848        0G      1.35    0.0898         0      1.44        10       512:  71%|#######1  | 10/14 [00:47<00:17,  4.30s/it]\n",
      "   845/848        0G      1.35    0.0898         0      1.44        10       512:  79%|#######8  | 11/14 [00:47<00:12,  4.24s/it]\n",
      "   845/848        0G      1.32    0.0926         0      1.41        13       512:  79%|#######8  | 11/14 [00:51<00:12,  4.24s/it]\n",
      "   845/848        0G      1.32    0.0926         0      1.41        13       512:  86%|########5 | 12/14 [00:51<00:08,  4.22s/it]\n",
      "   845/848        0G      1.31    0.0921         0       1.4         8       512:  86%|########5 | 12/14 [00:55<00:08,  4.22s/it]\n",
      "   845/848        0G      1.31    0.0921         0       1.4         8       512:  93%|#########2| 13/14 [00:55<00:04,  4.21s/it]\n",
      "   845/848        0G      1.29    0.0918         0      1.38         3       512:  93%|#########2| 13/14 [00:57<00:04,  4.21s/it]\n",
      "   845/848        0G      1.29    0.0918         0      1.38         3       512: 100%|##########| 14/14 [00:57<00:00,  3.40s/it]\n",
      "   845/848        0G      1.29    0.0918         0      1.38         3       512: 100%|##########| 14/14 [00:58<00:00,  4.17s/it]\n",
      "\n",
      "               Class    Images   Targets         P         R   mAP@0.5        F1:   0%|          | 0/4 [00:00<?, ?it/s]2024-03-05 09:43:34.697010: I tensorflow/core/util/port.cc:113] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
      "2024-03-05 09:43:34.745155: I tensorflow/core/util/port.cc:113] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
      "2024-03-05 09:43:34.839858: I tensorflow/core/util/port.cc:113] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
      "WARNING:tensorflow:From C:\\Users\\mit017\\anaconda3\\Lib\\site-packages\\keras\\src\\losses.py:2976: The name tf.losses.sparse_softmax_cross_entropy is deprecated. Please use tf.compat.v1.losses.sparse_softmax_cross_entropy instead.\n",
      "\n",
      "WARNING:tensorflow:From C:\\Users\\mit017\\anaconda3\\Lib\\site-packages\\keras\\src\\losses.py:2976: The name tf.losses.sparse_softmax_cross_entropy is deprecated. Please use tf.compat.v1.losses.sparse_softmax_cross_entropy instead.\n",
      "\n",
      "WARNING:tensorflow:From C:\\Users\\mit017\\anaconda3\\Lib\\site-packages\\keras\\src\\losses.py:2976: The name tf.losses.sparse_softmax_cross_entropy is deprecated. Please use tf.compat.v1.losses.sparse_softmax_cross_entropy instead.\n",
      "\n",
      "\n",
      "               Class    Images   Targets         P         R   mAP@0.5        F1:  25%|##5       | 1/4 [00:13<00:39, 13.32s/it]\n",
      "               Class    Images   Targets         P         R   mAP@0.5        F1:  50%|#####     | 2/4 [00:15<00:13,  6.67s/it]\n",
      "               Class    Images   Targets         P         R   mAP@0.5        F1:  75%|#######5  | 3/4 [00:17<00:04,  4.54s/it]\n",
      "               Class    Images   Targets         P         R   mAP@0.5        F1: 100%|##########| 4/4 [00:18<00:00,  3.04s/it]\n",
      "               Class    Images   Targets         P         R   mAP@0.5        F1: 100%|##########| 4/4 [00:19<00:00,  4.76s/it]\n",
      "2024-03-05 09:43:53.585644: I tensorflow/core/util/port.cc:113] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
      "WARNING:tensorflow:From C:\\Users\\mit017\\anaconda3\\Lib\\site-packages\\keras\\src\\losses.py:2976: The name tf.losses.sparse_softmax_cross_entropy is deprecated. Please use tf.compat.v1.losses.sparse_softmax_cross_entropy instead.\n",
      "\n",
      "2024-03-05 09:44:03.744120: I tensorflow/core/util/port.cc:113] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
      "WARNING:tensorflow:From C:\\Users\\mit017\\anaconda3\\Lib\\site-packages\\keras\\src\\losses.py:2976: The name tf.losses.sparse_softmax_cross_entropy is deprecated. Please use tf.compat.v1.losses.sparse_softmax_cross_entropy instead.\n",
      "\n",
      "2024-03-05 09:44:13.902752: I tensorflow/core/util/port.cc:113] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
      "WARNING:tensorflow:From C:\\Users\\mit017\\anaconda3\\Lib\\site-packages\\keras\\src\\losses.py:2976: The name tf.losses.sparse_softmax_cross_entropy is deprecated. Please use tf.compat.v1.losses.sparse_softmax_cross_entropy instead.\n",
      "\n",
      "\n",
      "  0%|          | 0/14 [00:00<?, ?it/s]\n",
      "   846/848        0G       1.1    0.0763         0      1.17         9       448:   0%|          | 0/14 [00:03<?, ?it/s]\n",
      "   846/848        0G       1.1    0.0763         0      1.17         9       448:   7%|7         | 1/14 [00:03<00:47,  3.62s/it]\n",
      "   846/848        0G       1.1    0.0841         0      1.18         9       448:   7%|7         | 1/14 [00:06<00:47,  3.62s/it]\n",
      "   846/848        0G       1.1    0.0841         0      1.18         9       448:  14%|#4        | 2/14 [00:06<00:40,  3.34s/it]\n",
      "   846/848        0G      1.13    0.0801         0      1.21         8       448:  14%|#4        | 2/14 [00:09<00:40,  3.34s/it]\n",
      "   846/848        0G      1.13    0.0801         0      1.21         8       448:  21%|##1       | 3/14 [00:09<00:36,  3.28s/it]\n",
      "   846/848        0G      1.15    0.0819         0      1.23        12       448:  21%|##1       | 3/14 [00:13<00:36,  3.28s/it]\n",
      "   846/848        0G      1.15    0.0819         0      1.23        12       448:  29%|##8       | 4/14 [00:13<00:32,  3.27s/it]\n",
      "   846/848        0G      1.14    0.0838         0      1.22        12       448:  29%|##8       | 4/14 [00:16<00:32,  3.27s/it]\n",
      "   846/848        0G      1.14    0.0838         0      1.22        12       448:  36%|###5      | 5/14 [00:16<00:29,  3.24s/it]\n",
      "   846/848        0G      1.16    0.0856         0      1.24         9       448:  36%|###5      | 5/14 [00:19<00:29,  3.24s/it]\n",
      "   846/848        0G      1.16    0.0856         0      1.24         9       448:  43%|####2     | 6/14 [00:19<00:25,  3.23s/it]\n",
      "   846/848        0G      1.13    0.0913         0      1.22         9       448:  43%|####2     | 6/14 [00:22<00:25,  3.23s/it]\n",
      "   846/848        0G      1.13    0.0913         0      1.22         9       448:  50%|#####     | 7/14 [00:22<00:22,  3.21s/it]\n",
      "   846/848        0G      1.16    0.0894         0      1.25         9       448:  50%|#####     | 7/14 [00:26<00:22,  3.21s/it]\n",
      "   846/848        0G      1.16    0.0894         0      1.25         9       448:  57%|#####7    | 8/14 [00:26<00:19,  3.22s/it]\n",
      "   846/848        0G      1.17    0.0891         0      1.26        10       448:  57%|#####7    | 8/14 [00:29<00:19,  3.22s/it]\n",
      "   846/848        0G      1.17    0.0891         0      1.26        10       448:  64%|######4   | 9/14 [00:29<00:16,  3.22s/it]\n",
      "   846/848        0G      1.18    0.0869         0      1.27         9       448:  64%|######4   | 9/14 [00:32<00:16,  3.22s/it]\n",
      "   846/848        0G      1.18    0.0869         0      1.27         9       448:  71%|#######1  | 10/14 [00:32<00:12,  3.20s/it]\n",
      "   846/848        0G      1.16    0.0855         0      1.25         9       448:  71%|#######1  | 10/14 [00:35<00:12,  3.20s/it]\n",
      "   846/848        0G      1.16    0.0855         0      1.25         9       448:  79%|#######8  | 11/14 [00:35<00:09,  3.20s/it]\n",
      "   846/848        0G      1.15    0.0871         0      1.24         9       448:  79%|#######8  | 11/14 [00:38<00:09,  3.20s/it]\n",
      "   846/848        0G      1.15    0.0871         0      1.24         9       448:  86%|########5 | 12/14 [00:38<00:06,  3.19s/it]\n",
      "   846/848        0G      1.17    0.0852         0      1.25         9       448:  86%|########5 | 12/14 [00:41<00:06,  3.19s/it]\n",
      "   846/848        0G      1.17    0.0852         0      1.25         9       448:  93%|#########2| 13/14 [00:41<00:03,  3.20s/it]\n",
      "   846/848        0G      1.19    0.0856         0      1.28         3       448:  93%|#########2| 13/14 [00:43<00:03,  3.20s/it]\n",
      "   846/848        0G      1.19    0.0856         0      1.28         3       448: 100%|##########| 14/14 [00:43<00:00,  2.59s/it]\n",
      "   846/848        0G      1.19    0.0856         0      1.28         3       448: 100%|##########| 14/14 [00:44<00:00,  3.15s/it]\n",
      "\n",
      "               Class    Images   Targets         P         R   mAP@0.5        F1:   0%|          | 0/4 [00:00<?, ?it/s]2024-03-05 09:45:08.332124: I tensorflow/core/util/port.cc:113] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
      "2024-03-05 09:45:08.389395: I tensorflow/core/util/port.cc:113] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
      "2024-03-05 09:45:08.471282: I tensorflow/core/util/port.cc:113] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
      "WARNING:tensorflow:From C:\\Users\\mit017\\anaconda3\\Lib\\site-packages\\keras\\src\\losses.py:2976: The name tf.losses.sparse_softmax_cross_entropy is deprecated. Please use tf.compat.v1.losses.sparse_softmax_cross_entropy instead.\n",
      "\n",
      "WARNING:tensorflow:From C:\\Users\\mit017\\anaconda3\\Lib\\site-packages\\keras\\src\\losses.py:2976: The name tf.losses.sparse_softmax_cross_entropy is deprecated. Please use tf.compat.v1.losses.sparse_softmax_cross_entropy instead.\n",
      "\n",
      "WARNING:tensorflow:From C:\\Users\\mit017\\anaconda3\\Lib\\site-packages\\keras\\src\\losses.py:2976: The name tf.losses.sparse_softmax_cross_entropy is deprecated. Please use tf.compat.v1.losses.sparse_softmax_cross_entropy instead.\n",
      "\n",
      "\n",
      "               Class    Images   Targets         P         R   mAP@0.5        F1:  25%|##5       | 1/4 [00:13<00:40, 13.36s/it]\n",
      "               Class    Images   Targets         P         R   mAP@0.5        F1:  50%|#####     | 2/4 [00:15<00:13,  6.69s/it]\n",
      "               Class    Images   Targets         P         R   mAP@0.5        F1:  75%|#######5  | 3/4 [00:17<00:04,  4.55s/it]\n",
      "               Class    Images   Targets         P         R   mAP@0.5        F1: 100%|##########| 4/4 [00:18<00:00,  3.04s/it]\n",
      "               Class    Images   Targets         P         R   mAP@0.5        F1: 100%|##########| 4/4 [00:19<00:00,  4.77s/it]\n",
      "2024-03-05 09:45:27.241967: I tensorflow/core/util/port.cc:113] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
      "WARNING:tensorflow:From C:\\Users\\mit017\\anaconda3\\Lib\\site-packages\\keras\\src\\losses.py:2976: The name tf.losses.sparse_softmax_cross_entropy is deprecated. Please use tf.compat.v1.losses.sparse_softmax_cross_entropy instead.\n",
      "\n",
      "2024-03-05 09:45:37.306230: I tensorflow/core/util/port.cc:113] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
      "WARNING:tensorflow:From C:\\Users\\mit017\\anaconda3\\Lib\\site-packages\\keras\\src\\losses.py:2976: The name tf.losses.sparse_softmax_cross_entropy is deprecated. Please use tf.compat.v1.losses.sparse_softmax_cross_entropy instead.\n",
      "\n",
      "2024-03-05 09:45:47.397643: I tensorflow/core/util/port.cc:113] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
      "WARNING:tensorflow:From C:\\Users\\mit017\\anaconda3\\Lib\\site-packages\\keras\\src\\losses.py:2976: The name tf.losses.sparse_softmax_cross_entropy is deprecated. Please use tf.compat.v1.losses.sparse_softmax_cross_entropy instead.\n",
      "\n",
      "\n",
      "  0%|          | 0/14 [00:00<?, ?it/s]\n",
      "   847/848        0G      1.08    0.0904         0      1.17        11       448:   0%|          | 0/14 [00:03<?, ?it/s]\n",
      "   847/848        0G      1.08    0.0904         0      1.17        11       448:   7%|7         | 1/14 [00:03<00:45,  3.52s/it]\n",
      "   847/848        0G     0.979    0.0934         0      1.07         9       448:   7%|7         | 1/14 [00:06<00:45,  3.52s/it]\n",
      "   847/848        0G     0.979    0.0934         0      1.07         9       448:  14%|#4        | 2/14 [00:06<00:39,  3.33s/it]\n",
      "   847/848        0G      1.04     0.103         0      1.15        12       448:  14%|#4        | 2/14 [00:09<00:39,  3.33s/it]\n",
      "   847/848        0G      1.04     0.103         0      1.15        12       448:  21%|##1       | 3/14 [00:09<00:36,  3.30s/it]\n",
      "   847/848        0G      1.04    0.0989         0      1.14        11       448:  21%|##1       | 3/14 [00:13<00:36,  3.30s/it]\n",
      "   847/848        0G      1.04    0.0989         0      1.14        11       448:  29%|##8       | 4/14 [00:13<00:32,  3.28s/it]\n",
      "   847/848        0G      1.06    0.0932         0      1.15         9       448:  29%|##8       | 4/14 [00:16<00:32,  3.28s/it]\n",
      "   847/848        0G      1.06    0.0932         0      1.15         9       448:  36%|###5      | 5/14 [00:16<00:29,  3.28s/it]\n",
      "   847/848        0G      1.09    0.0911         0      1.18        10       448:  36%|###5      | 5/14 [00:19<00:29,  3.28s/it]\n",
      "   847/848        0G      1.09    0.0911         0      1.18        10       448:  43%|####2     | 6/14 [00:19<00:26,  3.26s/it]\n",
      "   847/848        0G      1.08    0.0893         0      1.17         9       448:  43%|####2     | 6/14 [00:23<00:26,  3.26s/it]\n",
      "   847/848        0G      1.08    0.0893         0      1.17         9       448:  50%|#####     | 7/14 [00:23<00:22,  3.27s/it]\n",
      "   847/848        0G      1.07    0.0858         0      1.16         9       544:  50%|#####     | 7/14 [00:27<00:22,  3.27s/it]\n",
      "   847/848        0G      1.07    0.0858         0      1.16         9       544:  57%|#####7    | 8/14 [00:27<00:22,  3.78s/it]\n",
      "   847/848        0G      1.22    0.0875         0      1.31         9       544:  57%|#####7    | 8/14 [00:32<00:22,  3.78s/it]\n",
      "   847/848        0G      1.22    0.0875         0      1.31         9       544:  64%|######4   | 9/14 [00:32<00:20,  4.04s/it]\n",
      "   847/848        0G      1.22     0.086         0      1.31        11       544:  64%|######4   | 9/14 [00:37<00:20,  4.04s/it]\n",
      "   847/848        0G      1.22     0.086         0      1.31        11       544:  71%|#######1  | 10/14 [00:37<00:16,  4.23s/it]\n",
      "   847/848        0G       1.2    0.0845         0      1.29         9       544:  71%|#######1  | 10/14 [00:41<00:16,  4.23s/it]\n",
      "   847/848        0G       1.2    0.0845         0      1.29         9       544:  79%|#######8  | 11/14 [00:41<00:13,  4.38s/it]\n",
      "   847/848        0G      1.37    0.0864         0      1.46         9       544:  79%|#######8  | 11/14 [00:46<00:13,  4.38s/it]\n",
      "   847/848        0G      1.37    0.0864         0      1.46         9       544:  86%|########5 | 12/14 [00:46<00:08,  4.47s/it]\n",
      "   847/848        0G      1.34    0.0855         0      1.43         9       544:  86%|########5 | 12/14 [00:51<00:08,  4.47s/it]\n",
      "   847/848        0G      1.34    0.0855         0      1.43         9       544:  93%|#########2| 13/14 [00:51<00:04,  4.51s/it]\n",
      "   847/848        0G      1.32    0.0848         0       1.4         3       544:  93%|#########2| 13/14 [00:52<00:04,  4.51s/it]\n",
      "   847/848        0G      1.32    0.0848         0       1.4         3       544: 100%|##########| 14/14 [00:52<00:00,  3.65s/it]\n",
      "   847/848        0G      1.32    0.0848         0       1.4         3       544: 100%|##########| 14/14 [00:53<00:00,  3.84s/it]\n",
      "\n",
      "               Class    Images   Targets         P         R   mAP@0.5        F1:   0%|          | 0/4 [00:00<?, ?it/s]2024-03-05 09:46:51.458383: I tensorflow/core/util/port.cc:113] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
      "2024-03-05 09:46:51.511700: I tensorflow/core/util/port.cc:113] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
      "2024-03-05 09:46:51.612441: I tensorflow/core/util/port.cc:113] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
      "WARNING:tensorflow:From C:\\Users\\mit017\\anaconda3\\Lib\\site-packages\\keras\\src\\losses.py:2976: The name tf.losses.sparse_softmax_cross_entropy is deprecated. Please use tf.compat.v1.losses.sparse_softmax_cross_entropy instead.\n",
      "\n",
      "WARNING:tensorflow:From C:\\Users\\mit017\\anaconda3\\Lib\\site-packages\\keras\\src\\losses.py:2976: The name tf.losses.sparse_softmax_cross_entropy is deprecated. Please use tf.compat.v1.losses.sparse_softmax_cross_entropy instead.\n",
      "\n",
      "WARNING:tensorflow:From C:\\Users\\mit017\\anaconda3\\Lib\\site-packages\\keras\\src\\losses.py:2976: The name tf.losses.sparse_softmax_cross_entropy is deprecated. Please use tf.compat.v1.losses.sparse_softmax_cross_entropy instead.\n",
      "\n",
      "\n",
      "               Class    Images   Targets         P         R   mAP@0.5        F1:  25%|##5       | 1/4 [00:13<00:39, 13.04s/it]\n",
      "               Class    Images   Targets         P         R   mAP@0.5        F1:  50%|#####     | 2/4 [00:15<00:13,  6.54s/it]\n",
      "               Class    Images   Targets         P         R   mAP@0.5        F1:  75%|#######5  | 3/4 [00:17<00:04,  4.45s/it]\n",
      "               Class    Images   Targets         P         R   mAP@0.5        F1: 100%|##########| 4/4 [00:17<00:00,  2.97s/it]\n",
      "               Class    Images   Targets         P         R   mAP@0.5        F1: 100%|##########| 4/4 [00:18<00:00,  4.66s/it]\n",
      "2024-03-05 09:47:10.002869: I tensorflow/core/util/port.cc:113] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
      "WARNING:tensorflow:From C:\\Users\\mit017\\anaconda3\\Lib\\site-packages\\keras\\src\\losses.py:2976: The name tf.losses.sparse_softmax_cross_entropy is deprecated. Please use tf.compat.v1.losses.sparse_softmax_cross_entropy instead.\n",
      "\n",
      "2024-03-05 09:47:20.104925: I tensorflow/core/util/port.cc:113] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
      "WARNING:tensorflow:From C:\\Users\\mit017\\anaconda3\\Lib\\site-packages\\keras\\src\\losses.py:2976: The name tf.losses.sparse_softmax_cross_entropy is deprecated. Please use tf.compat.v1.losses.sparse_softmax_cross_entropy instead.\n",
      "\n",
      "2024-03-05 09:47:30.217709: I tensorflow/core/util/port.cc:113] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
      "WARNING:tensorflow:From C:\\Users\\mit017\\anaconda3\\Lib\\site-packages\\keras\\src\\losses.py:2976: The name tf.losses.sparse_softmax_cross_entropy is deprecated. Please use tf.compat.v1.losses.sparse_softmax_cross_entropy instead.\n",
      "\n",
      "\n",
      "  0%|          | 0/14 [00:00<?, ?it/s]\n",
      "   848/848        0G      1.05    0.0724         0      1.12        10       544:   0%|          | 0/14 [00:04<?, ?it/s]\n",
      "   848/848        0G      1.05    0.0724         0      1.12        10       544:   7%|7         | 1/14 [00:04<01:04,  4.96s/it]\n",
      "   848/848        0G      1.06    0.0854         0      1.14        10       544:   7%|7         | 1/14 [00:09<01:04,  4.96s/it]\n",
      "   848/848        0G      1.06    0.0854         0      1.14        10       544:  14%|#4        | 2/14 [00:09<00:57,  4.78s/it]\n",
      "   848/848        0G      1.07    0.0854         0      1.16         9       544:  14%|#4        | 2/14 [00:14<00:57,  4.78s/it]\n",
      "   848/848        0G      1.07    0.0854         0      1.16         9       544:  21%|##1       | 3/14 [00:14<00:51,  4.71s/it]\n",
      "   848/848        0G      1.63    0.0879         0      1.71         9       544:  21%|##1       | 3/14 [00:18<00:51,  4.71s/it]\n",
      "   848/848        0G      1.63    0.0879         0      1.71         9       544:  29%|##8       | 4/14 [00:18<00:46,  4.66s/it]\n",
      "   848/848        0G      1.51    0.0828         0       1.6         9       544:  29%|##8       | 4/14 [00:23<00:46,  4.66s/it]\n",
      "   848/848        0G      1.51    0.0828         0       1.6         9       544:  36%|###5      | 5/14 [00:23<00:41,  4.66s/it]\n",
      "   848/848        0G      1.78    0.0847         0      1.87        10       544:  36%|###5      | 5/14 [00:28<00:41,  4.66s/it]\n",
      "   848/848        0G      1.78    0.0847         0      1.87        10       544:  43%|####2     | 6/14 [00:28<00:37,  4.67s/it]\n",
      "   848/848        0G      1.68    0.0869         0      1.77        10       544:  43%|####2     | 6/14 [00:32<00:37,  4.67s/it]\n",
      "   848/848        0G      1.68    0.0869         0      1.77        10       544:  50%|#####     | 7/14 [00:32<00:32,  4.65s/it]\n",
      "   848/848        0G      1.89    0.0914         0      1.98        12       544:  50%|#####     | 7/14 [00:37<00:32,  4.65s/it]\n",
      "   848/848        0G      1.89    0.0914         0      1.98        12       544:  57%|#####7    | 8/14 [00:37<00:27,  4.66s/it]\n",
      "   848/848        0G      1.79    0.0887         0      1.88         9       544:  57%|#####7    | 8/14 [00:42<00:27,  4.66s/it]\n",
      "   848/848        0G      1.79    0.0887         0      1.88         9       544:  64%|######4   | 9/14 [00:42<00:23,  4.66s/it]\n",
      "   848/848        0G      1.86      0.09         0      1.95         9       544:  64%|######4   | 9/14 [00:46<00:23,  4.66s/it]\n",
      "   848/848        0G      1.86      0.09         0      1.95         9       544:  71%|#######1  | 10/14 [00:46<00:18,  4.67s/it]\n",
      "   848/848        0G      1.79    0.0899         0      1.88        11       544:  71%|#######1  | 10/14 [00:51<00:18,  4.67s/it]\n",
      "   848/848        0G      1.79    0.0899         0      1.88        11       544:  79%|#######8  | 11/14 [00:51<00:13,  4.65s/it]\n",
      "   848/848        0G      1.74    0.0874         0      1.83         8       544:  79%|#######8  | 11/14 [00:56<00:13,  4.65s/it]\n",
      "   848/848        0G      1.74    0.0874         0      1.83         8       544:  86%|########5 | 12/14 [00:56<00:09,  4.65s/it]\n",
      "   848/848        0G      1.68    0.0874         0      1.76         9       544:  86%|########5 | 12/14 [01:00<00:09,  4.65s/it]\n",
      "   848/848        0G      1.68    0.0874         0      1.76         9       544:  93%|#########2| 13/14 [01:00<00:04,  4.66s/it]\n",
      "   848/848        0G      1.63    0.0869         0      1.72         3       544:  93%|#########2| 13/14 [01:02<00:04,  4.66s/it]\n",
      "   848/848        0G      1.63    0.0869         0      1.72         3       544: 100%|##########| 14/14 [01:02<00:00,  3.76s/it]\n",
      "   848/848        0G      1.63    0.0869         0      1.72         3       544: 100%|##########| 14/14 [01:03<00:00,  4.53s/it]\n",
      "\n",
      "               Class    Images   Targets         P         R   mAP@0.5        F1:   0%|          | 0/4 [00:00<?, ?it/s]2024-03-05 09:48:43.854120: I tensorflow/core/util/port.cc:113] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
      "2024-03-05 09:48:43.904403: I tensorflow/core/util/port.cc:113] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
      "2024-03-05 09:48:43.993499: I tensorflow/core/util/port.cc:113] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
      "WARNING:tensorflow:From C:\\Users\\mit017\\anaconda3\\Lib\\site-packages\\keras\\src\\losses.py:2976: The name tf.losses.sparse_softmax_cross_entropy is deprecated. Please use tf.compat.v1.losses.sparse_softmax_cross_entropy instead.\n",
      "\n",
      "WARNING:tensorflow:From C:\\Users\\mit017\\anaconda3\\Lib\\site-packages\\keras\\src\\losses.py:2976: The name tf.losses.sparse_softmax_cross_entropy is deprecated. Please use tf.compat.v1.losses.sparse_softmax_cross_entropy instead.\n",
      "\n",
      "WARNING:tensorflow:From C:\\Users\\mit017\\anaconda3\\Lib\\site-packages\\keras\\src\\losses.py:2976: The name tf.losses.sparse_softmax_cross_entropy is deprecated. Please use tf.compat.v1.losses.sparse_softmax_cross_entropy instead.\n",
      "\n",
      "\n",
      "               Class    Images   Targets         P         R   mAP@0.5        F1:  25%|##5       | 1/4 [00:13<00:39, 13.29s/it]\n",
      "               Class    Images   Targets         P         R   mAP@0.5        F1:  50%|#####     | 2/4 [00:15<00:13,  6.65s/it]\n",
      "               Class    Images   Targets         P         R   mAP@0.5        F1:  75%|#######5  | 3/4 [00:17<00:04,  4.53s/it]\n",
      "               Class    Images   Targets         P         R   mAP@0.5        F1: 100%|##########| 4/4 [00:18<00:00,  3.02s/it]\n",
      "               Class    Images   Targets         P         R   mAP@0.5        F1: 100%|##########| 4/4 [00:18<00:00,  4.74s/it]\n"
     ]
    }
   ],
   "source": [
    "!python train.py --epochs 15 --weights weights/last.pt --batch-size 3 --cfg yolov3-spp.cfg --data custom.data --nosave --device cpu"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "299334f4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Namespace(cfg='yolov3-spp.cfg', names='classes.names', weights='weights/last.pt', source='images', output='result', img_size=512, conf_thres=0.3, iou_thres=0.6, fourcc='mp4v', half=False, device='', view_img=False, save_txt=False, classes=None, agnostic_nms=False, augment=False)\n",
      "Using CPU\n",
      "\n",
      "Model Summary: 225 layers, 6.25733e+07 parameters, 6.25733e+07 gradients\n",
      "image 1/50 images\\002_20200622_203136(3).jpg: 512x512 3 defects, Done. (0.670s)\n",
      "image 2/50 images\\002_20200622_203140(8).jpg: 512x512 2 defects, Done. (0.569s)\n",
      "image 3/50 images\\002_20200622_203145(3).jpg: 512x512 3 defects, Done. (0.504s)\n",
      "image 4/50 images\\002_20200622_203149(8).jpg: 512x512 3 defects, Done. (0.487s)\n",
      "image 5/50 images\\002_20200622_203154(3).jpg: 512x512 2 defects, Done. (0.491s)\n",
      "image 6/50 images\\002_20200622_203158(8).jpg: 512x512 2 defects, Done. (0.487s)\n",
      "image 7/50 images\\002_20200623_003351(2).jpg: 512x512 3 defects, Done. (0.502s)\n",
      "image 8/50 images\\002_20200623_003355(7).jpg: 512x512 2 defects, Done. (0.494s)\n",
      "image 9/50 images\\002_20200623_003400(2).jpg: 512x512 2 defects, Done. (0.492s)\n",
      "image 10/50 images\\002_20200623_003404(7).jpg: 512x512 2 defects, Done. (0.479s)\n",
      "image 11/50 images\\002_20200623_003409(2).jpg: 512x512 2 defects, Done. (0.483s)\n",
      "image 12/50 images\\002_20200623_003413(7).jpg: 512x512 2 defects, Done. (0.490s)\n",
      "image 13/50 images\\002_20200623_043056(0).jpg: 512x512 3 defects, Done. (0.548s)\n",
      "image 14/50 images\\002_20200623_043100(6).jpg: 512x512 3 defects, Done. (0.488s)\n",
      "image 15/50 images\\002_20200623_043105(0).jpg: 512x512 3 defects, Done. (0.460s)\n",
      "image 16/50 images\\002_20200623_043109(4).jpg: 512x512 2 defects, Done. (0.484s)\n",
      "image 17/50 images\\002_20200623_043115(4).jpg: 512x512 3 defects, Done. (0.500s)\n",
      "image 18/50 images\\002_20200623_043120(0).jpg: 512x512 3 defects, Done. (0.485s)\n",
      "image 19/50 images\\002_20200623_082249(3).jpg: 512x512 3 defects, Done. (0.482s)\n",
      "image 20/50 images\\002_20200623_082253(8).jpg: 512x512 2 defects, Done. (0.478s)\n",
      "image 21/50 images\\002_20200623_082258(4).jpg: 512x512 3 defects, Done. (0.475s)\n",
      "image 22/50 images\\002_20200623_082302(7).jpg: 512x512 3 defects, Done. (0.470s)\n",
      "image 23/50 images\\002_20200623_082307(2).jpg: 512x512 3 defects, Done. (0.480s)\n",
      "image 24/50 images\\002_20200623_082311(8).jpg: 512x512 3 defects, Done. (0.489s)\n",
      "image 25/50 images\\002_20200623_123042(0).jpg: 512x512 3 defects, Done. (0.481s)\n",
      "image 26/50 images\\002_20200623_123046(4).jpg: 512x512 2 defects, Done. (0.457s)\n",
      "image 27/50 images\\002_20200623_123051(1).jpg: 512x512 3 defects, Done. (0.481s)\n",
      "image 28/50 images\\002_20200623_123055(5).jpg: 512x512 3 defects, Done. (0.496s)\n",
      "image 29/50 images\\002_20200623_123100(0).jpg: 512x512 3 defects, Done. (0.499s)\n",
      "image 30/50 images\\002_20200623_123104(5).jpg: 512x512 2 defects, Done. (0.488s)\n",
      "image 31/50 images\\002_20200623_163020(3).jpg: 512x512 3 defects, Done. (0.470s)\n",
      "image 32/50 images\\002_20200623_163023(3).jpg: 512x512 Done. (0.493s)\n",
      "image 33/50 images\\002_20200623_163026(3).jpg: 512x512 2 defects, Done. (0.478s)\n",
      "image 34/50 images\\002_20200623_163029(6).jpg: 512x512 3 defects, Done. (0.480s)\n",
      "image 35/50 images\\002_20200623_163032(5).jpg: 512x512 2 defects, Done. (0.479s)\n",
      "image 36/50 images\\002_20200623_163035(5).jpg: 512x512 3 defects, Done. (0.486s)\n",
      "image 37/50 images\\002_20200623_203033(6).jpg: 512x512 3 defects, Done. (0.500s)\n",
      "image 38/50 images\\002_20200623_203038(0).jpg: 512x512 2 defects, Done. (0.489s)\n",
      "image 39/50 images\\002_20200623_203042(5).jpg: 512x512 3 defects, Done. (0.479s)\n",
      "image 40/50 images\\002_20200623_203047(0).jpg: 512x512 2 defects, Done. (0.451s)\n",
      "image 41/50 images\\002_20200623_203050(0).jpg: 512x512 2 defects, Done. (0.500s)\n",
      "image 42/50 images\\002_20200623_203054(6).jpg: 512x512 3 defects, Done. (0.492s)\n",
      "image 43/50 images\\002_20200624_003115(6).jpg: 512x512 3 defects, Done. (0.497s)\n",
      "image 44/50 images\\002_20200624_003118(6).jpg: 512x512 3 defects, Done. (0.472s)\n",
      "image 45/50 images\\002_20200624_003123(0).jpg: 512x512 3 defects, Done. (0.477s)\n",
      "image 46/50 images\\002_20200624_003127(5).jpg: 512x512 2 defects, Done. (0.478s)\n",
      "image 47/50 images\\002_20200624_003132(0).jpg: 512x512 3 defects, Done. (0.473s)\n",
      "image 48/50 images\\002_20200624_003136(5).jpg: 512x512 2 defects, Done. (0.488s)\n",
      "image 49/50 images\\002_20200624_043136(9).jpg: 512x512 3 defects, Done. (0.471s)\n",
      "image 50/50 images\\002_20200624_043141(4).jpg: 512x512 2 defects, Done. (0.475s)\n",
      "Results saved to C:\\Users\\mit017\\Desktop\\myproject\\XRAY_PROJECT\\XrayInspection\\dataset\\test1\\yolov3\\result\n",
      "Done. (24.880s)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\mit017\\anaconda3\\Lib\\site-packages\\torch\\functional.py:507: UserWarning: torch.meshgrid: in an upcoming release, it will be required to pass the indexing argument. (Triggered internally at ..\\aten\\src\\ATen\\native\\TensorShape.cpp:3550.)\n",
      "  return _VF.meshgrid(tensors, **kwargs)  # type: ignore[attr-defined]\n"
     ]
    }
   ],
   "source": [
    "!python detect.py --weights weights/last.pt --source images --cfg yolov3-spp.cfg --names classes.names --output result "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "e86aa7b0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Namespace(cfg='yolov3-spp.cfg', data='custom.data', weights='weights/last.pt', batch_size=16, img_size=512, conf_thres=0.001, iou_thres=0.6, save_json=False, task='test', device='', single_cls=False, augment=False)\n",
      "Using CPU\n",
      "\n",
      "WARNING: smart bias initialization failure.\n",
      "WARNING: smart bias initialization failure.\n",
      "WARNING: smart bias initialization failure.\n",
      "Model Summary: 225 layers, 6.25733e+07 parameters, 6.25733e+07 gradients\n",
      "Fusing layers...\n",
      "Model Summary: 152 layers, 6.25465e+07 parameters, 6.25465e+07 gradients\n",
      "                 all        10        30     0.936     0.933     0.963     0.935\n",
      "Speed: 460.7/3.1/463.8 ms inference/NMS/total per 512x512 image at batch-size 10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "  0%|          | 0/10 [00:00<?, ?it/s]\n",
      "Caching labels C:\\Users\\mit017\\Desktop\\myproject\\XRAY_PROJECT\\XrayInspection\\dataset\\test1\\yolov3\\test.txt (10 found, 0 missing, 0 empty, 0 duplicate, for 10 images): 100%|##########| 10/10 [00:00<00:00, 3368.11it/s]\n",
      "\n",
      "               Class    Images   Targets         P         R   mAP@0.5        F1:   0%|          | 0/1 [00:00<?, ?it/s]C:\\Users\\mit017\\anaconda3\\Lib\\site-packages\\torch\\functional.py:507: UserWarning: torch.meshgrid: in an upcoming release, it will be required to pass the indexing argument. (Triggered internally at ..\\aten\\src\\ATen\\native\\TensorShape.cpp:3550.)\n",
      "  return _VF.meshgrid(tensors, **kwargs)  # type: ignore[attr-defined]\n",
      "\n",
      "               Class    Images   Targets         P         R   mAP@0.5        F1: 100%|##########| 1/1 [00:10<00:00, 10.90s/it]\n",
      "               Class    Images   Targets         P         R   mAP@0.5        F1: 100%|##########| 1/1 [00:11<00:00, 11.88s/it]\n"
     ]
    }
   ],
   "source": [
    "!python test.py --cfg yolov3-spp.cfg --data custom.data --weights weights/last.pt "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "08077020",
   "metadata": {},
   "source": [
    "결과 정리<br>\n",
    "15 :  0.78     0.571     0.675     0.659 <br>\n",
    "200: 0.881     0.933     0.885     0.907 <br>\n",
    "50: 0.936     0.933     0.963     0.935"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a889e8ae",
   "metadata": {},
   "source": [
    "## 100개"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "3e5e234a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-> Please ignore this error message\n",
      "\n",
      "Showing image 0/99, path: input\\002_20200622_203136(3).bmp\n",
      "Welcome!\n",
      " Press [h] for help.\n",
      "Showing image 1/99, path: input\\002_20200622_203140(8).bmp\n",
      "Showing image 1/99, path: input\\002_20200622_203140(8).bmp\n",
      "Showing image 2/99, path: input\\002_20200622_203145(3).bmp\n",
      "Showing image 2/99, path: input\\002_20200622_203145(3).bmp\n",
      "Showing image 3/99, path: input\\002_20200622_203149(8).bmp\n",
      "Showing image 3/99, path: input\\002_20200622_203149(8).bmp\n",
      "Showing image 4/99, path: input\\002_20200622_203154(3).bmp\n",
      "Showing image 4/99, path: input\\002_20200622_203154(3).bmp\n",
      "Showing image 5/99, path: input\\002_20200622_203158(8).bmp\n",
      "Showing image 5/99, path: input\\002_20200622_203158(8).bmp\n",
      "Showing image 6/99, path: input\\002_20200623_003351(2).bmp\n",
      "Showing image 6/99, path: input\\002_20200623_003351(2).bmp\n",
      "Showing image 7/99, path: input\\002_20200623_003355(7).bmp\n",
      "Showing image 7/99, path: input\\002_20200623_003355(7).bmp\n",
      "Showing image 8/99, path: input\\002_20200623_003400(2).bmp\n",
      "Showing image 8/99, path: input\\002_20200623_003400(2).bmp\n",
      "Showing image 9/99, path: input\\002_20200623_003404(7).bmp\n",
      "Showing image 9/99, path: input\\002_20200623_003404(7).bmp\n",
      "Showing image 10/99, path: input\\002_20200623_003409(2).bmp\n",
      "Showing image 10/99, path: input\\002_20200623_003409(2).bmp\n",
      "Showing image 11/99, path: input\\002_20200623_003413(7).bmp\n",
      "Showing image 11/99, path: input\\002_20200623_003413(7).bmp\n",
      "Showing image 12/99, path: input\\002_20200623_043056(0).bmp\n",
      "Showing image 12/99, path: input\\002_20200623_043056(0).bmp\n",
      "Showing image 13/99, path: input\\002_20200623_043100(6).bmp\n",
      "Showing image 13/99, path: input\\002_20200623_043100(6).bmp\n",
      "Showing image 14/99, path: input\\002_20200623_043105(0).bmp\n",
      "Showing image 14/99, path: input\\002_20200623_043105(0).bmp\n",
      "Showing image 15/99, path: input\\002_20200623_043109(4).bmp\n",
      "Showing image 15/99, path: input\\002_20200623_043109(4).bmp\n",
      "Showing image 16/99, path: input\\002_20200623_043115(4).bmp\n",
      "Showing image 16/99, path: input\\002_20200623_043115(4).bmp\n",
      "Showing image 17/99, path: input\\002_20200623_043120(0).bmp\n",
      "Showing image 17/99, path: input\\002_20200623_043120(0).bmp\n",
      "Showing image 18/99, path: input\\002_20200623_082249(3).bmp\n",
      "Showing image 18/99, path: input\\002_20200623_082249(3).bmp\n",
      "Showing image 19/99, path: input\\002_20200623_082253(8).bmp\n",
      "Showing image 19/99, path: input\\002_20200623_082253(8).bmp\n",
      "Showing image 20/99, path: input\\002_20200623_082258(4).bmp\n",
      "Showing image 20/99, path: input\\002_20200623_082258(4).bmp\n",
      "Showing image 21/99, path: input\\002_20200623_082302(7).bmp\n",
      "Showing image 21/99, path: input\\002_20200623_082302(7).bmp\n",
      "Showing image 22/99, path: input\\002_20200623_082307(2).bmp\n",
      "Showing image 22/99, path: input\\002_20200623_082307(2).bmp\n",
      "Showing image 23/99, path: input\\002_20200623_082311(8).bmp\n",
      "Showing image 23/99, path: input\\002_20200623_082311(8).bmp\n",
      "Showing image 24/99, path: input\\002_20200623_123042(0).bmp\n",
      "Showing image 24/99, path: input\\002_20200623_123042(0).bmp\n",
      "Showing image 25/99, path: input\\002_20200623_123046(4).bmp\n",
      "Showing image 25/99, path: input\\002_20200623_123046(4).bmp\n",
      "Showing image 26/99, path: input\\002_20200623_123051(1).bmp\n",
      "Showing image 26/99, path: input\\002_20200623_123051(1).bmp\n",
      "Showing image 27/99, path: input\\002_20200623_123055(5).bmp\n",
      "Showing image 27/99, path: input\\002_20200623_123055(5).bmp\n",
      "Showing image 28/99, path: input\\002_20200623_123100(0).bmp\n",
      "Showing image 28/99, path: input\\002_20200623_123100(0).bmp\n",
      "Showing image 29/99, path: input\\002_20200623_123104(5).bmp\n",
      "Showing image 29/99, path: input\\002_20200623_123104(5).bmp\n",
      "Showing image 30/99, path: input\\002_20200623_163020(3).bmp\n",
      "Showing image 30/99, path: input\\002_20200623_163020(3).bmp\n",
      "Showing image 31/99, path: input\\002_20200623_163023(3).bmp\n",
      "Showing image 31/99, path: input\\002_20200623_163023(3).bmp\n",
      "Showing image 32/99, path: input\\002_20200623_163026(3).bmp\n",
      "Showing image 32/99, path: input\\002_20200623_163026(3).bmp\n",
      "Showing image 33/99, path: input\\002_20200623_163029(6).bmp\n",
      "Showing image 33/99, path: input\\002_20200623_163029(6).bmp\n",
      "Showing image 34/99, path: input\\002_20200623_163032(5).bmp\n",
      "Showing image 34/99, path: input\\002_20200623_163032(5).bmp\n",
      "Showing image 35/99, path: input\\002_20200623_163035(5).bmp\n",
      "Showing image 35/99, path: input\\002_20200623_163035(5).bmp\n",
      "Showing image 36/99, path: input\\002_20200623_203033(6).bmp\n",
      "Showing image 36/99, path: input\\002_20200623_203033(6).bmp\n",
      "Showing image 37/99, path: input\\002_20200623_203038(0).bmp\n",
      "Showing image 37/99, path: input\\002_20200623_203038(0).bmp\n",
      "Showing image 38/99, path: input\\002_20200623_203042(5).bmp\n",
      "Showing image 38/99, path: input\\002_20200623_203042(5).bmp\n",
      "Showing image 39/99, path: input\\002_20200623_203047(0).bmp\n",
      "Showing image 39/99, path: input\\002_20200623_203047(0).bmp\n",
      "Showing image 40/99, path: input\\002_20200623_203050(0).bmp\n",
      "Showing image 40/99, path: input\\002_20200623_203050(0).bmp\n",
      "Showing image 41/99, path: input\\002_20200623_203054(6).bmp\n",
      "Showing image 41/99, path: input\\002_20200623_203054(6).bmp\n",
      "Showing image 42/99, path: input\\002_20200624_003115(6).bmp\n",
      "Showing image 42/99, path: input\\002_20200624_003115(6).bmp\n",
      "Showing image 43/99, path: input\\002_20200624_003118(6).bmp\n",
      "Showing image 43/99, path: input\\002_20200624_003118(6).bmp\n",
      "Showing image 44/99, path: input\\002_20200624_003123(0).bmp\n",
      "Showing image 44/99, path: input\\002_20200624_003123(0).bmp\n",
      "Showing image 45/99, path: input\\002_20200624_003127(5).bmp\n",
      "Showing image 45/99, path: input\\002_20200624_003127(5).bmp\n",
      "Showing image 46/99, path: input\\002_20200624_003132(0).bmp\n",
      "Showing image 46/99, path: input\\002_20200624_003132(0).bmp\n",
      "Showing image 47/99, path: input\\002_20200624_003136(5).bmp\n",
      "Showing image 47/99, path: input\\002_20200624_003136(5).bmp\n",
      "Showing image 48/99, path: input\\002_20200624_043136(9).bmp\n",
      "Showing image 48/99, path: input\\002_20200624_043136(9).bmp\n",
      "Showing image 49/99, path: input\\002_20200624_043141(4).bmp\n",
      "Showing image 49/99, path: input\\002_20200624_043141(4).bmp\n",
      "Showing image 50/99, path: input\\002_20200624_043145(8).bmp\n",
      "Showing image 50/99, path: input\\002_20200624_043145(8).bmp\n",
      "Showing image 51/99, path: input\\002_20200624_043150(3).bmp\n",
      "Showing image 51/99, path: input\\002_20200624_043150(3).bmp\n",
      "Showing image 52/99, path: input\\002_20200624_043154(8).bmp\n",
      "Showing image 52/99, path: input\\002_20200624_043154(8).bmp\n",
      "Showing image 53/99, path: input\\002_20200624_043159(4).bmp\n",
      "Showing image 53/99, path: input\\002_20200624_043159(4).bmp\n",
      "Showing image 54/99, path: input\\002_20200624_083032(4).bmp\n",
      "Showing image 54/99, path: input\\002_20200624_083032(4).bmp\n",
      "Showing image 55/99, path: input\\002_20200624_083036(9).bmp\n",
      "Showing image 55/99, path: input\\002_20200624_083036(9).bmp\n",
      "Showing image 56/99, path: input\\002_20200624_083041(3).bmp\n",
      "Showing image 56/99, path: input\\002_20200624_083041(3).bmp\n",
      "Showing image 57/99, path: input\\002_20200624_083045(8).bmp\n",
      "Showing image 57/99, path: input\\002_20200624_083045(8).bmp\n",
      "Showing image 58/99, path: input\\002_20200624_083050(4).bmp\n",
      "Showing image 58/99, path: input\\002_20200624_083050(4).bmp\n",
      "Showing image 59/99, path: input\\002_20200624_083054(9).bmp\n",
      "Showing image 59/99, path: input\\002_20200624_083054(9).bmp\n",
      "Showing image 60/99, path: input\\002_20200624_123144(0).bmp\n",
      "Showing image 60/99, path: input\\002_20200624_123144(0).bmp\n",
      "Showing image 61/99, path: input\\002_20200624_123148(2).bmp\n",
      "Showing image 61/99, path: input\\002_20200624_123148(2).bmp\n",
      "Showing image 62/99, path: input\\002_20200624_123152(7).bmp\n",
      "Showing image 62/99, path: input\\002_20200624_123152(7).bmp\n",
      "Showing image 63/99, path: input\\002_20200624_123157(4).bmp\n",
      "Showing image 63/99, path: input\\002_20200624_123157(4).bmp\n",
      "Showing image 64/99, path: input\\002_20200624_123201(7).bmp\n",
      "Showing image 64/99, path: input\\002_20200624_123201(7).bmp\n",
      "Showing image 65/99, path: input\\002_20200624_123206(2).bmp\n",
      "Showing image 65/99, path: input\\002_20200624_123206(2).bmp\n",
      "Showing image 66/99, path: input\\002_20200624_162708(9).bmp\n",
      "Showing image 66/99, path: input\\002_20200624_162708(9).bmp\n",
      "Showing image 67/99, path: input\\002_20200624_162713(4).bmp\n",
      "Showing image 67/99, path: input\\002_20200624_162713(4).bmp\n",
      "Showing image 68/99, path: input\\002_20200624_162717(9).bmp\n",
      "Showing image 68/99, path: input\\002_20200624_162717(9).bmp\n",
      "Showing image 69/99, path: input\\002_20200624_162722(4).bmp\n",
      "Showing image 69/99, path: input\\002_20200624_162722(4).bmp\n",
      "Showing image 70/99, path: input\\002_20200624_162726(9).bmp\n",
      "Showing image 70/99, path: input\\002_20200624_162726(9).bmp\n",
      "Showing image 71/99, path: input\\002_20200624_162737(5).bmp\n",
      "Showing image 71/99, path: input\\002_20200624_162737(5).bmp\n",
      "Showing image 72/99, path: input\\002_20200624_203111(4).bmp\n",
      "Showing image 72/99, path: input\\002_20200624_203111(4).bmp\n",
      "Showing image 73/99, path: input\\002_20200624_203114(3).bmp\n",
      "Showing image 73/99, path: input\\002_20200624_203114(3).bmp\n",
      "Showing image 74/99, path: input\\002_20200624_203117(3).bmp\n",
      "Showing image 74/99, path: input\\002_20200624_203117(3).bmp\n",
      "Showing image 75/99, path: input\\002_20200624_203120(3).bmp\n",
      "Showing image 75/99, path: input\\002_20200624_203120(3).bmp\n",
      "Showing image 76/99, path: input\\002_20200624_203123(3).bmp\n",
      "Showing image 76/99, path: input\\002_20200624_203123(3).bmp\n",
      "Showing image 77/99, path: input\\002_20200624_203126(3).bmp\n",
      "Showing image 77/99, path: input\\002_20200624_203126(3).bmp\n",
      "Showing image 78/99, path: input\\002_20200625_003352(9).bmp\n",
      "Showing image 78/99, path: input\\002_20200625_003352(9).bmp\n",
      "Showing image 79/99, path: input\\002_20200625_003357(4).bmp\n",
      "Showing image 79/99, path: input\\002_20200625_003357(4).bmp\n",
      "Showing image 80/99, path: input\\002_20200625_003401(8).bmp\n",
      "Showing image 80/99, path: input\\002_20200625_003401(8).bmp\n",
      "Showing image 81/99, path: input\\002_20200625_003406(3).bmp\n",
      "Showing image 81/99, path: input\\002_20200625_003406(3).bmp\n",
      "Showing image 82/99, path: input\\002_20200625_003410(8).bmp\n",
      "Showing image 82/99, path: input\\002_20200625_003410(8).bmp\n",
      "Showing image 83/99, path: input\\002_20200625_003415(4).bmp\n",
      "Showing image 83/99, path: input\\002_20200625_003415(4).bmp\n",
      "Showing image 84/99, path: input\\002_20200629_082823(5).bmp\n",
      "Showing image 84/99, path: input\\002_20200629_082823(5).bmp\n",
      "Showing image 85/99, path: input\\002_20200629_082828(5).bmp\n",
      "Showing image 85/99, path: input\\002_20200629_082828(5).bmp\n",
      "Showing image 86/99, path: input\\002_20200629_082831(3).bmp\n",
      "Showing image 86/99, path: input\\002_20200629_082831(3).bmp\n",
      "Showing image 87/99, path: input\\002_20200629_082834(2).bmp\n",
      "Showing image 87/99, path: input\\002_20200629_082834(2).bmp\n",
      "Showing image 88/99, path: input\\002_20200629_082837(0).bmp\n",
      "Showing image 88/99, path: input\\002_20200629_082837(0).bmp\n",
      "Showing image 89/99, path: input\\002_20200629_082839(9).bmp\n",
      "Showing image 89/99, path: input\\002_20200629_082839(9).bmp\n",
      "Showing image 90/99, path: input\\002_20200629_123442(5).bmp\n",
      "Showing image 90/99, path: input\\002_20200629_123442(5).bmp\n",
      "Showing image 91/99, path: input\\002_20200629_123447(0).bmp\n",
      "Showing image 91/99, path: input\\002_20200629_123447(0).bmp\n",
      "Showing image 92/99, path: input\\002_20200629_123451(5).bmp\n",
      "Showing image 92/99, path: input\\002_20200629_123451(5).bmp\n",
      "Showing image 93/99, path: input\\002_20200629_123456(0).bmp\n",
      "Showing image 93/99, path: input\\002_20200629_123456(0).bmp\n",
      "Showing image 94/99, path: input\\002_20200629_123500(5).bmp\n",
      "Showing image 94/99, path: input\\002_20200629_123500(5).bmp\n",
      "Showing image 95/99, path: input\\002_20200629_123505(0).bmp\n",
      "Showing image 95/99, path: input\\002_20200629_123505(0).bmp\n",
      "Showing image 96/99, path: input\\002_20200629_163656(7).bmp\n",
      "Showing image 96/99, path: input\\002_20200629_163656(7).bmp\n",
      "Showing image 97/99, path: input\\002_20200629_163659(7).bmp\n",
      "Showing image 97/99, path: input\\002_20200629_163659(7).bmp\n",
      "Showing image 98/99, path: input\\002_20200629_163702(8).bmp\n",
      "Showing image 98/99, path: input\\002_20200629_163702(8).bmp\n",
      "Showing image 99/99, path: input\\002_20200629_163705(8).bmp\n",
      "Showing image 99/99, path: input\\002_20200629_163705(8).bmp\n",
      "Showing image 0/99, path: input\\002_20200622_203136(3).bmp\n",
      "Showing image 0/99, path: input\\002_20200622_203136(3).bmp\n",
      "Showing image 1/99, path: input\\002_20200622_203140(8).bmp\n",
      "Showing image 1/99, path: input\\002_20200622_203140(8).bmp\n",
      "Showing image 0/99, path: input\\002_20200622_203136(3).bmp\n",
      "Showing image 0/99, path: input\\002_20200622_203136(3).bmp\n",
      "Showing image 99/99, path: input\\002_20200629_163705(8).bmp\n",
      "Showing image 99/99, path: input\\002_20200629_163705(8).bmp\n",
      "Showing image 98/99, path: input\\002_20200629_163702(8).bmp\n",
      "Showing image 98/99, path: input\\002_20200629_163702(8).bmp\n",
      "Showing image 97/99, path: input\\002_20200629_163659(7).bmp\n",
      "Showing image 97/99, path: input\\002_20200629_163659(7).bmp\n",
      "Showing image 96/99, path: input\\002_20200629_163656(7).bmp\n",
      "Showing image 96/99, path: input\\002_20200629_163656(7).bmp\n",
      "Showing image 95/99, path: input\\002_20200629_123505(0).bmp\n",
      "Showing image 95/99, path: input\\002_20200629_123505(0).bmp\n",
      "Showing image 94/99, path: input\\002_20200629_123500(5).bmp\n",
      "Showing image 94/99, path: input\\002_20200629_123500(5).bmp\n",
      "Showing image 93/99, path: input\\002_20200629_123456(0).bmp\n",
      "Showing image 93/99, path: input\\002_20200629_123456(0).bmp\n",
      "Showing image 92/99, path: input\\002_20200629_123451(5).bmp\n",
      "Showing image 92/99, path: input\\002_20200629_123451(5).bmp\n",
      "Showing image 91/99, path: input\\002_20200629_123447(0).bmp\n",
      "Showing image 91/99, path: input\\002_20200629_123447(0).bmp\n",
      "Showing image 90/99, path: input\\002_20200629_123442(5).bmp\n",
      "Showing image 90/99, path: input\\002_20200629_123442(5).bmp\n",
      "Showing image 89/99, path: input\\002_20200629_082839(9).bmp\n",
      "Showing image 89/99, path: input\\002_20200629_082839(9).bmp\n",
      "Showing image 88/99, path: input\\002_20200629_082837(0).bmp\n",
      "Showing image 88/99, path: input\\002_20200629_082837(0).bmp\n",
      "Showing image 87/99, path: input\\002_20200629_082834(2).bmp\n",
      "Showing image 87/99, path: input\\002_20200629_082834(2).bmp\n",
      "Showing image 86/99, path: input\\002_20200629_082831(3).bmp\n",
      "Showing image 86/99, path: input\\002_20200629_082831(3).bmp\n",
      "Showing image 85/99, path: input\\002_20200629_082828(5).bmp\n",
      "Showing image 85/99, path: input\\002_20200629_082828(5).bmp\n",
      "Showing image 84/99, path: input\\002_20200629_082823(5).bmp\n",
      "Showing image 84/99, path: input\\002_20200629_082823(5).bmp\n",
      "Showing image 83/99, path: input\\002_20200625_003415(4).bmp\n",
      "Showing image 83/99, path: input\\002_20200625_003415(4).bmp\n",
      "Showing image 82/99, path: input\\002_20200625_003410(8).bmp\n",
      "Showing image 82/99, path: input\\002_20200625_003410(8).bmp\n",
      "Showing image 81/99, path: input\\002_20200625_003406(3).bmp\n",
      "Showing image 81/99, path: input\\002_20200625_003406(3).bmp\n",
      "Showing image 80/99, path: input\\002_20200625_003401(8).bmp\n",
      "Showing image 80/99, path: input\\002_20200625_003401(8).bmp\n",
      "Showing image 79/99, path: input\\002_20200625_003357(4).bmp\n",
      "Showing image 79/99, path: input\\002_20200625_003357(4).bmp\n",
      "Showing image 78/99, path: input\\002_20200625_003352(9).bmp\n",
      "Showing image 78/99, path: input\\002_20200625_003352(9).bmp\n",
      "Showing image 77/99, path: input\\002_20200624_203126(3).bmp\n",
      "Showing image 77/99, path: input\\002_20200624_203126(3).bmp\n",
      "Showing image 76/99, path: input\\002_20200624_203123(3).bmp\n",
      "Showing image 76/99, path: input\\002_20200624_203123(3).bmp\n",
      "Showing image 75/99, path: input\\002_20200624_203120(3).bmp\n",
      "Showing image 75/99, path: input\\002_20200624_203120(3).bmp\n",
      "Showing image 74/99, path: input\\002_20200624_203117(3).bmp\n",
      "Showing image 74/99, path: input\\002_20200624_203117(3).bmp\n",
      "Showing image 73/99, path: input\\002_20200624_203114(3).bmp\n",
      "Showing image 73/99, path: input\\002_20200624_203114(3).bmp\n",
      "Showing image 72/99, path: input\\002_20200624_203111(4).bmp\n",
      "Showing image 72/99, path: input\\002_20200624_203111(4).bmp\n",
      "Showing image 71/99, path: input\\002_20200624_162737(5).bmp\n",
      "Showing image 71/99, path: input\\002_20200624_162737(5).bmp\n",
      "Showing image 70/99, path: input\\002_20200624_162726(9).bmp\n",
      "Showing image 70/99, path: input\\002_20200624_162726(9).bmp\n",
      "Showing image 69/99, path: input\\002_20200624_162722(4).bmp\n",
      "Showing image 69/99, path: input\\002_20200624_162722(4).bmp\n",
      "Showing image 68/99, path: input\\002_20200624_162717(9).bmp\n",
      "Showing image 68/99, path: input\\002_20200624_162717(9).bmp\n",
      "Showing image 67/99, path: input\\002_20200624_162713(4).bmp\n",
      "Showing image 67/99, path: input\\002_20200624_162713(4).bmp\n",
      "Showing image 66/99, path: input\\002_20200624_162708(9).bmp\n",
      "Showing image 66/99, path: input\\002_20200624_162708(9).bmp\n",
      "Showing image 65/99, path: input\\002_20200624_123206(2).bmp\n",
      "Showing image 65/99, path: input\\002_20200624_123206(2).bmp\n",
      "Showing image 64/99, path: input\\002_20200624_123201(7).bmp\n",
      "Showing image 64/99, path: input\\002_20200624_123201(7).bmp\n",
      "Showing image 63/99, path: input\\002_20200624_123157(4).bmp\n",
      "Showing image 63/99, path: input\\002_20200624_123157(4).bmp\n",
      "Showing image 62/99, path: input\\002_20200624_123152(7).bmp\n",
      "Showing image 62/99, path: input\\002_20200624_123152(7).bmp\n",
      "Showing image 61/99, path: input\\002_20200624_123148(2).bmp\n",
      "Showing image 61/99, path: input\\002_20200624_123148(2).bmp\n",
      "Showing image 60/99, path: input\\002_20200624_123144(0).bmp\n",
      "Showing image 60/99, path: input\\002_20200624_123144(0).bmp\n",
      "Showing image 59/99, path: input\\002_20200624_083054(9).bmp\n",
      "Showing image 59/99, path: input\\002_20200624_083054(9).bmp\n",
      "Showing image 58/99, path: input\\002_20200624_083050(4).bmp\n",
      "Showing image 58/99, path: input\\002_20200624_083050(4).bmp\n",
      "Showing image 57/99, path: input\\002_20200624_083045(8).bmp\n",
      "Showing image 57/99, path: input\\002_20200624_083045(8).bmp\n",
      "Showing image 56/99, path: input\\002_20200624_083041(3).bmp\n",
      "Showing image 56/99, path: input\\002_20200624_083041(3).bmp\n",
      "Showing image 55/99, path: input\\002_20200624_083036(9).bmp\n",
      "Showing image 55/99, path: input\\002_20200624_083036(9).bmp\n",
      "Showing image 54/99, path: input\\002_20200624_083032(4).bmp\n",
      "Showing image 54/99, path: input\\002_20200624_083032(4).bmp\n",
      "Showing image 53/99, path: input\\002_20200624_043159(4).bmp\n",
      "Showing image 53/99, path: input\\002_20200624_043159(4).bmp\n",
      "Showing image 52/99, path: input\\002_20200624_043154(8).bmp\n",
      "Showing image 52/99, path: input\\002_20200624_043154(8).bmp\n",
      "Showing image 51/99, path: input\\002_20200624_043150(3).bmp\n",
      "Showing image 51/99, path: input\\002_20200624_043150(3).bmp\n",
      "Showing image 50/99, path: input\\002_20200624_043145(8).bmp\n",
      "Showing image 50/99, path: input\\002_20200624_043145(8).bmp\n"
     ]
    }
   ],
   "source": [
    "!python C:/Users/mit017/Desktop/myproject/XRAY_PROJECT/XrayInspection/dataset/OpenLabeling-master/main/main.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "888ff912",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "C:\\Users\\mit017\\Desktop\\myproject\\XRAY_PROJECT\\XrayInspection\\dataset\\test1\\yolov3\n"
     ]
    }
   ],
   "source": [
    "%cd C:/Users/mit017/Desktop/myproject/XRAY_PROJECT/XrayInspection/dataset/test1/yolov3/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "6a0a4942",
   "metadata": {},
   "outputs": [],
   "source": [
    "image_dir='C:/Users/mit017/Desktop/myproject/XRAY_PROJECT/XrayInspection/dataset/test1/yolov3/images'\n",
    "\n",
    "import random\n",
    "import os\n",
    "import subprocess\n",
    "import sys\n",
    "\n",
    "split_data_set(image_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "b626eb32",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Apex recommended for faster mixed precision training: https://github.com/NVIDIA/apex\n",
      "Namespace(epochs=15, batch_size=3, cfg='yolov3-spp.cfg', data='custom.data', multi_scale=False, img_size=[320, 640], rect=False, resume=False, nosave=True, notest=False, evolve=False, bucket='', cache_images=False, weights='weights/last.pt', name='', device='cpu', adam=False, single_cls=False, freeze_layers=False)\n",
      "Using CPU\n",
      "\n",
      "Start Tensorboard with \"tensorboard --logdir=runs\", view at http://localhost:6006/\n",
      "WARNING: smart bias initialization failure.\n",
      "WARNING: smart bias initialization failure.\n",
      "WARNING: smart bias initialization failure.\n",
      "Model Summary: 225 layers, 6.25733e+07 parameters, 6.25733e+07 gradients\n",
      "Optimizer groups: 76 .bias, 76 Conv2d.weight, 73 other\n",
      "weights/last.pt has been trained for 848 epochs. Fine-tuning for 15 additional epochs.\n",
      "Image sizes 320 - 640 train, 640 test\n",
      "Using 3 dataloader workers\n",
      "Starting training for 863 epochs...\n",
      "\n",
      "     Epoch   gpu_mem      GIoU       obj       cls     total   targets  img_size\n",
      "Apex recommended for faster mixed precision training: https://github.com/NVIDIA/apex\n",
      "Apex recommended for faster mixed precision training: https://github.com/NVIDIA/apex\n",
      "Apex recommended for faster mixed precision training: https://github.com/NVIDIA/apex\n",
      "Apex recommended for faster mixed precision training: https://github.com/NVIDIA/apex\n",
      "Apex recommended for faster mixed precision training: https://github.com/NVIDIA/apex\n",
      "Apex recommended for faster mixed precision training: https://github.com/NVIDIA/apex\n",
      "                 all        11        33     0.845     0.818     0.844     0.831\n",
      "\n",
      "     Epoch   gpu_mem      GIoU       obj       cls     total   targets  img_size\n",
      "Apex recommended for faster mixed precision training: https://github.com/NVIDIA/apex\n",
      "Apex recommended for faster mixed precision training: https://github.com/NVIDIA/apex\n",
      "Apex recommended for faster mixed precision training: https://github.com/NVIDIA/apex\n",
      "Apex recommended for faster mixed precision training: https://github.com/NVIDIA/apex\n",
      "Apex recommended for faster mixed precision training: https://github.com/NVIDIA/apex\n",
      "Apex recommended for faster mixed precision training: https://github.com/NVIDIA/apex\n",
      "                 all        11        33     0.845     0.818     0.844     0.831\n",
      "\n",
      "     Epoch   gpu_mem      GIoU       obj       cls     total   targets  img_size\n",
      "Apex recommended for faster mixed precision training: https://github.com/NVIDIA/apex\n",
      "Apex recommended for faster mixed precision training: https://github.com/NVIDIA/apex\n",
      "Apex recommended for faster mixed precision training: https://github.com/NVIDIA/apex\n",
      "Apex recommended for faster mixed precision training: https://github.com/NVIDIA/apex\n",
      "Apex recommended for faster mixed precision training: https://github.com/NVIDIA/apex\n",
      "Apex recommended for faster mixed precision training: https://github.com/NVIDIA/apex\n",
      "                 all        11        33     0.845     0.818     0.845     0.831\n",
      "\n",
      "     Epoch   gpu_mem      GIoU       obj       cls     total   targets  img_size\n",
      "Apex recommended for faster mixed precision training: https://github.com/NVIDIA/apex\n",
      "Apex recommended for faster mixed precision training: https://github.com/NVIDIA/apex\n",
      "Apex recommended for faster mixed precision training: https://github.com/NVIDIA/apex\n",
      "Apex recommended for faster mixed precision training: https://github.com/NVIDIA/apex\n",
      "Apex recommended for faster mixed precision training: https://github.com/NVIDIA/apex\n",
      "Apex recommended for faster mixed precision training: https://github.com/NVIDIA/apex\n",
      "                 all        11        33     0.848     0.818     0.845     0.833\n",
      "\n",
      "     Epoch   gpu_mem      GIoU       obj       cls     total   targets  img_size\n",
      "Apex recommended for faster mixed precision training: https://github.com/NVIDIA/apex\n",
      "Apex recommended for faster mixed precision training: https://github.com/NVIDIA/apex\n",
      "Apex recommended for faster mixed precision training: https://github.com/NVIDIA/apex\n",
      "Apex recommended for faster mixed precision training: https://github.com/NVIDIA/apex\n",
      "Apex recommended for faster mixed precision training: https://github.com/NVIDIA/apex\n",
      "Apex recommended for faster mixed precision training: https://github.com/NVIDIA/apex\n",
      "                 all        11        33     0.848     0.818     0.845     0.833\n",
      "\n",
      "     Epoch   gpu_mem      GIoU       obj       cls     total   targets  img_size\n",
      "Apex recommended for faster mixed precision training: https://github.com/NVIDIA/apex\n",
      "Apex recommended for faster mixed precision training: https://github.com/NVIDIA/apex\n",
      "Apex recommended for faster mixed precision training: https://github.com/NVIDIA/apex\n",
      "Apex recommended for faster mixed precision training: https://github.com/NVIDIA/apex\n",
      "Apex recommended for faster mixed precision training: https://github.com/NVIDIA/apex\n",
      "Apex recommended for faster mixed precision training: https://github.com/NVIDIA/apex\n",
      "                 all        11        33     0.859     0.738     0.808     0.794\n",
      "\n",
      "     Epoch   gpu_mem      GIoU       obj       cls     total   targets  img_size\n",
      "Apex recommended for faster mixed precision training: https://github.com/NVIDIA/apex\n",
      "Apex recommended for faster mixed precision training: https://github.com/NVIDIA/apex\n",
      "Apex recommended for faster mixed precision training: https://github.com/NVIDIA/apex\n",
      "Apex recommended for faster mixed precision training: https://github.com/NVIDIA/apex\n",
      "Apex recommended for faster mixed precision training: https://github.com/NVIDIA/apex\n",
      "Apex recommended for faster mixed precision training: https://github.com/NVIDIA/apex\n",
      "                 all        11        33     0.859     0.738     0.808     0.794\n",
      "\n",
      "     Epoch   gpu_mem      GIoU       obj       cls     total   targets  img_size\n",
      "Apex recommended for faster mixed precision training: https://github.com/NVIDIA/apex\n",
      "Apex recommended for faster mixed precision training: https://github.com/NVIDIA/apex\n",
      "Apex recommended for faster mixed precision training: https://github.com/NVIDIA/apex\n",
      "Apex recommended for faster mixed precision training: https://github.com/NVIDIA/apex\n",
      "Apex recommended for faster mixed precision training: https://github.com/NVIDIA/apex\n",
      "Apex recommended for faster mixed precision training: https://github.com/NVIDIA/apex\n",
      "                 all        11        33     0.827     0.725     0.747     0.773\n",
      "\n",
      "     Epoch   gpu_mem      GIoU       obj       cls     total   targets  img_size\n",
      "Apex recommended for faster mixed precision training: https://github.com/NVIDIA/apex\n",
      "Apex recommended for faster mixed precision training: https://github.com/NVIDIA/apex\n",
      "Apex recommended for faster mixed precision training: https://github.com/NVIDIA/apex\n",
      "Apex recommended for faster mixed precision training: https://github.com/NVIDIA/apex\n",
      "Apex recommended for faster mixed precision training: https://github.com/NVIDIA/apex\n",
      "Apex recommended for faster mixed precision training: https://github.com/NVIDIA/apex\n",
      "                 all        11        33     0.868     0.848     0.873     0.858\n",
      "\n",
      "     Epoch   gpu_mem      GIoU       obj       cls     total   targets  img_size\n",
      "Apex recommended for faster mixed precision training: https://github.com/NVIDIA/apex\n",
      "Apex recommended for faster mixed precision training: https://github.com/NVIDIA/apex\n",
      "Apex recommended for faster mixed precision training: https://github.com/NVIDIA/apex\n",
      "Apex recommended for faster mixed precision training: https://github.com/NVIDIA/apex\n",
      "Apex recommended for faster mixed precision training: https://github.com/NVIDIA/apex\n",
      "Apex recommended for faster mixed precision training: https://github.com/NVIDIA/apex\n",
      "                 all        11        33     0.868     0.848     0.873     0.858\n",
      "\n",
      "     Epoch   gpu_mem      GIoU       obj       cls     total   targets  img_size\n",
      "Apex recommended for faster mixed precision training: https://github.com/NVIDIA/apex\n",
      "Apex recommended for faster mixed precision training: https://github.com/NVIDIA/apex\n",
      "Apex recommended for faster mixed precision training: https://github.com/NVIDIA/apex\n",
      "Apex recommended for faster mixed precision training: https://github.com/NVIDIA/apex\n",
      "Apex recommended for faster mixed precision training: https://github.com/NVIDIA/apex\n",
      "Apex recommended for faster mixed precision training: https://github.com/NVIDIA/apex\n",
      "                 all        11        33     0.863     0.848     0.872     0.855\n",
      "\n",
      "     Epoch   gpu_mem      GIoU       obj       cls     total   targets  img_size\n",
      "Apex recommended for faster mixed precision training: https://github.com/NVIDIA/apex\n",
      "Apex recommended for faster mixed precision training: https://github.com/NVIDIA/apex\n",
      "Apex recommended for faster mixed precision training: https://github.com/NVIDIA/apex\n",
      "Apex recommended for faster mixed precision training: https://github.com/NVIDIA/apex\n",
      "Apex recommended for faster mixed precision training: https://github.com/NVIDIA/apex\n",
      "Apex recommended for faster mixed precision training: https://github.com/NVIDIA/apex\n",
      "                 all        11        33     0.863     0.848     0.872     0.855\n",
      "\n",
      "     Epoch   gpu_mem      GIoU       obj       cls     total   targets  img_size\n",
      "Apex recommended for faster mixed precision training: https://github.com/NVIDIA/apex\n",
      "Apex recommended for faster mixed precision training: https://github.com/NVIDIA/apex\n",
      "Apex recommended for faster mixed precision training: https://github.com/NVIDIA/apex\n",
      "Apex recommended for faster mixed precision training: https://github.com/NVIDIA/apex\n",
      "Apex recommended for faster mixed precision training: https://github.com/NVIDIA/apex\n",
      "Apex recommended for faster mixed precision training: https://github.com/NVIDIA/apex\n",
      "                 all        11        33     0.894     0.879     0.898     0.886\n",
      "\n",
      "     Epoch   gpu_mem      GIoU       obj       cls     total   targets  img_size\n",
      "Apex recommended for faster mixed precision training: https://github.com/NVIDIA/apex\n",
      "Apex recommended for faster mixed precision training: https://github.com/NVIDIA/apex\n",
      "Apex recommended for faster mixed precision training: https://github.com/NVIDIA/apex\n",
      "Apex recommended for faster mixed precision training: https://github.com/NVIDIA/apex\n",
      "Apex recommended for faster mixed precision training: https://github.com/NVIDIA/apex\n",
      "Apex recommended for faster mixed precision training: https://github.com/NVIDIA/apex\n",
      "                 all        11        33     0.841     0.818     0.809      0.83\n",
      "14 epochs completed in 0.413 hours.\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-03-05 09:55:27.594686: I tensorflow/core/util/port.cc:113] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
      "WARNING:tensorflow:From C:\\Users\\mit017\\anaconda3\\Lib\\site-packages\\keras\\src\\losses.py:2976: The name tf.losses.sparse_softmax_cross_entropy is deprecated. Please use tf.compat.v1.losses.sparse_softmax_cross_entropy instead.\n",
      "\n",
      "\n",
      "Reading image shapes:   0%|          | 0/39 [00:00<?, ?it/s]\n",
      "Reading image shapes: 100%|##########| 39/39 [00:00<00:00, 1499.31it/s]\n",
      "\n",
      "  0%|          | 0/39 [00:00<?, ?it/s]\n",
      "Caching labels C:\\Users\\mit017\\Desktop\\myproject\\XRAY_PROJECT\\XrayInspection\\dataset\\test1\\yolov3\\train.txt (39 found, 0 missing, 0 empty, 0 duplicate, for 39 images): 100%|##########| 39/39 [00:00<00:00, 2051.16it/s]\n",
      "\n",
      "Reading image shapes:   0%|          | 0/11 [00:00<?, ?it/s]\n",
      "Reading image shapes: 100%|##########| 11/11 [00:00<00:00, 2748.23it/s]\n",
      "\n",
      "  0%|          | 0/11 [00:00<?, ?it/s]\n",
      "Caching labels C:\\Users\\mit017\\Desktop\\myproject\\XRAY_PROJECT\\XrayInspection\\dataset\\test1\\yolov3\\test.txt (11 found, 0 missing, 0 empty, 0 duplicate, for 11 images): 100%|##########| 11/11 [00:00<00:00, 2437.65it/s]\n",
      "2024-03-05 09:55:39.968893: I tensorflow/core/util/port.cc:113] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
      "WARNING:tensorflow:From C:\\Users\\mit017\\anaconda3\\Lib\\site-packages\\keras\\src\\losses.py:2976: The name tf.losses.sparse_softmax_cross_entropy is deprecated. Please use tf.compat.v1.losses.sparse_softmax_cross_entropy instead.\n",
      "\n",
      "2024-03-05 09:55:50.363005: I tensorflow/core/util/port.cc:113] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
      "WARNING:tensorflow:From C:\\Users\\mit017\\anaconda3\\Lib\\site-packages\\keras\\src\\losses.py:2976: The name tf.losses.sparse_softmax_cross_entropy is deprecated. Please use tf.compat.v1.losses.sparse_softmax_cross_entropy instead.\n",
      "\n",
      "2024-03-05 09:56:00.452542: I tensorflow/core/util/port.cc:113] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
      "WARNING:tensorflow:From C:\\Users\\mit017\\anaconda3\\Lib\\site-packages\\keras\\src\\losses.py:2976: The name tf.losses.sparse_softmax_cross_entropy is deprecated. Please use tf.compat.v1.losses.sparse_softmax_cross_entropy instead.\n",
      "\n",
      "\n",
      "  0%|          | 0/13 [00:00<?, ?it/s]\n",
      "   849/862        0G      3.64    0.0888         0      3.73         9       640:   0%|          | 0/13 [00:06<?, ?it/s]\n",
      "   849/862        0G      3.64    0.0888         0      3.73         9       640:   8%|7         | 1/13 [00:06<01:23,  6.93s/it]\n",
      "   849/862        0G      3.18    0.0925         0      3.27        11       640:   8%|7         | 1/13 [00:13<01:23,  6.93s/it]\n",
      "   849/862        0G      3.18    0.0925         0      3.27        11       640:  15%|#5        | 2/13 [00:13<01:14,  6.80s/it]\n",
      "   849/862        0G      2.55    0.0856         0      2.64        10       640:  15%|#5        | 2/13 [00:20<01:14,  6.80s/it]\n",
      "   849/862        0G      2.55    0.0856         0      2.64        10       640:  23%|##3       | 3/13 [00:20<01:08,  6.89s/it]\n",
      "   849/862        0G      2.65    0.0917         0      2.74         9       640:  23%|##3       | 3/13 [00:27<01:08,  6.89s/it]\n",
      "   849/862        0G      2.65    0.0917         0      2.74         9       640:  31%|###       | 4/13 [00:27<01:01,  6.83s/it]\n",
      "   849/862        0G      2.71    0.0894         0       2.8         8       640:  31%|###       | 4/13 [00:34<01:01,  6.83s/it]\n",
      "   849/862        0G      2.71    0.0894         0       2.8         8       640:  38%|###8      | 5/13 [00:34<00:54,  6.79s/it]\n",
      "   849/862        0G      2.44    0.0842         0      2.52         8       640:  38%|###8      | 5/13 [00:40<00:54,  6.79s/it]\n",
      "   849/862        0G      2.44    0.0842         0      2.52         8       640:  46%|####6     | 6/13 [00:40<00:47,  6.77s/it]\n",
      "   849/862        0G      2.29    0.0817         0      2.37         9       640:  46%|####6     | 6/13 [00:47<00:47,  6.77s/it]\n",
      "   849/862        0G      2.29    0.0817         0      2.37         9       640:  54%|#####3    | 7/13 [00:47<00:40,  6.74s/it]\n",
      "   849/862        0G      2.41    0.0832         0      2.49         9       640:  54%|#####3    | 7/13 [00:54<00:40,  6.74s/it]\n",
      "   849/862        0G      2.41    0.0832         0      2.49         9       640:  62%|######1   | 8/13 [00:54<00:33,  6.68s/it]\n",
      "   849/862        0G      2.52    0.0841         0       2.6         9       640:  62%|######1   | 8/13 [01:00<00:33,  6.68s/it]\n",
      "   849/862        0G      2.52    0.0841         0       2.6         9       640:  69%|######9   | 9/13 [01:00<00:26,  6.65s/it]\n",
      "   849/862        0G      2.39    0.0863         0      2.48        12       512:  69%|######9   | 9/13 [01:05<00:26,  6.65s/it]\n",
      "   849/862        0G      2.39    0.0863         0      2.48        12       512:  77%|#######6  | 10/13 [01:05<00:18,  6.09s/it]\n",
      "   849/862        0G      2.27    0.0862         0      2.36         9       512:  77%|#######6  | 10/13 [01:09<00:18,  6.09s/it]\n",
      "   849/862        0G      2.27    0.0862         0      2.36         9       512:  85%|########4 | 11/13 [01:09<00:10,  5.48s/it]\n",
      "   849/862        0G      2.35    0.0875         0      2.44         9       512:  85%|########4 | 11/13 [01:13<00:10,  5.48s/it]\n",
      "   849/862        0G      2.35    0.0875         0      2.44         9       512:  92%|#########2| 12/13 [01:13<00:05,  5.09s/it]\n",
      "   849/862        0G      2.27    0.0856         0      2.36         9       512:  92%|#########2| 12/13 [01:17<00:05,  5.09s/it]\n",
      "   849/862        0G      2.27    0.0856         0      2.36         9       512: 100%|##########| 13/13 [01:17<00:00,  4.82s/it]\n",
      "   849/862        0G      2.27    0.0856         0      2.36         9       512: 100%|##########| 13/13 [01:18<00:00,  6.07s/it]\n",
      "\n",
      "               Class    Images   Targets         P         R   mAP@0.5        F1:   0%|          | 0/4 [00:00<?, ?it/s]2024-03-05 09:57:29.681843: I tensorflow/core/util/port.cc:113] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
      "2024-03-05 09:57:29.737427: I tensorflow/core/util/port.cc:113] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
      "2024-03-05 09:57:29.826048: I tensorflow/core/util/port.cc:113] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
      "WARNING:tensorflow:From C:\\Users\\mit017\\anaconda3\\Lib\\site-packages\\keras\\src\\losses.py:2976: The name tf.losses.sparse_softmax_cross_entropy is deprecated. Please use tf.compat.v1.losses.sparse_softmax_cross_entropy instead.\n",
      "\n",
      "WARNING:tensorflow:From C:\\Users\\mit017\\anaconda3\\Lib\\site-packages\\keras\\src\\losses.py:2976: The name tf.losses.sparse_softmax_cross_entropy is deprecated. Please use tf.compat.v1.losses.sparse_softmax_cross_entropy instead.\n",
      "\n",
      "WARNING:tensorflow:From C:\\Users\\mit017\\anaconda3\\Lib\\site-packages\\keras\\src\\losses.py:2976: The name tf.losses.sparse_softmax_cross_entropy is deprecated. Please use tf.compat.v1.losses.sparse_softmax_cross_entropy instead.\n",
      "\n",
      "C:\\Users\\mit017\\anaconda3\\Lib\\site-packages\\torch\\functional.py:507: UserWarning: torch.meshgrid: in an upcoming release, it will be required to pass the indexing argument. (Triggered internally at ..\\aten\\src\\ATen\\native\\TensorShape.cpp:3550.)\n",
      "  return _VF.meshgrid(tensors, **kwargs)  # type: ignore[attr-defined]\n",
      "\n",
      "               Class    Images   Targets         P         R   mAP@0.5        F1:  25%|##5       | 1/4 [00:13<00:39, 13.29s/it]\n",
      "               Class    Images   Targets         P         R   mAP@0.5        F1:  50%|#####     | 2/4 [00:15<00:13,  6.67s/it]\n",
      "               Class    Images   Targets         P         R   mAP@0.5        F1:  75%|#######5  | 3/4 [00:17<00:04,  4.55s/it]\n",
      "               Class    Images   Targets         P         R   mAP@0.5        F1: 100%|##########| 4/4 [00:18<00:00,  3.30s/it]\n",
      "               Class    Images   Targets         P         R   mAP@0.5        F1: 100%|##########| 4/4 [00:19<00:00,  4.92s/it]\n",
      "2024-03-05 09:57:49.245229: I tensorflow/core/util/port.cc:113] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
      "WARNING:tensorflow:From C:\\Users\\mit017\\anaconda3\\Lib\\site-packages\\keras\\src\\losses.py:2976: The name tf.losses.sparse_softmax_cross_entropy is deprecated. Please use tf.compat.v1.losses.sparse_softmax_cross_entropy instead.\n",
      "\n",
      "2024-03-05 09:57:59.309610: I tensorflow/core/util/port.cc:113] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
      "WARNING:tensorflow:From C:\\Users\\mit017\\anaconda3\\Lib\\site-packages\\keras\\src\\losses.py:2976: The name tf.losses.sparse_softmax_cross_entropy is deprecated. Please use tf.compat.v1.losses.sparse_softmax_cross_entropy instead.\n",
      "\n",
      "2024-03-05 09:58:09.448023: I tensorflow/core/util/port.cc:113] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
      "WARNING:tensorflow:From C:\\Users\\mit017\\anaconda3\\Lib\\site-packages\\keras\\src\\losses.py:2976: The name tf.losses.sparse_softmax_cross_entropy is deprecated. Please use tf.compat.v1.losses.sparse_softmax_cross_entropy instead.\n",
      "\n",
      "\n",
      "  0%|          | 0/13 [00:00<?, ?it/s]\n",
      "   850/862        0G      1.13    0.0697         0       1.2        10       512:   0%|          | 0/13 [00:04<?, ?it/s]\n",
      "   850/862        0G      1.13    0.0697         0       1.2        10       512:   8%|7         | 1/13 [00:04<00:52,  4.38s/it]\n",
      "   850/862        0G      1.21    0.0819         0      1.29        12       512:   8%|7         | 1/13 [00:08<00:52,  4.38s/it]\n",
      "   850/862        0G      1.21    0.0819         0      1.29        12       512:  15%|#5        | 2/13 [00:08<00:47,  4.28s/it]\n",
      "   850/862        0G      1.18     0.094         0      1.27        14       512:  15%|#5        | 2/13 [00:12<00:47,  4.28s/it]\n",
      "   850/862        0G      1.18     0.094         0      1.27        14       512:  23%|##3       | 3/13 [00:12<00:42,  4.22s/it]\n",
      "   850/862        0G       1.2    0.0911         0      1.29        10       512:  23%|##3       | 3/13 [00:16<00:42,  4.22s/it]\n",
      "   850/862        0G       1.2    0.0911         0      1.29        10       512:  31%|###       | 4/13 [00:16<00:37,  4.18s/it]\n",
      "   850/862        0G       1.2    0.0879         0      1.29         9       512:  31%|###       | 4/13 [00:21<00:37,  4.18s/it]\n",
      "   850/862        0G       1.2    0.0879         0      1.29         9       512:  38%|###8      | 5/13 [00:21<00:33,  4.21s/it]\n",
      "   850/862        0G      1.13    0.0869         0      1.22         9       512:  38%|###8      | 5/13 [00:25<00:33,  4.21s/it]\n",
      "   850/862        0G      1.13    0.0869         0      1.22         9       512:  46%|####6     | 6/13 [00:25<00:29,  4.20s/it]\n",
      "   850/862        0G      1.15    0.0854         0      1.24         9       512:  46%|####6     | 6/13 [00:29<00:29,  4.20s/it]\n",
      "   850/862        0G      1.15    0.0854         0      1.24         9       512:  54%|#####3    | 7/13 [00:29<00:25,  4.20s/it]\n",
      "   850/862        0G      1.14    0.0888         0      1.23        12       512:  54%|#####3    | 7/13 [00:33<00:25,  4.20s/it]\n",
      "   850/862        0G      1.14    0.0888         0      1.23        12       512:  62%|######1   | 8/13 [00:33<00:20,  4.18s/it]\n",
      "   850/862        0G      1.11    0.0906         0       1.2         9       512:  62%|######1   | 8/13 [00:37<00:20,  4.18s/it]\n",
      "   850/862        0G      1.11    0.0906         0       1.2         9       512:  69%|######9   | 9/13 [00:37<00:16,  4.19s/it]\n",
      "   850/862        0G      1.34    0.0904         0      1.44         9       512:  69%|######9   | 9/13 [00:42<00:16,  4.19s/it]\n",
      "   850/862        0G      1.34    0.0904         0      1.44         9       512:  77%|#######6  | 10/13 [00:42<00:12,  4.19s/it]\n",
      "   850/862        0G      1.33    0.0909         0      1.42        12       512:  77%|#######6  | 10/13 [00:46<00:12,  4.19s/it]\n",
      "   850/862        0G      1.33    0.0909         0      1.42        12       512:  85%|########4 | 11/13 [00:46<00:08,  4.18s/it]\n",
      "   850/862        0G      1.31    0.0907         0       1.4        10       512:  85%|########4 | 11/13 [00:50<00:08,  4.18s/it]\n",
      "   850/862        0G      1.31    0.0907         0       1.4        10       512:  92%|#########2| 12/13 [00:50<00:04,  4.17s/it]\n",
      "   850/862        0G      1.29    0.0901         0      1.38         9       512:  92%|#########2| 12/13 [00:54<00:04,  4.17s/it]\n",
      "   850/862        0G      1.29    0.0901         0      1.38         9       512: 100%|##########| 13/13 [00:54<00:00,  4.19s/it]\n",
      "   850/862        0G      1.29    0.0901         0      1.38         9       512: 100%|##########| 13/13 [00:55<00:00,  4.27s/it]\n",
      "\n",
      "               Class    Images   Targets         P         R   mAP@0.5        F1:   0%|          | 0/4 [00:00<?, ?it/s]2024-03-05 09:59:15.246120: I tensorflow/core/util/port.cc:113] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
      "2024-03-05 09:59:15.317830: I tensorflow/core/util/port.cc:113] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
      "2024-03-05 09:59:15.407621: I tensorflow/core/util/port.cc:113] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
      "WARNING:tensorflow:From C:\\Users\\mit017\\anaconda3\\Lib\\site-packages\\keras\\src\\losses.py:2976: The name tf.losses.sparse_softmax_cross_entropy is deprecated. Please use tf.compat.v1.losses.sparse_softmax_cross_entropy instead.\n",
      "\n",
      "WARNING:tensorflow:From C:\\Users\\mit017\\anaconda3\\Lib\\site-packages\\keras\\src\\losses.py:2976: The name tf.losses.sparse_softmax_cross_entropy is deprecated. Please use tf.compat.v1.losses.sparse_softmax_cross_entropy instead.\n",
      "\n",
      "WARNING:tensorflow:From C:\\Users\\mit017\\anaconda3\\Lib\\site-packages\\keras\\src\\losses.py:2976: The name tf.losses.sparse_softmax_cross_entropy is deprecated. Please use tf.compat.v1.losses.sparse_softmax_cross_entropy instead.\n",
      "\n",
      "\n",
      "               Class    Images   Targets         P         R   mAP@0.5        F1:  25%|##5       | 1/4 [00:13<00:39, 13.12s/it]\n",
      "               Class    Images   Targets         P         R   mAP@0.5        F1:  50%|#####     | 2/4 [00:15<00:13,  6.57s/it]\n",
      "               Class    Images   Targets         P         R   mAP@0.5        F1:  75%|#######5  | 3/4 [00:17<00:04,  4.50s/it]\n",
      "               Class    Images   Targets         P         R   mAP@0.5        F1: 100%|##########| 4/4 [00:18<00:00,  3.25s/it]\n",
      "               Class    Images   Targets         P         R   mAP@0.5        F1: 100%|##########| 4/4 [00:19<00:00,  4.85s/it]\n",
      "2024-03-05 09:59:34.562086: I tensorflow/core/util/port.cc:113] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
      "WARNING:tensorflow:From C:\\Users\\mit017\\anaconda3\\Lib\\site-packages\\keras\\src\\losses.py:2976: The name tf.losses.sparse_softmax_cross_entropy is deprecated. Please use tf.compat.v1.losses.sparse_softmax_cross_entropy instead.\n",
      "\n",
      "2024-03-05 09:59:44.644869: I tensorflow/core/util/port.cc:113] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
      "WARNING:tensorflow:From C:\\Users\\mit017\\anaconda3\\Lib\\site-packages\\keras\\src\\losses.py:2976: The name tf.losses.sparse_softmax_cross_entropy is deprecated. Please use tf.compat.v1.losses.sparse_softmax_cross_entropy instead.\n",
      "\n",
      "2024-03-05 09:59:54.735235: I tensorflow/core/util/port.cc:113] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
      "WARNING:tensorflow:From C:\\Users\\mit017\\anaconda3\\Lib\\site-packages\\keras\\src\\losses.py:2976: The name tf.losses.sparse_softmax_cross_entropy is deprecated. Please use tf.compat.v1.losses.sparse_softmax_cross_entropy instead.\n",
      "\n",
      "\n",
      "  0%|          | 0/13 [00:00<?, ?it/s]\n",
      "   851/862        0G     0.986    0.0665         0      1.05         9       512:   0%|          | 0/13 [00:04<?, ?it/s]\n",
      "   851/862        0G     0.986    0.0665         0      1.05         9       512:   8%|7         | 1/13 [00:04<00:53,  4.44s/it]\n",
      "   851/862        0G      1.05    0.0836         0      1.13         9       512:   8%|7         | 1/13 [00:08<00:53,  4.44s/it]\n",
      "   851/862        0G      1.05    0.0836         0      1.13         9       512:  15%|#5        | 2/13 [00:08<00:47,  4.31s/it]\n",
      "   851/862        0G      1.14    0.0837         0      1.23         9       512:  15%|#5        | 2/13 [00:12<00:47,  4.31s/it]\n",
      "   851/862        0G      1.14    0.0837         0      1.23         9       512:  23%|##3       | 3/13 [00:12<00:42,  4.29s/it]\n",
      "   851/862        0G      1.09    0.0818         0      1.17         9       512:  23%|##3       | 3/13 [00:17<00:42,  4.29s/it]\n",
      "   851/862        0G      1.09    0.0818         0      1.17         9       512:  31%|###       | 4/13 [00:17<00:38,  4.25s/it]\n",
      "   851/862        0G      1.08    0.0783         0      1.16         9       512:  31%|###       | 4/13 [00:21<00:38,  4.25s/it]\n",
      "   851/862        0G      1.08    0.0783         0      1.16         9       512:  38%|###8      | 5/13 [00:21<00:34,  4.32s/it]\n",
      "   851/862        0G       1.1     0.077         0      1.18         9       512:  38%|###8      | 5/13 [00:25<00:34,  4.32s/it]\n",
      "   851/862        0G       1.1     0.077         0      1.18         9       512:  46%|####6     | 6/13 [00:25<00:29,  4.26s/it]\n",
      "   851/862        0G       1.1     0.081         0      1.18        13       512:  46%|####6     | 6/13 [00:29<00:29,  4.26s/it]\n",
      "   851/862        0G       1.1     0.081         0      1.18        13       512:  54%|#####3    | 7/13 [00:29<00:25,  4.25s/it]\n",
      "   851/862        0G      1.09    0.0795         0      1.16         9       512:  54%|#####3    | 7/13 [00:34<00:25,  4.25s/it]\n",
      "   851/862        0G      1.09    0.0795         0      1.16         9       512:  62%|######1   | 8/13 [00:34<00:21,  4.23s/it]\n",
      "   851/862        0G      1.11    0.0804         0      1.19         9       512:  62%|######1   | 8/13 [00:38<00:21,  4.23s/it]\n",
      "   851/862        0G      1.11    0.0804         0      1.19         9       512:  69%|######9   | 9/13 [00:38<00:16,  4.22s/it]\n",
      "   851/862        0G       1.1    0.0801         0      1.18         9       512:  69%|######9   | 9/13 [00:42<00:16,  4.22s/it]\n",
      "   851/862        0G       1.1    0.0801         0      1.18         9       512:  77%|#######6  | 10/13 [00:42<00:12,  4.21s/it]\n",
      "   851/862        0G      1.12    0.0793         0       1.2         9       512:  77%|#######6  | 10/13 [00:46<00:12,  4.21s/it]\n",
      "   851/862        0G      1.12    0.0793         0       1.2         9       512:  85%|########4 | 11/13 [00:46<00:08,  4.20s/it]\n",
      "   851/862        0G      1.11    0.0803         0      1.19        11       512:  85%|########4 | 11/13 [00:50<00:08,  4.20s/it]\n",
      "   851/862        0G      1.11    0.0803         0      1.19        11       512:  92%|#########2| 12/13 [00:50<00:04,  4.21s/it]\n",
      "   851/862        0G      1.13    0.0808         0      1.21        10       512:  92%|#########2| 12/13 [00:55<00:04,  4.21s/it]\n",
      "   851/862        0G      1.13    0.0808         0      1.21        10       512: 100%|##########| 13/13 [00:55<00:00,  4.21s/it]\n",
      "   851/862        0G      1.13    0.0808         0      1.21        10       512: 100%|##########| 13/13 [00:56<00:00,  4.31s/it]\n",
      "\n",
      "               Class    Images   Targets         P         R   mAP@0.5        F1:   0%|          | 0/4 [00:00<?, ?it/s]2024-03-05 10:01:01.118037: I tensorflow/core/util/port.cc:113] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
      "2024-03-05 10:01:01.162917: I tensorflow/core/util/port.cc:113] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
      "2024-03-05 10:01:01.243770: I tensorflow/core/util/port.cc:113] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
      "WARNING:tensorflow:From C:\\Users\\mit017\\anaconda3\\Lib\\site-packages\\keras\\src\\losses.py:2976: The name tf.losses.sparse_softmax_cross_entropy is deprecated. Please use tf.compat.v1.losses.sparse_softmax_cross_entropy instead.\n",
      "\n",
      "WARNING:tensorflow:From C:\\Users\\mit017\\anaconda3\\Lib\\site-packages\\keras\\src\\losses.py:2976: The name tf.losses.sparse_softmax_cross_entropy is deprecated. Please use tf.compat.v1.losses.sparse_softmax_cross_entropy instead.\n",
      "\n",
      "WARNING:tensorflow:From C:\\Users\\mit017\\anaconda3\\Lib\\site-packages\\keras\\src\\losses.py:2976: The name tf.losses.sparse_softmax_cross_entropy is deprecated. Please use tf.compat.v1.losses.sparse_softmax_cross_entropy instead.\n",
      "\n",
      "\n",
      "               Class    Images   Targets         P         R   mAP@0.5        F1:  25%|##5       | 1/4 [00:13<00:39, 13.25s/it]\n",
      "               Class    Images   Targets         P         R   mAP@0.5        F1:  50%|#####     | 2/4 [00:15<00:13,  6.67s/it]\n",
      "               Class    Images   Targets         P         R   mAP@0.5        F1:  75%|#######5  | 3/4 [00:17<00:04,  4.58s/it]\n",
      "               Class    Images   Targets         P         R   mAP@0.5        F1: 100%|##########| 4/4 [00:18<00:00,  3.31s/it]\n",
      "               Class    Images   Targets         P         R   mAP@0.5        F1: 100%|##########| 4/4 [00:19<00:00,  4.93s/it]\n",
      "2024-03-05 10:01:20.697450: I tensorflow/core/util/port.cc:113] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
      "WARNING:tensorflow:From C:\\Users\\mit017\\anaconda3\\Lib\\site-packages\\keras\\src\\losses.py:2976: The name tf.losses.sparse_softmax_cross_entropy is deprecated. Please use tf.compat.v1.losses.sparse_softmax_cross_entropy instead.\n",
      "\n",
      "2024-03-05 10:01:30.806277: I tensorflow/core/util/port.cc:113] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
      "WARNING:tensorflow:From C:\\Users\\mit017\\anaconda3\\Lib\\site-packages\\keras\\src\\losses.py:2976: The name tf.losses.sparse_softmax_cross_entropy is deprecated. Please use tf.compat.v1.losses.sparse_softmax_cross_entropy instead.\n",
      "\n",
      "2024-03-05 10:01:40.972278: I tensorflow/core/util/port.cc:113] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
      "WARNING:tensorflow:From C:\\Users\\mit017\\anaconda3\\Lib\\site-packages\\keras\\src\\losses.py:2976: The name tf.losses.sparse_softmax_cross_entropy is deprecated. Please use tf.compat.v1.losses.sparse_softmax_cross_entropy instead.\n",
      "\n",
      "\n",
      "  0%|          | 0/13 [00:00<?, ?it/s]\n",
      "   852/862        0G      1.11    0.0869         0       1.2         9       512:   0%|          | 0/13 [00:04<?, ?it/s]\n",
      "   852/862        0G      1.11    0.0869         0       1.2         9       512:   8%|7         | 1/13 [00:04<00:52,  4.35s/it]\n",
      "   852/862        0G      1.07    0.0852         0      1.16         9       512:   8%|7         | 1/13 [00:08<00:52,  4.35s/it]\n",
      "   852/862        0G      1.07    0.0852         0      1.16         9       512:  15%|#5        | 2/13 [00:08<00:46,  4.25s/it]\n",
      "   852/862        0G      1.11    0.0802         0      1.19         9       512:  15%|#5        | 2/13 [00:12<00:46,  4.25s/it]\n",
      "   852/862        0G      1.11    0.0802         0      1.19         9       512:  23%|##3       | 3/13 [00:12<00:42,  4.23s/it]\n",
      "   852/862        0G      1.07    0.0809         0      1.16        10       512:  23%|##3       | 3/13 [00:16<00:42,  4.23s/it]\n",
      "   852/862        0G      1.07    0.0809         0      1.16        10       512:  31%|###       | 4/13 [00:16<00:37,  4.20s/it]\n",
      "   852/862        0G       1.1    0.0773         0      1.18         9       512:  31%|###       | 4/13 [00:21<00:37,  4.20s/it]\n",
      "   852/862        0G       1.1    0.0773         0      1.18         9       512:  38%|###8      | 5/13 [00:21<00:33,  4.17s/it]\n",
      "   852/862        0G      1.14    0.0783         0      1.22         9       512:  38%|###8      | 5/13 [00:25<00:33,  4.17s/it]\n",
      "   852/862        0G      1.14    0.0783         0      1.22         9       512:  46%|####6     | 6/13 [00:25<00:29,  4.16s/it]\n",
      "   852/862        0G      1.13    0.0834         0      1.21        12       512:  46%|####6     | 6/13 [00:29<00:29,  4.16s/it]\n",
      "   852/862        0G      1.13    0.0834         0      1.21        12       512:  54%|#####3    | 7/13 [00:29<00:25,  4.17s/it]\n",
      "   852/862        0G      1.13    0.0839         0      1.21        11       512:  54%|#####3    | 7/13 [00:33<00:25,  4.17s/it]\n",
      "   852/862        0G      1.13    0.0839         0      1.21        11       512:  62%|######1   | 8/13 [00:33<00:20,  4.16s/it]\n",
      "   852/862        0G      1.13    0.0839         0      1.21        12       512:  62%|######1   | 8/13 [00:37<00:20,  4.16s/it]\n",
      "   852/862        0G      1.13    0.0839         0      1.21        12       512:  69%|######9   | 9/13 [00:37<00:16,  4.17s/it]\n",
      "   852/862        0G      1.12    0.0886         0      1.21        13       512:  69%|######9   | 9/13 [00:41<00:16,  4.17s/it]\n",
      "   852/862        0G      1.12    0.0886         0      1.21        13       512:  77%|#######6  | 10/13 [00:41<00:12,  4.15s/it]\n",
      "   852/862        0G      1.13    0.0868         0      1.22         9       512:  77%|#######6  | 10/13 [00:45<00:12,  4.15s/it]\n",
      "   852/862        0G      1.13    0.0868         0      1.22         9       512:  85%|########4 | 11/13 [00:45<00:08,  4.15s/it]\n",
      "   852/862        0G      1.13    0.0857         0      1.21         9       512:  85%|########4 | 11/13 [00:50<00:08,  4.15s/it]\n",
      "   852/862        0G      1.13    0.0857         0      1.21         9       512:  92%|#########2| 12/13 [00:50<00:04,  4.16s/it]\n",
      "   852/862        0G      1.13    0.0857         0      1.21         9       320:  92%|#########2| 12/13 [00:52<00:04,  4.16s/it]\n",
      "   852/862        0G      1.13    0.0857         0      1.21         9       320: 100%|##########| 13/13 [00:52<00:00,  3.51s/it]\n",
      "   852/862        0G      1.13    0.0857         0      1.21         9       320: 100%|##########| 13/13 [00:53<00:00,  4.08s/it]\n",
      "\n",
      "               Class    Images   Targets         P         R   mAP@0.5        F1:   0%|          | 0/4 [00:00<?, ?it/s]2024-03-05 10:02:44.299764: I tensorflow/core/util/port.cc:113] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
      "2024-03-05 10:02:44.413134: I tensorflow/core/util/port.cc:113] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
      "2024-03-05 10:02:44.503400: I tensorflow/core/util/port.cc:113] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
      "WARNING:tensorflow:From C:\\Users\\mit017\\anaconda3\\Lib\\site-packages\\keras\\src\\losses.py:2976: The name tf.losses.sparse_softmax_cross_entropy is deprecated. Please use tf.compat.v1.losses.sparse_softmax_cross_entropy instead.\n",
      "\n",
      "WARNING:tensorflow:From C:\\Users\\mit017\\anaconda3\\Lib\\site-packages\\keras\\src\\losses.py:2976: The name tf.losses.sparse_softmax_cross_entropy is deprecated. Please use tf.compat.v1.losses.sparse_softmax_cross_entropy instead.\n",
      "\n",
      "WARNING:tensorflow:From C:\\Users\\mit017\\anaconda3\\Lib\\site-packages\\keras\\src\\losses.py:2976: The name tf.losses.sparse_softmax_cross_entropy is deprecated. Please use tf.compat.v1.losses.sparse_softmax_cross_entropy instead.\n",
      "\n",
      "\n",
      "               Class    Images   Targets         P         R   mAP@0.5        F1:  25%|##5       | 1/4 [00:13<00:40, 13.62s/it]\n",
      "               Class    Images   Targets         P         R   mAP@0.5        F1:  50%|#####     | 2/4 [00:15<00:13,  6.80s/it]\n",
      "               Class    Images   Targets         P         R   mAP@0.5        F1:  75%|#######5  | 3/4 [00:17<00:04,  4.61s/it]\n",
      "               Class    Images   Targets         P         R   mAP@0.5        F1: 100%|##########| 4/4 [00:19<00:00,  3.33s/it]\n",
      "               Class    Images   Targets         P         R   mAP@0.5        F1: 100%|##########| 4/4 [00:19<00:00,  4.99s/it]\n",
      "2024-03-05 10:03:04.181501: I tensorflow/core/util/port.cc:113] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
      "WARNING:tensorflow:From C:\\Users\\mit017\\anaconda3\\Lib\\site-packages\\keras\\src\\losses.py:2976: The name tf.losses.sparse_softmax_cross_entropy is deprecated. Please use tf.compat.v1.losses.sparse_softmax_cross_entropy instead.\n",
      "\n",
      "2024-03-05 10:03:14.287424: I tensorflow/core/util/port.cc:113] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
      "WARNING:tensorflow:From C:\\Users\\mit017\\anaconda3\\Lib\\site-packages\\keras\\src\\losses.py:2976: The name tf.losses.sparse_softmax_cross_entropy is deprecated. Please use tf.compat.v1.losses.sparse_softmax_cross_entropy instead.\n",
      "\n",
      "2024-03-05 10:03:24.406029: I tensorflow/core/util/port.cc:113] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
      "WARNING:tensorflow:From C:\\Users\\mit017\\anaconda3\\Lib\\site-packages\\keras\\src\\losses.py:2976: The name tf.losses.sparse_softmax_cross_entropy is deprecated. Please use tf.compat.v1.losses.sparse_softmax_cross_entropy instead.\n",
      "\n",
      "\n",
      "  0%|          | 0/13 [00:00<?, ?it/s]\n",
      "   853/862        0G      1.24    0.0825         0      1.32         9       320:   0%|          | 0/13 [00:01<?, ?it/s]\n",
      "   853/862        0G      1.24    0.0825         0      1.32         9       320:   8%|7         | 1/13 [00:01<00:22,  1.87s/it]\n",
      "   853/862        0G      1.22    0.0769         0       1.3         9       320:   8%|7         | 1/13 [00:03<00:22,  1.87s/it]\n",
      "   853/862        0G      1.22    0.0769         0       1.3         9       320:  15%|#5        | 2/13 [00:03<00:19,  1.78s/it]\n",
      "   853/862        0G      1.23    0.0943         0      1.32        13       320:  15%|#5        | 2/13 [00:05<00:19,  1.78s/it]\n",
      "   853/862        0G      1.23    0.0943         0      1.32        13       320:  23%|##3       | 3/13 [00:05<00:17,  1.78s/it]\n",
      "   853/862        0G      1.22     0.112         0      1.34        11       320:  23%|##3       | 3/13 [00:07<00:17,  1.78s/it]\n",
      "   853/862        0G      1.22     0.112         0      1.34        11       320:  31%|###       | 4/13 [00:07<00:15,  1.76s/it]\n",
      "   853/862        0G      1.22     0.107         0      1.33         9       320:  31%|###       | 4/13 [00:08<00:15,  1.76s/it]\n",
      "   853/862        0G      1.22     0.107         0      1.33         9       320:  38%|###8      | 5/13 [00:08<00:14,  1.76s/it]\n",
      "   853/862        0G      1.22     0.107         0      1.32        10       320:  38%|###8      | 5/13 [00:10<00:14,  1.76s/it]\n",
      "   853/862        0G      1.22     0.107         0      1.32        10       320:  46%|####6     | 6/13 [00:10<00:12,  1.76s/it]\n",
      "   853/862        0G      1.22     0.103         0      1.33         9       320:  46%|####6     | 6/13 [00:12<00:12,  1.76s/it]\n",
      "   853/862        0G      1.22     0.103         0      1.33         9       320:  54%|#####3    | 7/13 [00:12<00:10,  1.75s/it]\n",
      "   853/862        0G      1.21     0.103         0      1.32        11       320:  54%|#####3    | 7/13 [00:14<00:10,  1.75s/it]\n",
      "   853/862        0G      1.21     0.103         0      1.32        11       320:  62%|######1   | 8/13 [00:14<00:08,  1.75s/it]\n",
      "   853/862        0G       1.2       0.1         0       1.3        10       320:  62%|######1   | 8/13 [00:15<00:08,  1.75s/it]\n",
      "   853/862        0G       1.2       0.1         0       1.3        10       320:  69%|######9   | 9/13 [00:15<00:07,  1.78s/it]\n",
      "   853/862        0G      1.21     0.104         0      1.31        13       320:  69%|######9   | 9/13 [00:17<00:07,  1.78s/it]\n",
      "   853/862        0G      1.21     0.104         0      1.31        13       320:  77%|#######6  | 10/13 [00:17<00:05,  1.82s/it]\n",
      "   853/862        0G      1.18     0.102         0      1.29         9       320:  77%|#######6  | 10/13 [00:19<00:05,  1.82s/it]\n",
      "   853/862        0G      1.18     0.102         0      1.29         9       320:  85%|########4 | 11/13 [00:19<00:03,  1.82s/it]\n",
      "   853/862        0G      1.18     0.101         0      1.28         9       320:  85%|########4 | 11/13 [00:21<00:03,  1.82s/it]\n",
      "   853/862        0G      1.18     0.101         0      1.28         9       320:  92%|#########2| 12/13 [00:21<00:01,  1.85s/it]\n",
      "   853/862        0G      1.19       0.1         0      1.29        10       320:  92%|#########2| 12/13 [00:23<00:01,  1.85s/it]\n",
      "   853/862        0G      1.19       0.1         0      1.29        10       320: 100%|##########| 13/13 [00:23<00:00,  1.88s/it]\n",
      "   853/862        0G      1.19       0.1         0      1.29        10       320: 100%|##########| 13/13 [00:24<00:00,  1.90s/it]\n",
      "\n",
      "               Class    Images   Targets         P         R   mAP@0.5        F1:   0%|          | 0/4 [00:00<?, ?it/s]2024-03-05 10:03:59.580263: I tensorflow/core/util/port.cc:113] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
      "2024-03-05 10:03:59.662065: I tensorflow/core/util/port.cc:113] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
      "2024-03-05 10:03:59.760064: I tensorflow/core/util/port.cc:113] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
      "WARNING:tensorflow:From C:\\Users\\mit017\\anaconda3\\Lib\\site-packages\\keras\\src\\losses.py:2976: The name tf.losses.sparse_softmax_cross_entropy is deprecated. Please use tf.compat.v1.losses.sparse_softmax_cross_entropy instead.\n",
      "\n",
      "WARNING:tensorflow:From C:\\Users\\mit017\\anaconda3\\Lib\\site-packages\\keras\\src\\losses.py:2976: The name tf.losses.sparse_softmax_cross_entropy is deprecated. Please use tf.compat.v1.losses.sparse_softmax_cross_entropy instead.\n",
      "\n",
      "WARNING:tensorflow:From C:\\Users\\mit017\\anaconda3\\Lib\\site-packages\\keras\\src\\losses.py:2976: The name tf.losses.sparse_softmax_cross_entropy is deprecated. Please use tf.compat.v1.losses.sparse_softmax_cross_entropy instead.\n",
      "\n",
      "\n",
      "               Class    Images   Targets         P         R   mAP@0.5        F1:  25%|##5       | 1/4 [00:14<00:42, 14.32s/it]\n",
      "               Class    Images   Targets         P         R   mAP@0.5        F1:  50%|#####     | 2/4 [00:16<00:14,  7.16s/it]\n",
      "               Class    Images   Targets         P         R   mAP@0.5        F1:  75%|#######5  | 3/4 [00:18<00:04,  4.89s/it]\n",
      "               Class    Images   Targets         P         R   mAP@0.5        F1: 100%|##########| 4/4 [00:20<00:00,  3.56s/it]\n",
      "               Class    Images   Targets         P         R   mAP@0.5        F1: 100%|##########| 4/4 [00:21<00:00,  5.32s/it]\n",
      "2024-03-05 10:04:20.761481: I tensorflow/core/util/port.cc:113] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
      "WARNING:tensorflow:From C:\\Users\\mit017\\anaconda3\\Lib\\site-packages\\keras\\src\\losses.py:2976: The name tf.losses.sparse_softmax_cross_entropy is deprecated. Please use tf.compat.v1.losses.sparse_softmax_cross_entropy instead.\n",
      "\n",
      "2024-03-05 10:04:32.958942: I tensorflow/core/util/port.cc:113] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
      "WARNING:tensorflow:From C:\\Users\\mit017\\anaconda3\\Lib\\site-packages\\keras\\src\\losses.py:2976: The name tf.losses.sparse_softmax_cross_entropy is deprecated. Please use tf.compat.v1.losses.sparse_softmax_cross_entropy instead.\n",
      "\n",
      "2024-03-05 10:04:43.827019: I tensorflow/core/util/port.cc:113] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
      "WARNING:tensorflow:From C:\\Users\\mit017\\anaconda3\\Lib\\site-packages\\keras\\src\\losses.py:2976: The name tf.losses.sparse_softmax_cross_entropy is deprecated. Please use tf.compat.v1.losses.sparse_softmax_cross_entropy instead.\n",
      "\n",
      "\n",
      "  0%|          | 0/13 [00:00<?, ?it/s]\n",
      "   854/862        0G      1.21    0.0788         0      1.29         9       320:   0%|          | 0/13 [00:05<?, ?it/s]\n",
      "   854/862        0G      1.21    0.0788         0      1.29         9       320:   8%|7         | 1/13 [00:05<01:09,  5.83s/it]\n",
      "   854/862        0G      1.15    0.0935         0      1.24         8       320:   8%|7         | 1/13 [00:07<01:09,  5.83s/it]\n",
      "   854/862        0G      1.15    0.0935         0      1.24         8       320:  15%|#5        | 2/13 [00:07<00:38,  3.46s/it]\n",
      "   854/862        0G      1.28    0.0836         0      1.37         9       320:  15%|#5        | 2/13 [00:09<00:38,  3.46s/it]\n",
      "   854/862        0G      1.28    0.0836         0      1.37         9       320:  23%|##3       | 3/13 [00:09<00:26,  2.68s/it]\n",
      "   854/862        0G      1.31    0.0847         0      1.39         9       320:  23%|##3       | 3/13 [00:11<00:26,  2.68s/it]\n",
      "   854/862        0G      1.31    0.0847         0      1.39         9       320:  31%|###       | 4/13 [00:11<00:20,  2.31s/it]\n",
      "   854/862        0G      1.28    0.0858         0      1.36        10       320:  31%|###       | 4/13 [00:12<00:20,  2.31s/it]\n",
      "   854/862        0G      1.28    0.0858         0      1.36        10       320:  38%|###8      | 5/13 [00:12<00:16,  2.10s/it]\n",
      "   854/862        0G      1.24     0.086         0      1.33         9       320:  38%|###8      | 5/13 [00:14<00:16,  2.10s/it]\n",
      "   854/862        0G      1.24     0.086         0      1.33         9       320:  46%|####6     | 6/13 [00:14<00:13,  1.99s/it]\n",
      "   854/862        0G      1.23    0.0856         0      1.31        10       320:  46%|####6     | 6/13 [00:16<00:13,  1.99s/it]\n",
      "   854/862        0G      1.23    0.0856         0      1.31        10       320:  54%|#####3    | 7/13 [00:16<00:11,  1.90s/it]\n",
      "   854/862        0G      1.22    0.0843         0      1.31         9       448:  54%|#####3    | 7/13 [00:19<00:11,  1.90s/it]\n",
      "   854/862        0G      1.22    0.0843         0      1.31         9       448:  62%|######1   | 8/13 [00:19<00:12,  2.42s/it]\n",
      "   854/862        0G      1.21    0.0839         0      1.29         9       448:  62%|######1   | 8/13 [00:23<00:12,  2.42s/it]\n",
      "   854/862        0G      1.21    0.0839         0      1.29         9       448:  69%|######9   | 9/13 [00:23<00:10,  2.67s/it]\n",
      "   854/862        0G      1.21    0.0876         0      1.29         9       448:  69%|######9   | 9/13 [00:26<00:10,  2.67s/it]\n",
      "   854/862        0G      1.21    0.0876         0      1.29         9       448:  77%|#######6  | 10/13 [00:26<00:08,  2.88s/it]\n",
      "   854/862        0G      1.19    0.0868         0      1.28        10       448:  77%|#######6  | 10/13 [00:29<00:08,  2.88s/it]\n",
      "   854/862        0G      1.19    0.0868         0      1.28        10       448:  85%|########4 | 11/13 [00:29<00:06,  3.02s/it]\n",
      "   854/862        0G      1.19    0.0869         0      1.28        10       448:  85%|########4 | 11/13 [00:33<00:06,  3.02s/it]\n",
      "   854/862        0G      1.19    0.0869         0      1.28        10       448:  92%|#########2| 12/13 [00:33<00:03,  3.19s/it]\n",
      "   854/862        0G      1.19    0.0881         0      1.28         9       448:  92%|#########2| 12/13 [00:36<00:03,  3.19s/it]\n",
      "   854/862        0G      1.19    0.0881         0      1.28         9       448: 100%|##########| 13/13 [00:36<00:00,  3.19s/it]\n",
      "   854/862        0G      1.19    0.0881         0      1.28         9       448: 100%|##########| 13/13 [00:37<00:00,  2.89s/it]\n",
      "\n",
      "               Class    Images   Targets         P         R   mAP@0.5        F1:   0%|          | 0/4 [00:00<?, ?it/s]2024-03-05 10:05:32.722040: I tensorflow/core/util/port.cc:113] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
      "2024-03-05 10:05:32.729871: I tensorflow/core/util/port.cc:113] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
      "2024-03-05 10:05:32.730087: I tensorflow/core/util/port.cc:113] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
      "WARNING:tensorflow:From C:\\Users\\mit017\\anaconda3\\Lib\\site-packages\\keras\\src\\losses.py:2976: The name tf.losses.sparse_softmax_cross_entropy is deprecated. Please use tf.compat.v1.losses.sparse_softmax_cross_entropy instead.\n",
      "\n",
      "WARNING:tensorflow:From C:\\Users\\mit017\\anaconda3\\Lib\\site-packages\\keras\\src\\losses.py:2976: The name tf.losses.sparse_softmax_cross_entropy is deprecated. Please use tf.compat.v1.losses.sparse_softmax_cross_entropy instead.\n",
      "\n",
      "WARNING:tensorflow:From C:\\Users\\mit017\\anaconda3\\Lib\\site-packages\\keras\\src\\losses.py:2976: The name tf.losses.sparse_softmax_cross_entropy is deprecated. Please use tf.compat.v1.losses.sparse_softmax_cross_entropy instead.\n",
      "\n",
      "\n",
      "               Class    Images   Targets         P         R   mAP@0.5        F1:  25%|##5       | 1/4 [00:15<00:45, 15.22s/it]\n",
      "               Class    Images   Targets         P         R   mAP@0.5        F1:  50%|#####     | 2/4 [00:17<00:14,  7.49s/it]\n",
      "               Class    Images   Targets         P         R   mAP@0.5        F1:  75%|#######5  | 3/4 [00:19<00:05,  5.09s/it]\n",
      "               Class    Images   Targets         P         R   mAP@0.5        F1: 100%|##########| 4/4 [00:20<00:00,  3.64s/it]\n",
      "               Class    Images   Targets         P         R   mAP@0.5        F1: 100%|##########| 4/4 [00:21<00:00,  5.49s/it]\n",
      "2024-03-05 10:05:53.905186: I tensorflow/core/util/port.cc:113] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
      "WARNING:tensorflow:From C:\\Users\\mit017\\anaconda3\\Lib\\site-packages\\keras\\src\\losses.py:2976: The name tf.losses.sparse_softmax_cross_entropy is deprecated. Please use tf.compat.v1.losses.sparse_softmax_cross_entropy instead.\n",
      "\n",
      "2024-03-05 10:06:04.123230: I tensorflow/core/util/port.cc:113] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
      "WARNING:tensorflow:From C:\\Users\\mit017\\anaconda3\\Lib\\site-packages\\keras\\src\\losses.py:2976: The name tf.losses.sparse_softmax_cross_entropy is deprecated. Please use tf.compat.v1.losses.sparse_softmax_cross_entropy instead.\n",
      "\n",
      "2024-03-05 10:06:14.400072: I tensorflow/core/util/port.cc:113] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
      "WARNING:tensorflow:From C:\\Users\\mit017\\anaconda3\\Lib\\site-packages\\keras\\src\\losses.py:2976: The name tf.losses.sparse_softmax_cross_entropy is deprecated. Please use tf.compat.v1.losses.sparse_softmax_cross_entropy instead.\n",
      "\n",
      "\n",
      "  0%|          | 0/13 [00:00<?, ?it/s]\n",
      "   855/862        0G         1    0.0849         0      1.09         9       448:   0%|          | 0/13 [00:03<?, ?it/s]\n",
      "   855/862        0G         1    0.0849         0      1.09         9       448:   8%|7         | 1/13 [00:03<00:42,  3.51s/it]\n",
      "   855/862        0G         1    0.0856         0      1.09         8       448:   8%|7         | 1/13 [00:06<00:42,  3.51s/it]\n",
      "   855/862        0G         1    0.0856         0      1.09         8       448:  15%|#5        | 2/13 [00:06<00:36,  3.36s/it]\n",
      "   855/862        0G      1.07     0.086         0      1.16         9       448:  15%|#5        | 2/13 [00:09<00:36,  3.36s/it]\n",
      "   855/862        0G      1.07     0.086         0      1.16         9       448:  23%|##3       | 3/13 [00:09<00:32,  3.30s/it]\n",
      "   855/862        0G      1.11     0.084         0      1.19         9       448:  23%|##3       | 3/13 [00:13<00:32,  3.30s/it]\n",
      "   855/862        0G      1.11     0.084         0      1.19         9       448:  31%|###       | 4/13 [00:13<00:29,  3.27s/it]\n",
      "   855/862        0G       1.1    0.0829         0      1.18        10       448:  31%|###       | 4/13 [00:16<00:29,  3.27s/it]\n",
      "   855/862        0G       1.1    0.0829         0      1.18        10       448:  38%|###8      | 5/13 [00:16<00:26,  3.29s/it]\n",
      "   855/862        0G       1.1    0.0841         0      1.19         9       448:  38%|###8      | 5/13 [00:19<00:26,  3.29s/it]\n",
      "   855/862        0G       1.1    0.0841         0      1.19         9       448:  46%|####6     | 6/13 [00:19<00:22,  3.27s/it]\n",
      "   855/862        0G      1.12    0.0813         0       1.2         9       448:  46%|####6     | 6/13 [00:23<00:22,  3.27s/it]\n",
      "   855/862        0G      1.12    0.0813         0       1.2         9       448:  54%|#####3    | 7/13 [00:23<00:19,  3.26s/it]\n",
      "   855/862        0G      1.15    0.0853         0      1.23        11       448:  54%|#####3    | 7/13 [00:26<00:19,  3.26s/it]\n",
      "   855/862        0G      1.15    0.0853         0      1.23        11       448:  62%|######1   | 8/13 [00:26<00:16,  3.23s/it]\n",
      "   855/862        0G      1.18     0.083         0      1.26         9       448:  62%|######1   | 8/13 [00:29<00:16,  3.23s/it]\n",
      "   855/862        0G      1.18     0.083         0      1.26         9       448:  69%|######9   | 9/13 [00:29<00:12,  3.24s/it]\n",
      "   855/862        0G      1.15    0.0862         0      1.23         9       448:  69%|######9   | 9/13 [00:32<00:12,  3.24s/it]\n",
      "   855/862        0G      1.15    0.0862         0      1.23         9       448:  77%|#######6  | 10/13 [00:32<00:09,  3.24s/it]\n",
      "   855/862        0G      1.14    0.0877         0      1.23         9       448:  77%|#######6  | 10/13 [00:35<00:09,  3.24s/it]\n",
      "   855/862        0G      1.14    0.0877         0      1.23         9       448:  85%|########4 | 11/13 [00:35<00:06,  3.24s/it]\n",
      "   855/862        0G      1.13    0.0882         0      1.22         9       448:  85%|########4 | 11/13 [00:39<00:06,  3.24s/it]\n",
      "   855/862        0G      1.13    0.0882         0      1.22         9       448:  92%|#########2| 12/13 [00:39<00:03,  3.25s/it]\n",
      "   855/862        0G      1.14    0.0882         0      1.22         9       448:  92%|#########2| 12/13 [00:42<00:03,  3.25s/it]\n",
      "   855/862        0G      1.14    0.0882         0      1.22         9       448: 100%|##########| 13/13 [00:42<00:00,  3.25s/it]\n",
      "   855/862        0G      1.14    0.0882         0      1.22         9       448: 100%|##########| 13/13 [00:43<00:00,  3.34s/it]\n",
      "\n",
      "               Class    Images   Targets         P         R   mAP@0.5        F1:   0%|          | 0/4 [00:00<?, ?it/s]2024-03-05 10:07:08.064083: I tensorflow/core/util/port.cc:113] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
      "2024-03-05 10:07:08.153286: I tensorflow/core/util/port.cc:113] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
      "2024-03-05 10:07:08.217633: I tensorflow/core/util/port.cc:113] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
      "WARNING:tensorflow:From C:\\Users\\mit017\\anaconda3\\Lib\\site-packages\\keras\\src\\losses.py:2976: The name tf.losses.sparse_softmax_cross_entropy is deprecated. Please use tf.compat.v1.losses.sparse_softmax_cross_entropy instead.\n",
      "\n",
      "WARNING:tensorflow:From C:\\Users\\mit017\\anaconda3\\Lib\\site-packages\\keras\\src\\losses.py:2976: The name tf.losses.sparse_softmax_cross_entropy is deprecated. Please use tf.compat.v1.losses.sparse_softmax_cross_entropy instead.\n",
      "\n",
      "WARNING:tensorflow:From C:\\Users\\mit017\\anaconda3\\Lib\\site-packages\\keras\\src\\losses.py:2976: The name tf.losses.sparse_softmax_cross_entropy is deprecated. Please use tf.compat.v1.losses.sparse_softmax_cross_entropy instead.\n",
      "\n",
      "\n",
      "               Class    Images   Targets         P         R   mAP@0.5        F1:  25%|##5       | 1/4 [00:13<00:40, 13.41s/it]\n",
      "               Class    Images   Targets         P         R   mAP@0.5        F1:  50%|#####     | 2/4 [00:15<00:13,  6.70s/it]\n",
      "               Class    Images   Targets         P         R   mAP@0.5        F1:  75%|#######5  | 3/4 [00:17<00:04,  4.56s/it]\n",
      "               Class    Images   Targets         P         R   mAP@0.5        F1: 100%|##########| 4/4 [00:18<00:00,  3.33s/it]\n",
      "               Class    Images   Targets         P         R   mAP@0.5        F1: 100%|##########| 4/4 [00:19<00:00,  4.96s/it]\n",
      "2024-03-05 10:07:27.784495: I tensorflow/core/util/port.cc:113] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
      "WARNING:tensorflow:From C:\\Users\\mit017\\anaconda3\\Lib\\site-packages\\keras\\src\\losses.py:2976: The name tf.losses.sparse_softmax_cross_entropy is deprecated. Please use tf.compat.v1.losses.sparse_softmax_cross_entropy instead.\n",
      "\n",
      "2024-03-05 10:07:37.919040: I tensorflow/core/util/port.cc:113] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
      "WARNING:tensorflow:From C:\\Users\\mit017\\anaconda3\\Lib\\site-packages\\keras\\src\\losses.py:2976: The name tf.losses.sparse_softmax_cross_entropy is deprecated. Please use tf.compat.v1.losses.sparse_softmax_cross_entropy instead.\n",
      "\n",
      "2024-03-05 10:07:48.021752: I tensorflow/core/util/port.cc:113] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
      "WARNING:tensorflow:From C:\\Users\\mit017\\anaconda3\\Lib\\site-packages\\keras\\src\\losses.py:2976: The name tf.losses.sparse_softmax_cross_entropy is deprecated. Please use tf.compat.v1.losses.sparse_softmax_cross_entropy instead.\n",
      "\n",
      "\n",
      "  0%|          | 0/13 [00:00<?, ?it/s]\n",
      "   856/862        0G     0.958    0.0733         0      1.03         9       448:   0%|          | 0/13 [00:03<?, ?it/s]\n",
      "   856/862        0G     0.958    0.0733         0      1.03         9       448:   8%|7         | 1/13 [00:03<00:40,  3.40s/it]\n",
      "   856/862        0G      1.08    0.0723         0      1.15         9       448:   8%|7         | 1/13 [00:06<00:40,  3.40s/it]\n",
      "   856/862        0G      1.08    0.0723         0      1.15         9       448:  15%|#5        | 2/13 [00:06<00:35,  3.25s/it]\n",
      "   856/862        0G      1.08    0.0735         0      1.15        12       576:  15%|#5        | 2/13 [00:11<00:35,  3.25s/it]\n",
      "   856/862        0G      1.08    0.0735         0      1.15        12       576:  23%|##3       | 3/13 [00:11<00:42,  4.23s/it]\n",
      "   856/862        0G      1.68     0.075         0      1.76         9       576:  23%|##3       | 3/13 [00:17<00:42,  4.23s/it]\n",
      "   856/862        0G      1.68     0.075         0      1.76         9       576:  31%|###       | 4/13 [00:17<00:41,  4.60s/it]\n",
      "   856/862        0G      1.84    0.0785         0      1.92        10       576:  31%|###       | 4/13 [00:22<00:41,  4.60s/it]\n",
      "   856/862        0G      1.84    0.0785         0      1.92        10       576:  38%|###8      | 5/13 [00:22<00:38,  4.83s/it]\n",
      "   856/862        0G      1.71    0.0761         0      1.79         9       576:  38%|###8      | 5/13 [00:27<00:38,  4.83s/it]\n",
      "   856/862        0G      1.71    0.0761         0      1.79         9       576:  46%|####6     | 6/13 [00:27<00:34,  4.98s/it]\n",
      "   856/862        0G      1.93    0.0797         0      2.01        12       576:  46%|####6     | 6/13 [00:32<00:34,  4.98s/it]\n",
      "   856/862        0G      1.93    0.0797         0      2.01        12       576:  54%|#####3    | 7/13 [00:32<00:30,  5.09s/it]\n",
      "   856/862        0G      2.05    0.0806         0      2.13         9       576:  54%|#####3    | 7/13 [00:38<00:30,  5.09s/it]\n",
      "   856/862        0G      2.05    0.0806         0      2.13         9       576:  62%|######1   | 8/13 [00:38<00:25,  5.18s/it]\n",
      "   856/862        0G      1.96    0.0792         0      2.04        10       576:  62%|######1   | 8/13 [00:43<00:25,  5.18s/it]\n",
      "   856/862        0G      1.96    0.0792         0      2.04        10       576:  69%|######9   | 9/13 [00:43<00:20,  5.20s/it]\n",
      "   856/862        0G      1.86    0.0778         0      1.94         8       576:  69%|######9   | 9/13 [00:48<00:20,  5.20s/it]\n",
      "   856/862        0G      1.86    0.0778         0      1.94         8       576:  77%|#######6  | 10/13 [00:48<00:15,  5.21s/it]\n",
      "   856/862        0G       1.8    0.0765         0      1.88        11       576:  77%|#######6  | 10/13 [00:54<00:15,  5.21s/it]\n",
      "   856/862        0G       1.8    0.0765         0      1.88        11       576:  85%|########4 | 11/13 [00:54<00:10,  5.25s/it]\n",
      "   856/862        0G      1.96    0.0779         0      2.04         9       576:  85%|########4 | 11/13 [01:00<00:10,  5.25s/it]\n",
      "   856/862        0G      1.96    0.0779         0      2.04         9       576:  92%|#########2| 12/13 [01:00<00:05,  5.71s/it]\n",
      "   856/862        0G      2.05    0.0786         0      2.13        10       576:  92%|#########2| 12/13 [01:06<00:05,  5.71s/it]\n",
      "   856/862        0G      2.05    0.0786         0      2.13        10       576: 100%|##########| 13/13 [01:06<00:00,  5.71s/it]\n",
      "   856/862        0G      2.05    0.0786         0      2.13        10       576: 100%|##########| 13/13 [01:07<00:00,  5.21s/it]\n",
      "\n",
      "               Class    Images   Targets         P         R   mAP@0.5        F1:   0%|          | 0/4 [00:00<?, ?it/s]2024-03-05 10:09:06.491379: I tensorflow/core/util/port.cc:113] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
      "2024-03-05 10:09:06.546253: I tensorflow/core/util/port.cc:113] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
      "2024-03-05 10:09:06.653900: I tensorflow/core/util/port.cc:113] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
      "WARNING:tensorflow:From C:\\Users\\mit017\\anaconda3\\Lib\\site-packages\\keras\\src\\losses.py:2976: The name tf.losses.sparse_softmax_cross_entropy is deprecated. Please use tf.compat.v1.losses.sparse_softmax_cross_entropy instead.\n",
      "\n",
      "WARNING:tensorflow:From C:\\Users\\mit017\\anaconda3\\Lib\\site-packages\\keras\\src\\losses.py:2976: The name tf.losses.sparse_softmax_cross_entropy is deprecated. Please use tf.compat.v1.losses.sparse_softmax_cross_entropy instead.\n",
      "\n",
      "WARNING:tensorflow:From C:\\Users\\mit017\\anaconda3\\Lib\\site-packages\\keras\\src\\losses.py:2976: The name tf.losses.sparse_softmax_cross_entropy is deprecated. Please use tf.compat.v1.losses.sparse_softmax_cross_entropy instead.\n",
      "\n",
      "\n",
      "               Class    Images   Targets         P         R   mAP@0.5        F1:  25%|##5       | 1/4 [00:14<00:44, 14.98s/it]\n",
      "               Class    Images   Targets         P         R   mAP@0.5        F1:  50%|#####     | 2/4 [00:17<00:14,  7.42s/it]\n",
      "               Class    Images   Targets         P         R   mAP@0.5        F1:  75%|#######5  | 3/4 [00:19<00:05,  5.03s/it]\n",
      "               Class    Images   Targets         P         R   mAP@0.5        F1: 100%|##########| 4/4 [00:21<00:00,  3.73s/it]\n",
      "               Class    Images   Targets         P         R   mAP@0.5        F1: 100%|##########| 4/4 [00:22<00:00,  5.52s/it]\n",
      "2024-03-05 10:09:28.153476: I tensorflow/core/util/port.cc:113] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
      "WARNING:tensorflow:From C:\\Users\\mit017\\anaconda3\\Lib\\site-packages\\keras\\src\\losses.py:2976: The name tf.losses.sparse_softmax_cross_entropy is deprecated. Please use tf.compat.v1.losses.sparse_softmax_cross_entropy instead.\n",
      "\n",
      "2024-03-05 10:09:38.751807: I tensorflow/core/util/port.cc:113] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
      "WARNING:tensorflow:From C:\\Users\\mit017\\anaconda3\\Lib\\site-packages\\keras\\src\\losses.py:2976: The name tf.losses.sparse_softmax_cross_entropy is deprecated. Please use tf.compat.v1.losses.sparse_softmax_cross_entropy instead.\n",
      "\n",
      "2024-03-05 10:09:49.235173: I tensorflow/core/util/port.cc:113] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
      "WARNING:tensorflow:From C:\\Users\\mit017\\anaconda3\\Lib\\site-packages\\keras\\src\\losses.py:2976: The name tf.losses.sparse_softmax_cross_entropy is deprecated. Please use tf.compat.v1.losses.sparse_softmax_cross_entropy instead.\n",
      "\n",
      "\n",
      "  0%|          | 0/13 [00:00<?, ?it/s]\n",
      "   857/862        0G      1.72     0.142         0      1.86        12       576:   0%|          | 0/13 [00:05<?, ?it/s]\n",
      "   857/862        0G      1.72     0.142         0      1.86        12       576:   8%|7         | 1/13 [00:05<01:11,  5.95s/it]\n",
      "   857/862        0G      2.52     0.115         0      2.63         9       576:   8%|7         | 1/13 [00:11<01:11,  5.95s/it]\n",
      "   857/862        0G      2.52     0.115         0      2.63         9       576:  15%|#5        | 2/13 [00:11<01:04,  5.86s/it]\n",
      "   857/862        0G      2.06    0.0981         0      2.16         9       576:  15%|#5        | 2/13 [00:17<01:04,  5.86s/it]\n",
      "   857/862        0G      2.06    0.0981         0      2.16         9       576:  23%|##3       | 3/13 [00:17<00:57,  5.78s/it]\n",
      "   857/862        0G      1.82      0.09         0      1.91         9       576:  23%|##3       | 3/13 [00:23<00:57,  5.78s/it]\n",
      "   857/862        0G      1.82      0.09         0      1.91         9       576:  31%|###       | 4/13 [00:23<00:51,  5.76s/it]\n",
      "   857/862        0G       1.7    0.0836         0      1.78        10       576:  31%|###       | 4/13 [00:28<00:51,  5.76s/it]\n",
      "   857/862        0G       1.7    0.0836         0      1.78        10       576:  38%|###8      | 5/13 [00:28<00:45,  5.70s/it]\n",
      "   857/862        0G      1.61    0.0807         0      1.69         9       576:  38%|###8      | 5/13 [00:34<00:45,  5.70s/it]\n",
      "   857/862        0G      1.61    0.0807         0      1.69         9       576:  46%|####6     | 6/13 [00:34<00:39,  5.70s/it]\n",
      "   857/862        0G      1.54     0.081         0      1.62        10       576:  46%|####6     | 6/13 [00:39<00:39,  5.70s/it]\n",
      "   857/862        0G      1.54     0.081         0      1.62        10       576:  54%|#####3    | 7/13 [00:39<00:33,  5.62s/it]\n",
      "   857/862        0G      1.49    0.0803         0      1.57        10       576:  54%|#####3    | 7/13 [00:45<00:33,  5.62s/it]\n",
      "   857/862        0G      1.49    0.0803         0      1.57        10       576:  62%|######1   | 8/13 [00:45<00:27,  5.56s/it]\n",
      "   857/862        0G      1.58    0.0821         0      1.67         9       576:  62%|######1   | 8/13 [00:50<00:27,  5.56s/it]\n",
      "   857/862        0G      1.58    0.0821         0      1.67         9       576:  69%|######9   | 9/13 [00:50<00:21,  5.45s/it]\n",
      "   857/862        0G      1.74    0.0875         0      1.83        12       576:  69%|######9   | 9/13 [00:55<00:21,  5.45s/it]\n",
      "   857/862        0G      1.74    0.0875         0      1.83        12       576:  77%|#######6  | 10/13 [00:55<00:16,  5.40s/it]\n",
      "   857/862        0G      1.69    0.0856         0      1.78         9       544:  77%|#######6  | 10/13 [01:00<00:16,  5.40s/it]\n",
      "   857/862        0G      1.69    0.0856         0      1.78         9       544:  85%|########4 | 11/13 [01:00<00:10,  5.28s/it]\n",
      "   857/862        0G      1.64    0.0852         0      1.73         9       544:  85%|########4 | 11/13 [01:05<00:10,  5.28s/it]\n",
      "   857/862        0G      1.64    0.0852         0      1.73         9       544:  92%|#########2| 12/13 [01:05<00:05,  5.08s/it]\n",
      "   857/862        0G      1.69    0.0865         0      1.77        10       544:  92%|#########2| 12/13 [01:10<00:05,  5.08s/it]\n",
      "   857/862        0G      1.69    0.0865         0      1.77        10       544: 100%|##########| 13/13 [01:10<00:00,  4.97s/it]\n",
      "   857/862        0G      1.69    0.0865         0      1.77        10       544: 100%|##########| 13/13 [01:11<00:00,  5.48s/it]\n",
      "\n",
      "               Class    Images   Targets         P         R   mAP@0.5        F1:   0%|          | 0/4 [00:00<?, ?it/s]2024-03-05 10:11:11.077630: I tensorflow/core/util/port.cc:113] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
      "2024-03-05 10:11:11.159137: I tensorflow/core/util/port.cc:113] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
      "2024-03-05 10:11:11.223309: I tensorflow/core/util/port.cc:113] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
      "WARNING:tensorflow:From C:\\Users\\mit017\\anaconda3\\Lib\\site-packages\\keras\\src\\losses.py:2976: The name tf.losses.sparse_softmax_cross_entropy is deprecated. Please use tf.compat.v1.losses.sparse_softmax_cross_entropy instead.\n",
      "\n",
      "WARNING:tensorflow:From C:\\Users\\mit017\\anaconda3\\Lib\\site-packages\\keras\\src\\losses.py:2976: The name tf.losses.sparse_softmax_cross_entropy is deprecated. Please use tf.compat.v1.losses.sparse_softmax_cross_entropy instead.\n",
      "\n",
      "WARNING:tensorflow:From C:\\Users\\mit017\\anaconda3\\Lib\\site-packages\\keras\\src\\losses.py:2976: The name tf.losses.sparse_softmax_cross_entropy is deprecated. Please use tf.compat.v1.losses.sparse_softmax_cross_entropy instead.\n",
      "\n",
      "\n",
      "               Class    Images   Targets         P         R   mAP@0.5        F1:  25%|##5       | 1/4 [00:14<00:42, 14.11s/it]\n",
      "               Class    Images   Targets         P         R   mAP@0.5        F1:  50%|#####     | 2/4 [00:16<00:14,  7.17s/it]\n",
      "               Class    Images   Targets         P         R   mAP@0.5        F1:  75%|#######5  | 3/4 [00:18<00:04,  4.85s/it]\n",
      "               Class    Images   Targets         P         R   mAP@0.5        F1: 100%|##########| 4/4 [00:19<00:00,  3.51s/it]\n",
      "               Class    Images   Targets         P         R   mAP@0.5        F1: 100%|##########| 4/4 [00:21<00:00,  5.26s/it]\n",
      "2024-03-05 10:11:32.095639: I tensorflow/core/util/port.cc:113] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
      "WARNING:tensorflow:From C:\\Users\\mit017\\anaconda3\\Lib\\site-packages\\keras\\src\\losses.py:2976: The name tf.losses.sparse_softmax_cross_entropy is deprecated. Please use tf.compat.v1.losses.sparse_softmax_cross_entropy instead.\n",
      "\n",
      "2024-03-05 10:11:42.706992: I tensorflow/core/util/port.cc:113] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
      "WARNING:tensorflow:From C:\\Users\\mit017\\anaconda3\\Lib\\site-packages\\keras\\src\\losses.py:2976: The name tf.losses.sparse_softmax_cross_entropy is deprecated. Please use tf.compat.v1.losses.sparse_softmax_cross_entropy instead.\n",
      "\n",
      "2024-03-05 10:11:53.524183: I tensorflow/core/util/port.cc:113] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
      "WARNING:tensorflow:From C:\\Users\\mit017\\anaconda3\\Lib\\site-packages\\keras\\src\\losses.py:2976: The name tf.losses.sparse_softmax_cross_entropy is deprecated. Please use tf.compat.v1.losses.sparse_softmax_cross_entropy instead.\n",
      "\n",
      "\n",
      "  0%|          | 0/13 [00:00<?, ?it/s]\n",
      "   858/862        0G      2.92    0.0829         0      3.01         9       544:   0%|          | 0/13 [00:05<?, ?it/s]\n",
      "   858/862        0G      2.92    0.0829         0      3.01         9       544:   8%|7         | 1/13 [00:05<01:01,  5.14s/it]\n",
      "   858/862        0G         2    0.0863         0      2.09        10       544:   8%|7         | 1/13 [00:09<01:01,  5.14s/it]\n",
      "   858/862        0G         2    0.0863         0      2.09        10       544:  15%|#5        | 2/13 [00:09<00:54,  4.93s/it]\n",
      "   858/862        0G      2.25    0.0871         0      2.34         8       544:  15%|#5        | 2/13 [00:14<00:54,  4.93s/it]\n",
      "   858/862        0G      2.25    0.0871         0      2.34         8       544:  23%|##3       | 3/13 [00:14<00:48,  4.80s/it]\n",
      "   858/862        0G      1.98    0.0852         0      2.06        10       544:  23%|##3       | 3/13 [00:19<00:48,  4.80s/it]\n",
      "   858/862        0G      1.98    0.0852         0      2.06        10       544:  31%|###       | 4/13 [00:19<00:42,  4.73s/it]\n",
      "   858/862        0G      1.78    0.0811         0      1.86         9       544:  31%|###       | 4/13 [00:23<00:42,  4.73s/it]\n",
      "   858/862        0G      1.78    0.0811         0      1.86         9       544:  38%|###8      | 5/13 [00:23<00:37,  4.70s/it]\n",
      "   858/862        0G      1.67      0.08         0      1.75         9       544:  38%|###8      | 5/13 [00:28<00:37,  4.70s/it]\n",
      "   858/862        0G      1.67      0.08         0      1.75         9       544:  46%|####6     | 6/13 [00:28<00:32,  4.70s/it]\n",
      "   858/862        0G      1.59    0.0784         0      1.66        10       544:  46%|####6     | 6/13 [00:33<00:32,  4.70s/it]\n",
      "   858/862        0G      1.59    0.0784         0      1.66        10       544:  54%|#####3    | 7/13 [00:33<00:28,  4.78s/it]\n",
      "   858/862        0G      1.53    0.0775         0      1.61         9       544:  54%|#####3    | 7/13 [00:38<00:28,  4.78s/it]\n",
      "   858/862        0G      1.53    0.0775         0      1.61         9       544:  62%|######1   | 8/13 [00:38<00:23,  4.77s/it]\n",
      "   858/862        0G       1.7    0.0788         0      1.77         9       544:  62%|######1   | 8/13 [00:42<00:23,  4.77s/it]\n",
      "   858/862        0G       1.7    0.0788         0      1.77         9       544:  69%|######9   | 9/13 [00:42<00:18,  4.74s/it]\n",
      "   858/862        0G      1.64    0.0795         0      1.72         9       544:  69%|######9   | 9/13 [00:47<00:18,  4.74s/it]\n",
      "   858/862        0G      1.64    0.0795         0      1.72         9       544:  77%|#######6  | 10/13 [00:47<00:14,  4.71s/it]\n",
      "   858/862        0G      1.75    0.0824         0      1.83        12       544:  77%|#######6  | 10/13 [00:52<00:14,  4.71s/it]\n",
      "   858/862        0G      1.75    0.0824         0      1.83        12       544:  85%|########4 | 11/13 [00:52<00:09,  4.67s/it]\n",
      "   858/862        0G      1.88    0.0852         0      1.96         9       544:  85%|########4 | 11/13 [00:56<00:09,  4.67s/it]\n",
      "   858/862        0G      1.88    0.0852         0      1.96         9       544:  92%|#########2| 12/13 [00:56<00:04,  4.65s/it]\n",
      "   858/862        0G      1.87     0.087         0      1.96         9       544:  92%|#########2| 12/13 [01:01<00:04,  4.65s/it]\n",
      "   858/862        0G      1.87     0.087         0      1.96         9       544: 100%|##########| 13/13 [01:01<00:00,  4.70s/it]\n",
      "   858/862        0G      1.87     0.087         0      1.96         9       544: 100%|##########| 13/13 [01:02<00:00,  4.81s/it]\n",
      "\n",
      "               Class    Images   Targets         P         R   mAP@0.5        F1:   0%|          | 0/4 [00:00<?, ?it/s]2024-03-05 10:13:06.679256: I tensorflow/core/util/port.cc:113] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
      "2024-03-05 10:13:06.724569: I tensorflow/core/util/port.cc:113] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
      "2024-03-05 10:13:06.828781: I tensorflow/core/util/port.cc:113] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
      "WARNING:tensorflow:From C:\\Users\\mit017\\anaconda3\\Lib\\site-packages\\keras\\src\\losses.py:2976: The name tf.losses.sparse_softmax_cross_entropy is deprecated. Please use tf.compat.v1.losses.sparse_softmax_cross_entropy instead.\n",
      "\n",
      "WARNING:tensorflow:From C:\\Users\\mit017\\anaconda3\\Lib\\site-packages\\keras\\src\\losses.py:2976: The name tf.losses.sparse_softmax_cross_entropy is deprecated. Please use tf.compat.v1.losses.sparse_softmax_cross_entropy instead.\n",
      "\n",
      "WARNING:tensorflow:From C:\\Users\\mit017\\anaconda3\\Lib\\site-packages\\keras\\src\\losses.py:2976: The name tf.losses.sparse_softmax_cross_entropy is deprecated. Please use tf.compat.v1.losses.sparse_softmax_cross_entropy instead.\n",
      "\n",
      "\n",
      "               Class    Images   Targets         P         R   mAP@0.5        F1:  25%|##5       | 1/4 [00:13<00:41, 13.94s/it]\n",
      "               Class    Images   Targets         P         R   mAP@0.5        F1:  50%|#####     | 2/4 [00:15<00:13,  6.93s/it]\n",
      "               Class    Images   Targets         P         R   mAP@0.5        F1:  75%|#######5  | 3/4 [00:17<00:04,  4.66s/it]\n",
      "               Class    Images   Targets         P         R   mAP@0.5        F1: 100%|##########| 4/4 [00:19<00:00,  3.36s/it]\n",
      "               Class    Images   Targets         P         R   mAP@0.5        F1: 100%|##########| 4/4 [00:20<00:00,  5.07s/it]\n",
      "2024-03-05 10:13:26.710555: I tensorflow/core/util/port.cc:113] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
      "WARNING:tensorflow:From C:\\Users\\mit017\\anaconda3\\Lib\\site-packages\\keras\\src\\losses.py:2976: The name tf.losses.sparse_softmax_cross_entropy is deprecated. Please use tf.compat.v1.losses.sparse_softmax_cross_entropy instead.\n",
      "\n",
      "2024-03-05 10:13:36.865776: I tensorflow/core/util/port.cc:113] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
      "WARNING:tensorflow:From C:\\Users\\mit017\\anaconda3\\Lib\\site-packages\\keras\\src\\losses.py:2976: The name tf.losses.sparse_softmax_cross_entropy is deprecated. Please use tf.compat.v1.losses.sparse_softmax_cross_entropy instead.\n",
      "\n",
      "2024-03-05 10:13:47.046719: I tensorflow/core/util/port.cc:113] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
      "WARNING:tensorflow:From C:\\Users\\mit017\\anaconda3\\Lib\\site-packages\\keras\\src\\losses.py:2976: The name tf.losses.sparse_softmax_cross_entropy is deprecated. Please use tf.compat.v1.losses.sparse_softmax_cross_entropy instead.\n",
      "\n",
      "\n",
      "  0%|          | 0/13 [00:00<?, ?it/s]\n",
      "   859/862        0G     0.933    0.0831         0      1.02         9       544:   0%|          | 0/13 [00:04<?, ?it/s]\n",
      "   859/862        0G     0.933    0.0831         0      1.02         9       544:   8%|7         | 1/13 [00:04<00:59,  4.95s/it]\n",
      "   859/862        0G      2.18     0.107         0      2.29        12       544:   8%|7         | 1/13 [00:09<00:59,  4.95s/it]\n",
      "   859/862        0G      2.18     0.107         0      2.29        12       544:  15%|#5        | 2/13 [00:09<00:52,  4.81s/it]\n",
      "   859/862        0G      2.15     0.111         0      2.26        12       544:  15%|#5        | 2/13 [00:14<00:52,  4.81s/it]\n",
      "   859/862        0G      2.15     0.111         0      2.26        12       544:  23%|##3       | 3/13 [00:14<00:47,  4.77s/it]\n",
      "   859/862        0G      1.91     0.101         0      2.01         9       544:  23%|##3       | 3/13 [00:19<00:47,  4.77s/it]\n",
      "   859/862        0G      1.91     0.101         0      2.01         9       544:  31%|###       | 4/13 [00:19<00:42,  4.74s/it]\n",
      "   859/862        0G      1.73    0.0954         0      1.82         9       544:  31%|###       | 4/13 [00:23<00:42,  4.74s/it]\n",
      "   859/862        0G      1.73    0.0954         0      1.82         9       544:  38%|###8      | 5/13 [00:23<00:37,  4.75s/it]\n",
      "   859/862        0G       1.9    0.0957         0      1.99         9       512:  38%|###8      | 5/13 [00:28<00:37,  4.75s/it]\n",
      "   859/862        0G       1.9    0.0957         0      1.99         9       512:  46%|####6     | 6/13 [00:28<00:32,  4.64s/it]\n",
      "   859/862        0G       1.8    0.0901         0      1.89         9       512:  46%|####6     | 6/13 [00:32<00:32,  4.64s/it]\n",
      "   859/862        0G       1.8    0.0901         0      1.89         9       512:  54%|#####3    | 7/13 [00:32<00:27,  4.51s/it]\n",
      "   859/862        0G      1.69    0.0909         0      1.78        11       512:  54%|#####3    | 7/13 [00:36<00:27,  4.51s/it]\n",
      "   859/862        0G      1.69    0.0909         0      1.78        11       512:  62%|######1   | 8/13 [00:36<00:22,  4.44s/it]\n",
      "   859/862        0G      1.63    0.0921         0      1.72        11       512:  62%|######1   | 8/13 [00:41<00:22,  4.44s/it]\n",
      "   859/862        0G      1.63    0.0921         0      1.72        11       512:  69%|######9   | 9/13 [00:41<00:17,  4.38s/it]\n",
      "   859/862        0G      1.57    0.0903         0      1.66         9       512:  69%|######9   | 9/13 [00:45<00:17,  4.38s/it]\n",
      "   859/862        0G      1.57    0.0903         0      1.66         9       512:  77%|#######6  | 10/13 [00:45<00:13,  4.34s/it]\n",
      "   859/862        0G      1.78    0.0888         0      1.87         9       512:  77%|#######6  | 10/13 [00:49<00:13,  4.34s/it]\n",
      "   859/862        0G      1.78    0.0888         0      1.87         9       512:  85%|########4 | 11/13 [00:49<00:08,  4.29s/it]\n",
      "   859/862        0G      1.71    0.0889         0       1.8        11       512:  85%|########4 | 11/13 [00:53<00:08,  4.29s/it]\n",
      "   859/862        0G      1.71    0.0889         0       1.8        11       512:  92%|#########2| 12/13 [00:53<00:04,  4.23s/it]\n",
      "   859/862        0G      1.67    0.0906         0      1.76        13       512:  92%|#########2| 12/13 [00:57<00:04,  4.23s/it]\n",
      "   859/862        0G      1.67    0.0906         0      1.76        13       512: 100%|##########| 13/13 [00:57<00:00,  4.21s/it]\n",
      "   859/862        0G      1.67    0.0906         0      1.76        13       512: 100%|##########| 13/13 [00:58<00:00,  4.51s/it]\n",
      "\n",
      "               Class    Images   Targets         P         R   mAP@0.5        F1:   0%|          | 0/4 [00:00<?, ?it/s]2024-03-05 10:14:56.324149: I tensorflow/core/util/port.cc:113] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
      "2024-03-05 10:14:56.415533: I tensorflow/core/util/port.cc:113] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
      "2024-03-05 10:14:56.495964: I tensorflow/core/util/port.cc:113] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
      "WARNING:tensorflow:From C:\\Users\\mit017\\anaconda3\\Lib\\site-packages\\keras\\src\\losses.py:2976: The name tf.losses.sparse_softmax_cross_entropy is deprecated. Please use tf.compat.v1.losses.sparse_softmax_cross_entropy instead.\n",
      "\n",
      "WARNING:tensorflow:From C:\\Users\\mit017\\anaconda3\\Lib\\site-packages\\keras\\src\\losses.py:2976: The name tf.losses.sparse_softmax_cross_entropy is deprecated. Please use tf.compat.v1.losses.sparse_softmax_cross_entropy instead.\n",
      "\n",
      "WARNING:tensorflow:From C:\\Users\\mit017\\anaconda3\\Lib\\site-packages\\keras\\src\\losses.py:2976: The name tf.losses.sparse_softmax_cross_entropy is deprecated. Please use tf.compat.v1.losses.sparse_softmax_cross_entropy instead.\n",
      "\n",
      "\n",
      "               Class    Images   Targets         P         R   mAP@0.5        F1:  25%|##5       | 1/4 [00:13<00:39, 13.31s/it]\n",
      "               Class    Images   Targets         P         R   mAP@0.5        F1:  50%|#####     | 2/4 [00:15<00:13,  6.66s/it]\n",
      "               Class    Images   Targets         P         R   mAP@0.5        F1:  75%|#######5  | 3/4 [00:17<00:04,  4.54s/it]\n",
      "               Class    Images   Targets         P         R   mAP@0.5        F1: 100%|##########| 4/4 [00:18<00:00,  3.27s/it]\n",
      "               Class    Images   Targets         P         R   mAP@0.5        F1: 100%|##########| 4/4 [00:19<00:00,  4.91s/it]\n",
      "2024-03-05 10:15:15.827510: I tensorflow/core/util/port.cc:113] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
      "WARNING:tensorflow:From C:\\Users\\mit017\\anaconda3\\Lib\\site-packages\\keras\\src\\losses.py:2976: The name tf.losses.sparse_softmax_cross_entropy is deprecated. Please use tf.compat.v1.losses.sparse_softmax_cross_entropy instead.\n",
      "\n",
      "2024-03-05 10:15:25.988315: I tensorflow/core/util/port.cc:113] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
      "WARNING:tensorflow:From C:\\Users\\mit017\\anaconda3\\Lib\\site-packages\\keras\\src\\losses.py:2976: The name tf.losses.sparse_softmax_cross_entropy is deprecated. Please use tf.compat.v1.losses.sparse_softmax_cross_entropy instead.\n",
      "\n",
      "2024-03-05 10:15:36.205592: I tensorflow/core/util/port.cc:113] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
      "WARNING:tensorflow:From C:\\Users\\mit017\\anaconda3\\Lib\\site-packages\\keras\\src\\losses.py:2976: The name tf.losses.sparse_softmax_cross_entropy is deprecated. Please use tf.compat.v1.losses.sparse_softmax_cross_entropy instead.\n",
      "\n",
      "\n",
      "  0%|          | 0/13 [00:00<?, ?it/s]\n",
      "   860/862        0G      1.17    0.0955         0      1.26         9       512:   0%|          | 0/13 [00:04<?, ?it/s]\n",
      "   860/862        0G      1.17    0.0955         0      1.26         9       512:   8%|7         | 1/13 [00:04<00:53,  4.43s/it]\n",
      "   860/862        0G      1.16     0.076         0      1.24         9       512:   8%|7         | 1/13 [00:08<00:53,  4.43s/it]\n",
      "   860/862        0G      1.16     0.076         0      1.24         9       512:  15%|#5        | 2/13 [00:08<00:47,  4.28s/it]\n",
      "   860/862        0G      1.08    0.0758         0      1.16         8       512:  15%|#5        | 2/13 [00:12<00:47,  4.28s/it]\n",
      "   860/862        0G      1.08    0.0758         0      1.16         8       512:  23%|##3       | 3/13 [00:12<00:42,  4.25s/it]\n",
      "   860/862        0G       1.1    0.0809         0      1.18        13       512:  23%|##3       | 3/13 [00:17<00:42,  4.25s/it]\n",
      "   860/862        0G       1.1    0.0809         0      1.18        13       512:  31%|###       | 4/13 [00:17<00:38,  4.24s/it]\n",
      "   860/862        0G      1.09    0.0793         0      1.17        10       512:  31%|###       | 4/13 [00:21<00:38,  4.24s/it]\n",
      "   860/862        0G      1.09    0.0793         0      1.17        10       512:  38%|###8      | 5/13 [00:21<00:33,  4.21s/it]\n",
      "   860/862        0G      1.09    0.0768         0      1.16         9       512:  38%|###8      | 5/13 [00:25<00:33,  4.21s/it]\n",
      "   860/862        0G      1.09    0.0768         0      1.16         9       512:  46%|####6     | 6/13 [00:25<00:29,  4.21s/it]\n",
      "   860/862        0G      1.08    0.0774         0      1.15         9       512:  46%|####6     | 6/13 [00:29<00:29,  4.21s/it]\n",
      "   860/862        0G      1.08    0.0774         0      1.15         9       512:  54%|#####3    | 7/13 [00:29<00:25,  4.24s/it]\n",
      "   860/862        0G      1.11    0.0755         0      1.19         9       512:  54%|#####3    | 7/13 [00:34<00:25,  4.24s/it]\n",
      "   860/862        0G      1.11    0.0755         0      1.19         9       512:  62%|######1   | 8/13 [00:34<00:21,  4.28s/it]\n",
      "   860/862        0G      1.12    0.0775         0       1.2        11       512:  62%|######1   | 8/13 [00:38<00:21,  4.28s/it]\n",
      "   860/862        0G      1.12    0.0775         0       1.2        11       512:  69%|######9   | 9/13 [00:38<00:17,  4.32s/it]\n",
      "   860/862        0G      1.13    0.0773         0      1.21         9       512:  69%|######9   | 9/13 [00:42<00:17,  4.32s/it]\n",
      "   860/862        0G      1.13    0.0773         0      1.21         9       512:  77%|#######6  | 10/13 [00:42<00:12,  4.28s/it]\n",
      "   860/862        0G      1.14    0.0762         0      1.22         9       512:  77%|#######6  | 10/13 [00:46<00:12,  4.28s/it]\n",
      "   860/862        0G      1.14    0.0762         0      1.22         9       512:  85%|########4 | 11/13 [00:46<00:08,  4.27s/it]\n",
      "   860/862        0G      1.14    0.0774         0      1.22         9       512:  85%|########4 | 11/13 [00:51<00:08,  4.27s/it]\n",
      "   860/862        0G      1.14    0.0774         0      1.22         9       512:  92%|#########2| 12/13 [00:51<00:04,  4.26s/it]\n",
      "   860/862        0G      1.14    0.0768         0      1.22         9       512:  92%|#########2| 12/13 [00:55<00:04,  4.26s/it]\n",
      "   860/862        0G      1.14    0.0768         0      1.22         9       512: 100%|##########| 13/13 [00:55<00:00,  4.23s/it]\n",
      "   860/862        0G      1.14    0.0768         0      1.22         9       512: 100%|##########| 13/13 [00:56<00:00,  4.33s/it]\n",
      "\n",
      "               Class    Images   Targets         P         R   mAP@0.5        F1:   0%|          | 0/4 [00:00<?, ?it/s]2024-03-05 10:16:42.966876: I tensorflow/core/util/port.cc:113] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
      "2024-03-05 10:16:43.034402: I tensorflow/core/util/port.cc:113] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
      "2024-03-05 10:16:43.108469: I tensorflow/core/util/port.cc:113] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
      "WARNING:tensorflow:From C:\\Users\\mit017\\anaconda3\\Lib\\site-packages\\keras\\src\\losses.py:2976: The name tf.losses.sparse_softmax_cross_entropy is deprecated. Please use tf.compat.v1.losses.sparse_softmax_cross_entropy instead.\n",
      "\n",
      "WARNING:tensorflow:From C:\\Users\\mit017\\anaconda3\\Lib\\site-packages\\keras\\src\\losses.py:2976: The name tf.losses.sparse_softmax_cross_entropy is deprecated. Please use tf.compat.v1.losses.sparse_softmax_cross_entropy instead.\n",
      "\n",
      "WARNING:tensorflow:From C:\\Users\\mit017\\anaconda3\\Lib\\site-packages\\keras\\src\\losses.py:2976: The name tf.losses.sparse_softmax_cross_entropy is deprecated. Please use tf.compat.v1.losses.sparse_softmax_cross_entropy instead.\n",
      "\n",
      "\n",
      "               Class    Images   Targets         P         R   mAP@0.5        F1:  25%|##5       | 1/4 [00:13<00:41, 13.99s/it]\n",
      "               Class    Images   Targets         P         R   mAP@0.5        F1:  50%|#####     | 2/4 [00:15<00:13,  6.93s/it]\n",
      "               Class    Images   Targets         P         R   mAP@0.5        F1:  75%|#######5  | 3/4 [00:17<00:04,  4.69s/it]\n",
      "               Class    Images   Targets         P         R   mAP@0.5        F1: 100%|##########| 4/4 [00:19<00:00,  3.38s/it]\n",
      "               Class    Images   Targets         P         R   mAP@0.5        F1: 100%|##########| 4/4 [00:20<00:00,  5.08s/it]\n",
      "2024-03-05 10:17:03.112452: I tensorflow/core/util/port.cc:113] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
      "WARNING:tensorflow:From C:\\Users\\mit017\\anaconda3\\Lib\\site-packages\\keras\\src\\losses.py:2976: The name tf.losses.sparse_softmax_cross_entropy is deprecated. Please use tf.compat.v1.losses.sparse_softmax_cross_entropy instead.\n",
      "\n",
      "2024-03-05 10:17:13.394742: I tensorflow/core/util/port.cc:113] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
      "WARNING:tensorflow:From C:\\Users\\mit017\\anaconda3\\Lib\\site-packages\\keras\\src\\losses.py:2976: The name tf.losses.sparse_softmax_cross_entropy is deprecated. Please use tf.compat.v1.losses.sparse_softmax_cross_entropy instead.\n",
      "\n",
      "2024-03-05 10:17:23.715334: I tensorflow/core/util/port.cc:113] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
      "WARNING:tensorflow:From C:\\Users\\mit017\\anaconda3\\Lib\\site-packages\\keras\\src\\losses.py:2976: The name tf.losses.sparse_softmax_cross_entropy is deprecated. Please use tf.compat.v1.losses.sparse_softmax_cross_entropy instead.\n",
      "\n",
      "\n",
      "  0%|          | 0/13 [00:00<?, ?it/s]\n",
      "   861/862        0G      1.07    0.0797         0      1.15        10       448:   0%|          | 0/13 [00:03<?, ?it/s]\n",
      "   861/862        0G      1.07    0.0797         0      1.15        10       448:   8%|7         | 1/13 [00:03<00:44,  3.68s/it]\n",
      "   861/862        0G      1.03    0.0797         0      1.11        10       448:   8%|7         | 1/13 [00:06<00:44,  3.68s/it]\n",
      "   861/862        0G      1.03    0.0797         0      1.11        10       448:  15%|#5        | 2/13 [00:06<00:37,  3.39s/it]\n",
      "   861/862        0G      1.11    0.0856         0      1.19        12       448:  15%|#5        | 2/13 [00:10<00:37,  3.39s/it]\n",
      "   861/862        0G      1.11    0.0856         0      1.19        12       448:  23%|##3       | 3/13 [00:10<00:33,  3.31s/it]\n",
      "   861/862        0G      1.08    0.0859         0      1.17        10       448:  23%|##3       | 3/13 [00:13<00:33,  3.31s/it]\n",
      "   861/862        0G      1.08    0.0859         0      1.17        10       448:  31%|###       | 4/13 [00:13<00:29,  3.25s/it]\n",
      "   861/862        0G      1.07    0.0896         0      1.15        12       448:  31%|###       | 4/13 [00:16<00:29,  3.25s/it]\n",
      "   861/862        0G      1.07    0.0896         0      1.15        12       448:  38%|###8      | 5/13 [00:16<00:25,  3.24s/it]\n",
      "   861/862        0G      1.09    0.0898         0      1.18        12       448:  38%|###8      | 5/13 [00:19<00:25,  3.24s/it]\n",
      "   861/862        0G      1.09    0.0898         0      1.18        12       448:  46%|####6     | 6/13 [00:19<00:22,  3.24s/it]\n",
      "   861/862        0G       1.1    0.0885         0      1.19         9       448:  46%|####6     | 6/13 [00:22<00:22,  3.24s/it]\n",
      "   861/862        0G       1.1    0.0885         0      1.19         9       448:  54%|#####3    | 7/13 [00:22<00:19,  3.24s/it]\n",
      "   861/862        0G      1.12    0.0879         0      1.21         8       448:  54%|#####3    | 7/13 [00:26<00:19,  3.24s/it]\n",
      "   861/862        0G      1.12    0.0879         0      1.21         8       448:  62%|######1   | 8/13 [00:26<00:16,  3.23s/it]\n",
      "   861/862        0G      1.11    0.0911         0       1.2        12       448:  62%|######1   | 8/13 [00:29<00:16,  3.23s/it]\n",
      "   861/862        0G      1.11    0.0911         0       1.2        12       448:  69%|######9   | 9/13 [00:29<00:12,  3.22s/it]\n",
      "   861/862        0G      1.11    0.0884         0       1.2         8       448:  69%|######9   | 9/13 [00:32<00:12,  3.22s/it]\n",
      "   861/862        0G      1.11    0.0884         0       1.2         8       448:  77%|#######6  | 10/13 [00:32<00:09,  3.21s/it]\n",
      "   861/862        0G      1.11    0.0893         0       1.2         9       448:  77%|#######6  | 10/13 [00:35<00:09,  3.21s/it]\n",
      "   861/862        0G      1.11    0.0893         0       1.2         9       448:  85%|########4 | 11/13 [00:35<00:06,  3.20s/it]\n",
      "   861/862        0G      1.13    0.0922         0      1.22        11       448:  85%|########4 | 11/13 [00:38<00:06,  3.20s/it]\n",
      "   861/862        0G      1.13    0.0922         0      1.22        11       448:  92%|#########2| 12/13 [00:38<00:03,  3.19s/it]\n",
      "   861/862        0G      1.12     0.092         0      1.21         9       448:  92%|#########2| 12/13 [00:42<00:03,  3.19s/it]\n",
      "   861/862        0G      1.12     0.092         0      1.21         9       448: 100%|##########| 13/13 [00:42<00:00,  3.21s/it]\n",
      "   861/862        0G      1.12     0.092         0      1.21         9       448: 100%|##########| 13/13 [00:43<00:00,  3.32s/it]\n",
      "\n",
      "               Class    Images   Targets         P         R   mAP@0.5        F1:   0%|          | 0/4 [00:00<?, ?it/s]2024-03-05 10:18:17.498478: I tensorflow/core/util/port.cc:113] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
      "2024-03-05 10:18:17.573983: I tensorflow/core/util/port.cc:113] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
      "2024-03-05 10:18:17.654273: I tensorflow/core/util/port.cc:113] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
      "WARNING:tensorflow:From C:\\Users\\mit017\\anaconda3\\Lib\\site-packages\\keras\\src\\losses.py:2976: The name tf.losses.sparse_softmax_cross_entropy is deprecated. Please use tf.compat.v1.losses.sparse_softmax_cross_entropy instead.\n",
      "\n",
      "WARNING:tensorflow:From C:\\Users\\mit017\\anaconda3\\Lib\\site-packages\\keras\\src\\losses.py:2976: The name tf.losses.sparse_softmax_cross_entropy is deprecated. Please use tf.compat.v1.losses.sparse_softmax_cross_entropy instead.\n",
      "\n",
      "WARNING:tensorflow:From C:\\Users\\mit017\\anaconda3\\Lib\\site-packages\\keras\\src\\losses.py:2976: The name tf.losses.sparse_softmax_cross_entropy is deprecated. Please use tf.compat.v1.losses.sparse_softmax_cross_entropy instead.\n",
      "\n",
      "\n",
      "               Class    Images   Targets         P         R   mAP@0.5        F1:  25%|##5       | 1/4 [00:13<00:41, 13.84s/it]\n",
      "               Class    Images   Targets         P         R   mAP@0.5        F1:  50%|#####     | 2/4 [00:15<00:13,  6.89s/it]\n",
      "               Class    Images   Targets         P         R   mAP@0.5        F1:  75%|#######5  | 3/4 [00:17<00:04,  4.65s/it]\n",
      "               Class    Images   Targets         P         R   mAP@0.5        F1: 100%|##########| 4/4 [00:19<00:00,  3.36s/it]\n",
      "               Class    Images   Targets         P         R   mAP@0.5        F1: 100%|##########| 4/4 [00:20<00:00,  5.09s/it]\n",
      "2024-03-05 10:18:37.634055: I tensorflow/core/util/port.cc:113] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
      "WARNING:tensorflow:From C:\\Users\\mit017\\anaconda3\\Lib\\site-packages\\keras\\src\\losses.py:2976: The name tf.losses.sparse_softmax_cross_entropy is deprecated. Please use tf.compat.v1.losses.sparse_softmax_cross_entropy instead.\n",
      "\n",
      "2024-03-05 10:18:47.934910: I tensorflow/core/util/port.cc:113] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
      "WARNING:tensorflow:From C:\\Users\\mit017\\anaconda3\\Lib\\site-packages\\keras\\src\\losses.py:2976: The name tf.losses.sparse_softmax_cross_entropy is deprecated. Please use tf.compat.v1.losses.sparse_softmax_cross_entropy instead.\n",
      "\n",
      "2024-03-05 10:18:58.231866: I tensorflow/core/util/port.cc:113] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
      "WARNING:tensorflow:From C:\\Users\\mit017\\anaconda3\\Lib\\site-packages\\keras\\src\\losses.py:2976: The name tf.losses.sparse_softmax_cross_entropy is deprecated. Please use tf.compat.v1.losses.sparse_softmax_cross_entropy instead.\n",
      "\n",
      "\n",
      "  0%|          | 0/13 [00:00<?, ?it/s]\n",
      "   862/862        0G      1.12    0.0989         0      1.22        10       448:   0%|          | 0/13 [00:04<?, ?it/s]\n",
      "   862/862        0G      1.12    0.0989         0      1.22        10       448:   8%|7         | 1/13 [00:04<00:52,  4.35s/it]\n",
      "   862/862        0G      1.16    0.0867         0      1.24        10       448:   8%|7         | 1/13 [00:08<00:52,  4.35s/it]\n",
      "   862/862        0G      1.16    0.0867         0      1.24        10       448:  15%|#5        | 2/13 [00:08<00:43,  3.97s/it]\n",
      "   862/862        0G      1.19     0.079         0      1.27         9       448:  15%|#5        | 2/13 [00:11<00:43,  3.97s/it]\n",
      "   862/862        0G      1.19     0.079         0      1.27         9       448:  23%|##3       | 3/13 [00:11<00:36,  3.69s/it]\n",
      "   862/862        0G      1.21    0.0777         0      1.29         9       448:  23%|##3       | 3/13 [00:14<00:36,  3.69s/it]\n",
      "   862/862        0G      1.21    0.0777         0      1.29         9       448:  31%|###       | 4/13 [00:14<00:31,  3.53s/it]\n",
      "   862/862        0G      1.22    0.0794         0       1.3         9       448:  31%|###       | 4/13 [00:17<00:31,  3.53s/it]\n",
      "   862/862        0G      1.22    0.0794         0       1.3         9       448:  38%|###8      | 5/13 [00:17<00:27,  3.42s/it]\n",
      "   862/862        0G      1.18    0.0834         0      1.26        11       448:  38%|###8      | 5/13 [00:21<00:27,  3.42s/it]\n",
      "   862/862        0G      1.18    0.0834         0      1.26        11       448:  46%|####6     | 6/13 [00:21<00:23,  3.37s/it]\n",
      "   862/862        0G      1.19    0.0848         0      1.28        11       448:  46%|####6     | 6/13 [00:24<00:23,  3.37s/it]\n",
      "   862/862        0G      1.19    0.0848         0      1.28        11       448:  54%|#####3    | 7/13 [00:24<00:20,  3.35s/it]\n",
      "   862/862        0G      1.18    0.0846         0      1.26         9       448:  54%|#####3    | 7/13 [00:27<00:20,  3.35s/it]\n",
      "   862/862        0G      1.18    0.0846         0      1.26         9       448:  62%|######1   | 8/13 [00:27<00:16,  3.35s/it]\n",
      "   862/862        0G      1.15    0.0835         0      1.24        10       544:  62%|######1   | 8/13 [00:33<00:16,  3.35s/it]\n",
      "   862/862        0G      1.15    0.0835         0      1.24        10       544:  69%|######9   | 9/13 [00:33<00:15,  3.95s/it]\n",
      "   862/862        0G      1.15    0.0828         0      1.24        11       544:  69%|######9   | 9/13 [00:38<00:15,  3.95s/it]\n",
      "   862/862        0G      1.15    0.0828         0      1.24        11       544:  77%|#######6  | 10/13 [00:38<00:12,  4.25s/it]\n",
      "   862/862        0G      1.15    0.0814         0      1.23         9       544:  77%|#######6  | 10/13 [00:43<00:12,  4.25s/it]\n",
      "   862/862        0G      1.15    0.0814         0      1.23         9       544:  85%|########4 | 11/13 [00:43<00:09,  4.50s/it]\n",
      "   862/862        0G      1.13     0.081         0      1.21         9       544:  85%|########4 | 11/13 [00:48<00:09,  4.50s/it]\n",
      "   862/862        0G      1.13     0.081         0      1.21         9       544:  92%|#########2| 12/13 [00:48<00:04,  4.69s/it]\n",
      "   862/862        0G      1.29     0.082         0      1.37         9       544:  92%|#########2| 12/13 [00:53<00:04,  4.69s/it]\n",
      "   862/862        0G      1.29     0.082         0      1.37         9       544: 100%|##########| 13/13 [00:53<00:00,  4.79s/it]\n",
      "   862/862        0G      1.29     0.082         0      1.37         9       544: 100%|##########| 13/13 [00:54<00:00,  4.18s/it]\n",
      "\n",
      "               Class    Images   Targets         P         R   mAP@0.5        F1:   0%|          | 0/4 [00:00<?, ?it/s]2024-03-05 10:20:03.828571: I tensorflow/core/util/port.cc:113] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
      "2024-03-05 10:20:03.864102: I tensorflow/core/util/port.cc:113] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
      "2024-03-05 10:20:03.959826: I tensorflow/core/util/port.cc:113] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
      "WARNING:tensorflow:From C:\\Users\\mit017\\anaconda3\\Lib\\site-packages\\keras\\src\\losses.py:2976: The name tf.losses.sparse_softmax_cross_entropy is deprecated. Please use tf.compat.v1.losses.sparse_softmax_cross_entropy instead.\n",
      "\n",
      "WARNING:tensorflow:From C:\\Users\\mit017\\anaconda3\\Lib\\site-packages\\keras\\src\\losses.py:2976: The name tf.losses.sparse_softmax_cross_entropy is deprecated. Please use tf.compat.v1.losses.sparse_softmax_cross_entropy instead.\n",
      "\n",
      "WARNING:tensorflow:From C:\\Users\\mit017\\anaconda3\\Lib\\site-packages\\keras\\src\\losses.py:2976: The name tf.losses.sparse_softmax_cross_entropy is deprecated. Please use tf.compat.v1.losses.sparse_softmax_cross_entropy instead.\n",
      "\n",
      "\n",
      "               Class    Images   Targets         P         R   mAP@0.5        F1:  25%|##5       | 1/4 [00:13<00:41, 13.77s/it]\n",
      "               Class    Images   Targets         P         R   mAP@0.5        F1:  50%|#####     | 2/4 [00:15<00:13,  6.86s/it]\n",
      "               Class    Images   Targets         P         R   mAP@0.5        F1:  75%|#######5  | 3/4 [00:17<00:04,  4.71s/it]\n",
      "               Class    Images   Targets         P         R   mAP@0.5        F1: 100%|##########| 4/4 [00:19<00:00,  3.41s/it]\n",
      "               Class    Images   Targets         P         R   mAP@0.5        F1: 100%|##########| 4/4 [00:20<00:00,  5.09s/it]\n"
     ]
    }
   ],
   "source": [
    "!python train.py --epochs 15 --weights weights/last.pt --batch-size 3 --cfg yolov3-spp.cfg --data custom.data --nosave --device cpu"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "d72ad1d5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Namespace(cfg='yolov3-spp.cfg', names='classes.names', weights='weights/last.pt', source='images', output='result', img_size=512, conf_thres=0.3, iou_thres=0.6, fourcc='mp4v', half=False, device='', view_img=False, save_txt=False, classes=None, agnostic_nms=False, augment=False)\n",
      "Using CPU\n",
      "\n",
      "Model Summary: 225 layers, 6.25733e+07 parameters, 6.25733e+07 gradients\n",
      "image 1/100 images\\002_20200622_203136(3).jpg: 512x512 3 defects, Done. (0.531s)\n",
      "image 2/100 images\\002_20200622_203140(8).jpg: 512x512 2 defects, Done. (0.651s)\n",
      "image 3/100 images\\002_20200622_203145(3).jpg: 512x512 3 defects, Done. (0.469s)\n",
      "image 4/100 images\\002_20200622_203149(8).jpg: 512x512 3 defects, Done. (0.504s)\n",
      "image 5/100 images\\002_20200622_203154(3).jpg: 512x512 2 defects, Done. (0.495s)\n",
      "image 6/100 images\\002_20200622_203158(8).jpg: 512x512 2 defects, Done. (0.533s)\n",
      "image 7/100 images\\002_20200623_003351(2).jpg: 512x512 3 defects, Done. (0.497s)\n",
      "image 8/100 images\\002_20200623_003355(7).jpg: 512x512 3 defects, Done. (0.490s)\n",
      "image 9/100 images\\002_20200623_003400(2).jpg: 512x512 2 defects, Done. (0.500s)\n",
      "image 10/100 images\\002_20200623_003404(7).jpg: 512x512 3 defects, Done. (0.478s)\n",
      "image 11/100 images\\002_20200623_003409(2).jpg: 512x512 3 defects, Done. (0.494s)\n",
      "image 12/100 images\\002_20200623_003413(7).jpg: 512x512 3 defects, Done. (0.479s)\n",
      "image 13/100 images\\002_20200623_043056(0).jpg: 512x512 3 defects, Done. (0.488s)\n",
      "image 14/100 images\\002_20200623_043100(6).jpg: 512x512 3 defects, Done. (0.488s)\n",
      "image 15/100 images\\002_20200623_043105(0).jpg: 512x512 3 defects, Done. (0.503s)\n",
      "image 16/100 images\\002_20200623_043109(4).jpg: 512x512 2 defects, Done. (0.612s)\n",
      "image 17/100 images\\002_20200623_043115(4).jpg: 512x512 3 defects, Done. (0.521s)\n",
      "image 18/100 images\\002_20200623_043120(0).jpg: 512x512 3 defects, Done. (0.515s)\n",
      "image 19/100 images\\002_20200623_082249(3).jpg: 512x512 3 defects, Done. (0.459s)\n",
      "image 20/100 images\\002_20200623_082253(8).jpg: 512x512 2 defects, Done. (0.467s)\n",
      "image 21/100 images\\002_20200623_082258(4).jpg: 512x512 3 defects, Done. (0.499s)\n",
      "image 22/100 images\\002_20200623_082302(7).jpg: 512x512 3 defects, Done. (0.513s)\n",
      "image 23/100 images\\002_20200623_082307(2).jpg: 512x512 3 defects, Done. (0.492s)\n",
      "image 24/100 images\\002_20200623_082311(8).jpg: 512x512 3 defects, Done. (0.488s)\n",
      "image 25/100 images\\002_20200623_123042(0).jpg: 512x512 3 defects, Done. (0.518s)\n",
      "image 26/100 images\\002_20200623_123046(4).jpg: 512x512 2 defects, Done. (0.498s)\n",
      "image 27/100 images\\002_20200623_123051(1).jpg: 512x512 3 defects, Done. (0.503s)\n",
      "image 28/100 images\\002_20200623_123055(5).jpg: 512x512 3 defects, Done. (0.465s)\n",
      "image 29/100 images\\002_20200623_123100(0).jpg: 512x512 3 defects, Done. (0.500s)\n",
      "image 30/100 images\\002_20200623_123104(5).jpg: 512x512 3 defects, Done. (0.509s)\n",
      "image 31/100 images\\002_20200623_163020(3).jpg: 512x512 3 defects, Done. (0.487s)\n",
      "image 32/100 images\\002_20200623_163023(3).jpg: 512x512 2 defects, Done. (0.485s)\n",
      "image 33/100 images\\002_20200623_163026(3).jpg: 512x512 3 defects, Done. (0.494s)\n",
      "image 34/100 images\\002_20200623_163029(6).jpg: 512x512 3 defects, Done. (0.503s)\n",
      "image 35/100 images\\002_20200623_163032(5).jpg: 512x512 2 defects, Done. (0.479s)\n",
      "image 36/100 images\\002_20200623_163035(5).jpg: 512x512 3 defects, Done. (0.497s)\n",
      "image 37/100 images\\002_20200623_203033(6).jpg: 512x512 3 defects, Done. (0.509s)\n",
      "image 38/100 images\\002_20200623_203038(0).jpg: 512x512 3 defects, Done. (0.473s)\n",
      "image 39/100 images\\002_20200623_203042(5).jpg: 512x512 3 defects, Done. (0.506s)\n",
      "image 40/100 images\\002_20200623_203047(0).jpg: 512x512 3 defects, Done. (0.502s)\n",
      "image 41/100 images\\002_20200623_203050(0).jpg: 512x512 2 defects, Done. (0.500s)\n",
      "image 42/100 images\\002_20200623_203054(6).jpg: 512x512 3 defects, Done. (0.521s)\n",
      "image 43/100 images\\002_20200624_003115(6).jpg: 512x512 3 defects, Done. (0.463s)\n",
      "image 44/100 images\\002_20200624_003118(6).jpg: 512x512 3 defects, Done. (0.481s)\n",
      "image 45/100 images\\002_20200624_003123(0).jpg: 512x512 3 defects, Done. (0.480s)\n",
      "image 46/100 images\\002_20200624_003127(5).jpg: 512x512 3 defects, Done. (0.490s)\n",
      "image 47/100 images\\002_20200624_003132(0).jpg: 512x512 3 defects, Done. (0.497s)\n",
      "image 48/100 images\\002_20200624_003136(5).jpg: 512x512 2 defects, Done. (0.510s)\n",
      "image 49/100 images\\002_20200624_043136(9).jpg: 512x512 3 defects, Done. (0.551s)\n",
      "image 50/100 images\\002_20200624_043141(4).jpg: 512x512 2 defects, Done. (0.548s)\n",
      "image 51/100 images\\002_20200624_043145(8).bmp: 512x512 3 defects, Done. (0.513s)\n",
      "image 52/100 images\\002_20200624_043150(3).bmp: 512x512 2 defects, Done. (0.488s)\n",
      "image 53/100 images\\002_20200624_043154(8).bmp: 512x512 3 defects, Done. (0.485s)\n",
      "image 54/100 images\\002_20200624_043159(4).bmp: 512x512 3 defects, Done. (0.507s)\n",
      "image 55/100 images\\002_20200624_083032(4).bmp: 512x512 3 defects, Done. (0.484s)\n",
      "image 56/100 images\\002_20200624_083036(9).bmp: 512x512 3 defects, Done. (0.505s)\n",
      "image 57/100 images\\002_20200624_083041(3).bmp: 512x512 3 defects, Done. (0.487s)\n",
      "image 58/100 images\\002_20200624_083045(8).bmp: 512x512 3 defects, Done. (0.481s)\n",
      "image 59/100 images\\002_20200624_083050(4).bmp: 512x512 2 defects, Done. (0.512s)\n",
      "image 60/100 images\\002_20200624_083054(9).bmp: 512x512 2 defects, Done. (0.503s)\n",
      "image 61/100 images\\002_20200624_123144(0).bmp: 512x512 3 defects, Done. (0.508s)\n",
      "image 62/100 images\\002_20200624_123148(2).bmp: 512x512 3 defects, Done. (0.488s)\n",
      "image 63/100 images\\002_20200624_123152(7).bmp: 512x512 3 defects, Done. (0.490s)\n",
      "image 64/100 images\\002_20200624_123157(4).bmp: 512x512 3 defects, Done. (0.486s)\n",
      "image 65/100 images\\002_20200624_123201(7).bmp: 512x512 3 defects, Done. (0.506s)\n",
      "image 66/100 images\\002_20200624_123206(2).bmp: 512x512 3 defects, Done. (0.477s)\n",
      "image 67/100 images\\002_20200624_162708(9).bmp: 512x512 3 defects, Done. (0.505s)\n",
      "image 68/100 images\\002_20200624_162713(4).bmp: 512x512 3 defects, Done. (0.513s)\n",
      "image 69/100 images\\002_20200624_162717(9).bmp: 512x512 3 defects, Done. (0.500s)\n",
      "image 70/100 images\\002_20200624_162722(4).bmp: 512x512 3 defects, Done. (0.502s)\n",
      "image 71/100 images\\002_20200624_162726(9).bmp: 512x512 3 defects, Done. (0.472s)\n",
      "image 72/100 images\\002_20200624_162737(5).bmp: 512x512 3 defects, Done. (0.498s)\n",
      "image 73/100 images\\002_20200624_203111(4).bmp: 512x512 2 defects, Done. (0.534s)\n",
      "image 74/100 images\\002_20200624_203114(3).bmp: 512x512 2 defects, Done. (0.491s)\n",
      "image 75/100 images\\002_20200624_203117(3).bmp: 512x512 3 defects, Done. (0.502s)\n",
      "image 76/100 images\\002_20200624_203120(3).bmp: 512x512 3 defects, Done. (0.489s)\n",
      "image 77/100 images\\002_20200624_203123(3).bmp: 512x512 1 defects, Done. (0.507s)\n",
      "image 78/100 images\\002_20200624_203126(3).bmp: 512x512 3 defects, Done. (0.495s)\n",
      "image 79/100 images\\002_20200625_003352(9).bmp: 512x512 3 defects, Done. (0.484s)\n",
      "image 80/100 images\\002_20200625_003357(4).bmp: 512x512 3 defects, Done. (0.496s)\n",
      "image 81/100 images\\002_20200625_003401(8).bmp: 512x512 3 defects, Done. (0.491s)\n",
      "image 82/100 images\\002_20200625_003406(3).bmp: 512x512 3 defects, Done. (0.490s)\n",
      "image 83/100 images\\002_20200625_003410(8).bmp: 512x512 3 defects, Done. (0.489s)\n",
      "image 84/100 images\\002_20200625_003415(4).bmp: 512x512 3 defects, Done. (0.487s)\n",
      "image 85/100 images\\002_20200629_082823(5).bmp: 512x512 3 defects, Done. (0.492s)\n",
      "image 86/100 images\\002_20200629_082828(5).bmp: 512x512 2 defects, Done. (0.479s)\n",
      "image 87/100 images\\002_20200629_082831(3).bmp: 512x512 2 defects, Done. (0.489s)\n",
      "image 88/100 images\\002_20200629_082834(2).bmp: 512x512 3 defects, Done. (0.473s)\n",
      "image 89/100 images\\002_20200629_082837(0).bmp: 512x512 2 defects, Done. (0.478s)\n",
      "image 90/100 images\\002_20200629_082839(9).bmp: 512x512 2 defects, Done. (0.490s)\n",
      "image 91/100 images\\002_20200629_123442(5).bmp: 512x512 3 defects, Done. (0.484s)\n",
      "image 92/100 images\\002_20200629_123447(0).bmp: 512x512 3 defects, Done. (0.481s)\n",
      "image 93/100 images\\002_20200629_123451(5).bmp: 512x512 3 defects, Done. (0.498s)\n",
      "image 94/100 images\\002_20200629_123456(0).bmp: 512x512 2 defects, Done. (0.502s)\n",
      "image 95/100 images\\002_20200629_123500(5).bmp: 512x512 3 defects, Done. (0.472s)\n",
      "image 96/100 images\\002_20200629_123505(0).bmp: 512x512 2 defects, Done. (0.501s)\n",
      "image 97/100 images\\002_20200629_163656(7).bmp: 512x512 2 defects, Done. (0.518s)\n",
      "image 98/100 images\\002_20200629_163659(7).bmp: 512x512 2 defects, Done. (0.534s)\n",
      "image 99/100 images\\002_20200629_163702(8).bmp: 512x512 3 defects, Done. (0.506s)\n",
      "image 100/100 images\\002_20200629_163705(8).bmp: 512x512 3 defects, Done. (0.483s)\n",
      "Results saved to C:\\Users\\mit017\\Desktop\\myproject\\XRAY_PROJECT\\XrayInspection\\dataset\\test1\\yolov3\\result\n",
      "Done. (50.785s)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\mit017\\anaconda3\\Lib\\site-packages\\torch\\functional.py:507: UserWarning: torch.meshgrid: in an upcoming release, it will be required to pass the indexing argument. (Triggered internally at ..\\aten\\src\\ATen\\native\\TensorShape.cpp:3550.)\n",
      "  return _VF.meshgrid(tensors, **kwargs)  # type: ignore[attr-defined]\n"
     ]
    }
   ],
   "source": [
    "!python detect.py --weights weights/last.pt --source images --cfg yolov3-spp.cfg --names classes.names --output result "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "cab8b7b1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Namespace(cfg='yolov3-spp.cfg', data='custom.data', weights='weights/last.pt', batch_size=16, img_size=512, conf_thres=0.001, iou_thres=0.6, save_json=False, task='test', device='', single_cls=False, augment=False)\n",
      "Using CPU\n",
      "\n",
      "WARNING: smart bias initialization failure.\n",
      "WARNING: smart bias initialization failure.\n",
      "WARNING: smart bias initialization failure.\n",
      "Model Summary: 225 layers, 6.25733e+07 parameters, 6.25733e+07 gradients\n",
      "Fusing layers...\n",
      "Model Summary: 152 layers, 6.25465e+07 parameters, 6.25465e+07 gradients\n",
      "                 all        11        33     0.883     0.909     0.843     0.896\n",
      "Speed: 465.3/2.6/467.9 ms inference/NMS/total per 512x512 image at batch-size 11\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "  0%|          | 0/11 [00:00<?, ?it/s]\n",
      "Caching labels C:\\Users\\mit017\\Desktop\\myproject\\XRAY_PROJECT\\XrayInspection\\dataset\\test1\\yolov3\\test.txt (11 found, 0 missing, 0 empty, 0 duplicate, for 11 images): 100%|##########| 11/11 [00:00<00:00, 2435.07it/s]\n",
      "\n",
      "               Class    Images   Targets         P         R   mAP@0.5        F1:   0%|          | 0/1 [00:00<?, ?it/s]C:\\Users\\mit017\\anaconda3\\Lib\\site-packages\\torch\\functional.py:507: UserWarning: torch.meshgrid: in an upcoming release, it will be required to pass the indexing argument. (Triggered internally at ..\\aten\\src\\ATen\\native\\TensorShape.cpp:3550.)\n",
      "  return _VF.meshgrid(tensors, **kwargs)  # type: ignore[attr-defined]\n",
      "\n",
      "               Class    Images   Targets         P         R   mAP@0.5        F1: 100%|##########| 1/1 [00:11<00:00, 11.85s/it]\n",
      "               Class    Images   Targets         P         R   mAP@0.5        F1: 100%|##########| 1/1 [00:12<00:00, 12.85s/it]\n"
     ]
    }
   ],
   "source": [
    "!python test.py --cfg yolov3-spp.cfg --data custom.data --weights weights/last.pt "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0da6fb5e",
   "metadata": {},
   "source": [
    "결과 정리<br>\n",
    "15 :  0.78     0.571     0.675     0.659 <br>\n",
    "50: 0.936     0.933     0.963     0.935 <br>\n",
    "100 : 0.883     0.909     0.843     0.896<br>\n",
    "200: 0.881     0.933     0.885     0.907 <br>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5016a54c",
   "metadata": {},
   "source": [
    "## 300개"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "a74dc54c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-> Please ignore this error message\n",
      "\n",
      "Showing image 0/299, path: input\\001_20200622_203305(8).jpg\n",
      "Welcome!\n",
      " Press [h] for help.\n",
      "Showing image 1/299, path: input\\001_20200622_203309(1).jpg\n",
      "Showing image 1/299, path: input\\001_20200622_203309(1).jpg\n",
      "Showing image 2/299, path: input\\001_20200622_203312(6).jpg\n",
      "Showing image 2/299, path: input\\001_20200622_203312(6).jpg\n",
      "Showing image 3/299, path: input\\001_20200622_203316(0).jpg\n",
      "Showing image 3/299, path: input\\001_20200622_203316(0).jpg\n",
      "Showing image 4/299, path: input\\001_20200622_203319(4).jpg\n",
      "Showing image 4/299, path: input\\001_20200622_203319(4).jpg\n",
      "Showing image 5/299, path: input\\001_20200622_203330(3).jpg\n",
      "Showing image 5/299, path: input\\001_20200622_203330(3).jpg\n",
      "Showing image 6/299, path: input\\001_20200623_003516(8).jpg\n",
      "Showing image 6/299, path: input\\001_20200623_003516(8).jpg\n",
      "Showing image 7/299, path: input\\001_20200623_003520(5).jpg\n",
      "Showing image 7/299, path: input\\001_20200623_003520(5).jpg\n",
      "Showing image 8/299, path: input\\001_20200623_003524(0).jpg\n",
      "Showing image 8/299, path: input\\001_20200623_003524(0).jpg\n",
      "Showing image 9/299, path: input\\001_20200623_003529(0).jpg\n",
      "Showing image 9/299, path: input\\001_20200623_003529(0).jpg\n",
      "Showing image 10/299, path: input\\001_20200623_003532(5).jpg\n",
      "Showing image 10/299, path: input\\001_20200623_003532(5).jpg\n",
      "Showing image 11/299, path: input\\001_20200623_003536(0).jpg\n",
      "Showing image 11/299, path: input\\001_20200623_003536(0).jpg\n",
      "Showing image 12/299, path: input\\001_20200623_043227(1).jpg\n",
      "Showing image 12/299, path: input\\001_20200623_043227(1).jpg\n",
      "Showing image 13/299, path: input\\001_20200623_043231(6).jpg\n",
      "Showing image 13/299, path: input\\001_20200623_043231(6).jpg\n",
      "Showing image 14/299, path: input\\001_20200623_043236(1).jpg\n",
      "Showing image 14/299, path: input\\001_20200623_043236(1).jpg\n",
      "Showing image 15/299, path: input\\001_20200623_043240(6).jpg\n",
      "Showing image 15/299, path: input\\001_20200623_043240(6).jpg\n",
      "Showing image 16/299, path: input\\001_20200623_043245(2).jpg\n",
      "Showing image 16/299, path: input\\001_20200623_043245(2).jpg\n",
      "Showing image 17/299, path: input\\001_20200623_043249(6).jpg\n",
      "Showing image 17/299, path: input\\001_20200623_043249(6).jpg\n",
      "Showing image 18/299, path: input\\001_20200623_082407(9).jpg\n",
      "Showing image 18/299, path: input\\001_20200623_082407(9).jpg\n",
      "Showing image 19/299, path: input\\001_20200623_082411(0).jpg\n",
      "Showing image 19/299, path: input\\001_20200623_082411(0).jpg\n",
      "Showing image 20/299, path: input\\001_20200623_082414(1).jpg\n",
      "Showing image 20/299, path: input\\001_20200623_082414(1).jpg\n",
      "Showing image 21/299, path: input\\001_20200623_082416(7).jpg\n",
      "Showing image 21/299, path: input\\001_20200623_082416(7).jpg\n",
      "Showing image 22/299, path: input\\001_20200623_082419(6).jpg\n",
      "Showing image 22/299, path: input\\001_20200623_082419(6).jpg\n",
      "Showing image 23/299, path: input\\001_20200623_082422(5).jpg\n",
      "Showing image 23/299, path: input\\001_20200623_082422(5).jpg\n",
      "Showing image 24/299, path: input\\001_20200623_123214(3).jpg\n",
      "Showing image 24/299, path: input\\001_20200623_123214(3).jpg\n",
      "Showing image 25/299, path: input\\001_20200623_123223(3).jpg\n",
      "Showing image 25/299, path: input\\001_20200623_123223(3).jpg\n",
      "Showing image 26/299, path: input\\001_20200623_123232(3).jpg\n",
      "Showing image 26/299, path: input\\001_20200623_123232(3).jpg\n",
      "Showing image 27/299, path: input\\001_20200623_123236(9).jpg\n",
      "Showing image 27/299, path: input\\001_20200623_123236(9).jpg\n",
      "Showing image 28/299, path: input\\001_20200623_123241(3).jpg\n",
      "Showing image 28/299, path: input\\001_20200623_123241(3).jpg\n",
      "Showing image 29/299, path: input\\001_20200623_123245(8).jpg\n",
      "Showing image 29/299, path: input\\001_20200623_123245(8).jpg\n",
      "Showing image 30/299, path: input\\001_20200623_163159(5).jpg\n",
      "Showing image 30/299, path: input\\001_20200623_163159(5).jpg\n",
      "Showing image 31/299, path: input\\001_20200623_163209(3).jpg\n",
      "Showing image 31/299, path: input\\001_20200623_163209(3).jpg\n",
      "Showing image 32/299, path: input\\001_20200623_163212(9).jpg\n",
      "Showing image 32/299, path: input\\001_20200623_163212(9).jpg\n",
      "Showing image 33/299, path: input\\001_20200623_163216(2).jpg\n",
      "Showing image 33/299, path: input\\001_20200623_163216(2).jpg\n",
      "Showing image 34/299, path: input\\001_20200623_163219(5).jpg\n",
      "Showing image 34/299, path: input\\001_20200623_163219(5).jpg\n",
      "Showing image 35/299, path: input\\001_20200623_163222(9).jpg\n",
      "Showing image 35/299, path: input\\001_20200623_163222(9).jpg\n",
      "Showing image 36/299, path: input\\001_20200623_203217(4).jpg\n",
      "Showing image 36/299, path: input\\001_20200623_203217(4).jpg\n",
      "Showing image 37/299, path: input\\001_20200623_203222(0).jpg\n",
      "Showing image 37/299, path: input\\001_20200623_203222(0).jpg\n",
      "Showing image 38/299, path: input\\001_20200623_203226(3).jpg\n",
      "Showing image 38/299, path: input\\001_20200623_203226(3).jpg\n",
      "Showing image 39/299, path: input\\001_20200623_203230(9).jpg\n",
      "Showing image 39/299, path: input\\001_20200623_203230(9).jpg\n",
      "Showing image 40/299, path: input\\001_20200623_203235(3).jpg\n",
      "Showing image 40/299, path: input\\001_20200623_203235(3).jpg\n",
      "Showing image 41/299, path: input\\001_20200623_203247(5).jpg\n",
      "Showing image 41/299, path: input\\001_20200623_203247(5).jpg\n",
      "Showing image 42/299, path: input\\001_20200624_003240(4).jpg\n",
      "Showing image 42/299, path: input\\001_20200624_003240(4).jpg\n",
      "Showing image 43/299, path: input\\001_20200624_003244(2).jpg\n",
      "Showing image 43/299, path: input\\001_20200624_003244(2).jpg\n",
      "Showing image 44/299, path: input\\001_20200624_003247(7).jpg\n",
      "Showing image 44/299, path: input\\001_20200624_003247(7).jpg\n",
      "Showing image 45/299, path: input\\001_20200624_003251(1).jpg\n",
      "Showing image 45/299, path: input\\001_20200624_003251(1).jpg\n",
      "Showing image 46/299, path: input\\001_20200624_003254(3).jpg\n",
      "Showing image 46/299, path: input\\001_20200624_003254(3).jpg\n",
      "Showing image 47/299, path: input\\001_20200624_003303(5).jpg\n",
      "Showing image 47/299, path: input\\001_20200624_003303(5).jpg\n",
      "Showing image 48/299, path: input\\001_20200624_043315(2).jpg\n",
      "Showing image 48/299, path: input\\001_20200624_043315(2).jpg\n",
      "Showing image 49/299, path: input\\001_20200624_043324(2).jpg\n",
      "Showing image 49/299, path: input\\001_20200624_043324(2).jpg\n",
      "Showing image 50/299, path: input\\001_20200624_043328(7).jpg\n",
      "Showing image 50/299, path: input\\001_20200624_043328(7).jpg\n",
      "Showing image 51/299, path: input\\001_20200624_043333(2).jpg\n",
      "Showing image 51/299, path: input\\001_20200624_043333(2).jpg\n",
      "Showing image 52/299, path: input\\001_20200624_043337(8).jpg\n",
      "Showing image 52/299, path: input\\001_20200624_043337(8).jpg\n",
      "Showing image 53/299, path: input\\001_20200624_043349(7).jpg\n",
      "Showing image 53/299, path: input\\001_20200624_043349(7).jpg\n",
      "Showing image 54/299, path: input\\001_20200624_083150(7).jpg\n",
      "Showing image 54/299, path: input\\001_20200624_083150(7).jpg\n",
      "Showing image 55/299, path: input\\001_20200624_083153(8).jpg\n",
      "Showing image 55/299, path: input\\001_20200624_083153(8).jpg\n",
      "Showing image 56/299, path: input\\001_20200624_083156(9).jpg\n",
      "Showing image 56/299, path: input\\001_20200624_083156(9).jpg\n",
      "Showing image 57/299, path: input\\001_20200624_083159(6).jpg\n",
      "Showing image 57/299, path: input\\001_20200624_083159(6).jpg\n",
      "Showing image 58/299, path: input\\001_20200624_083202(6).jpg\n",
      "Showing image 58/299, path: input\\001_20200624_083202(6).jpg\n",
      "Showing image 59/299, path: input\\001_20200624_083205(7).jpg\n",
      "Showing image 59/299, path: input\\001_20200624_083205(7).jpg\n",
      "Showing image 60/299, path: input\\001_20200624_123313(4).jpg\n",
      "Showing image 60/299, path: input\\001_20200624_123313(4).jpg\n",
      "Showing image 61/299, path: input\\001_20200624_123317(8).jpg\n",
      "Showing image 61/299, path: input\\001_20200624_123317(8).jpg\n",
      "Showing image 62/299, path: input\\001_20200624_123322(3).jpg\n",
      "Showing image 62/299, path: input\\001_20200624_123322(3).jpg\n",
      "Showing image 63/299, path: input\\001_20200624_123326(6).jpg\n",
      "Showing image 63/299, path: input\\001_20200624_123326(6).jpg\n",
      "Showing image 64/299, path: input\\001_20200624_123331(2).jpg\n",
      "Showing image 64/299, path: input\\001_20200624_123331(2).jpg\n",
      "Showing image 65/299, path: input\\001_20200624_123335(6).jpg\n",
      "Showing image 65/299, path: input\\001_20200624_123335(6).jpg\n",
      "Showing image 66/299, path: input\\001_20200624_162816(3).jpg\n",
      "Showing image 66/299, path: input\\001_20200624_162816(3).jpg\n",
      "Showing image 67/299, path: input\\001_20200624_162821(2).jpg\n",
      "Showing image 67/299, path: input\\001_20200624_162821(2).jpg\n",
      "Showing image 68/299, path: input\\001_20200624_162831(2).jpg\n",
      "Showing image 68/299, path: input\\001_20200624_162831(2).jpg\n",
      "Showing image 69/299, path: input\\001_20200624_162835(8).jpg\n",
      "Showing image 69/299, path: input\\001_20200624_162835(8).jpg\n",
      "Showing image 70/299, path: input\\001_20200624_162846(3).jpg\n",
      "Showing image 70/299, path: input\\001_20200624_162846(3).jpg\n",
      "Showing image 71/299, path: input\\001_20200624_162850(9).jpg\n",
      "Showing image 71/299, path: input\\001_20200624_162850(9).jpg\n",
      "Showing image 72/299, path: input\\001_20200624_203149(7).jpg\n",
      "Showing image 72/299, path: input\\001_20200624_203149(7).jpg\n",
      "Showing image 73/299, path: input\\001_20200624_203154(3).jpg\n",
      "Showing image 73/299, path: input\\001_20200624_203154(3).jpg\n",
      "Showing image 74/299, path: input\\001_20200624_203203(1).jpg\n",
      "Showing image 74/299, path: input\\001_20200624_203203(1).jpg\n",
      "Showing image 75/299, path: input\\001_20200624_203207(8).jpg\n",
      "Showing image 75/299, path: input\\001_20200624_203207(8).jpg\n",
      "Showing image 76/299, path: input\\001_20200624_203212(2).jpg\n",
      "Showing image 76/299, path: input\\001_20200624_203212(2).jpg\n",
      "Showing image 77/299, path: input\\001_20200624_203225(8).jpg\n",
      "Showing image 77/299, path: input\\001_20200624_203225(8).jpg\n",
      "Showing image 78/299, path: input\\001_20200625_003507(0).jpg\n",
      "Showing image 78/299, path: input\\001_20200625_003507(0).jpg\n",
      "Showing image 79/299, path: input\\001_20200625_003511(4).jpg\n",
      "Showing image 79/299, path: input\\001_20200625_003511(4).jpg\n",
      "Showing image 80/299, path: input\\001_20200625_003515(9).jpg\n",
      "Showing image 80/299, path: input\\001_20200625_003515(9).jpg\n",
      "Showing image 81/299, path: input\\001_20200625_003520(4).jpg\n",
      "Showing image 81/299, path: input\\001_20200625_003520(4).jpg\n",
      "Showing image 82/299, path: input\\001_20200625_003524(9).jpg\n",
      "Showing image 82/299, path: input\\001_20200625_003524(9).jpg\n",
      "Showing image 83/299, path: input\\001_20200625_003529(2).jpg\n",
      "Showing image 83/299, path: input\\001_20200625_003529(2).jpg\n",
      "Showing image 84/299, path: input\\001_20200625_043323(7).jpg\n",
      "Showing image 84/299, path: input\\001_20200625_043323(7).jpg\n",
      "Showing image 85/299, path: input\\001_20200625_043328(3).jpg\n",
      "Showing image 85/299, path: input\\001_20200625_043328(3).jpg\n",
      "Showing image 86/299, path: input\\001_20200625_043337(3).jpg\n",
      "Showing image 86/299, path: input\\001_20200625_043337(3).jpg\n",
      "Showing image 87/299, path: input\\001_20200625_043341(7).jpg\n",
      "Showing image 87/299, path: input\\001_20200625_043341(7).jpg\n",
      "Showing image 88/299, path: input\\001_20200625_043346(2).jpg\n",
      "Showing image 88/299, path: input\\001_20200625_043346(2).jpg\n",
      "Showing image 89/299, path: input\\001_20200625_043359(8).jpg\n",
      "Showing image 89/299, path: input\\001_20200625_043359(8).jpg\n",
      "Showing image 90/299, path: input\\001_20200629_082825(1).jpg\n",
      "Showing image 90/299, path: input\\001_20200629_082825(1).jpg\n",
      "Showing image 91/299, path: input\\001_20200629_082828(0).jpg\n",
      "Showing image 91/299, path: input\\001_20200629_082828(0).jpg\n",
      "Showing image 92/299, path: input\\001_20200629_082831(0).jpg\n",
      "Showing image 92/299, path: input\\001_20200629_082831(0).jpg\n",
      "Showing image 93/299, path: input\\001_20200629_082834(2).jpg\n",
      "Showing image 93/299, path: input\\001_20200629_082834(2).jpg\n",
      "Showing image 94/299, path: input\\001_20200629_082837(2).jpg\n",
      "Showing image 94/299, path: input\\001_20200629_082837(2).jpg\n",
      "Showing image 95/299, path: input\\001_20200629_082840(2).jpg\n",
      "Showing image 95/299, path: input\\001_20200629_082840(2).jpg\n",
      "Showing image 96/299, path: input\\001_20200629_082905(4).jpg\n",
      "Showing image 96/299, path: input\\001_20200629_082905(4).jpg\n",
      "Showing image 97/299, path: input\\001_20200629_123107(1).jpg\n",
      "Showing image 97/299, path: input\\001_20200629_123107(1).jpg\n",
      "Showing image 98/299, path: input\\001_20200629_123111(6).jpg\n",
      "Showing image 98/299, path: input\\001_20200629_123111(6).jpg\n",
      "Showing image 99/299, path: input\\001_20200629_123116(1).jpg\n",
      "Showing image 99/299, path: input\\001_20200629_123116(1).jpg\n",
      "Showing image 100/299, path: input\\002_20200622_203136(3).bmp\n",
      "Showing image 100/299, path: input\\002_20200622_203136(3).bmp\n",
      "Showing image 101/299, path: input\\002_20200622_203140(8).bmp\n",
      "Showing image 101/299, path: input\\002_20200622_203140(8).bmp\n",
      "Showing image 102/299, path: input\\002_20200622_203145(3).bmp\n",
      "Showing image 102/299, path: input\\002_20200622_203145(3).bmp\n",
      "Showing image 103/299, path: input\\002_20200622_203149(8).bmp\n",
      "Showing image 103/299, path: input\\002_20200622_203149(8).bmp\n",
      "Showing image 104/299, path: input\\002_20200622_203154(3).bmp\n",
      "Showing image 104/299, path: input\\002_20200622_203154(3).bmp\n",
      "Showing image 105/299, path: input\\002_20200622_203158(8).bmp\n",
      "Showing image 105/299, path: input\\002_20200622_203158(8).bmp\n",
      "Showing image 106/299, path: input\\002_20200623_003351(2).bmp\n",
      "Showing image 106/299, path: input\\002_20200623_003351(2).bmp\n",
      "Showing image 107/299, path: input\\002_20200623_003355(7).bmp\n",
      "Showing image 107/299, path: input\\002_20200623_003355(7).bmp\n",
      "Showing image 108/299, path: input\\002_20200623_003400(2).bmp\n",
      "Showing image 108/299, path: input\\002_20200623_003400(2).bmp\n",
      "Showing image 109/299, path: input\\002_20200623_003404(7).bmp\n",
      "Showing image 109/299, path: input\\002_20200623_003404(7).bmp\n",
      "Showing image 110/299, path: input\\002_20200623_003409(2).bmp\n",
      "Showing image 110/299, path: input\\002_20200623_003409(2).bmp\n",
      "Showing image 111/299, path: input\\002_20200623_003413(7).bmp\n",
      "Showing image 111/299, path: input\\002_20200623_003413(7).bmp\n",
      "Showing image 112/299, path: input\\002_20200623_043056(0).bmp\n",
      "Showing image 112/299, path: input\\002_20200623_043056(0).bmp\n",
      "Showing image 113/299, path: input\\002_20200623_043100(6).bmp\n",
      "Showing image 113/299, path: input\\002_20200623_043100(6).bmp\n",
      "Showing image 114/299, path: input\\002_20200623_043105(0).bmp\n",
      "Showing image 114/299, path: input\\002_20200623_043105(0).bmp\n",
      "Showing image 115/299, path: input\\002_20200623_043109(4).bmp\n",
      "Showing image 115/299, path: input\\002_20200623_043109(4).bmp\n",
      "Showing image 116/299, path: input\\002_20200623_043115(4).bmp\n",
      "Showing image 116/299, path: input\\002_20200623_043115(4).bmp\n",
      "Showing image 117/299, path: input\\002_20200623_043120(0).bmp\n",
      "Showing image 117/299, path: input\\002_20200623_043120(0).bmp\n",
      "Showing image 118/299, path: input\\002_20200623_082249(3).bmp\n",
      "Showing image 118/299, path: input\\002_20200623_082249(3).bmp\n",
      "Showing image 119/299, path: input\\002_20200623_082253(8).bmp\n",
      "Showing image 119/299, path: input\\002_20200623_082253(8).bmp\n",
      "Showing image 120/299, path: input\\002_20200623_082258(4).bmp\n",
      "Showing image 120/299, path: input\\002_20200623_082258(4).bmp\n",
      "Showing image 121/299, path: input\\002_20200623_082302(7).bmp\n",
      "Showing image 121/299, path: input\\002_20200623_082302(7).bmp\n",
      "Showing image 122/299, path: input\\002_20200623_082307(2).bmp\n",
      "Showing image 122/299, path: input\\002_20200623_082307(2).bmp\n",
      "Showing image 123/299, path: input\\002_20200623_082311(8).bmp\n",
      "Showing image 123/299, path: input\\002_20200623_082311(8).bmp\n",
      "Showing image 124/299, path: input\\002_20200623_123042(0).bmp\n",
      "Showing image 124/299, path: input\\002_20200623_123042(0).bmp\n",
      "Showing image 125/299, path: input\\002_20200623_123046(4).bmp\n",
      "Showing image 125/299, path: input\\002_20200623_123046(4).bmp\n",
      "Showing image 126/299, path: input\\002_20200623_123051(1).bmp\n",
      "Showing image 126/299, path: input\\002_20200623_123051(1).bmp\n",
      "Showing image 127/299, path: input\\002_20200623_123055(5).bmp\n",
      "Showing image 127/299, path: input\\002_20200623_123055(5).bmp\n",
      "Showing image 128/299, path: input\\002_20200623_123100(0).bmp\n",
      "Showing image 128/299, path: input\\002_20200623_123100(0).bmp\n",
      "Showing image 129/299, path: input\\002_20200623_123104(5).bmp\n",
      "Showing image 129/299, path: input\\002_20200623_123104(5).bmp\n",
      "Showing image 130/299, path: input\\002_20200623_163020(3).bmp\n",
      "Showing image 130/299, path: input\\002_20200623_163020(3).bmp\n",
      "Showing image 131/299, path: input\\002_20200623_163023(3).bmp\n",
      "Showing image 131/299, path: input\\002_20200623_163023(3).bmp\n",
      "Showing image 132/299, path: input\\002_20200623_163026(3).bmp\n",
      "Showing image 132/299, path: input\\002_20200623_163026(3).bmp\n",
      "Showing image 133/299, path: input\\002_20200623_163029(6).bmp\n",
      "Showing image 133/299, path: input\\002_20200623_163029(6).bmp\n",
      "Showing image 134/299, path: input\\002_20200623_163032(5).bmp\n",
      "Showing image 134/299, path: input\\002_20200623_163032(5).bmp\n",
      "Showing image 135/299, path: input\\002_20200623_163035(5).bmp\n",
      "Showing image 135/299, path: input\\002_20200623_163035(5).bmp\n",
      "Showing image 136/299, path: input\\002_20200623_203033(6).bmp\n",
      "Showing image 136/299, path: input\\002_20200623_203033(6).bmp\n",
      "Showing image 137/299, path: input\\002_20200623_203038(0).bmp\n",
      "Showing image 137/299, path: input\\002_20200623_203038(0).bmp\n",
      "Showing image 138/299, path: input\\002_20200623_203042(5).bmp\n",
      "Showing image 138/299, path: input\\002_20200623_203042(5).bmp\n",
      "Showing image 139/299, path: input\\002_20200623_203047(0).bmp\n",
      "Showing image 139/299, path: input\\002_20200623_203047(0).bmp\n",
      "Showing image 140/299, path: input\\002_20200623_203050(0).bmp\n",
      "Showing image 140/299, path: input\\002_20200623_203050(0).bmp\n",
      "Showing image 141/299, path: input\\002_20200623_203054(6).bmp\n",
      "Showing image 141/299, path: input\\002_20200623_203054(6).bmp\n",
      "Showing image 142/299, path: input\\002_20200624_003115(6).bmp\n",
      "Showing image 142/299, path: input\\002_20200624_003115(6).bmp\n",
      "Showing image 143/299, path: input\\002_20200624_003118(6).bmp\n",
      "Showing image 143/299, path: input\\002_20200624_003118(6).bmp\n",
      "Showing image 144/299, path: input\\002_20200624_003123(0).bmp\n",
      "Showing image 144/299, path: input\\002_20200624_003123(0).bmp\n",
      "Showing image 145/299, path: input\\002_20200624_003127(5).bmp\n",
      "Showing image 145/299, path: input\\002_20200624_003127(5).bmp\n",
      "Showing image 146/299, path: input\\002_20200624_003132(0).bmp\n",
      "Showing image 146/299, path: input\\002_20200624_003132(0).bmp\n",
      "Showing image 147/299, path: input\\002_20200624_003136(5).bmp\n",
      "Showing image 147/299, path: input\\002_20200624_003136(5).bmp\n",
      "Showing image 148/299, path: input\\002_20200624_043136(9).bmp\n",
      "Showing image 148/299, path: input\\002_20200624_043136(9).bmp\n",
      "Showing image 149/299, path: input\\002_20200624_043141(4).bmp\n",
      "Showing image 149/299, path: input\\002_20200624_043141(4).bmp\n",
      "Showing image 150/299, path: input\\002_20200624_043145(8).bmp\n",
      "Showing image 150/299, path: input\\002_20200624_043145(8).bmp\n",
      "Showing image 151/299, path: input\\002_20200624_043150(3).bmp\n",
      "Showing image 151/299, path: input\\002_20200624_043150(3).bmp\n",
      "Showing image 152/299, path: input\\002_20200624_043154(8).bmp\n",
      "Showing image 152/299, path: input\\002_20200624_043154(8).bmp\n",
      "Showing image 153/299, path: input\\002_20200624_043159(4).bmp\n",
      "Showing image 153/299, path: input\\002_20200624_043159(4).bmp\n",
      "Showing image 154/299, path: input\\002_20200624_083032(4).bmp\n",
      "Showing image 154/299, path: input\\002_20200624_083032(4).bmp\n",
      "Showing image 155/299, path: input\\002_20200624_083036(9).bmp\n",
      "Showing image 155/299, path: input\\002_20200624_083036(9).bmp\n",
      "Showing image 156/299, path: input\\002_20200624_083041(3).bmp\n",
      "Showing image 156/299, path: input\\002_20200624_083041(3).bmp\n",
      "Showing image 157/299, path: input\\002_20200624_083045(8).bmp\n",
      "Showing image 157/299, path: input\\002_20200624_083045(8).bmp\n",
      "Showing image 158/299, path: input\\002_20200624_083050(4).bmp\n",
      "Showing image 158/299, path: input\\002_20200624_083050(4).bmp\n",
      "Showing image 159/299, path: input\\002_20200624_083054(9).bmp\n",
      "Showing image 159/299, path: input\\002_20200624_083054(9).bmp\n",
      "Showing image 160/299, path: input\\002_20200624_123144(0).bmp\n",
      "Showing image 160/299, path: input\\002_20200624_123144(0).bmp\n",
      "Showing image 161/299, path: input\\002_20200624_123148(2).bmp\n",
      "Showing image 161/299, path: input\\002_20200624_123148(2).bmp\n",
      "Showing image 162/299, path: input\\002_20200624_123152(7).bmp\n",
      "Showing image 162/299, path: input\\002_20200624_123152(7).bmp\n",
      "Showing image 163/299, path: input\\002_20200624_123157(4).bmp\n",
      "Showing image 163/299, path: input\\002_20200624_123157(4).bmp\n",
      "Showing image 164/299, path: input\\002_20200624_123201(7).bmp\n",
      "Showing image 164/299, path: input\\002_20200624_123201(7).bmp\n",
      "Showing image 165/299, path: input\\002_20200624_123206(2).bmp\n",
      "Showing image 165/299, path: input\\002_20200624_123206(2).bmp\n",
      "Showing image 166/299, path: input\\002_20200624_162708(9).bmp\n",
      "Showing image 166/299, path: input\\002_20200624_162708(9).bmp\n",
      "Showing image 167/299, path: input\\002_20200624_162713(4).bmp\n",
      "Showing image 167/299, path: input\\002_20200624_162713(4).bmp\n",
      "Showing image 168/299, path: input\\002_20200624_162717(9).bmp\n",
      "Showing image 168/299, path: input\\002_20200624_162717(9).bmp\n",
      "Showing image 169/299, path: input\\002_20200624_162722(4).bmp\n",
      "Showing image 169/299, path: input\\002_20200624_162722(4).bmp\n",
      "Showing image 170/299, path: input\\002_20200624_162726(9).bmp\n",
      "Showing image 170/299, path: input\\002_20200624_162726(9).bmp\n",
      "Showing image 171/299, path: input\\002_20200624_162737(5).bmp\n",
      "Showing image 171/299, path: input\\002_20200624_162737(5).bmp\n",
      "Showing image 172/299, path: input\\002_20200624_203111(4).bmp\n",
      "Showing image 172/299, path: input\\002_20200624_203111(4).bmp\n",
      "Showing image 173/299, path: input\\002_20200624_203114(3).bmp\n",
      "Showing image 173/299, path: input\\002_20200624_203114(3).bmp\n",
      "Showing image 174/299, path: input\\002_20200624_203117(3).bmp\n",
      "Showing image 174/299, path: input\\002_20200624_203117(3).bmp\n",
      "Showing image 175/299, path: input\\002_20200624_203120(3).bmp\n",
      "Showing image 175/299, path: input\\002_20200624_203120(3).bmp\n",
      "Showing image 176/299, path: input\\002_20200624_203123(3).bmp\n",
      "Showing image 176/299, path: input\\002_20200624_203123(3).bmp\n",
      "Showing image 177/299, path: input\\002_20200624_203126(3).bmp\n",
      "Showing image 177/299, path: input\\002_20200624_203126(3).bmp\n",
      "Showing image 178/299, path: input\\002_20200625_003352(9).bmp\n",
      "Showing image 178/299, path: input\\002_20200625_003352(9).bmp\n",
      "Showing image 179/299, path: input\\002_20200625_003357(4).bmp\n",
      "Showing image 179/299, path: input\\002_20200625_003357(4).bmp\n",
      "Showing image 180/299, path: input\\002_20200625_003401(8).bmp\n",
      "Showing image 180/299, path: input\\002_20200625_003401(8).bmp\n",
      "Showing image 181/299, path: input\\002_20200625_003406(3).bmp\n",
      "Showing image 181/299, path: input\\002_20200625_003406(3).bmp\n",
      "Showing image 182/299, path: input\\002_20200625_003410(8).bmp\n",
      "Showing image 182/299, path: input\\002_20200625_003410(8).bmp\n",
      "Showing image 183/299, path: input\\002_20200625_003415(4).bmp\n",
      "Showing image 183/299, path: input\\002_20200625_003415(4).bmp\n",
      "Showing image 184/299, path: input\\002_20200629_082823(5).bmp\n",
      "Showing image 184/299, path: input\\002_20200629_082823(5).bmp\n",
      "Showing image 185/299, path: input\\002_20200629_082828(5).bmp\n",
      "Showing image 185/299, path: input\\002_20200629_082828(5).bmp\n",
      "Showing image 186/299, path: input\\002_20200629_082831(3).bmp\n",
      "Showing image 186/299, path: input\\002_20200629_082831(3).bmp\n",
      "Showing image 187/299, path: input\\002_20200629_082834(2).bmp\n",
      "Showing image 187/299, path: input\\002_20200629_082834(2).bmp\n",
      "Showing image 188/299, path: input\\002_20200629_082837(0).bmp\n",
      "Showing image 188/299, path: input\\002_20200629_082837(0).bmp\n",
      "Showing image 189/299, path: input\\002_20200629_082839(9).bmp\n",
      "Showing image 189/299, path: input\\002_20200629_082839(9).bmp\n",
      "Showing image 190/299, path: input\\002_20200629_123442(5).bmp\n",
      "Showing image 190/299, path: input\\002_20200629_123442(5).bmp\n",
      "Showing image 191/299, path: input\\002_20200629_123447(0).bmp\n",
      "Showing image 191/299, path: input\\002_20200629_123447(0).bmp\n",
      "Showing image 192/299, path: input\\002_20200629_123451(5).bmp\n",
      "Showing image 192/299, path: input\\002_20200629_123451(5).bmp\n",
      "Showing image 193/299, path: input\\002_20200629_123456(0).bmp\n",
      "Showing image 193/299, path: input\\002_20200629_123456(0).bmp\n",
      "Showing image 194/299, path: input\\002_20200629_123500(5).bmp\n",
      "Showing image 194/299, path: input\\002_20200629_123500(5).bmp\n",
      "Showing image 195/299, path: input\\002_20200629_123505(0).bmp\n",
      "Showing image 195/299, path: input\\002_20200629_123505(0).bmp\n",
      "Showing image 196/299, path: input\\002_20200629_163656(7).bmp\n",
      "Showing image 196/299, path: input\\002_20200629_163656(7).bmp\n",
      "Showing image 197/299, path: input\\002_20200629_163659(7).bmp\n",
      "Showing image 197/299, path: input\\002_20200629_163659(7).bmp\n",
      "Showing image 198/299, path: input\\002_20200629_163702(8).bmp\n",
      "Showing image 198/299, path: input\\002_20200629_163702(8).bmp\n",
      "Showing image 199/299, path: input\\002_20200629_163705(8).bmp\n",
      "Showing image 199/299, path: input\\002_20200629_163705(8).bmp\n",
      "Showing image 200/299, path: input\\002_20200629_163708(9).bmp\n",
      "Showing image 200/299, path: input\\002_20200629_163708(9).bmp\n",
      "Showing image 201/299, path: input\\002_20200629_163711(8).bmp\n",
      "Showing image 201/299, path: input\\002_20200629_163711(8).bmp\n",
      "Showing image 202/299, path: input\\002_20200629_202727(4).bmp\n",
      "Showing image 202/299, path: input\\002_20200629_202727(4).bmp\n",
      "Showing image 203/299, path: input\\002_20200629_202731(9).bmp\n",
      "Showing image 203/299, path: input\\002_20200629_202731(9).bmp\n",
      "Showing image 204/299, path: input\\002_20200629_202736(4).bmp\n",
      "Showing image 204/299, path: input\\002_20200629_202736(4).bmp\n",
      "Showing image 205/299, path: input\\002_20200629_202741(1).bmp\n",
      "Showing image 205/299, path: input\\002_20200629_202741(1).bmp\n",
      "Showing image 206/299, path: input\\002_20200629_202745(5).bmp\n",
      "Showing image 206/299, path: input\\002_20200629_202745(5).bmp\n",
      "Showing image 207/299, path: input\\002_20200629_202750(0).bmp\n",
      "Showing image 207/299, path: input\\002_20200629_202750(0).bmp\n",
      "Showing image 208/299, path: input\\002_20200630_002937(6).bmp\n",
      "Showing image 208/299, path: input\\002_20200630_002937(6).bmp\n",
      "Showing image 209/299, path: input\\002_20200630_002942(1).bmp\n",
      "Showing image 209/299, path: input\\002_20200630_002942(1).bmp\n",
      "Showing image 210/299, path: input\\002_20200630_002946(4).bmp\n",
      "Showing image 210/299, path: input\\002_20200630_002946(4).bmp\n",
      "Showing image 211/299, path: input\\002_20200630_002951(2).bmp\n",
      "Showing image 211/299, path: input\\002_20200630_002951(2).bmp\n",
      "Showing image 212/299, path: input\\002_20200630_002955(6).bmp\n",
      "Showing image 212/299, path: input\\002_20200630_002955(6).bmp\n",
      "Showing image 213/299, path: input\\002_20200630_003000(0).bmp\n",
      "Showing image 213/299, path: input\\002_20200630_003000(0).bmp\n",
      "Showing image 214/299, path: input\\002_20200630_043222(4).bmp\n",
      "Showing image 214/299, path: input\\002_20200630_043222(4).bmp\n",
      "Showing image 215/299, path: input\\002_20200630_043226(7).bmp\n",
      "Showing image 215/299, path: input\\002_20200630_043226(7).bmp\n",
      "Showing image 216/299, path: input\\002_20200630_043231(3).bmp\n",
      "Showing image 216/299, path: input\\002_20200630_043231(3).bmp\n",
      "Showing image 217/299, path: input\\002_20200630_043235(6).bmp\n",
      "Showing image 217/299, path: input\\002_20200630_043235(6).bmp\n",
      "Showing image 218/299, path: input\\002_20200630_043240(2).bmp\n",
      "Showing image 218/299, path: input\\002_20200630_043240(2).bmp\n",
      "Showing image 219/299, path: input\\002_20200630_043244(6).bmp\n",
      "Showing image 219/299, path: input\\002_20200630_043244(6).bmp\n",
      "Showing image 220/299, path: input\\002_20200630_083221(8).bmp\n",
      "Showing image 220/299, path: input\\002_20200630_083221(8).bmp\n",
      "Showing image 221/299, path: input\\002_20200630_083224(8).bmp\n",
      "Showing image 221/299, path: input\\002_20200630_083224(8).bmp\n",
      "Showing image 222/299, path: input\\002_20200630_083227(8).bmp\n",
      "Showing image 222/299, path: input\\002_20200630_083227(8).bmp\n",
      "Showing image 223/299, path: input\\002_20200630_083230(8).bmp\n",
      "Showing image 223/299, path: input\\002_20200630_083230(8).bmp\n",
      "Showing image 224/299, path: input\\002_20200630_083233(8).bmp\n",
      "Showing image 224/299, path: input\\002_20200630_083233(8).bmp\n",
      "Showing image 225/299, path: input\\002_20200630_083236(8).bmp\n",
      "Showing image 225/299, path: input\\002_20200630_083236(8).bmp\n",
      "Showing image 226/299, path: input\\002_20200630_123159(3).bmp\n",
      "Showing image 226/299, path: input\\002_20200630_123159(3).bmp\n",
      "Showing image 227/299, path: input\\002_20200630_123203(6).bmp\n",
      "Showing image 227/299, path: input\\002_20200630_123203(6).bmp\n",
      "Showing image 228/299, path: input\\002_20200630_123232(0).bmp\n",
      "Showing image 228/299, path: input\\002_20200630_123232(0).bmp\n",
      "Showing image 229/299, path: input\\002_20200630_123235(0).bmp\n",
      "Showing image 229/299, path: input\\002_20200630_123235(0).bmp\n",
      "Showing image 230/299, path: input\\002_20200630_123238(0).bmp\n",
      "Showing image 230/299, path: input\\002_20200630_123238(0).bmp\n",
      "Showing image 231/299, path: input\\002_20200630_123241(0).bmp\n",
      "Showing image 231/299, path: input\\002_20200630_123241(0).bmp\n",
      "Showing image 232/299, path: input\\002_20200630_163105(7).bmp\n",
      "Showing image 232/299, path: input\\002_20200630_163105(7).bmp\n",
      "Showing image 233/299, path: input\\002_20200630_163108(9).bmp\n",
      "Showing image 233/299, path: input\\002_20200630_163108(9).bmp\n",
      "Showing image 234/299, path: input\\002_20200630_163112(5).bmp\n",
      "Showing image 234/299, path: input\\002_20200630_163112(5).bmp\n",
      "Showing image 235/299, path: input\\002_20200630_163116(0).bmp\n",
      "Showing image 235/299, path: input\\002_20200630_163116(0).bmp\n",
      "Showing image 236/299, path: input\\002_20200630_163119(5).bmp\n",
      "Showing image 236/299, path: input\\002_20200630_163119(5).bmp\n",
      "Showing image 237/299, path: input\\002_20200630_163122(8).bmp\n",
      "Showing image 237/299, path: input\\002_20200630_163122(8).bmp\n",
      "Showing image 238/299, path: input\\002_20200630_203013(9).bmp\n",
      "Showing image 238/299, path: input\\002_20200630_203013(9).bmp\n",
      "Showing image 239/299, path: input\\002_20200630_203018(4).bmp\n",
      "Showing image 239/299, path: input\\002_20200630_203018(4).bmp\n",
      "Showing image 240/299, path: input\\002_20200630_203022(9).bmp\n",
      "Showing image 240/299, path: input\\002_20200630_203022(9).bmp\n",
      "Showing image 241/299, path: input\\002_20200630_203027(4).bmp\n",
      "Showing image 241/299, path: input\\002_20200630_203027(4).bmp\n",
      "Showing image 242/299, path: input\\002_20200630_203031(8).bmp\n",
      "Showing image 242/299, path: input\\002_20200630_203031(8).bmp\n",
      "Showing image 243/299, path: input\\002_20200630_203036(4).bmp\n",
      "Showing image 243/299, path: input\\002_20200630_203036(4).bmp\n",
      "Showing image 244/299, path: input\\002_20200701_004107(2).bmp\n",
      "Showing image 244/299, path: input\\002_20200701_004107(2).bmp\n",
      "Showing image 245/299, path: input\\002_20200701_004111(5).bmp\n",
      "Showing image 245/299, path: input\\002_20200701_004111(5).bmp\n",
      "Showing image 246/299, path: input\\002_20200701_004116(1).bmp\n",
      "Showing image 246/299, path: input\\002_20200701_004116(1).bmp\n",
      "Showing image 247/299, path: input\\002_20200701_004120(5).bmp\n",
      "Showing image 247/299, path: input\\002_20200701_004120(5).bmp\n",
      "Showing image 248/299, path: input\\002_20200701_004125(0).bmp\n",
      "Showing image 248/299, path: input\\002_20200701_004125(0).bmp\n",
      "Showing image 249/299, path: input\\002_20200701_004129(6).bmp\n",
      "Showing image 249/299, path: input\\002_20200701_004129(6).bmp\n",
      "Showing image 250/299, path: input\\002_20200701_043204(8).bmp\n",
      "Showing image 250/299, path: input\\002_20200701_043204(8).bmp\n",
      "Showing image 251/299, path: input\\002_20200701_043209(5).bmp\n",
      "Showing image 251/299, path: input\\002_20200701_043209(5).bmp\n",
      "Showing image 252/299, path: input\\002_20200701_043213(9).bmp\n",
      "Showing image 252/299, path: input\\002_20200701_043213(9).bmp\n",
      "Showing image 253/299, path: input\\002_20200701_043218(4).bmp\n",
      "Showing image 253/299, path: input\\002_20200701_043218(4).bmp\n",
      "Showing image 254/299, path: input\\002_20200701_043222(8).bmp\n",
      "Showing image 254/299, path: input\\002_20200701_043222(8).bmp\n",
      "Showing image 255/299, path: input\\002_20200701_043227(2).bmp\n",
      "Showing image 255/299, path: input\\002_20200701_043227(2).bmp\n",
      "Showing image 256/299, path: input\\002_20200701_083102(9).bmp\n",
      "Showing image 256/299, path: input\\002_20200701_083102(9).bmp\n",
      "Showing image 257/299, path: input\\002_20200701_083105(7).bmp\n",
      "Showing image 257/299, path: input\\002_20200701_083105(7).bmp\n",
      "Showing image 258/299, path: input\\002_20200701_083108(8).bmp\n",
      "Showing image 258/299, path: input\\002_20200701_083108(8).bmp\n",
      "Showing image 259/299, path: input\\002_20200701_083111(8).bmp\n",
      "Showing image 259/299, path: input\\002_20200701_083111(8).bmp\n",
      "Showing image 260/299, path: input\\002_20200701_083114(8).bmp\n",
      "Showing image 260/299, path: input\\002_20200701_083114(8).bmp\n",
      "Showing image 261/299, path: input\\002_20200701_083117(8).bmp\n",
      "Showing image 261/299, path: input\\002_20200701_083117(8).bmp\n",
      "Showing image 262/299, path: input\\002_20200701_123502(6).bmp\n",
      "Showing image 262/299, path: input\\002_20200701_123502(6).bmp\n",
      "Showing image 263/299, path: input\\002_20200701_123505(9).bmp\n",
      "Showing image 263/299, path: input\\002_20200701_123505(9).bmp\n",
      "Showing image 264/299, path: input\\002_20200701_123508(7).bmp\n",
      "Showing image 264/299, path: input\\002_20200701_123508(7).bmp\n",
      "Showing image 265/299, path: input\\002_20200701_123511(5).bmp\n",
      "Showing image 265/299, path: input\\002_20200701_123511(5).bmp\n",
      "Showing image 266/299, path: input\\002_20200701_123514(1).bmp\n",
      "Showing image 266/299, path: input\\002_20200701_123514(1).bmp\n",
      "Showing image 267/299, path: input\\002_20200701_123516(7).bmp\n",
      "Showing image 267/299, path: input\\002_20200701_123516(7).bmp\n",
      "Showing image 268/299, path: input\\002_20200701_163100(6).bmp\n",
      "Showing image 268/299, path: input\\002_20200701_163100(6).bmp\n",
      "Showing image 269/299, path: input\\002_20200701_163104(5).bmp\n",
      "Showing image 269/299, path: input\\002_20200701_163104(5).bmp\n",
      "Showing image 270/299, path: input\\002_20200701_163108(4).bmp\n",
      "Showing image 270/299, path: input\\002_20200701_163108(4).bmp\n",
      "Showing image 271/299, path: input\\002_20200701_163112(3).bmp\n",
      "Showing image 271/299, path: input\\002_20200701_163112(3).bmp\n",
      "Showing image 272/299, path: input\\002_20200701_163116(3).bmp\n",
      "Showing image 272/299, path: input\\002_20200701_163116(3).bmp\n",
      "Showing image 273/299, path: input\\002_20200701_163120(4).bmp\n",
      "Showing image 273/299, path: input\\002_20200701_163120(4).bmp\n",
      "Showing image 274/299, path: input\\002_20200701_203449(7).bmp\n",
      "Showing image 274/299, path: input\\002_20200701_203449(7).bmp\n",
      "Showing image 275/299, path: input\\002_20200701_203454(3).bmp\n",
      "Showing image 275/299, path: input\\002_20200701_203454(3).bmp\n",
      "Showing image 276/299, path: input\\002_20200701_203458(5).bmp\n",
      "Showing image 276/299, path: input\\002_20200701_203458(5).bmp\n",
      "Showing image 277/299, path: input\\002_20200701_203503(2).bmp\n",
      "Showing image 277/299, path: input\\002_20200701_203503(2).bmp\n",
      "Showing image 278/299, path: input\\002_20200701_203507(7).bmp\n",
      "Showing image 278/299, path: input\\002_20200701_203507(7).bmp\n",
      "Showing image 279/299, path: input\\002_20200701_203512(1).bmp\n",
      "Showing image 279/299, path: input\\002_20200701_203512(1).bmp\n",
      "Showing image 280/299, path: input\\002_20200702_002959(7).bmp\n",
      "Showing image 280/299, path: input\\002_20200702_002959(7).bmp\n",
      "Showing image 281/299, path: input\\002_20200702_003004(2).bmp\n",
      "Showing image 281/299, path: input\\002_20200702_003004(2).bmp\n",
      "Showing image 282/299, path: input\\002_20200702_003008(7).bmp\n",
      "Showing image 282/299, path: input\\002_20200702_003008(7).bmp\n",
      "Showing image 283/299, path: input\\002_20200702_003011(7).bmp\n",
      "Showing image 283/299, path: input\\002_20200702_003011(7).bmp\n",
      "Showing image 284/299, path: input\\002_20200702_003016(3).bmp\n",
      "Showing image 284/299, path: input\\002_20200702_003016(3).bmp\n",
      "Showing image 285/299, path: input\\002_20200702_003020(8).bmp\n",
      "Showing image 285/299, path: input\\002_20200702_003020(8).bmp\n",
      "Showing image 286/299, path: input\\002_20200702_043936(2).bmp\n",
      "Showing image 286/299, path: input\\002_20200702_043936(2).bmp\n",
      "Showing image 287/299, path: input\\002_20200702_043940(7).bmp\n",
      "Showing image 287/299, path: input\\002_20200702_043940(7).bmp\n",
      "Showing image 288/299, path: input\\002_20200702_043945(1).bmp\n",
      "Showing image 288/299, path: input\\002_20200702_043945(1).bmp\n",
      "Showing image 289/299, path: input\\002_20200702_043949(6).bmp\n",
      "Showing image 289/299, path: input\\002_20200702_043949(6).bmp\n",
      "Showing image 290/299, path: input\\002_20200702_043954(0).bmp\n",
      "Showing image 290/299, path: input\\002_20200702_043954(0).bmp\n",
      "Showing image 291/299, path: input\\002_20200702_043958(5).bmp\n",
      "Showing image 291/299, path: input\\002_20200702_043958(5).bmp\n",
      "Showing image 292/299, path: input\\002_20200706_083210(1).bmp\n",
      "Showing image 292/299, path: input\\002_20200706_083210(1).bmp\n",
      "Showing image 293/299, path: input\\002_20200706_083227(7).bmp\n",
      "Showing image 293/299, path: input\\002_20200706_083227(7).bmp\n",
      "Showing image 294/299, path: input\\002_20200706_083231(8).bmp\n",
      "Showing image 294/299, path: input\\002_20200706_083231(8).bmp\n",
      "Showing image 295/299, path: input\\002_20200706_083234(7).bmp\n",
      "Showing image 295/299, path: input\\002_20200706_083234(7).bmp\n",
      "Showing image 296/299, path: input\\002_20200706_083237(9).bmp\n",
      "Showing image 296/299, path: input\\002_20200706_083237(9).bmp\n",
      "Showing image 297/299, path: input\\002_20200706_083241(0).bmp\n",
      "Showing image 297/299, path: input\\002_20200706_083241(0).bmp\n",
      "Showing image 298/299, path: input\\002_20200706_123239(6).bmp\n",
      "Showing image 298/299, path: input\\002_20200706_123239(6).bmp\n",
      "Showing image 299/299, path: input\\002_20200706_123242(9).bmp\n",
      "Showing image 299/299, path: input\\002_20200706_123242(9).bmp\n"
     ]
    }
   ],
   "source": [
    "!python C:/Users/mit017/Desktop/myproject/XRAY_PROJECT/XrayInspection/dataset/OpenLabeling-master/main/main.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "43247e24",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "C:\\Users\\mit017\\Desktop\\myproject\\XRAY_PROJECT\\XrayInspection\\dataset\\test1\\yolov3\n"
     ]
    }
   ],
   "source": [
    "%cd C:/Users/mit017/Desktop/myproject/XRAY_PROJECT/XrayInspection/dataset/test1/yolov3/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "51e4fc71",
   "metadata": {},
   "outputs": [],
   "source": [
    "image_dir='C:/Users/mit017/Desktop/myproject/XRAY_PROJECT/XrayInspection/dataset/test1/yolov3/images'\n",
    "\n",
    "import random\n",
    "import os\n",
    "import subprocess\n",
    "import sys\n",
    "\n",
    "split_data_set(image_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ab660701",
   "metadata": {},
   "outputs": [],
   "source": [
    "!python train.py --epochs 15 --weights weights/last.pt --batch-size 3 --cfg yolov3-spp.cfg --data custom.data --nosave --device cpu"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8be3a585",
   "metadata": {},
   "outputs": [],
   "source": [
    "!python detect.py --weights weights/last.pt --source images --cfg yolov3-spp.cfg --names classes.names --output result "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "810c6d24",
   "metadata": {},
   "outputs": [],
   "source": [
    "!python test.py --cfg yolov3-spp.cfg --data custom.data --weights weights/last.pt "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "97013d5a",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
